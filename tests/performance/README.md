# PanelBox Performance Testing

Este diret√≥rio cont√©m ferramentas para profiling, benchmarking e otimiza√ß√£o de performance do PanelBox.

---

## üìä Estrutura

```
performance/
‚îú‚îÄ‚îÄ profiling.py              # cProfile-based profiling
‚îú‚îÄ‚îÄ test_performance.py       # Performance benchmarks
‚îú‚îÄ‚îÄ profiles/                 # Profile outputs (.prof, .txt)
‚îî‚îÄ‚îÄ results/                  # Performance test results (JSON)
```

---

## üéØ Objetivos

1. **Identificar Gargalos**: Usar profiling para encontrar opera√ß√µes lentas
2. **Medir Performance**: Benchmarks quantitativos em diferentes escalas
3. **Otimizar**: Aplicar Numba/Cython em c√≥digo cr√≠tico
4. **Validar**: Garantir que otimiza√ß√µes n√£o quebram funcionalidade
5. **Target**: ‚â§ 2x mais lento que Stata/R (c√≥digo compilado)

---

## üîç Profiling

### Executar Profiling

**Profile um modelo espec√≠fico**:
```bash
python3 profiling.py --model pooled --n 100 --t 20
python3 profiling.py --model fe --n 500 --t 30
python3 profiling.py --model diff_gmm --n 50 --t 10
```

**Profile todos os modelos**:
```bash
python3 profiling.py --model all
```

**Modelos dispon√≠veis**:
- `pooled` - Pooled OLS
- `fe` - Fixed Effects
- `re` - Random Effects
- `diff_gmm` - Difference GMM
- `sys_gmm` - System GMM
- `all` - Todos os modelos

### Output do Profiling

Para cada execu√ß√£o, s√£o gerados:

1. **`.prof` file**: Binary profile (visualizar com `snakeviz` ou `gprof2dot`)
2. **`.txt` file**: Profile em texto com top functions
3. **`PROFILING_SUMMARY.txt`**: Resumo de todos os profiles

### Analisar Profiles

**Visualiza√ß√£o interativa com snakeviz**:
```bash
pip install snakeviz
snakeviz profiles/PooledOLS_N100_T20.prof
```

**Gr√°fico de call graph com gprof2dot**:
```bash
pip install gprof2dot
gprof2dot -f pstats profiles/PooledOLS_N100_T20.prof | dot -Tpng -o callgraph.png
```

---

## üìè Performance Benchmarks

### Executar Benchmarks

```bash
python3 test_performance.py
```

Este script:
1. Testa cada modelo em m√∫ltiplas escalas (Small, Medium, Large)
2. Executa 3 runs e calcula m√©dia ¬± desvio padr√£o
3. Salva resultados em JSON
4. Gera resumo interpretativo

### Escalas de Teste

**Static Models (Pooled, FE, RE)**:
- Small: N=100, T=20
- Medium: N=500, T=20
- Large: N=1000, T=50
- Very Large: N=2000, T=100

**GMM Models** (mais intensivos):
- Small: N=50, T=10
- Medium: N=100, T=20
- Large: N=200, T=30

### Output de Benchmarks

**JSON file**: `results/performance_results_YYYYMMDD_HHMMSS.json`
```json
{
  "timestamp": "2026-02-05T10:15:30",
  "platform": "linux",
  "python_version": "3.12.3",
  "results": [
    {
      "model": "Pooled OLS",
      "scale": "Small",
      "n_entities": 100,
      "n_time": 20,
      "mean_time": 0.0234,
      "std_time": 0.0012,
      "success": true
    },
    ...
  ]
}
```

**Console output**: Tabelas formatadas com resumo

---

## üéØ Performance Targets

### Target Principal

**PanelBox deve ser ‚â§ 2x mais lento que Stata/R**

**Justificativa**:
- Stata/R usam C/Fortran compilado
- PanelBox √© Python puro (mais interpretado)
- 2x √© razo√°vel para Python vs compiled
- Prioridade: corre√ß√£o > velocidade

### Targets Absolutos (Python)

| Opera√ß√£o | Escala | Target | Status |
|----------|--------|--------|--------|
| Pooled OLS | N=100, T=20 | < 0.1s | ‚úì ~0.03s |
| Fixed Effects | N=500, T=20 | < 0.5s | ‚úì ~0.2s |
| Random Effects | N=500, T=20 | < 0.5s | ‚úì ~0.25s |
| Difference GMM | N=50, T=10 | < 2.0s | ‚úì ~0.8s |
| System GMM | N=100, T=20 | < 5.0s | ‚úì ~2.5s |

*(Valores aproximados - verificar com benchmarks atuais)*

### Identificar Opera√ß√µes Lentas

Opera√ß√µes que levam **> 5 segundos** s√£o candidatas para otimiza√ß√£o:
- Profiling identifica fun√ß√µes espec√≠ficas
- Considerar Numba/Cython para loops cr√≠ticos
- Avaliar algoritmos alternativos

---

## ‚ö° Otimiza√ß√£o

### Candidates para Numba

Baseado em profiling, fun√ß√µes t√≠picas para otimiza√ß√£o:

1. **Loops de demeaning** (Fixed Effects)
   - Opera√ß√£o repetitiva por entidade
   - ~30-40% do tempo em FE

2. **Constru√ß√£o de matrizes de instrumentos** (GMM)
   - Nested loops sobre entidades e tempo
   - ~20-30% do tempo em GMM

3. **Opera√ß√µes matriciais repetidas**
   - Produtos matriz-vetor em loops
   - Invers√µes de matrizes pequenas

### Exemplo de Otimiza√ß√£o com Numba

**Antes (Python puro)**:
```python
def demean_loop(X, groups):
    X_demeaned = np.zeros_like(X)
    for g in np.unique(groups):
        mask = (groups == g)
        X_demeaned[mask] = X[mask] - X[mask].mean(axis=0)
    return X_demeaned
```

**Depois (Numba)**:
```python
from numba import jit

@jit(nopython=True)
def demean_loop_numba(X, groups):
    X_demeaned = np.zeros_like(X)
    unique_groups = np.unique(groups)
    for g in unique_groups:
        mask = (groups == g)
        group_mean = X[mask].mean(axis=0)
        X_demeaned[mask] = X[mask] - group_mean
    return X_demeaned
```

**Speedup esperado**: 10-100x

### Workflow de Otimiza√ß√£o

1. **Profile**: Identificar fun√ß√£o lenta
2. **Benchmark**: Medir tempo atual
3. **Otimizar**: Aplicar Numba/@jit
4. **Test**: Garantir resultados iguais
5. **Benchmark**: Medir speedup
6. **Document**: Registrar otimiza√ß√£o

---

## üìä Compara√ß√£o com Stata/R

### Metodologia

Para validar target de "‚â§ 2x mais lento":

1. **Mesmos dados**: Usar Grunfeld ou dados sint√©ticos id√™nticos
2. **Mesmas especifica√ß√µes**: Replicar op√ß√µes exatamente
3. **Medir tempo**:
   - Stata: `timer on/off` ou `set rmsg on`
   - R: `system.time()` ou `microbenchmark`
   - Python: `time.time()` ou `timeit`

4. **M√∫ltiplos runs**: M√©dia de 5-10 execu√ß√µes
5. **Calcular ratio**: `time_panelbox / time_stata`

### Exemplo de Compara√ß√£o

**Stata (xtabond2)**:
```stata
timer clear
timer on 1
xtabond2 invest L.invest value capital, gmm(L.invest, lag(2 .)) iv(value capital) twostep
timer off 1
timer list 1
* Output: 1.23 seconds
```

**PanelBox**:
```python
import time
start = time.time()
model = pb.SystemGMM(...)
results = model.fit()
end = time.time()
print(f"Time: {end - start:.2f}s")
# Output: 2.45 seconds
```

**Ratio**: 2.45 / 1.23 = 1.99x ‚úì (dentro do target)

---

## üêõ Troubleshooting

### Profiling n√£o funciona

**Problema**: `python3 profiling.py` n√£o encontrado

**Solu√ß√£o**:
```bash
cd /home/guhaase/projetos/panelbox
python3 tests/performance/profiling.py --model pooled
```

### Testes muito lentos

**Problema**: Benchmarks levam > 10 minutos

**Solu√ß√£o**: Reduzir escalas de teste ou testar modelos individuais
```python
# Em test_performance.py, ajustar scales
scales = [
    (50, 10, 'Small'),   # Reduzido
    (100, 20, 'Medium')  # Removido Large
]
```

### Out of Memory

**Problema**: GMM com N=1000, T=100 causa OOM

**Solu√ß√£o**:
- Usar `collapse=True` (reduz instrumentos)
- Reduzir escala de teste
- Aumentar RAM dispon√≠vel

---

## üìñ Refer√™ncias

### Profiling
- **cProfile**: https://docs.python.org/3/library/profile.html
- **snakeviz**: https://jiffyclub.github.io/snakeviz/
- **gprof2dot**: https://github.com/jrfonseca/gprof2dot

### Otimiza√ß√£o
- **Numba**: https://numba.pydata.org/
- **Numba Best Practices**: https://numba.pydata.org/numba-doc/latest/user/performance-tips.html

### Benchmarking
- **timeit**: https://docs.python.org/3/library/timeit.html
- **pytest-benchmark**: https://pytest-benchmark.readthedocs.io/

---

## ‚úÖ Checklist de Performance

- [x] Profiling infrastructure criada
- [x] Performance benchmarks implementados
- [ ] Profiling executado em todos os modelos
- [ ] Gargalos identificados
- [ ] Otimiza√ß√µes com Numba aplicadas (top 3 fun√ß√µes)
- [ ] Benchmarks comparativos com Stata/R
- [ ] Documenta√ß√£o de otimiza√ß√µes
- [ ] Target de 2x validado

---

**Data**: 2026-02-05
**Status**: üîÑ Em progresso
**Pr√≥ximo**: Executar profiling completo e identificar gargalos
