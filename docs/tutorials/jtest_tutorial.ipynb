{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Davidson-MacKinnon J-Test Tutorial: Comparing Non-Nested Models\n",
    "\n",
    "This tutorial demonstrates how to use the Davidson-MacKinnon J-test to compare non-nested model specifications in panel data.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The J-test is used when you have two competing models that are **not nested** (i.e., neither model is a special case of the other). Common examples include:\n",
    "\n",
    "- Linear vs. log-linear specifications\n",
    "- Different functional forms (Cobb-Douglas vs. Translog production functions)\n",
    "- Different sets of explanatory variables\n",
    "\n",
    "### How the J-Test Works\n",
    "\n",
    "Given two models:\n",
    "- **Model 1**: $y = X_1'\\beta_1 + \\varepsilon_1$\n",
    "- **Model 2**: $y = X_2'\\beta_2 + \\varepsilon_2$\n",
    "\n",
    "The J-test:\n",
    "1. Estimates both models and obtains fitted values $\\hat{y}_1$ and $\\hat{y}_2$\n",
    "2. **Forward test**: Augments Model 1 with $\\hat{y}_2$ and tests if $\\alpha=0$ in:\n",
    "   $$y = X_1'\\beta_1 + \\alpha \\hat{y}_2 + \\varepsilon$$\n",
    "3. **Reverse test**: Augments Model 2 with $\\hat{y}_1$ and tests if $\\gamma=0$ in:\n",
    "   $$y = X_2'\\beta_2 + \\gamma \\hat{y}_1 + \\varepsilon$$\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "| Forward Test | Reverse Test | Interpretation |\n",
    "|--------------|--------------|----------------|\n",
    "| Reject H₀    | Don't reject | Prefer Model 2 |\n",
    "| Don't reject | Reject H₀    | Prefer Model 1 |\n",
    "| Reject both  | Reject both  | Neither model adequate |\n",
    "| Don't reject | Don't reject | Both models acceptable |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panelbox as pb\n",
    "from panelbox.diagnostics.specification import j_test\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Production Function Specification\n",
    "\n",
    "We'll compare two production function specifications:\n",
    "- **Model 1 (Cobb-Douglas)**: $\\log(Y) = \\beta_0 + \\beta_1 \\log(K) + \\beta_2 \\log(L) + \\varepsilon$\n",
    "- **Model 2 (Translog)**: Includes interaction and squared terms\n",
    "\n",
    "### Generate Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate panel data for firms\n",
    "n_firms = 100\n",
    "n_years = 10\n",
    "n_obs = n_firms * n_years\n",
    "\n",
    "# Create panel structure\n",
    "firms = np.repeat(np.arange(n_firms), n_years)\n",
    "years = np.tile(np.arange(n_years), n_firms)\n",
    "\n",
    "# Generate inputs (capital and labor)\n",
    "log_K = np.random.randn(n_obs) + 5  # Log capital\n",
    "log_L = np.random.randn(n_obs) + 4  # Log labor\n",
    "\n",
    "# True DGP: Cobb-Douglas with some nonlinearity\n",
    "log_Y_true = 2.0 + 0.3 * log_K + 0.7 * log_L + 0.05 * log_K * log_L\n",
    "log_Y = log_Y_true + np.random.randn(n_obs) * 0.3\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'firm': firms,\n",
    "    'year': years,\n",
    "    'log_Y': log_Y,\n",
    "    'log_K': log_K,\n",
    "    'log_L': log_L,\n",
    "    'log_K_sq': log_K**2,\n",
    "    'log_L_sq': log_L**2,\n",
    "    'log_K_log_L': log_K * log_L\n",
    "})\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nFirst few observations:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Model 1: Cobb-Douglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Simple Cobb-Douglas\n",
    "model1 = pb.PooledOLS(\n",
    "    \"log_Y ~ log_K + log_L\",\n",
    "    data=df,\n",
    "    entity_col='firm',\n",
    "    time_col='year'\n",
    ")\n",
    "result1 = model1.fit(cov_type='clustered')\n",
    "print(\"Model 1: Cobb-Douglas\")\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Model 2: Translog (with Interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Translog with interaction\n",
    "model2 = pb.PooledOLS(\n",
    "    \"log_Y ~ log_K + log_L + log_K_log_L\",\n",
    "    data=df,\n",
    "    entity_col='firm',\n",
    "    time_col='year'\n",
    ")\n",
    "result2 = model2.fit(cov_type='clustered')\n",
    "print(\"Model 2: Translog (with interaction)\")\n",
    "print(result2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform J-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform J-test\n",
    "jtest_result = j_test(result1, result2, direction='both')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Davidson-MacKinnon J-Test Results\")\n",
    "print(\"=\"*70)\n",
    "print(jtest_result.summary())\n",
    "\n",
    "# Show interpretation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "print(jtest_result.interpretation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fitted values\n",
    "fitted1 = result1.predict()\n",
    "fitted2 = result2.predict()\n",
    "\n",
    "# Create comparison plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Actual vs Fitted (Model 1)\n",
    "axes[0].scatter(df['log_Y'], fitted1, alpha=0.5, s=20)\n",
    "axes[0].plot([df['log_Y'].min(), df['log_Y'].max()], \n",
    "             [df['log_Y'].min(), df['log_Y'].max()], \n",
    "             'r--', lw=2, label='45° line')\n",
    "axes[0].set_xlabel('Actual log(Y)')\n",
    "axes[0].set_ylabel('Fitted log(Y)')\n",
    "axes[0].set_title(f'Model 1: Cobb-Douglas\\nR² = {result1.rsquared:.4f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Actual vs Fitted (Model 2)\n",
    "axes[1].scatter(df['log_Y'], fitted2, alpha=0.5, s=20, color='orange')\n",
    "axes[1].plot([df['log_Y'].min(), df['log_Y'].max()], \n",
    "             [df['log_Y'].min(), df['log_Y'].max()], \n",
    "             'r--', lw=2, label='45° line')\n",
    "axes[1].set_xlabel('Actual log(Y)')\n",
    "axes[1].set_ylabel('Fitted log(Y)')\n",
    "axes[1].set_title(f'Model 2: Translog\\nR² = {result2.rsquared:.4f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Linear vs. Log-Linear Specification\n",
    "\n",
    "Compare:\n",
    "- **Model 3 (Linear)**: $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\varepsilon$\n",
    "- **Model 4 (Log-Linear)**: $\\log(Y) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\varepsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new data for this example\n",
    "X1 = np.random.randn(n_obs)\n",
    "X2 = np.random.randn(n_obs)\n",
    "\n",
    "# True DGP: exponential relationship\n",
    "Y_level = np.exp(0.5 + 0.3 * X1 + 0.4 * X2 + np.random.randn(n_obs) * 0.2)\n",
    "log_Y_new = np.log(Y_level)\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'firm': firms,\n",
    "    'year': years,\n",
    "    'Y': Y_level,\n",
    "    'log_Y': log_Y_new,\n",
    "    'X1': X1,\n",
    "    'X2': X2\n",
    "})\n",
    "\n",
    "# Model 3: Linear\n",
    "model3 = pb.PooledOLS(\"Y ~ X1 + X2\", data=df2, entity_col='firm', time_col='year')\n",
    "result3 = model3.fit(cov_type='clustered')\n",
    "\n",
    "# Model 4: Log-linear\n",
    "model4 = pb.PooledOLS(\"log_Y ~ X1 + X2\", data=df2, entity_col='firm', time_col='year')\n",
    "result4 = model4.fit(cov_type='clustered')\n",
    "\n",
    "print(\"Model 3: Linear\")\n",
    "print(result3.summary())\n",
    "print(\"\\nModel 4: Log-Linear\")\n",
    "print(result4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: For J-test, we need models with same dependent variable\n",
    "# We'll use log-transformed fitted values from Model 3\n",
    "print(\"NOTE: When comparing linear vs. log-linear, ensure both models\")\n",
    "print(\"      use the same dependent variable. Here we show the conceptual\")\n",
    "print(\"      approach - in practice, you'd transform predictions appropriately.\")\n",
    "\n",
    "# For illustration, test linear vs. a different linear specification\n",
    "model3b = pb.PooledOLS(\"Y ~ X1\", data=df2, entity_col='firm', time_col='year')\n",
    "result3b = model3b.fit(cov_type='clustered')\n",
    "\n",
    "jtest_result2 = j_test(result3, result3b, direction='both')\n",
    "print(\"\\nJ-Test: Full Model vs. Restricted Model\")\n",
    "print(jtest_result2.summary())\n",
    "print(\"\\nInterpretation:\")\n",
    "print(jtest_result2.interpretation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### When to Use J-Test\n",
    "1. **Non-nested models**: Neither model is a special case of the other\n",
    "2. **Same dependent variable**: Both models must explain the same outcome\n",
    "3. **Theory-driven comparison**: Economic theory suggests multiple specifications\n",
    "\n",
    "### Interpreting Results\n",
    "- **Both reject**: Neither model adequate → consider alternative specifications\n",
    "- **Both don't reject**: Both acceptable → use economic theory, simplicity, or other criteria\n",
    "- **One rejects**: Clear preference for one model\n",
    "\n",
    "### Limitations\n",
    "- Low power with small samples\n",
    "- Can be sensitive to outliers\n",
    "- Should be combined with other model selection criteria (AIC, BIC, economic theory)\n",
    "\n",
    "### Next Steps\n",
    "- Combine with encompassing tests for more robust conclusions\n",
    "- Use cross-validation for out-of-sample performance\n",
    "- Consider economic interpretation and theoretical foundations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
