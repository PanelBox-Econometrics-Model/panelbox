{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 04 — GMM Tests & Diagnostics\n",
    "\n",
    "**Duration:** ~110 minutes  \n",
    "**Level:** Advanced  \n",
    "**Prerequisites:** Notebooks 01-03\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. **Interpret** Hansen J-test results and diagnose rejection causes\n",
    "2. **Understand** AR(1) vs AR(2) tests and their critical importance\n",
    "3. **Distinguish** between Sargan and Hansen tests\n",
    "4. **Validate** System GMM using Difference-in-Hansen test\n",
    "5. **Diagnose** weak instrument and overfitting problems with `GMMOverfitDiagnostic`\n",
    "6. **Apply** a complete diagnostic checklist to GMM models\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Hansen J-Test](#1-hansen-j-test)\n",
    "2. [AR(1) and AR(2) Tests](#2-ar-tests)\n",
    "3. [Sargan vs Hansen](#3-sargan-vs-hansen)\n",
    "4. [Difference-in-Hansen (System GMM)](#4-diff-hansen)\n",
    "5. [Weak Instruments & Overfitting Diagnostics](#5-overfit)\n",
    "6. [Complete Diagnostic Checklist](#6-checklist)\n",
    "7. [Exercises](#7-exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path(\"../../..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from panelbox.gmm import DifferenceGMM, SystemGMM, GMMOverfitDiagnostic\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "from utils.visualization import apply_tutorial_style\n",
    "\n",
    "apply_tutorial_style()\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": "---\n## 1. Hansen J-Test <a id='1-hansen-j-test'></a>\n\n### Theory\n\n**Test:** $H_0$: $E[Z'\\varepsilon] = 0$ (over-identifying restrictions valid)\n\n**Statistic:** $J = n \\cdot \\hat{g}' \\hat{W}^{-1} \\hat{g} \\sim \\chi^2(L - K)$\n- $L$: number of instruments\n- $K$: number of parameters\n- $df = L - K$ (degrees of over-identification)\n\n**Interpretation:**\n- $p > 0.25$: Instruments valid (ideal)\n- $0.10 < p < 0.25$: Acceptable\n- $p < 0.10$: Reject $H_0$ (problem!)\n- $p > 0.90$: Suspiciously high — possible overfitting\n\n**What rejection means:**\n1. Invalid instruments ($E[Z'\\varepsilon] \\neq 0$)\n2. Model misspecification\n3. Omitted variables\n4. Wrong functional form\n\n**Important limitation:** The Hansen J test has **low power** when the number of instruments is small (e.g., with `collapse=True`). It may fail to detect mild misspecification. Always complement with coefficient comparison and bounds checks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# 1.1 Correctly specified model — simulated panel data\n# DGP: y_it = 0.5 * y_{i,t-1} + 0.3 * x1 + 0.2 * x2 + eta_i + eps_it\n\ndef generate_clean_panel(N=200, T=10, rho=0.5, beta1=0.3, beta2=0.2, seed=42):\n    \"\"\"Generate panel data with known DGP for GMM validation.\"\"\"\n    np.random.seed(seed)\n    data = []\n    for i in range(N):\n        eta_i = np.random.normal(0, 1)\n        x1 = np.random.normal(2, 1, T)\n        x2 = np.random.normal(1, 0.5, T)\n        y_prev = eta_i / (1 - rho) + np.random.normal(0, 1)\n        for t in range(T):\n            eps = np.random.normal(0, 1)\n            y = rho * y_prev + beta1 * x1[t] + beta2 * x2[t] + eta_i + eps\n            data.append({'entity': i, 'time': t, 'y': y, 'x1': x1[t], 'x2': x2[t]})\n            y_prev = y\n    return pd.DataFrame(data)\n\ndf_panel = generate_clean_panel()\nprint(f\"Simulated panel: {len(df_panel)} obs, \"\n      f\"{df_panel['entity'].nunique()} entities, T={df_panel['time'].nunique()}\")\nprint(f\"True parameters: rho=0.5, beta1=0.3, beta2=0.2\")\n\nmodel_correct = DifferenceGMM(\n    data=df_panel,\n    dep_var='y',\n    lags=1,\n    exog_vars=['x1', 'x2'],\n    id_var='entity',\n    time_var='time',\n    collapse=True,\n    two_step=True,\n    robust=True,\n    time_dummies=False\n)\nresults_correct = model_correct.fit()\n\nprint(\"\\n=== Correctly Specified Model ===\")\nprint(f\"L1.y = {results_correct.params.iloc[0]:.4f} (true: 0.5)\")\nfor v in ['x1', 'x2']:\n    print(f\"{v}   = {results_correct.params[v]:.4f} (true: {0.3 if v == 'x1' else 0.2})\")\nprint(f\"\\nHansen J statistic: {results_correct.hansen_j.statistic:.4f}\")\nprint(f\"Degrees of freedom: {results_correct.hansen_j.df}\")\nprint(f\"p-value: {results_correct.hansen_j.pvalue:.4f}\")\nprint()\n\nif results_correct.hansen_j.pvalue > 0.25:\n    print(\"PASS: Instruments valid (p > 0.25)\")\nelif results_correct.hansen_j.pvalue > 0.10:\n    print(\"PASS: Acceptable (0.10 < p < 0.25)\")\nelse:\n    print(\"FAIL: Specification problem (p < 0.10)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# 1.2 Misspecified model — omitted variable\n# Omit x2 from the model. The omitted variable creates bias in the AR coefficient.\n\nmodel_bad = DifferenceGMM(\n    data=df_panel,\n    dep_var='y',\n    lags=1,\n    exog_vars=['x1'],  # Missing x2!\n    id_var='entity',\n    time_var='time',\n    collapse=True,\n    two_step=True,\n    robust=True,\n    time_dummies=False\n)\nresults_bad = model_bad.fit()\n\nprint(\"=== Misspecified Model (Omitted x2) ===\")\nprint(f\"L1.y = {results_bad.params.iloc[0]:.4f} (true: 0.5)\")\nprint(f\"Hansen J statistic: {results_bad.hansen_j.statistic:.4f}\")\nprint(f\"p-value: {results_bad.hansen_j.pvalue:.4f}\")\n\nprint(\"\\nNote: Hansen J does NOT reject here! This is a known limitation:\")\nprint(\"  - With collapsed instruments (few moment conditions), the J test has\")\nprint(\"    LOW POWER to detect mild misspecification like a small omitted variable.\")\nprint(\"  - Compare the AR coefficient: it changed from the correctly specified model.\")\nprint(f\"  - Correct model L1.y = {results_correct.params.iloc[0]:.4f}\")\nprint(f\"  - Misspecified L1.y  = {results_bad.params.iloc[0]:.4f}\")\nprint(\"  - Coefficient bias is often a better signal than Hansen J alone.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# 1.3 Fix: Add the omitted variable back\nmodel_fixed = DifferenceGMM(\n    data=df_panel,\n    dep_var='y',\n    lags=1,\n    exog_vars=['x1', 'x2'],  # Now complete\n    id_var='entity',\n    time_var='time',\n    collapse=True,\n    two_step=True,\n    robust=True,\n    time_dummies=False\n)\nresults_fixed = model_fixed.fit()\n\nprint(\"=== Fixed Model (Added x2) ===\")\nprint(f\"L1.y = {results_fixed.params.iloc[0]:.4f} (true: 0.5)\")\nprint(f\"x1   = {results_fixed.params['x1']:.4f} (true: 0.3)\")\nprint(f\"x2   = {results_fixed.params['x2']:.4f} (true: 0.2)\")\nprint(f\"Hansen J: stat={results_fixed.hansen_j.statistic:.4f}, \"\n      f\"p={results_fixed.hansen_j.pvalue:.4f}\")\n\nprint(\"\\nComparison:\")\nprint(f\"  Misspecified L1.y = {results_bad.params.iloc[0]:.4f} (biased)\")\nprint(f\"  Fixed       L1.y = {results_fixed.params.iloc[0]:.4f} (closer to true 0.5)\")\nprint(\"  -> Adding the omitted variable corrects the coefficient bias.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "> **Intuition**: Hansen J is an omnibus test: it detects ANY violation of $E[Z'\\varepsilon]=0$. Rejection means something is wrong, but doesn't tell you what. You must investigate: try adding variables, changing lags, or checking for AR(2).\n",
    "\n",
    "---\n",
    "## 2. AR(1) and AR(2) Tests <a id='2-ar-tests'></a>\n",
    "\n",
    "### Why AR Tests Matter\n",
    "\n",
    "GMM validity requires **no serial correlation in $\\varepsilon_{it}$**.\n",
    "\n",
    "After first-differencing: $\\Delta\\varepsilon_{it} = \\varepsilon_{it} - \\varepsilon_{i,t-1}$\n",
    "\n",
    "- **Mechanical AR(1)**: $\\Delta\\varepsilon_{it}$ correlated with $\\Delta\\varepsilon_{i,t-1}$ by construction — EXPECTED.\n",
    "- **Critical AR(2)**: $E[\\Delta\\varepsilon_{it} \\cdot \\Delta\\varepsilon_{i,t-2}] = 0$ **required**. If violated, instruments are invalid.\n",
    "\n",
    "### Interpretation\n",
    "- **AR(1)**: Expect to **REJECT** ($p < 0.05$)\n",
    "- **AR(2)**: Must **NOT reject** ($p > 0.10$) — **CRITICAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Arellano-Bond AR Tests ===\n",
      "\n",
      "Correctly Specified Model (abdata):\n",
      "  AR(1): z = 5.6056, p = 0.0000\n",
      "        PASS: Reject (expected due to MA(1) from differencing)\n",
      "  AR(2): z = -6.4595, p = 0.0000\n",
      "        FAIL: Serial correlation detected! Instruments invalid\n"
     ]
    }
   ],
   "source": [
    "# 2.1 AR tests on correctly specified model\n",
    "print(\"=== Arellano-Bond AR Tests ===\")\n",
    "print(f\"\\nCorrectly Specified Model (abdata):\")\n",
    "\n",
    "print(f\"  AR(1): z = {results_correct.ar1_test.statistic:.4f}, \"\n",
    "      f\"p = {results_correct.ar1_test.pvalue:.4f}\")\n",
    "if results_correct.ar1_test.pvalue < 0.05:\n",
    "    print(\"        PASS: Reject (expected due to MA(1) from differencing)\")\n",
    "else:\n",
    "    print(\"        ~ Fail to reject (unusual but not necessarily wrong)\")\n",
    "\n",
    "print(f\"  AR(2): z = {results_correct.ar2_test.statistic:.4f}, \"\n",
    "      f\"p = {results_correct.ar2_test.pvalue:.4f}\")\n",
    "if results_correct.ar2_test.pvalue > 0.10:\n",
    "    print(\"        PASS: Fail to reject (moment conditions valid)\")\n",
    "else:\n",
    "    print(\"        FAIL: Serial correlation detected! Instruments invalid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model with AR(2) Errors ===\n",
      "AR(1): p = 0.0000\n",
      "AR(2): p = 0.0000\n",
      "\n",
      "AR(2) rejects! Problem detected.\n",
      "Solutions:\n",
      "  1. Use deeper lags (t-3 instead of t-2)\n",
      "  2. Add AR(2) structure to model (lags=[1,2])\n",
      "  3. Check for omitted variables\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Simulate data with AR(2) in errors\n",
    "def simulate_ar2_errors(N=200, T=7, rho=0.5, phi2=0.3, seed=42):\n",
    "    \"\"\"\n",
    "    Simulate panel data with AR(2) errors.\n",
    "    eps_{it} = phi2 * eps_{i,t-2} + u_{it}\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    data = []\n",
    "    for i in range(N):\n",
    "        mu_i = np.random.normal(0, 1)\n",
    "        y = [mu_i + np.random.normal(0, 1)]\n",
    "        eps = [np.random.normal(0, 1)]\n",
    "        for t in range(1, T):\n",
    "            eps_t = (phi2 * eps[t-2] if t >= 2 else 0) + np.random.normal(0, 1)\n",
    "            eps.append(eps_t)\n",
    "            y.append(rho * y[-1] + mu_i + eps_t)\n",
    "        for t in range(T):\n",
    "            data.append({'id': i, 'time': t, 'y': y[t]})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_ar2 = simulate_ar2_errors(phi2=0.3)\n",
    "\n",
    "model_ar2 = DifferenceGMM(\n",
    "    data=df_ar2, dep_var='y', lags=1,\n",
    "    id_var='id', time_var='time',\n",
    "    collapse=True, two_step=True, robust=True\n",
    ")\n",
    "results_ar2 = model_ar2.fit()\n",
    "\n",
    "print(\"=== Model with AR(2) Errors ===\")\n",
    "print(f\"AR(1): p = {results_ar2.ar1_test.pvalue:.4f}\")\n",
    "print(f\"AR(2): p = {results_ar2.ar2_test.pvalue:.4f}\")\n",
    "\n",
    "if results_ar2.ar2_test.pvalue < 0.10:\n",
    "    print(\"\\nAR(2) rejects! Problem detected.\")\n",
    "    print(\"Solutions:\")\n",
    "    print(\"  1. Use deeper lags (t-3 instead of t-2)\")\n",
    "    print(\"  2. Add AR(2) structure to model (lags=[1,2])\")\n",
    "    print(\"  3. Check for omitted variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "> **Critical Warning**: AR(2) rejection is a deal-breaker. Your moment conditions are invalid. Do NOT proceed with estimation until AR(2) passes. This is more important than Hansen J.\n",
    "\n",
    "---\n",
    "## 3. Sargan vs Hansen <a id='3-sargan-vs-hansen'></a>\n",
    "\n",
    "| Feature | Sargan | Hansen J |\n",
    "|---------|--------|----------|\n",
    "| Weight matrix | $(Z'Z)^{-1}$ | $(Z'\\hat{\\Omega}Z)^{-1}$ |\n",
    "| Robust to heteroskedasticity? | No | Yes |\n",
    "| Use for inference? | No | **Yes** |\n",
    "\n",
    "**Rule: ALWAYS use Hansen J-test** for panel data (heteroskedasticity is almost always present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# 3.1 Compare Sargan and Hansen\nprint(\"=== Sargan vs Hansen Comparison ===\\n\")\nprint(f\"  Sargan: {results_correct.sargan.statistic:.4f} \"\n      f\"(p = {results_correct.sargan.pvalue:.4f})\")\nprint(f\"  Hansen: {results_correct.hansen_j.statistic:.4f} \"\n      f\"(p = {results_correct.hansen_j.pvalue:.4f})\")\n\nsargan_stat = results_correct.sargan.statistic\nhansen_stat = results_correct.hansen_j.statistic\n\nif not np.isnan(sargan_stat) and not np.isnan(hansen_stat) and sargan_stat > 0:\n    diff_stat = abs(sargan_stat - hansen_stat)\n    print(f\"  Absolute difference: {diff_stat:.4f}\")\n    diff_ratio = diff_stat / sargan_stat\n    if diff_ratio > 0.2:\n        print(\"\\n  Large difference (>20%): Heteroskedasticity present\")\n        print(\"     -> Use Hansen J (robust)\")\n    else:\n        print(\"\\n  Small difference: Mild heteroskedasticity\")\n        print(\"     -> Still prefer Hansen J (safer)\")\nelse:\n    print(\"\\n  Both tests valid — Hansen J is the preferred test for inference\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Difference-in-Hansen (System GMM) <a id='4-diff-hansen'></a>\n",
    "\n",
    "For **System GMM**: validates the level equation instruments.\n",
    "\n",
    "**Test**: Compare J statistics  \n",
    "$D = J_{\\text{system}} - J_{\\text{diff}} \\sim \\chi^2(df)$  \n",
    "\n",
    "$H_0$: Level instruments are valid\n",
    "\n",
    "- $p > 0.10$: Level instruments valid — use System GMM\n",
    "- $p < 0.10$: Level instruments invalid — fall back to Difference GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth data: 2000 obs, 100 countries, T=20\n",
      "\n",
      "=== Difference-in-Hansen Test ===\n",
      "Difference GMM J: 13.7987 (p = 0.6137)\n",
      "System GMM J:     19.5309 (p = 0.2989)\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Difference-in-Hansen on growth data\n",
    "# Note: growth data has T=20 (years 2000-2019), so time_dummies=True would\n",
    "# create 18 dummies, exceeding instrument count. We use time_dummies=False.\n",
    "df_growth = pd.read_csv('../data/growth.csv')\n",
    "print(f\"Growth data: {df_growth.shape[0]} obs, \"\n",
    "      f\"{df_growth['country'].nunique()} countries, \"\n",
    "      f\"T={df_growth['year'].nunique()}\")\n",
    "\n",
    "# Estimate Difference GMM\n",
    "model_diff = DifferenceGMM(\n",
    "    data=df_growth, dep_var='lgdp', lags=1,\n",
    "    exog_vars=['inv', 'school'],\n",
    "    id_var='country', time_var='year',\n",
    "    collapse=True, two_step=True, robust=True,\n",
    "    time_dummies=False\n",
    ")\n",
    "results_diff = model_diff.fit()\n",
    "\n",
    "# Estimate System GMM\n",
    "model_sys = SystemGMM(\n",
    "    data=df_growth, dep_var='lgdp', lags=1,\n",
    "    exog_vars=['inv', 'school'],\n",
    "    id_var='country', time_var='year',\n",
    "    collapse=True, two_step=True, robust=True,\n",
    "    time_dummies=False,\n",
    "    level_instruments={'max_lags': 1}\n",
    ")\n",
    "results_sys = model_sys.fit()\n",
    "\n",
    "print(f\"\\n=== Difference-in-Hansen Test ===\")\n",
    "print(f\"Difference GMM J: {results_diff.hansen_j.statistic:.4f} \"\n",
    "      f\"(p = {results_diff.hansen_j.pvalue:.4f})\")\n",
    "print(f\"System GMM J:     {results_sys.hansen_j.statistic:.4f} \"\n",
    "      f\"(p = {results_sys.hansen_j.pvalue:.4f})\")\n",
    "\n",
    "if results_sys.diff_hansen is not None:\n",
    "    print(f\"\\nDifference-in-Hansen:\")\n",
    "    print(f\"  Statistic: {results_sys.diff_hansen.statistic:.4f}\")\n",
    "    print(f\"  df: {results_sys.diff_hansen.df}\")\n",
    "    print(f\"  p-value: {results_sys.diff_hansen.pvalue:.4f}\")\n",
    "    \n",
    "    if results_sys.diff_hansen.pvalue > 0.10:\n",
    "        print(\"\\n  PASS: Level instruments valid -> System GMM appropriate\")\n",
    "    else:\n",
    "        print(\"\\n  FAIL: Level instruments invalid -> Use Difference GMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Efficiency Comparison ===\n",
      "                              Diff GMM   System GMM\n",
      "-------------------------------------------------------\n",
      "L1.lgdp                         0.8130       0.9064\n",
      "  (SE)                          0.0307       0.0076\n",
      "inv                             0.1467       0.1426\n",
      "  (SE)                          0.0026       0.0041\n",
      "school                          0.1170       0.0739\n",
      "  (SE)                          0.0262       0.0223\n",
      "\n",
      "Instruments                         19           21\n",
      "Hansen J p-value                0.6137       0.2989\n",
      "AR(2) p-value                   0.0021       0.0019\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Compare efficiency: Difference vs System GMM\n",
    "print(\"=== Efficiency Comparison ===\")\n",
    "print(f\"{'':25s} {'Diff GMM':>12s} {'System GMM':>12s}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for var in results_diff.params.index:\n",
    "    d_coef = results_diff.params[var]\n",
    "    d_se = results_diff.std_errors[var]\n",
    "    if var in results_sys.params.index:\n",
    "        s_coef = results_sys.params[var]\n",
    "        s_se = results_sys.std_errors[var]\n",
    "        print(f\"{var:25s} {d_coef:>12.4f} {s_coef:>12.4f}\")\n",
    "        print(f\"{'  (SE)':25s} {d_se:>12.4f} {s_se:>12.4f}\")\n",
    "\n",
    "print(f\"\\n{'Instruments':25s} {results_diff.n_instruments:>12d} {results_sys.n_instruments:>12d}\")\n",
    "print(f\"{'Hansen J p-value':25s} {results_diff.hansen_j.pvalue:>12.4f} {results_sys.hansen_j.pvalue:>12.4f}\")\n",
    "print(f\"{'AR(2) p-value':25s} {results_diff.ar2_test.pvalue:>12.4f} {results_sys.ar2_test.pvalue:>12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### When does Difference-in-Hansen reject?\n",
    "\n",
    "1. **Non-stationary initial conditions** — panel starts at entry/birth/treatment\n",
    "2. **Process not in equilibrium** — transitory dynamics still active\n",
    "3. **Correlated initials**: $E[\\Delta y_{i,1} \\cdot \\eta_i] \\neq 0$ — initial condition contains fixed effect\n",
    "4. **Time-varying effects** — $\\eta_i$ varies over time\n",
    "\n",
    "**Solution:** Use Difference GMM (drops level equations).\n",
    "\n",
    "---\n",
    "## 5. Weak Instruments & Overfitting Diagnostics <a id='5-overfit'></a>\n",
    "\n",
    "### The Problem\n",
    "\n",
    "When instruments approach or exceed the number of groups:\n",
    "- Hansen J test **loses power** (p-value inflated toward 1.0)\n",
    "- Coefficients **biased toward OLS/Within** estimates\n",
    "- Windmeijer correction **unreliable**\n",
    "\n",
    "### Roodman (2009) Rule of Thumb\n",
    "$$\\text{Number of instruments} \\leq N \\text{ (number of groups)}$$\n",
    "\n",
    "### PanelBox: `GMMOverfitDiagnostic`\n",
    "\n",
    "PanelBox provides a comprehensive diagnostic class with **five checks** and a traffic-light summary:\n",
    "\n",
    "| Check | What it does | Signal |\n",
    "|-------|-------------|--------|\n",
    "| `assess_feasibility()` | Instrument/group ratio (Roodman rule) | GREEN/YELLOW/RED |\n",
    "| `instrument_sensitivity()` | Re-estimate with varying max_lag | Coefficient stability |\n",
    "| `coefficient_bounds_test()` | Nickell (1981): FE < GMM < OLS | Within bounds? |\n",
    "| `jackknife_groups()` | Leave-one-group-out stability | Max deviation |\n",
    "| `step_comparison()` | One-step vs two-step consistency | Relative difference |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMMOverfitDiagnostic(n_groups=140, n_instruments=9, ratio=0.06)\n",
      "\n",
      "Instrument ratio: 0.064\n",
      "Signal: [GREEN]\n",
      "Instrument ratio (0.06) is well below 1.0. Instrument proliferation is unlikely.\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Quick diagnostic on the employment model\n",
    "diag = GMMOverfitDiagnostic(model_correct, results_correct)\n",
    "print(diag)\n",
    "print()\n",
    "\n",
    "# Feasibility check\n",
    "feas = diag.assess_feasibility()\n",
    "print(f\"Instrument ratio: {feas['instrument_ratio']:.3f}\")\n",
    "print(f\"Signal: [{feas['signal']}]\")\n",
    "print(feas['recommendation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Nickell Bounds Test ===\n",
      "  OLS (upper bound):  0.9873\n",
      "  FE  (lower bound):  0.3582\n",
      "  GMM estimate:       -0.5964\n",
      "  Within bounds: False\n",
      "  Signal: [RED]\n",
      "  GMM (-0.5964) is OUTSIDE bounds [FE=0.3582, OLS=0.9873]. This suggests overfitting or model misspecification.\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Coefficient bounds test (Nickell 1981)\n",
    "#\n",
    "# For a dynamic panel: FE is biased downward, OLS is biased upward.\n",
    "# A valid GMM estimate should lie between the two.\n",
    "\n",
    "bounds = diag.coefficient_bounds_test()\n",
    "\n",
    "print(\"=== Nickell Bounds Test ===\")\n",
    "print(f\"  OLS (upper bound):  {bounds['ols_coef']:.4f}\")\n",
    "print(f\"  FE  (lower bound):  {bounds['fe_coef']:.4f}\")\n",
    "print(f\"  GMM estimate:       {bounds['gmm_coef']:.4f}\")\n",
    "print(f\"  Within bounds: {bounds['within_bounds']}\")\n",
    "print(f\"  Signal: [{bounds['signal']}]\")\n",
    "print(f\"  {bounds['details']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Instrument Sensitivity ===\n",
      " gmm_max_lag  n_instruments  ar_coef  hansen_j_pval  ar2_pval\n",
      "           2              3 0.363818            NaN  0.000000\n",
      "           3              4 3.269389            NaN  0.000000\n",
      "           4              5 0.031180            NaN  0.000031\n",
      "           5              6 0.095327            NaN  0.000002\n",
      "\n",
      "Signal: [RED]\n",
      "Coefficient range: 344.5% of mean\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Instrument sensitivity — how do results change with max_lag?\n",
    "sens_df = diag.instrument_sensitivity(max_lag_range=[2, 3, 4, 5])\n",
    "print(\"=== Instrument Sensitivity ===\")\n",
    "print(sens_df.to_string(index=False))\n",
    "print(f\"\\nSignal: [{sens_df.attrs.get('signal', '?')}]\")\n",
    "if sens_df.attrs.get('relative_range') is not None:\n",
    "    print(f\"Coefficient range: {sens_df.attrs['relative_range']:.1%} of mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step Comparison ===\n",
      "  One-step coef:  0.0557\n",
      "  Two-step coef:  -0.5964\n",
      "  Relative diff:  200.0%\n",
      "  SE ratio (2s/1s): nan\n",
      "  Signal: [RED]\n"
     ]
    }
   ],
   "source": [
    "# 5.4 One-step vs two-step comparison\n",
    "step = diag.step_comparison()\n",
    "\n",
    "print(\"=== Step Comparison ===\")\n",
    "print(f\"  One-step coef:  {step['one_step_coef']:.4f}\")\n",
    "print(f\"  Two-step coef:  {step['two_step_coef']:.4f}\")\n",
    "print(f\"  Relative diff:  {step['rel_diff']:.1%}\")\n",
    "print(f\"  SE ratio (2s/1s): {step['se_ratio']:.3f}\")\n",
    "print(f\"  Signal: [{step['signal']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GMM Overfit Diagnostic Report\n",
      "======================================================================\n",
      "\n",
      "1. Instrument Feasibility (Roodman Rule)  [GREEN]\n",
      "----------------------------------------------------------------------\n",
      "   Groups (N):          140\n",
      "   Instruments:         9\n",
      "   Ratio (instr/N):     0.064\n",
      "   Instrument ratio (0.06) is well below 1.0. Instrument proliferation is unlikely.\n",
      "\n",
      "2. Instrument Sensitivity (varying max_lag)  [RED]\n",
      "----------------------------------------------------------------------\n",
      "   max_lag=2  instruments=3  AR_coef=0.3638  Hansen_p=nan\n",
      "   max_lag=3  instruments=4  AR_coef=3.2694  Hansen_p=nan\n",
      "   max_lag=4  instruments=5  AR_coef=0.0312  Hansen_p=nan\n",
      "   max_lag=5  instruments=6  AR_coef=0.0953  Hansen_p=nan\n",
      "   max_lag=6  instruments=7  AR_coef=1.9838  Hansen_p=nan\n",
      "   Coefficient range: 281.9% of mean\n",
      "\n",
      "3. Coefficient Bounds (Nickell 1981)  [RED]\n",
      "----------------------------------------------------------------------\n",
      "   OLS (upper bound):   0.9873\n",
      "   FE  (lower bound):   0.3582\n",
      "   GMM estimate:        -0.5964\n",
      "   GMM (-0.5964) is OUTSIDE bounds [FE=0.3582, OLS=0.9873]. This suggests overfitting or model misspecification.\n",
      "\n",
      "4. Jackknife Group Sensitivity  [SKIPPED]\n",
      "----------------------------------------------------------------------\n",
      "   Skipped by user request.\n",
      "\n",
      "5. One-Step vs Two-Step Comparison  [RED]\n",
      "----------------------------------------------------------------------\n",
      "   One-step coef:       0.0557\n",
      "   Two-step coef:       -0.5964\n",
      "   Relative difference: 200.0%\n",
      "   SE ratio (2s/1s):    nan\n",
      "   Large difference between one-step (0.0557) and two-step (-0.5964): 200.0%. SE ratio=nan. Sensitive to weighting matrix - possible instrument proliferation.\n",
      "\n",
      "======================================================================\n",
      "OVERALL VERDICT: [RED]\n",
      "----------------------------------------------------------------------\n",
      "One or more diagnostics indicate overfitting or instrument proliferation. Results may be unreliable. Consider:\n",
      "  - Using collapse=True\n",
      "  - Reducing gmm_max_lag\n",
      "  - Switching to Difference GMM\n",
      "  - Increasing sample size (more groups)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 5.5 Full diagnostic report (skipping jackknife for speed — N=140 firms)\n",
    "print(diag.summary(run_jackknife=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GMM Overfit Diagnostic Report\n",
      "======================================================================\n",
      "\n",
      "1. Instrument Feasibility (Roodman Rule)  [GREEN]\n",
      "----------------------------------------------------------------------\n",
      "   Groups (N):          100\n",
      "   Instruments:         21\n",
      "   Ratio (instr/N):     0.210\n",
      "   Instrument ratio (0.21) is well below 1.0. Instrument proliferation is unlikely.\n",
      "\n",
      "2. Instrument Sensitivity (varying max_lag)  [GREEN]\n",
      "----------------------------------------------------------------------\n",
      "   max_lag=2  instruments=5  AR_coef=0.8988  Hansen_p=0.0171\n",
      "   max_lag=3  instruments=6  AR_coef=0.9023  Hansen_p=0.0359\n",
      "   max_lag=4  instruments=7  AR_coef=0.9020  Hansen_p=0.0807\n",
      "   max_lag=5  instruments=8  AR_coef=0.9011  Hansen_p=0.0817\n",
      "   max_lag=6  instruments=9  AR_coef=0.8997  Hansen_p=0.1039\n",
      "   Coefficient range: 0.4% of mean\n",
      "\n",
      "3. Coefficient Bounds (Nickell 1981)  [GREEN]\n",
      "----------------------------------------------------------------------\n",
      "   OLS (upper bound):   0.9310\n",
      "   FE  (lower bound):   0.8441\n",
      "   GMM estimate:        0.9064\n",
      "   GMM (0.9064) is within bounds [FE=0.8441, OLS=0.9310]. Consistent with valid identification.\n",
      "\n",
      "4. Jackknife Group Sensitivity  [SKIPPED]\n",
      "----------------------------------------------------------------------\n",
      "   Skipped by user request.\n",
      "\n",
      "5. One-Step vs Two-Step Comparison  [GREEN]\n",
      "----------------------------------------------------------------------\n",
      "   One-step coef:       0.8997\n",
      "   Two-step coef:       0.9064\n",
      "   Relative difference: 0.7%\n",
      "   SE ratio (2s/1s):    0.758\n",
      "   One-step (0.8997) and two-step (0.9064) are consistent (diff=0.7%). SE ratio=0.76.\n",
      "\n",
      "======================================================================\n",
      "OVERALL VERDICT: [GREEN]\n",
      "----------------------------------------------------------------------\n",
      "All diagnostics pass. No evidence of instrument proliferation.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 5.6 Diagnostic on System GMM (growth data)\n",
    "diag_sys = GMMOverfitDiagnostic(model_sys, results_sys)\n",
    "print(diag_sys.summary(run_jackknife=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# 5.7 Visualize sensitivity: coefficient vs instrument count\nimport os\nsens_df2 = diag.instrument_sensitivity(max_lag_range=[2, 3, 4, 5, 6])\nvalid = sens_df2.dropna(subset=['ar_coef'])\n\nif len(valid) > 1:\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4.5))\n    \n    ax1.plot(valid['n_instruments'], valid['ar_coef'], 'o-', color='steelblue')\n    ax1.axhline(results_correct.params.iloc[0], ls='--', color='red', alpha=0.5,\n                label=f'Baseline ({results_correct.params.iloc[0]:.3f})')\n    ax1.set_xlabel('Number of instruments')\n    ax1.set_ylabel('AR coefficient')\n    ax1.set_title('AR Coefficient vs Instrument Count')\n    ax1.legend()\n    \n    ax2.plot(valid['n_instruments'], valid['hansen_j_pval'], 's-', color='darkorange')\n    ax2.axhline(0.10, ls='--', color='red', alpha=0.5, label='p = 0.10')\n    ax2.axhline(0.90, ls='--', color='gray', alpha=0.5, label='p = 0.90 (suspect)')\n    ax2.set_xlabel('Number of instruments')\n    ax2.set_ylabel('Hansen J p-value')\n    ax2.set_title('Hansen J p-value vs Instrument Count')\n    ax2.legend()\n    \n    fig.tight_layout()\n    os.makedirs('../outputs/figures', exist_ok=True)\n    fig.savefig('../outputs/figures/04_sensitivity_plot.png', dpi=150, bbox_inches='tight')\n    plt.show()\nelse:\n    print(\"Not enough valid estimations for sensitivity plot.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Complete Diagnostic Checklist <a id='6-checklist'></a>\n",
    "\n",
    "A systematic approach for validating any GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": "def full_validation(model, results, model_name=\"GMM\"):\n    \"\"\"Run complete validation on a GMM model.\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"GMM VALIDATION CHECKLIST — {model_name}\")\n    print('='*60)\n    \n    checks = {}\n    \n    # 1. AR(2) — CRITICAL\n    print(\"\\n1. Serial Correlation (AR Tests)\")\n    print(f\"   AR(1) p-value: {results.ar1_test.pvalue:.4f}\")\n    ar1_ok = results.ar1_test.pvalue < 0.10\n    print(f\"   {'PASS' if ar1_ok else '~'} Expected to reject (< 0.10)\")\n    \n    print(f\"   AR(2) p-value: {results.ar2_test.pvalue:.4f}\")\n    ar2_ok = results.ar2_test.pvalue > 0.10\n    print(f\"   {'PASS' if ar2_ok else 'FAIL'} Must NOT reject (> 0.10) — CRITICAL\")\n    checks['AR(2) valid'] = ar2_ok\n    \n    # 2. Hansen J\n    print(\"\\n2. Over-Identifying Restrictions (Hansen J)\")\n    hansen_stat = results.hansen_j.statistic\n    hansen_p = results.hansen_j.pvalue\n    print(f\"   J = {hansen_stat:.4f}, p = {hansen_p:.4f}\")\n    if np.isnan(hansen_p):\n        print(\"   N/A: Hansen J not available (model may be under-identified)\")\n        checks['Hansen J valid'] = False\n    elif hansen_p > 0.90:\n        print(\"   WARNING: Very high p (> 0.90) — possible overfitting\")\n        checks['Hansen J valid'] = False\n    elif hansen_p > 0.10:\n        print(\"   PASS: Valid (0.10 < p < 0.90)\")\n        checks['Hansen J valid'] = True\n    else:\n        print(\"   FAIL: Reject (p < 0.10)\")\n        checks['Hansen J valid'] = False\n    \n    # 3. Instrument ratio\n    print(\"\\n3. Instrument Count\")\n    ratio = results.instrument_ratio\n    print(f\"   Instruments: {results.n_instruments}, Groups: {results.n_groups}\")\n    print(f\"   Ratio: {ratio:.3f}\")\n    ratio_ok = ratio < 1.0\n    print(f\"   {'PASS' if ratio_ok else 'FAIL'} Ratio < 1.0\")\n    checks['Instrument ratio OK'] = ratio_ok\n    \n    # 4. Diff-in-Hansen (System GMM)\n    if results.diff_hansen is not None:\n        print(\"\\n4. Level Instruments (Diff-in-Hansen)\")\n        print(f\"   Statistic: {results.diff_hansen.statistic:.4f}, \"\n              f\"p = {results.diff_hansen.pvalue:.4f}\")\n        dh_ok = results.diff_hansen.pvalue > 0.10\n        print(f\"   {'PASS' if dh_ok else 'FAIL'} Level instruments valid (> 0.10)\")\n        checks['Level instruments valid'] = dh_ok\n    \n    # 5. Overfit diagnostic\n    print(\"\\n5. Overfitting Check (Nickell Bounds)\")\n    diag = GMMOverfitDiagnostic(model, results)\n    bounds = diag.coefficient_bounds_test()\n    if bounds['within_bounds'] is not None:\n        print(f\"   OLS={bounds['ols_coef']:.4f}, FE={bounds['fe_coef']:.4f}, \"\n              f\"GMM={bounds['gmm_coef']:.4f}\")\n        print(f\"   [{bounds['signal']}] {bounds['details']}\")\n        checks['Bounds OK'] = bounds['within_bounds']\n    \n    # Summary\n    print(f\"\\n{'='*60}\")\n    print(\"SUMMARY\")\n    print('='*60)\n    for name, passed in checks.items():\n        print(f\"  {'PASS' if passed else 'FAIL'}: {name}\")\n    \n    all_pass = all(checks.values())\n    print(f\"\\n{'='*60}\")\n    if all_pass:\n        print(\"MODEL PASSES ALL CRITICAL TESTS\")\n    else:\n        print(\"MODEL FAILS — revise specification\")\n    \n    return checks"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "# Apply checklist to our correctly specified model\nchecks_correct = full_validation(model_correct, results_correct, \"Difference GMM (Simulated Panel)\")"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DIAGNOSTIC FLOWCHART\n",
      "============================================================\n",
      "\n",
      "STEP 1: Check AR(2)\n",
      "  FAIL: AR(2) p = 0.0000 < 0.10\n",
      "  -> Serial correlation: use deeper lags or add AR(2) to model\n",
      "\n",
      "Result: AR2_FAIL\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Diagnostic flowchart\n",
    "def diagnostic_flowchart(results):\n",
    "    \"\"\"Decision tree for diagnosing GMM problems.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DIAGNOSTIC FLOWCHART\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Step 1: AR(2)\n",
    "    print(\"STEP 1: Check AR(2)\")\n",
    "    if results.ar2_test.pvalue > 0.10:\n",
    "        print(f\"  PASS: AR(2) p = {results.ar2_test.pvalue:.4f} > 0.10\")\n",
    "        \n",
    "        # Step 2: Hansen J\n",
    "        print(\"\\nSTEP 2: Check Hansen J\")\n",
    "        if 0.10 < results.hansen_j.pvalue < 0.90:\n",
    "            print(f\"  PASS: Hansen J p = {results.hansen_j.pvalue:.4f}\")\n",
    "            \n",
    "            # Step 3: Instrument ratio\n",
    "            print(\"\\nSTEP 3: Check instrument ratio\")\n",
    "            ratio = results.instrument_ratio\n",
    "            if ratio < 1.0:\n",
    "                print(f\"  PASS: Ratio = {ratio:.3f} < 1.0\")\n",
    "                print(\"\\n  -> MODEL VALIDATED\")\n",
    "                return \"VALID\"\n",
    "            else:\n",
    "                print(f\"  FAIL: Ratio = {ratio:.3f} > 1.0\")\n",
    "                print(\"  -> Use collapse=True or reduce max_lag\")\n",
    "                return \"TOO_MANY_INSTRUMENTS\"\n",
    "        elif results.hansen_j.pvalue > 0.90:\n",
    "            print(f\"  WARNING: Hansen J p = {results.hansen_j.pvalue:.4f} > 0.90\")\n",
    "            print(\"  -> Possible overfitting. Check with GMMOverfitDiagnostic\")\n",
    "            return \"OVERFITTING\"\n",
    "        else:\n",
    "            print(f\"  FAIL: Hansen J p = {results.hansen_j.pvalue:.4f} < 0.10\")\n",
    "            print(\"  -> Add variables, change specification\")\n",
    "            return \"HANSEN_REJECT\"\n",
    "    else:\n",
    "        print(f\"  FAIL: AR(2) p = {results.ar2_test.pvalue:.4f} < 0.10\")\n",
    "        print(\"  -> Serial correlation: use deeper lags or add AR(2) to model\")\n",
    "        return \"AR2_FAIL\"\n",
    "\n",
    "status = diagnostic_flowchart(results_correct)\n",
    "print(f\"\\nResult: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": "---\n## 7. Exercises <a id='7-exercises'></a>\n\n### Exercise 1: Diagnose Problems (Medium)\nLoad `bad_specification.csv` and:\n1. Estimate Difference GMM omitting `x2_omitted` (use `time_dummies=False, collapse=True`)\n2. Run `full_validation()` — which tests pass? Which fail?\n3. Add the omitted variable and re-validate\n4. Compare coefficients: how does the AR coefficient change?\n\n### Exercise 2: AR(2) Investigation (Advanced)\nUsing `simulate_ar2_errors()` with different `phi2` values (0, 0.1, 0.3, 0.5):\n1. Estimate each and compare AR(2) p-values\n2. At what `phi2` does AR(2) reliably reject?\n3. How does this affect the coefficient estimate?\n\n### Exercise 3: Overfitting Diagnostic (Advanced)\nUsing the growth data:\n1. Create `GMMOverfitDiagnostic` for both Difference and System GMM\n2. Run `summary()` with `run_jackknife=True`\n3. Compare the traffic-light signals\n4. Which model shows more overfitting risk and why?\n\n### Exercise 4: Complete Validation (Advanced)\nChoose any dataset and:\n1. Estimate both Difference and System GMM\n2. Run `full_validation()` and `diagnostic_flowchart()` on both\n3. Run `GMMOverfitDiagnostic.summary()` on both\n4. Write up your final recommendation"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for exercises\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. **AR(2) test** is the most critical diagnostic — rejection invalidates the entire instrument set\n",
    "2. **Hansen J** tests overall instrument validity, but is weakened by too many instruments\n",
    "3. Always use **Hansen** (robust), not Sargan (assumes homoskedasticity)\n",
    "4. **Difference-in-Hansen** validates the extra level-equation instruments in System GMM\n",
    "5. **`GMMOverfitDiagnostic`** provides five complementary checks for detecting overfitting:\n",
    "   - Feasibility (Roodman rule)\n",
    "   - Instrument sensitivity (varying max_lag)\n",
    "   - Coefficient bounds (Nickell)\n",
    "   - Jackknife group stability\n",
    "   - One-step vs two-step comparison\n",
    "6. Follow the **diagnostic flowchart**: AR(2) -> Hansen J -> Instrument ratio -> Bounds check\n",
    "\n",
    "### Next Notebook\n",
    "In **Notebook 05**, we cover **CUE-GMM and Bias Correction** methods.\n",
    "\n",
    "---\n",
    "**References:**\n",
    "- Arellano, M., & Bond, S. (1991). Some tests of specification for panel data. *Review of Economic Studies*, 58(2), 277-297.\n",
    "- Hansen, L. P. (1982). Large sample properties of GMM estimators. *Econometrica*, 50(4), 1029-1054.\n",
    "- Nickell, S. (1981). Biases in dynamic models with fixed effects. *Econometrica*, 49(6), 1417-1426.\n",
    "- Roodman, D. (2009). How to do xtabond2. *Stata Journal*, 9(1), 86-136.\n",
    "- Windmeijer, F. (2005). A finite sample correction for two-step GMM. *Journal of Econometrics*, 126(1), 25-51."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
