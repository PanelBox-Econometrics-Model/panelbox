{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 — Difference GMM Fundamentals\n",
    "\n",
    "**Duration:** ~80 minutes  \n",
    "**Level:** Intermediate  \n",
    "**Prerequisites:** Linear regression, panel data basics, instrumental variables\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand **why OLS and Fixed Effects fail** for dynamic panel models (Nickell bias)\n",
    "2. Explain the **Arellano-Bond Difference GMM** estimation strategy\n",
    "3. Estimate a Difference GMM model using PanelBox\n",
    "4. Compare OLS, Fixed Effects, and GMM estimates\n",
    "5. Interpret key diagnostic tests (Hansen J, AR(1), AR(2))\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [The Dynamic Panel Problem](#1-the-dynamic-panel-problem)\n",
    "2. [Nickell Bias: Why Fixed Effects Fails](#2-nickell-bias)\n",
    "3. [The Arellano-Bond Solution](#3-the-arellano-bond-solution)\n",
    "4. [Estimation with PanelBox](#4-estimation-with-panelbox)\n",
    "5. [OLS vs FE vs GMM Comparison](#5-ols-vs-fe-vs-gmm-comparison)\n",
    "6. [Diagnostic Tests](#6-diagnostic-tests)\n",
    "7. [Exercises](#7-exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\"../../..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# PanelBox imports\n",
    "from panelbox.gmm import DifferenceGMM, SystemGMM\n",
    "\n",
    "# Tutorial utilities\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "from utils.visualization import apply_tutorial_style, plot_coefficient_comparison, plot_nickell_bias\n",
    "from utils.data_generation import generate_nickell_bias_data\n",
    "\n",
    "# Plot style\n",
    "apply_tutorial_style()\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Dynamic Panel Problem\n",
    "\n",
    "Many economic models involve **persistence** — the current value of a variable depends on its past values. For example:\n",
    "\n",
    "- Employment adjusts slowly due to hiring/firing costs\n",
    "- GDP growth is autocorrelated across countries\n",
    "- Investment decisions depend on past capital levels\n",
    "\n",
    "The standard **dynamic panel model** is:\n",
    "\n",
    "$$y_{it} = \\rho \\, y_{i,t-1} + \\mathbf{x}'_{it} \\boldsymbol{\\beta} + \\mu_i + \\varepsilon_{it}$$\n",
    "\n",
    "where:\n",
    "- $y_{it}$: dependent variable for entity $i$ at time $t$\n",
    "- $y_{i,t-1}$: **lagged** dependent variable\n",
    "- $\\mathbf{x}_{it}$: vector of covariates\n",
    "- $\\mu_i$: entity-specific **fixed effect**\n",
    "- $\\varepsilon_{it}$: idiosyncratic error\n",
    "\n",
    "### The Core Problem\n",
    "\n",
    "The lagged dependent variable $y_{i,t-1}$ is **correlated with the fixed effect** $\\mu_i$ by construction:\n",
    "\n",
    "$$\\text{Corr}(y_{i,t-1}, \\mu_i) \\neq 0$$\n",
    "\n",
    "This means:\n",
    "- **OLS** is biased upward (positive correlation between $y_{i,t-1}$ and $\\mu_i + \\varepsilon_{it}$)\n",
    "- **Fixed Effects** (within estimator) is biased downward — this is **Nickell bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nickell Bias: Why Fixed Effects Fails\n",
    "\n",
    "Nickell (1981) showed that the FE estimator of $\\rho$ has a **negative bias** of order $O(1/T)$:\n",
    "\n",
    "$$\\text{plim}_{N \\to \\infty} \\hat{\\rho}_{FE} = \\rho - \\frac{1 + \\rho}{T - 1} + O\\left(\\frac{1}{T^2}\\right)$$\n",
    "\n",
    "This means:\n",
    "- For $T = 5$ and $\\rho = 0.5$: bias $\\approx -0.375$ (75% underestimate!)\n",
    "- For $T = 10$ and $\\rho = 0.5$: bias $\\approx -0.167$ (33% underestimate)\n",
    "- The bias diminishes **only as T grows**, not N\n",
    "\n",
    "Let's demonstrate this with simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Nickell bias demonstration data\n",
    "nickell_data = pd.read_csv(\"../data/dgp_nickell_bias.csv\")\n",
    "print(f\"Dataset shape: {nickell_data.shape}\")\n",
    "print(f\"Unique (rho, T) combinations: {nickell_data.groupby(['rho', 'T']).ngroups}\")\n",
    "nickell_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Nickell bias: compare FE and OLS estimates across (rho, T)\n",
    "from scipy import stats as sp_stats\n",
    "\n",
    "bias_results = []\n",
    "\n",
    "for (rho_true, T_true), group in nickell_data.groupby(['rho', 'T']):\n",
    "    # Create lagged y within this subset\n",
    "    df = group.sort_values(['entity', 'time']).copy()\n",
    "    df['y_lag'] = df.groupby('entity')['y'].shift(1)\n",
    "    df = df.dropna(subset=['y_lag'])\n",
    "    \n",
    "    # --- Pooled OLS ---\n",
    "    y = df['y'].values\n",
    "    X_ols = np.column_stack([np.ones(len(df)), df['y_lag'].values])\n",
    "    beta_ols = np.linalg.lstsq(X_ols, y, rcond=None)[0]\n",
    "    rho_ols = beta_ols[1]\n",
    "    \n",
    "    # --- Fixed Effects (within estimator) ---\n",
    "    # Demean within entity\n",
    "    entity_means_y = df.groupby('entity')['y'].transform('mean')\n",
    "    entity_means_ylag = df.groupby('entity')['y_lag'].transform('mean')\n",
    "    y_dm = (df['y'] - entity_means_y).values\n",
    "    X_fe = (df['y_lag'] - entity_means_ylag).values.reshape(-1, 1)\n",
    "    rho_fe = float(np.linalg.lstsq(X_fe, y_dm, rcond=None)[0][0])\n",
    "    \n",
    "    # --- Difference GMM ---\n",
    "    try:\n",
    "        model_gmm = DifferenceGMM(\n",
    "            data=df[['entity', 'time', 'y']],\n",
    "            dep_var='y',\n",
    "            lags=1,\n",
    "            id_var='entity',\n",
    "            time_var='time',\n",
    "            time_dummies=False,\n",
    "            collapse=True,\n",
    "            two_step=True,\n",
    "            robust=True\n",
    "        )\n",
    "        result_gmm = model_gmm.fit()\n",
    "        rho_gmm = float(result_gmm.params.iloc[0])\n",
    "    except Exception:\n",
    "        rho_gmm = np.nan\n",
    "    \n",
    "    bias_results.append({\n",
    "        'rho': rho_true,\n",
    "        'T': int(T_true),\n",
    "        'ols_estimate': rho_ols,\n",
    "        'fe_estimate': rho_fe,\n",
    "        'gmm_estimate': rho_gmm,\n",
    "        'ols_bias': rho_ols - rho_true,\n",
    "        'fe_bias': rho_fe - rho_true,\n",
    "        'gmm_bias': rho_gmm - rho_true if not np.isnan(rho_gmm) else np.nan,\n",
    "    })\n",
    "\n",
    "bias_df = pd.DataFrame(bias_results)\n",
    "print(\"\\nEstimation Results Across (rho, T):\")\n",
    "print(\"=\" * 80)\n",
    "print(bias_df.to_string(index=False, float_format='{:.4f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Nickell bias\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "estimators = [\n",
    "    ('ols_estimate', 'Pooled OLS', 'tab:red'),\n",
    "    ('fe_estimate', 'Fixed Effects', 'tab:orange'),\n",
    "    ('gmm_estimate', 'Difference GMM', 'tab:blue'),\n",
    "]\n",
    "\n",
    "for ax, (col, name, color) in zip(axes, estimators):\n",
    "    for rho in [0.3, 0.5, 0.8]:\n",
    "        sub = bias_df[bias_df['rho'] == rho]\n",
    "        ax.plot(sub['T'], sub[col], 'o-', label=f'rho = {rho}')\n",
    "        ax.axhline(rho, color='gray', linestyle=':', alpha=0.5)\n",
    "    ax.set_xlabel('T (panel length)')\n",
    "    ax.set_ylabel('Estimate of rho')\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "\n",
    "fig.suptitle('Nickell Bias Demonstration: OLS vs FE vs GMM', fontsize=14, y=1.02)\n",
    "fig.tight_layout()\n",
    "fig.savefig('../outputs/figures/01_nickell_bias_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways from the Simulation\n",
    "\n",
    "1. **OLS** consistently **overestimates** $\\rho$ (upward bias from fixed effects)\n",
    "2. **Fixed Effects** consistently **underestimates** $\\rho$ (Nickell bias)\n",
    "3. **Difference GMM** provides approximately **unbiased** estimates\n",
    "4. The FE bias is more severe for **small T** and **high $\\rho$**\n",
    "\n",
    "> **Rule of thumb**: In dynamic panels, the true $\\rho$ should lie **between** the FE estimate (lower bound) and the OLS estimate (upper bound). If your GMM estimate falls outside this range, suspect misspecification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Arellano-Bond Solution\n",
    "\n",
    "### Step 1: Eliminate Fixed Effects by First-Differencing\n",
    "\n",
    "$$\\Delta y_{it} = \\rho \\, \\Delta y_{i,t-1} + \\Delta \\mathbf{x}'_{it} \\boldsymbol{\\beta} + \\Delta \\varepsilon_{it}$$\n",
    "\n",
    "This removes $\\mu_i$, but creates a new problem: $\\Delta y_{i,t-1}$ is correlated with $\\Delta \\varepsilon_{it}$ because both contain $\\varepsilon_{i,t-1}$.\n",
    "\n",
    "### Step 2: Use Lagged Levels as Instruments\n",
    "\n",
    "Under the assumptions:\n",
    "- $E[\\varepsilon_{it} \\varepsilon_{is}] = 0$ for $t \\neq s$ (no serial correlation)\n",
    "- $E[y_{i,1} \\varepsilon_{it}] = 0$ for $t \\geq 2$ (predetermined initial conditions)\n",
    "\n",
    "We can use $y_{i,t-2}, y_{i,t-3}, \\ldots$ as **instruments** for $\\Delta y_{i,t-1}$:\n",
    "\n",
    "| Time | Endogenous | Valid Instruments |\n",
    "|------|------------|-------------------|\n",
    "| $t=3$ | $\\Delta y_{i,2}$ | $y_{i,1}$ |\n",
    "| $t=4$ | $\\Delta y_{i,3}$ | $y_{i,1}, y_{i,2}$ |\n",
    "| $t=5$ | $\\Delta y_{i,4}$ | $y_{i,1}, y_{i,2}, y_{i,3}$ |\n",
    "\n",
    "### Step 3: GMM Estimation\n",
    "\n",
    "The moment conditions are:\n",
    "\n",
    "$$E[y_{i,t-s} \\cdot \\Delta \\varepsilon_{it}] = 0 \\quad \\text{for } s \\geq 2$$\n",
    "\n",
    "GMM finds the parameters that minimize the weighted distance between sample and population moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estimation with PanelBox\n",
    "\n",
    "Now let's apply Difference GMM to real-world-style data: the Arellano-Bond employment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load employment data\n",
    "abdata = pd.read_csv(\"../data/abdata.csv\")\n",
    "print(f\"Shape: {abdata.shape}\")\n",
    "print(f\"Firms: {abdata['firm'].nunique()}\")\n",
    "print(f\"Years: {sorted(abdata['year'].unique())}\")\n",
    "print(f\"\\nDescriptive Statistics:\")\n",
    "abdata.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Difference GMM estimation\n",
    "# Model: n_{it} = rho * n_{i,t-1} + beta1 * w_{it} + beta2 * k_{it} + mu_i + eps_{it}\n",
    "\n",
    "model_diff = DifferenceGMM(\n",
    "    data=abdata,\n",
    "    dep_var='n',              # Log employment\n",
    "    lags=1,                    # Include n_{t-1}\n",
    "    id_var='firm',             # Firm identifier\n",
    "    time_var='year',           # Time variable\n",
    "    exog_vars=['w', 'k'],      # Strictly exogenous regressors\n",
    "    time_dummies=True,         # Include year dummies\n",
    "    collapse=True,             # Collapse instruments (recommended)\n",
    "    two_step=True,             # Two-step estimation\n",
    "    robust=True                # Windmeijer-corrected standard errors\n",
    ")\n",
    "\n",
    "results_diff = model_diff.fit()\n",
    "print(results_diff.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key results interpretation\n",
    "print(\"Key Coefficient Estimates:\")\n",
    "print(\"=\" * 50)\n",
    "for var in ['L1.n', 'w', 'k']:\n",
    "    if var in results_diff.params.index:\n",
    "        coef = results_diff.params[var]\n",
    "        se = results_diff.std_errors[var]\n",
    "        p = results_diff.pvalues[var]\n",
    "        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''\n",
    "        print(f\"  {var:<10}: {coef:>8.4f}  (SE: {se:.4f})  p={p:.4f} {sig}\")\n",
    "\n",
    "print(f\"\\nDiagnostic Tests:\")\n",
    "print(f\"  Hansen J:    p = {results_diff.hansen_j.pvalue:.4f}  [{results_diff.hansen_j.conclusion}]\")\n",
    "print(f\"  AR(1):       p = {results_diff.ar1_test.pvalue:.4f}  [{results_diff.ar1_test.conclusion}]\")\n",
    "print(f\"  AR(2):       p = {results_diff.ar2_test.pvalue:.4f}  [{results_diff.ar2_test.conclusion}]\")\n",
    "print(f\"  Instruments: {results_diff.n_instruments}\")\n",
    "print(f\"  Groups:      {results_diff.n_groups}\")\n",
    "print(f\"  Inst. ratio: {results_diff.instrument_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Results\n",
    "\n",
    "**Coefficients:**\n",
    "- `L1.n` ($\\hat{\\rho}$): persistence of employment\n",
    "- `w`: elasticity of employment with respect to wages\n",
    "- `k`: elasticity of employment with respect to capital\n",
    "\n",
    "**Diagnostic Tests:**\n",
    "- **Hansen J-test**: If $p > 0.10$, instruments are valid. If $p > 0.99$, may indicate too many instruments.\n",
    "- **AR(1)**: Expected to be significant (by construction in first-differences).\n",
    "- **AR(2)**: Should NOT be significant ($p > 0.10$) — validates the moment conditions.\n",
    "- **Instrument ratio**: Should be $< 1.0$ (fewer instruments than groups)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. OLS vs FE vs GMM Comparison\n",
    "\n",
    "Let's compare the three estimators on the employment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data with lagged variable\n",
    "df = abdata.sort_values(['firm', 'year']).copy()\n",
    "df['n_lag'] = df.groupby('firm')['n'].shift(1)\n",
    "df = df.dropna(subset=['n_lag'])\n",
    "\n",
    "# --- Pooled OLS ---\n",
    "y = df['n'].values\n",
    "X_ols = np.column_stack([np.ones(len(df)), df['n_lag'].values, df['w'].values, df['k'].values])\n",
    "beta_ols = np.linalg.lstsq(X_ols, y, rcond=None)[0]\n",
    "resid_ols = y - X_ols @ beta_ols\n",
    "se_ols = np.sqrt(np.diag(np.sum(resid_ols**2) / (len(y) - 4) * np.linalg.inv(X_ols.T @ X_ols)))\n",
    "\n",
    "# --- Fixed Effects ---\n",
    "for col in ['n', 'n_lag', 'w', 'k']:\n",
    "    df[f'{col}_dm'] = df[col] - df.groupby('firm')[col].transform('mean')\n",
    "\n",
    "y_dm = df['n_dm'].values\n",
    "X_fe = np.column_stack([df['n_lag_dm'].values, df['w_dm'].values, df['k_dm'].values])\n",
    "beta_fe = np.linalg.lstsq(X_fe, y_dm, rcond=None)[0]\n",
    "resid_fe = y_dm - X_fe @ beta_fe\n",
    "N_firms = df['firm'].nunique()\n",
    "se_fe = np.sqrt(np.diag(np.sum(resid_fe**2) / (len(y_dm) - N_firms - 3) * np.linalg.inv(X_fe.T @ X_fe)))\n",
    "\n",
    "# --- Collect GMM results ---\n",
    "rho_gmm = results_diff.params.get('L1.n', np.nan)\n",
    "se_gmm = results_diff.std_errors.get('L1.n', np.nan)\n",
    "\n",
    "# Comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'OLS': {'rho': beta_ols[1], 'w': beta_ols[2], 'k': beta_ols[3], 'SE(rho)': se_ols[1]},\n",
    "    'Fixed Effects': {'rho': beta_fe[0], 'w': beta_fe[1], 'k': beta_fe[2], 'SE(rho)': se_fe[0]},\n",
    "    'Difference GMM': {\n",
    "        'rho': rho_gmm,\n",
    "        'w': results_diff.params.get('w', np.nan),\n",
    "        'k': results_diff.params.get('k', np.nan),\n",
    "        'SE(rho)': se_gmm,\n",
    "    },\n",
    "})\n",
    "\n",
    "print(\"Estimator Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison.round(4).to_string())\n",
    "print(f\"\\nExpected ordering: FE(rho) < GMM(rho) < OLS(rho)\")\n",
    "print(f\"Actual: FE={beta_fe[0]:.4f}, GMM={rho_gmm:.4f}, OLS={beta_ols[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "estimates = {\n",
    "    'Pooled OLS': (beta_ols[1], se_ols[1]),\n",
    "    'Fixed Effects': (beta_fe[0], se_fe[0]),\n",
    "    'Difference GMM': (rho_gmm, se_gmm),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "plot_coefficient_comparison(\n",
    "    estimates,\n",
    "    param_name='Persistence parameter (rho)',\n",
    "    title='Employment Persistence: OLS vs FE vs Difference GMM',\n",
    "    ax=ax\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig('../outputs/figures/01_ols_fe_gmm_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Diagnostic Tests\n",
    "\n",
    "GMM estimation is only as good as its specification. The key diagnostic tests are:\n",
    "\n",
    "### Hansen J-Test (Overidentification)\n",
    "\n",
    "- **H0**: All instruments are valid (moment conditions hold)\n",
    "- **Reject if** $p < 0.10$: instruments may be invalid\n",
    "- **Suspicious if** $p > 0.99$: too many instruments (overfitting)\n",
    "- **Ideal range**: $0.10 < p < 0.25$\n",
    "\n",
    "### AR(1) and AR(2) Tests\n",
    "\n",
    "- **AR(1)**: Expected to be significant (by construction in first differences)\n",
    "- **AR(2)**: Should NOT be significant ($p > 0.10$). Rejection implies serial correlation in levels, invalidating instruments.\n",
    "\n",
    "### Instrument Count\n",
    "\n",
    "Rule of thumb: number of instruments $\\leq$ number of groups (cross-sectional units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed diagnostic analysis\n",
    "print(\"=\"*70)\n",
    "print(\"DIAGNOSTIC REPORT: Difference GMM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Hansen J-test\n",
    "hansen = results_diff.hansen_j\n",
    "print(f\"\\n1. Hansen J-Test (Overidentification)\")\n",
    "print(f\"   Statistic: {hansen.statistic:.4f}\")\n",
    "print(f\"   P-value:   {hansen.pvalue:.4f}\")\n",
    "if hansen.df:\n",
    "    print(f\"   DF:        {hansen.df}\")\n",
    "if hansen.pvalue > 0.10:\n",
    "    print(f\"   Result:    PASS - Cannot reject instrument validity\")\n",
    "else:\n",
    "    print(f\"   Result:    FAIL - Instruments may be invalid\")\n",
    "\n",
    "# 2. AR tests\n",
    "ar1 = results_diff.ar1_test\n",
    "ar2 = results_diff.ar2_test\n",
    "print(f\"\\n2. Arellano-Bond AR Tests\")\n",
    "print(f\"   AR(1): z = {ar1.statistic:.4f}, p = {ar1.pvalue:.4f}\")\n",
    "print(f\"          {'Expected: significant' if ar1.pvalue < 0.10 else 'Unusual: not significant'}\")\n",
    "print(f\"   AR(2): z = {ar2.statistic:.4f}, p = {ar2.pvalue:.4f}\")\n",
    "print(f\"          {'PASS: No second-order autocorrelation' if ar2.pvalue > 0.10 else 'FAIL: Serial correlation detected'}\")\n",
    "\n",
    "# 3. Instrument count\n",
    "print(f\"\\n3. Instrument Count\")\n",
    "print(f\"   Instruments: {results_diff.n_instruments}\")\n",
    "print(f\"   Groups:      {results_diff.n_groups}\")\n",
    "ratio = results_diff.instrument_ratio\n",
    "print(f\"   Ratio:       {ratio:.3f} {'(OK)' if ratio <= 1.0 else '(TOO MANY)'}\")\n",
    "\n",
    "# Overall assessment\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "valid_hansen = hansen.pvalue > 0.10\n",
    "valid_ar2 = ar2.pvalue > 0.10\n",
    "valid_instruments = ratio <= 1.0\n",
    "\n",
    "if valid_hansen and valid_ar2 and valid_instruments:\n",
    "    print(\"OVERALL: Specification appears VALID\")\n",
    "else:\n",
    "    issues = []\n",
    "    if not valid_hansen: issues.append(\"Hansen J rejects\")\n",
    "    if not valid_ar2: issues.append(\"AR(2) significant\")\n",
    "    if not valid_instruments: issues.append(\"Too many instruments\")\n",
    "    print(f\"OVERALL: Issues — {', '.join(issues)}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exercises\n",
    "\n",
    "### Exercise 1: Sensitivity to Panel Length\n",
    "\n",
    "Using the Nickell bias data, estimate the FE and GMM coefficients for $\\rho = 0.8$ and $T \\in \\{5, 10, 20\\}$. How does the FE bias change with T? Does GMM remain consistent?\n",
    "\n",
    "### Exercise 2: Adding More Covariates\n",
    "\n",
    "Re-estimate the employment model adding `ys` (industry output) as an additional exogenous variable. How do the coefficient estimates change? Do the diagnostics still pass?\n",
    "\n",
    "### Exercise 3: Collapse vs. Non-Collapse\n",
    "\n",
    "Estimate the employment model with `collapse=False`. Compare the instrument count, Hansen J p-value, and coefficient estimates with the collapsed version. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise 1\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise 2\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for Exercise 3\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned:\n",
    "\n",
    "1. **Dynamic panel models** include lagged dependent variables, creating endogeneity\n",
    "2. **OLS overestimates** and **FE underestimates** the persistence parameter (Nickell bias)\n",
    "3. **Difference GMM** (Arellano-Bond) solves this by:\n",
    "   - First-differencing to eliminate fixed effects\n",
    "   - Using lagged levels as instruments\n",
    "4. **Key diagnostics**: Hansen J-test, AR(2) test, instrument count ratio\n",
    "5. **Best practices**: Always use `collapse=True`, check that instrument ratio < 1.0\n",
    "\n",
    "### Next Notebook\n",
    "\n",
    "In **Notebook 02**, we'll explore **System GMM (Blundell-Bond)**, which adds level equations for greater efficiency when series are persistent.\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- Arellano, M., & Bond, S. (1991). Some tests of specification for panel data. *Review of Economic Studies*, 58(2), 277-297.\n",
    "- Nickell, S. (1981). Biases in dynamic models with fixed effects. *Econometrica*, 49(6), 1417-1426.\n",
    "- Roodman, D. (2009). How to do xtabond2. *Stata Journal*, 9(1), 86-136."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
