{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions: Tutorial 04 - Spatial Fundamentals\n",
    "\n",
    "**Series**: PanelBox - Fundamentals (Solutions)\n",
    "**Level**: Intermediate\n",
    "**Tutorial**: 04_spatial_fundamentals.ipynb\n",
    "\n",
    "This notebook contains complete solutions to the exercises in Tutorial 04.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance_matrix\n",
    "import scipy\n",
    "from IPython.display import display\n",
    "\n",
    "# PanelBox library\n",
    "import sys\n",
    "sys.path.append('/home/guhaase/projetos/panelbox')\n",
    "import panelbox as pb\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(f\"PanelBox version: {pb.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5x5 grid\n",
    "n_rows, n_cols = 5, 5\n",
    "n_regions = n_rows * n_cols\n",
    "\n",
    "coords = []\n",
    "region_ids = []\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        coords.append([j, i])\n",
    "        region_ids.append(f\"R{i*n_cols + j + 1:02d}\")\n",
    "\n",
    "coords = np.array(coords)\n",
    "spatial_data = pd.DataFrame({\n",
    "    'region_id': region_ids,\n",
    "    'x': coords[:, 0],\n",
    "    'y': coords[:, 1]\n",
    "})\n",
    "\n",
    "# Add GDP per capita with spatial pattern\n",
    "np.random.seed(42)\n",
    "center_x, center_y = n_cols / 2, n_rows / 2\n",
    "distance_from_center = np.sqrt((spatial_data['x'] - center_x)**2 + \n",
    "                                (spatial_data['y'] - center_y)**2)\n",
    "spatial_data['gdp_pc'] = 100 - 5 * distance_from_center + np.random.normal(0, 5, n_regions)\n",
    "\n",
    "print(f\"Created {n_regions} regions in {n_rows}×{n_cols} grid\")\n",
    "display(spatial_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Compare Weight Matrices\n",
    "\n",
    "**Task**: Compare rook, queen, and KNN (k=6) weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SOLUTION 1: COMPARING WEIGHT MATRICES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Helper functions\n",
    "def create_rook_contiguity(n_rows, n_cols):\n",
    "    n = n_rows * n_cols\n",
    "    W = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        row_i = i // n_cols\n",
    "        col_i = i % n_cols\n",
    "        \n",
    "        neighbors = [\n",
    "            (row_i - 1, col_i),\n",
    "            (row_i + 1, col_i),\n",
    "            (row_i, col_i - 1),\n",
    "            (row_i, col_i + 1)\n",
    "        ]\n",
    "        \n",
    "        for row_j, col_j in neighbors:\n",
    "            if 0 <= row_j < n_rows and 0 <= col_j < n_cols:\n",
    "                j = row_j * n_cols + col_j\n",
    "                W[i, j] = 1\n",
    "    \n",
    "    return W\n",
    "\n",
    "def create_queen_contiguity(n_rows, n_cols):\n",
    "    n = n_rows * n_cols\n",
    "    W = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        row_i = i // n_cols\n",
    "        col_i = i % n_cols\n",
    "        \n",
    "        for dr in [-1, 0, 1]:\n",
    "            for dc in [-1, 0, 1]:\n",
    "                if dr == 0 and dc == 0:\n",
    "                    continue\n",
    "                \n",
    "                row_j = row_i + dr\n",
    "                col_j = col_i + dc\n",
    "                \n",
    "                if 0 <= row_j < n_rows and 0 <= col_j < n_cols:\n",
    "                    j = row_j * n_cols + col_j\n",
    "                    W[i, j] = 1\n",
    "    \n",
    "    return W\n",
    "\n",
    "def create_knn_weights(D, k):\n",
    "    n = D.shape[0]\n",
    "    W = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        distances = D[i, :]\n",
    "        nearest_indices = np.argsort(distances)[1:k+1]\n",
    "        W[i, nearest_indices] = 1\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create all three matrices\n",
    "W_rook = create_rook_contiguity(n_rows, n_cols)\n",
    "W_queen = create_queen_contiguity(n_rows, n_cols)\n",
    "\n",
    "# For KNN, need distance matrix\n",
    "coords_matrix = spatial_data[['x', 'y']].values\n",
    "D = distance_matrix(coords_matrix, coords_matrix)\n",
    "W_knn = create_knn_weights(D, k=6)\n",
    "\n",
    "print(\"\\nWeight matrices created:\")\n",
    "print(f\"  Rook: {W_rook.shape}\")\n",
    "print(f\"  Queen: {W_queen.shape}\")\n",
    "print(f\"  KNN (k=6): {W_knn.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WEIGHT MATRIX STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def matrix_stats(W, name):\n",
    "    total_connections = int(W.sum())\n",
    "    avg_neighbors = W.sum(axis=1).mean()\n",
    "    density = total_connections / (W.shape[0] * (W.shape[0] - 1))\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Total connections: {total_connections}\")\n",
    "    print(f\"  Average neighbors per region: {avg_neighbors:.2f}\")\n",
    "    print(f\"  Density: {density:.4f} ({100*density:.2f}%)\")\n",
    "    print(f\"  Min neighbors: {int(W.sum(axis=1).min())}\")\n",
    "    print(f\"  Max neighbors: {int(W.sum(axis=1).max())}\")\n",
    "    \n",
    "    return total_connections, avg_neighbors, density\n",
    "\n",
    "rook_stats = matrix_stats(W_rook, \"Rook Contiguity\")\n",
    "queen_stats = matrix_stats(W_queen, \"Queen Contiguity\")\n",
    "knn_stats = matrix_stats(W_knn, \"KNN (k=6)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Which is most/least connected?\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"COMPARISON\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Type': ['Rook', 'Queen', 'KNN (k=6)'],\n",
    "    'Total Connections': [rook_stats[0], queen_stats[0], knn_stats[0]],\n",
    "    'Avg Neighbors': [rook_stats[1], queen_stats[1], knn_stats[1]],\n",
    "    'Density': [rook_stats[2], queen_stats[2], knn_stats[2]]\n",
    "})\n",
    "\n",
    "display(stats_df)\n",
    "\n",
    "most_connected = stats_df.loc[stats_df['Total Connections'].idxmax(), 'Type']\n",
    "least_connected = stats_df.loc[stats_df['Total Connections'].idxmin(), 'Type']\n",
    "\n",
    "print(f\"\\nMost connected: {most_connected}\")\n",
    "print(f\"Least connected: {least_connected}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Queen > KNN(6) > Rook in connectivity\")\n",
    "print(\"  - Queen includes diagonal neighbors (more inclusive)\")\n",
    "print(\"  - KNN ensures each region has exactly k=6 neighbors\")\n",
    "print(\"  - Rook only considers edge-sharing neighbors (most restrictive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize network for one focal region\n",
    "focal_idx = 12  # Center region (R13)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "matrices = [W_rook, W_queen, W_knn]\n",
    "titles = ['Rook', 'Queen', 'KNN (k=6)']\n",
    "\n",
    "for ax, W, title in zip(axes, matrices, titles):\n",
    "    # Plot all regions\n",
    "    ax.scatter(spatial_data['x'], spatial_data['y'], s=150,\n",
    "              c='lightgray', edgecolors='black', linewidth=1.5, zorder=2)\n",
    "    \n",
    "    # Highlight focal region\n",
    "    ax.scatter(spatial_data.loc[focal_idx, 'x'],\n",
    "              spatial_data.loc[focal_idx, 'y'],\n",
    "              s=300, c='red', edgecolors='black', linewidth=2, zorder=3,\n",
    "              label='Focal region')\n",
    "    \n",
    "    # Draw connections\n",
    "    num_neighbors = 0\n",
    "    for j in range(n_regions):\n",
    "        if W[focal_idx, j] == 1:\n",
    "            ax.plot([spatial_data.loc[focal_idx, 'x'], spatial_data.loc[j, 'x']],\n",
    "                   [spatial_data.loc[focal_idx, 'y'], spatial_data.loc[j, 'y']],\n",
    "                   'b-', linewidth=2, alpha=0.6, zorder=1)\n",
    "            ax.scatter(spatial_data.loc[j, 'x'], spatial_data.loc[j, 'y'],\n",
    "                      s=200, c='lightblue', edgecolors='black', linewidth=2, zorder=2)\n",
    "            num_neighbors += 1\n",
    "    \n",
    "    ax.set_xlabel('X Coordinate', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Y Coordinate', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{title}\\n({num_neighbors} neighbors)', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFocal region: {spatial_data.loc[focal_idx, 'region_id']} (center of grid)\")\n",
    "print(f\"  Rook neighbors: 4 (up, down, left, right)\")\n",
    "print(f\"  Queen neighbors: 8 (rook + diagonals)\")\n",
    "print(f\"  KNN neighbors: 6 (closest regions by distance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Custom Distance Function\n",
    "\n",
    "**Task**: Create distance-based weight matrix with exponential decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SOLUTION 2: EXPONENTIAL DISTANCE DECAY WEIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Create exponential decay weights\n",
    "alpha = 0.3\n",
    "W_exp = np.exp(-alpha * D)\n",
    "np.fill_diagonal(W_exp, 0)  # No self-connection\n",
    "\n",
    "print(f\"\\nFormula: w_ij = exp(-{alpha} × d_ij)\")\n",
    "print(f\"\\nWeight matrix created: {W_exp.shape}\")\n",
    "print(f\"Total connections (non-zero): {np.sum(W_exp > 0)}\")\n",
    "\n",
    "print(\"\\nFirst 5×5 block:\")\n",
    "display(pd.DataFrame(W_exp[:5, :5],\n",
    "                    index=spatial_data['region_id'][:5],\n",
    "                    columns=spatial_data['region_id'][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Row-normalize\n",
    "def row_normalize(W):\n",
    "    row_sums = W.sum(axis=1, keepdims=True)\n",
    "    row_sums[row_sums == 0] = 1\n",
    "    return W / row_sums\n",
    "\n",
    "W_exp_row = row_normalize(W_exp)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ROW-NORMALIZED EXPONENTIAL WEIGHTS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\nRow-normalized matrix (first 5×5):\")\n",
    "display(pd.DataFrame(W_exp_row[:5, :5],\n",
    "                    index=spatial_data['region_id'][:5],\n",
    "                    columns=spatial_data['region_id'][:5]))\n",
    "\n",
    "# Verify row sums\n",
    "row_sums = W_exp_row.sum(axis=1)\n",
    "print(f\"\\nRow sums (first 10): {row_sums[:10]}\")\n",
    "print(f\"All row sums = 1? {np.allclose(row_sums, 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compare with inverse distance weights\n",
    "W_inv = 1 / (D + np.eye(n_regions))\n",
    "np.fill_diagonal(W_inv, 0)\n",
    "W_inv_row = row_normalize(W_inv)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"COMPARISON: EXPONENTIAL vs INVERSE DISTANCE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Compare weights for one region\n",
    "focal_idx = 12\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Distance': D[focal_idx, :],\n",
    "    'Exp Decay': W_exp_row[focal_idx, :],\n",
    "    'Inv Distance': W_inv_row[focal_idx, :]\n",
    "}, index=spatial_data['region_id'])\n",
    "\n",
    "comparison_df = comparison_df[comparison_df['Distance'] > 0].sort_values('Distance')\n",
    "print(f\"\\nWeights from {spatial_data.loc[focal_idx, 'region_id']} (sorted by distance):\")\n",
    "display(comparison_df.head(10))\n",
    "\n",
    "# Visualize decay functions\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "distances = comparison_df['Distance'].values\n",
    "ax.scatter(distances, comparison_df['Exp Decay'], label='Exponential decay', \n",
    "          alpha=0.7, s=60, marker='o')\n",
    "ax.scatter(distances, comparison_df['Inv Distance'], label='Inverse distance', \n",
    "          alpha=0.7, s=60, marker='^')\n",
    "\n",
    "# Plot smooth curves\n",
    "d_range = np.linspace(distances.min(), distances.max(), 100)\n",
    "ax.plot(d_range, np.exp(-alpha * d_range) / np.exp(-alpha * d_range).sum(), \n",
    "       'b-', linewidth=2, alpha=0.5, label='Exp (normalized)')\n",
    "ax.plot(d_range, (1/d_range) / (1/d_range).sum(), \n",
    "       'r--', linewidth=2, alpha=0.5, label='Inv (normalized)')\n",
    "\n",
    "ax.set_xlabel('Distance', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Weight', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Distance Decay Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Exponential decay: Weights decline faster initially, slower at distance\")\n",
    "print(\"  - Inverse distance: More gradual decline\")\n",
    "print(\"  - Choice depends on economic theory about spatial spillovers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Spatial Lag with Real Data\n",
    "\n",
    "**Task**: Use Grunfeld dataset to compute spatial lag of investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SOLUTION 3: SPATIAL LAG WITH GRUNFELD DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load Grunfeld data\n",
    "data_path = '/home/guhaase/projetos/panelbox/examples/datasets/grunfeld.csv'\n",
    "grunfeld = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"\\nGrunfeld dataset loaded: {grunfeld.shape[0]} observations\")\n",
    "print(f\"Variables: {list(grunfeld.columns)}\")\n",
    "print(f\"Firms: {grunfeld['firm'].nunique()}\")\n",
    "print(f\"Years: {grunfeld['year'].min()} to {grunfeld['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Assume firms can be ordered by ID\n",
    "# Get unique firms\n",
    "firms = sorted(grunfeld['firm'].unique())\n",
    "n_firms = len(firms)\n",
    "print(f\"\\nFirms: {firms}\")\n",
    "print(f\"Number of firms: {n_firms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create KNN weight matrix based on value similarity\n",
    "# Use firm averages across years\n",
    "firm_avg = grunfeld.groupby('firm')['value'].mean().sort_index()\n",
    "\n",
    "print(\"\\nFirm average values:\")\n",
    "display(firm_avg)\n",
    "\n",
    "# Create distance matrix based on value differences\n",
    "value_matrix = firm_avg.values.reshape(-1, 1)\n",
    "D_value = np.abs(value_matrix - value_matrix.T)\n",
    "\n",
    "print(f\"\\nValue-based distance matrix: {D_value.shape}\")\n",
    "print(\"\\nDistance matrix (first 5×5):\")\n",
    "display(pd.DataFrame(D_value[:5, :5],\n",
    "                    index=firm_avg.index[:5],\n",
    "                    columns=firm_avg.index[:5]))\n",
    "\n",
    "# Create KNN weights (k=3)\n",
    "k = 3\n",
    "W_value_knn = create_knn_weights(D_value, k)\n",
    "\n",
    "# Symmetrize\n",
    "W_value_knn = np.maximum(W_value_knn, W_value_knn.T)\n",
    "\n",
    "# Row-normalize\n",
    "W_value_knn_row = row_normalize(W_value_knn)\n",
    "\n",
    "print(f\"\\nKNN weight matrix (k={k}) created and symmetrized\")\n",
    "print(f\"Row-normalized: {np.allclose(W_value_knn_row.sum(axis=1), 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute spatial lag of investment\n",
    "# Use firm averages for this exercise\n",
    "invest_avg = grunfeld.groupby('firm')['invest'].mean().sort_index()\n",
    "\n",
    "# Spatial lag: W × y\n",
    "invest_lag = W_value_knn_row @ invest_avg.values\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Firm': firm_avg.index,\n",
    "    'Investment': invest_avg.values,\n",
    "    'Investment_Lag': invest_lag,\n",
    "    'Value': firm_avg.values\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INVESTMENT AND SPATIAL LAG\")\n",
    "print(\"=\"*70)\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  Investment_Lag = weighted average of investment in similar firms\")\n",
    "print(\"  (similar = close in terms of firm value)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Plot investment vs spatial lag\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.scatter(results_df['Investment'], results_df['Investment_Lag'], \n",
    "          alpha=0.7, s=100, edgecolors='k', linewidth=1.5)\n",
    "\n",
    "# Add firm labels\n",
    "for idx, row in results_df.iterrows():\n",
    "    ax.annotate(row['Firm'], \n",
    "               xy=(row['Investment'], row['Investment_Lag']),\n",
    "               xytext=(5, 5), textcoords='offset points',\n",
    "               fontsize=8, alpha=0.7)\n",
    "\n",
    "# Add regression line\n",
    "from scipy.stats import linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(\n",
    "    results_df['Investment'], results_df['Investment_Lag'])\n",
    "\n",
    "x_line = np.linspace(results_df['Investment'].min(), \n",
    "                     results_df['Investment'].max(), 100)\n",
    "y_line = slope * x_line + intercept\n",
    "ax.plot(x_line, y_line, 'r--', linewidth=2, \n",
    "       label=f'Slope = {slope:.3f} (p={p_value:.4f})')\n",
    "\n",
    "ax.set_xlabel('Investment', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Spatial Lag of Investment', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Moran Scatterplot: Investment vs Spatial Lag\\n(Neighbors = Similar Firms by Value)', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if slope > 0 and p_value < 0.05:\n",
    "    print(\"\\nResult: Positive spatial autocorrelation\")\n",
    "    print(\"  → Firms with similar values tend to have similar investment levels\")\n",
    "    print(\"  → Suggests clustering in investment behavior\")\n",
    "else:\n",
    "    print(\"\\nResult: No significant spatial autocorrelation\")\n",
    "    print(\"  → Investment patterns not strongly related to firm value similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Test for Spatial Autocorrelation\n",
    "\n",
    "**Task**: Test if investment exhibits spatial autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SOLUTION 4: MORAN'S I TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use firm averages (N=10)\n",
    "print(f\"\\nData: Firm averages across years\")\n",
    "print(f\"N = {n_firms} firms\")\n",
    "print(f\"Variable: Investment (average)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create contiguity matrix\n",
    "# Assume firms 1-5 in one group, 6-10 in another\n",
    "W_groups = np.zeros((n_firms, n_firms))\n",
    "\n",
    "# Group 1: firms 0-4 (first 5)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i != j:\n",
    "            W_groups[i, j] = 1\n",
    "\n",
    "# Group 2: firms 5-9 (last 5)\n",
    "for i in range(5, 10):\n",
    "    for j in range(5, 10):\n",
    "        if i != j:\n",
    "            W_groups[i, j] = 1\n",
    "\n",
    "print(\"\\nContiguity matrix (group-based):\")\n",
    "print(\"  Group 1: Firms 1-5 (all connected within group)\")\n",
    "print(\"  Group 2: Firms 6-10 (all connected within group)\")\n",
    "print(\"  Between groups: No connections\")\n",
    "\n",
    "print(f\"\\nWeight matrix:\")\n",
    "display(pd.DataFrame(W_groups,\n",
    "                    index=firm_avg.index,\n",
    "                    columns=firm_avg.index))\n",
    "\n",
    "# Row-normalize\n",
    "W_groups_row = row_normalize(W_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate Moran's I\n",
    "def morans_i(y, W):\n",
    "    \"\"\"Calculate Moran's I statistic.\"\"\"\n",
    "    n = len(y)\n",
    "    y_mean = y.mean()\n",
    "    y_dev = y - y_mean\n",
    "    \n",
    "    # Numerator\n",
    "    numerator = np.sum(W * np.outer(y_dev, y_dev))\n",
    "    \n",
    "    # Denominator\n",
    "    denominator = np.sum(y_dev**2)\n",
    "    \n",
    "    # Normalization\n",
    "    S0 = W.sum()\n",
    "    \n",
    "    I = (n / S0) * (numerator / denominator)\n",
    "    \n",
    "    return I\n",
    "\n",
    "y = invest_avg.values\n",
    "I_observed = morans_i(y, W_groups_row)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MORAN'S I STATISTIC\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nMoran's I = {I_observed:.4f}\")\n",
    "\n",
    "# Expected value under null\n",
    "E_I = -1 / (n_firms - 1)\n",
    "print(f\"Expected I (H₀: no autocorrelation) = {E_I:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "if I_observed > E_I:\n",
    "    print(f\"\\nI = {I_observed:.4f} > E(I) = {E_I:.4f}\")\n",
    "    print(\"→ Positive spatial autocorrelation detected\")\n",
    "    print(\"→ Firms in same group have similar investment levels\")\n",
    "    print(\"→ Investment exhibits spatial clustering\")\n",
    "elif I_observed < E_I:\n",
    "    print(f\"\\nI = {I_observed:.4f} < E(I) = {E_I:.4f}\")\n",
    "    print(\"→ Negative spatial autocorrelation detected\")\n",
    "    print(\"→ Firms in same group have dissimilar investment levels\")\n",
    "    print(\"→ Investment exhibits spatial dispersion\")\n",
    "else:\n",
    "    print(f\"\\nI ≈ {I_observed:.4f} ≈ E(I) = {E_I:.4f}\")\n",
    "    print(\"→ No spatial autocorrelation\")\n",
    "    print(\"→ Investment is randomly distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize groups\n",
    "results_df['Group'] = ['Group 1' if i < 5 else 'Group 2' for i in range(n_firms)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Investment by group\n",
    "for group in ['Group 1', 'Group 2']:\n",
    "    group_data = results_df[results_df['Group'] == group]\n",
    "    axes[0].scatter(group_data.index, group_data['Investment'],\n",
    "                   label=group, s=100, alpha=0.7)\n",
    "    axes[0].plot(group_data.index, group_data['Investment'],\n",
    "                alpha=0.3, linewidth=2)\n",
    "\n",
    "axes[0].set_xlabel('Firm Index', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Investment', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Investment by Group', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "group1_inv = results_df[results_df['Group'] == 'Group 1']['Investment']\n",
    "group2_inv = results_df[results_df['Group'] == 'Group 2']['Investment']\n",
    "\n",
    "axes[1].boxplot([group1_inv, group2_inv], labels=['Group 1', 'Group 2'])\n",
    "axes[1].set_ylabel('Investment', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Investment Distribution by Group', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGroup statistics:\")\n",
    "print(f\"\\nGroup 1 (Firms 1-5):\")\n",
    "print(f\"  Mean investment: {group1_inv.mean():.2f}\")\n",
    "print(f\"  Std deviation: {group1_inv.std():.2f}\")\n",
    "\n",
    "print(f\"\\nGroup 2 (Firms 6-10):\")\n",
    "print(f\"  Mean investment: {group2_inv.mean():.2f}\")\n",
    "print(f\"  Std deviation: {group2_inv.std():.2f}\")\n",
    "\n",
    "if I_observed > E_I:\n",
    "    print(\"\\nPositive Moran's I indicates firms within same group are more similar\")\n",
    "    print(\"than firms between groups → Spatial clustering!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In these exercises, you practiced:\n",
    "\n",
    "✅ **Exercise 1**: Comparing different weight matrix types (rook, queen, KNN)\n",
    "✅ **Exercise 2**: Creating custom distance-based weights with exponential decay\n",
    "✅ **Exercise 3**: Computing spatial lags using real panel data\n",
    "✅ **Exercise 4**: Testing for spatial autocorrelation with Moran's I\n",
    "\n",
    "### Key Skills Acquired\n",
    "\n",
    "1. **Weight matrix construction**: Contiguity, distance, KNN approaches\n",
    "2. **Normalization**: Row and spectral normalization methods\n",
    "3. **Spatial lags**: Computing weighted averages of neighbors\n",
    "4. **Autocorrelation testing**: Moran's I statistic and interpretation\n",
    "\n",
    "### Weight Matrix Decision Guide\n",
    "\n",
    "| Scenario | Recommended Weight Matrix | Reason |\n",
    "|----------|---------------------------|--------|\n",
    "| Regular grid (states, counties) | Rook or Queen contiguity | Natural geographic neighbors |\n",
    "| Irregular boundaries | Queen contiguity | More inclusive definition |\n",
    "| Point locations | Distance-based or KNN | No clear boundaries |\n",
    "| Economic spillovers | Inverse distance or exponential | Theory of distance decay |\n",
    "| Uneven spatial distribution | KNN | Ensures balanced connectivity |\n",
    "| Trade/network data | Economic distance | Based on actual flows |\n",
    "\n",
    "### Normalization Guide\n",
    "\n",
    "- **Row normalization**: Most common; weights sum to 1 per row\n",
    "  - Interpretation: Share of influence\n",
    "  - Spatial lag = weighted average\n",
    "\n",
    "- **Spectral normalization**: For theoretical models\n",
    "  - Ensures eigenvalues ≤ 1\n",
    "  - Required for some spatial econometric estimators\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "You are now ready for:\n",
    "\n",
    "**Module 4: Spatial Panel Models**\n",
    "- Spatial Lag Model (SAR)\n",
    "- Spatial Error Model (SEM)\n",
    "- Spatial Durbin Model (SDM)\n",
    "- Direct and indirect effects decomposition\n",
    "\n",
    "Or continue with:\n",
    "\n",
    "**Module 2: Classical Panel Estimators**\n",
    "- Fixed Effects, Random Effects\n",
    "- Then return to spatial models later\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SOLUTIONS COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou've successfully completed all exercises in Tutorial 04.\")\n",
    "print(\"You now understand spatial weight matrices and autocorrelation!\")\n",
    "print(\"\\nNext: Module 2 (Classical Estimators) or Module 4 (Spatial Models)\")\n",
    "print(\"\\nExcellent work!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
