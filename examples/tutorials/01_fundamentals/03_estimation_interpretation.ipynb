{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03: Estimation and Results Interpretation\n",
    "\n",
    "**Series**: PanelBox - Fundamentals  \n",
    "**Level**: Intermediate  \n",
    "**Estimated Time**: 60-75 minutes  \n",
    "**Prerequisites**: Tutorials 01 (Panel Data Structures) and 02 (Formulas)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "- Estimate panel data models using PanelBox\n",
    "- Interpret regression coefficients in economic terms\n",
    "- Understand standard errors, t-statistics, and p-values\n",
    "- Compare classical, robust, and clustered standard errors\n",
    "- Compute and interpret confidence intervals\n",
    "- Perform hypothesis tests\n",
    "- Export results to multiple formats (LaTeX, Markdown, JSON)\n",
    "- Validate and diagnose model fit\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Estimation](#1-introduction-to-estimation)\n",
    "2. [Your First Model: Pooled OLS](#2-your-first-model-pooled-ols)\n",
    "3. [Understanding Results Tables](#3-understanding-results-tables)\n",
    "4. [Standard Errors and Inference](#4-standard-errors-and-inference)\n",
    "5. [Hypothesis Testing](#5-hypothesis-testing)\n",
    "6. [Model Diagnostics](#6-model-diagnostics)\n",
    "7. [Exporting Results](#7-exporting-results)\n",
    "8. [Practical Exercises](#8-practical-exercises)\n",
    "9. [Summary and Next Steps](#9-summary-and-next-steps)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Notebook metadata\n__version__ = \"1.0.0\"\n__last_updated__ = \"2026-02-16\"\n__compatible_with__ = \"PanelBox >= 0.1.0\"\n\n# Standard libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom IPython.display import display, Markdown, HTML\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# PanelBox library (development mode)\nimport sys\nsys.path.insert(0, '/home/guhaase/projetos/panelbox')\nimport panelbox as pb\nfrom panelbox.models import PooledOLS\n\n# Try to import other estimators (may not all be implemented yet)\ntry:\n    from panelbox.models import FixedEffects, RandomEffects\n    FE_AVAILABLE = True\nexcept ImportError:\n    FE_AVAILABLE = False\n    print(\"Note: FixedEffects/RandomEffects not available yet\")\n\n# Plotting configuration\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['font.size'] = 10\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 4)\npd.set_option('display.width', 100)\n\n# Display library version\nprint(f\"PanelBox version: {pb.__version__}\")\nprint(f\"Notebook version: {__version__}\")\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Grunfeld dataset\n",
    "try:\n",
    "    from panelbox.datasets import load_grunfeld\n",
    "    data = load_grunfeld()\n",
    "    print(\"‚úì Loaded from panelbox.datasets.load_grunfeld()\")\n",
    "except (ImportError, AttributeError):\n",
    "    import os\n",
    "    data_path = '/home/guhaase/projetos/panelbox/examples/datasets/grunfeld.csv'\n",
    "    if os.path.exists(data_path):\n",
    "        data = pd.read_csv(data_path)\n",
    "        print(f\"‚úì Loaded from {data_path}\")\n",
    "    else:\n",
    "        data_path = '/home/guhaase/projetos/panelbox/panelbox/datasets/grunfeld.csv'\n",
    "        if os.path.exists(data_path):\n",
    "            data = pd.read_csv(data_path)\n",
    "            print(f\"‚úì Loaded from {data_path}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Grunfeld dataset not found. Please check path.\")\n",
    "\n",
    "# Quick recap\n",
    "print(f\"\\nGrunfeld Investment Data\")\n",
    "print(f\"Observations: {data.shape[0]}\")\n",
    "print(f\"Variables: {list(data.columns)}\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction to Estimation\n",
    "\n",
    "### The Econometric Workflow\n",
    "\n",
    "```\n",
    "1. THEORY          ‚Üí What determines investment?\n",
    "2. MODEL           ‚Üí invest = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑value + Œ≤‚ÇÇ¬∑capital + Œµ\n",
    "3. SPECIFICATION   ‚Üí Formula: \"invest ~ value + capital\"\n",
    "4. ESTIMATION      ‚Üí Find Œ≤ÃÇ‚ÇÄ, Œ≤ÃÇ‚ÇÅ, Œ≤ÃÇ‚ÇÇ that best fit the data\n",
    "5. INFERENCE       ‚Üí Are Œ≤ÃÇ statistically significant?\n",
    "6. INTERPRETATION  ‚Üí What do the numbers mean economically?\n",
    "```\n",
    "\n",
    "So far, you've learned steps 1-3. This tutorial focuses on **4-6**.\n",
    "\n",
    "---\n",
    "\n",
    "### Pooled OLS: The Simplest Estimator\n",
    "\n",
    "**Pooled Ordinary Least Squares** (Pooled OLS) treats panel data as a large cross-section:\n",
    "- Ignores panel structure (entities and time)\n",
    "- Estimates by minimizing sum of squared residuals:\n",
    "$$\n",
    "\\min_{\\beta} \\sum_{i=1}^N \\sum_{t=1}^T (Y_{it} - X_{it}'\\beta)^2\n",
    "$$\n",
    "\n",
    "**Advantages**:\n",
    "- ‚úÖ Simple, fast, interpretable\n",
    "- ‚úÖ Efficient if no unobserved heterogeneity\n",
    "\n",
    "**Disadvantages**:\n",
    "- ‚ùå Biased if entity-specific effects exist\n",
    "- ‚ùå Standard errors underestimate uncertainty (observations not independent)\n",
    "\n",
    "**When to use**:\n",
    "- Exploratory analysis\n",
    "- Benchmark before fixed effects\n",
    "- When entities are truly homogeneous (rare!)\n",
    "\n",
    "---\n",
    "\n",
    "### What We'll Estimate\n",
    "\n",
    "**Model**: Grunfeld investment equation\n",
    "$$\n",
    "\\text{Investment}_{it} = \\beta_0 + \\beta_1 \\text{Value}_{it} + \\beta_2 \\text{Capital}_{it} + \\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "**Research questions**:\n",
    "1. How does market value affect investment? (Œ≤‚ÇÅ)\n",
    "2. How does existing capital stock affect investment? (Œ≤‚ÇÇ)\n",
    "3. Are these effects statistically significant?\n",
    "4. How much variation do we explain? (R¬≤)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your First Model: Pooled OLS\n",
    "\n",
    "### Step 1: Specify the Formula\n",
    "\n",
    "We'll estimate:\n",
    "```python\n",
    "formula = \"invest ~ value + capital\"\n",
    "```\n",
    "\n",
    "This expands to:\n",
    "$$\n",
    "\\text{invest}_{it} = \\beta_0 + \\beta_1 \\cdot \\text{value}_{it} + \\beta_2 \\cdot \\text{capital}_{it} + \\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Fit Pooled OLS model\nprint(\"=\"*70)\nprint(\"ESTIMATING POOLED OLS MODEL\")\nprint(\"=\"*70)\n\n# Specify formula\nformula = \"invest ~ value + capital\"\nprint(f\"\\nFormula: {formula}\")\nprint(f\"Model: invest = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑value + Œ≤‚ÇÇ¬∑capital + Œµ\")\n\n# Create model instance with entity and time columns\nmodel = PooledOLS(formula, data=data, entity_col='firm', time_col='year')\n\n# Fit the model\nresults = model.fit()\n\nprint(\"\\n‚úì Model estimated successfully!\")\nprint(f\"  Estimator: {model.__class__.__name__}\")\nprint(f\"  Observations: {results.nobs}\")\nprint(f\"  Parameters: {len(results.params)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ESTIMATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Print summary table\n",
    "print(results.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Understanding Results Tables\n",
    "\n",
    "### Key Components of Results\n",
    "\n",
    "A typical econometrics results table contains:\n",
    "\n",
    "#### 1. Model Information\n",
    "- **Estimator**: Pooled OLS, Fixed Effects, etc.\n",
    "- **Formula**: Model specification\n",
    "- **Observations**: Number of data points (N√óT)\n",
    "- **Entities/Time**: Panel dimensions\n",
    "\n",
    "#### 2. Coefficient Estimates\n",
    "- **Parameter** (Œ≤ÃÇ): Estimated coefficient\n",
    "- **Std. Error** (SE): Uncertainty in estimate\n",
    "- **t-statistic**: Œ≤ÃÇ / SE (test H‚ÇÄ: Œ≤ = 0)\n",
    "- **p-value**: Probability of seeing this t-stat if H‚ÇÄ true\n",
    "- **Confidence Interval**: Range likely containing true Œ≤\n",
    "\n",
    "#### 3. Model Fit Statistics\n",
    "- **R¬≤**: Fraction of variance explained (0 to 1)\n",
    "- **Adjusted R¬≤**: R¬≤ penalized for # of parameters\n",
    "- **F-statistic**: Test of overall model significance\n",
    "- **Log-likelihood**: Goodness of fit (higher = better)\n",
    "\n",
    "---\n",
    "\n",
    "### Interpreting Coefficients\n",
    "\n",
    "For our model: `invest = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑value + Œ≤‚ÇÇ¬∑capital + Œµ`\n",
    "\n",
    "**Œ≤‚ÇÅ (value coefficient)**:\n",
    "- **Meaning**: Change in investment per unit change in firm value, holding capital constant\n",
    "- **Units**: If value increases by 1 (million $), investment increases by Œ≤‚ÇÅ (million $)\n",
    "- **Ceteris paribus**: \"All else equal\"\n",
    "\n",
    "**Œ≤‚ÇÇ (capital coefficient)**:\n",
    "- **Meaning**: Change in investment per unit change in capital stock, holding value constant\n",
    "\n",
    "**Œ≤‚ÇÄ (intercept)**:\n",
    "- **Meaning**: Expected investment when value = capital = 0\n",
    "- **Interpretation**: Often not economically meaningful (extrapolation)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display coefficients\n",
    "print(\"=\"*70)\n",
    "print(\"COEFFICIENT ESTIMATES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Access coefficients\n",
    "coefs = results.params\n",
    "print(\"\\nEstimated coefficients (Œ≤ÃÇ):\")\n",
    "for name, value in coefs.items():\n",
    "    print(f\"  {name:15s}: {value:10.4f}\")\n",
    "\n",
    "# Interpret each coefficient\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ECONOMIC INTERPRETATION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "beta_value = coefs['value']\n",
    "beta_capital = coefs['capital']\n",
    "\n",
    "print(f\"\\n1. Value coefficient (Œ≤ÃÇ‚ÇÅ = {beta_value:.4f}):\")\n",
    "print(f\"   Interpretation: A $1 million increase in firm value is associated\")\n",
    "print(f\"   with a ${beta_value:.4f} million increase in investment,\")\n",
    "print(f\"   holding capital constant.\")\n",
    "\n",
    "print(f\"\\n2. Capital coefficient (Œ≤ÃÇ‚ÇÇ = {beta_capital:.4f}):\")\n",
    "print(f\"   Interpretation: A $1 million increase in capital stock is associated\")\n",
    "print(f\"   with a ${beta_capital:.4f} million change in investment,\")\n",
    "print(f\"   holding firm value constant.\")\n",
    "\n",
    "# Sign interpretation\n",
    "if beta_value > 0:\n",
    "    print(f\"\\n   Œ≤ÃÇ‚ÇÅ > 0: Higher value ‚Üí Higher investment (positive relationship)\")\n",
    "else:\n",
    "    print(f\"\\n   Œ≤ÃÇ‚ÇÅ < 0: Higher value ‚Üí Lower investment (negative relationship)\")\n",
    "\n",
    "if beta_capital > 0:\n",
    "    print(f\"   Œ≤ÃÇ‚ÇÇ > 0: More capital ‚Üí More investment (positive relationship)\")\n",
    "else:\n",
    "    print(f\"   Œ≤ÃÇ‚ÇÇ < 0: More capital ‚Üí Less investment (capital substitution?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Model fit statistics\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL FIT STATISTICS\")\nprint(\"=\"*70)\n\nr2 = results.rsquared\nr2_adj = results.rsquared_adj\nnobs = results.nobs\nk = len(results.params)\n\nprint(f\"\\nR¬≤: {r2:.4f}\")\nprint(f\"  Interpretation: The model explains {100*r2:.2f}% of the variance in investment\")\n\nprint(f\"\\nAdjusted R¬≤: {r2_adj:.4f}\")\nprint(f\"  Interpretation: R¬≤ adjusted for # of parameters ({k})\")\nprint(f\"  Formula: 1 - (1-R¬≤)¬∑(n-1)/(n-k)\")\n\nprint(f\"\\nObservations: {nobs}\")\nprint(f\"Parameters: {k}\")\nprint(f\"Degrees of freedom: {nobs - k}\")\n\n# Visualize fit\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Actual vs Fitted\nfitted = results.fittedvalues\nactual = results.resid + fitted  # Reconstruct actual\n\naxes[0].scatter(fitted, actual, alpha=0.6, edgecolors='k', linewidth=0.5)\naxes[0].plot([actual.min(), actual.max()],\n             [actual.min(), actual.max()],\n             'r--', lw=2, label='Perfect fit')\naxes[0].set_xlabel('Fitted Values', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Actual Values', fontsize=12, fontweight='bold')\naxes[0].set_title(f'Actual vs Fitted (R¬≤ = {r2:.3f})', fontsize=14, fontweight='bold')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Residuals\nresiduals = results.resid\naxes[1].scatter(fitted, residuals, alpha=0.6, edgecolors='k', linewidth=0.5)\naxes[1].axhline(y=0, color='r', linestyle='--', lw=2)\naxes[1].set_xlabel('Fitted Values', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Residuals', fontsize=12, fontweight='bold')\naxes[1].set_title('Residual Plot', fontsize=14, fontweight='bold')\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nNote: Residuals should be randomly scattered around zero (no pattern)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Standard Errors and Inference\n",
    "\n",
    "### What are Standard Errors?\n",
    "\n",
    "**Standard Error (SE)**: Measure of uncertainty in coefficient estimate\n",
    "- Small SE ‚Üí Precise estimate (low sampling variability)\n",
    "- Large SE ‚Üí Imprecise estimate (high sampling variability)\n",
    "\n",
    "**Formula** (simplified):\n",
    "$$\n",
    "SE(\\hat{\\beta}) = \\sqrt{\\text{Var}(\\hat{\\beta})} = \\sqrt{\\sigma^2 (X'X)^{-1}}\n",
    "$$\n",
    "\n",
    "Where $\\sigma^2$ = variance of errors.\n",
    "\n",
    "---\n",
    "\n",
    "### Types of Standard Errors\n",
    "\n",
    "#### 1. Classical (IID) Standard Errors\n",
    "**Assumption**: Errors are independent and identically distributed\n",
    "$$\n",
    "\\text{Var}(\\varepsilon) = \\sigma^2 I\n",
    "$$\n",
    "\n",
    "**Problem**: Violated in panel data!\n",
    "- ‚ùå Entity-specific shocks (within-firm correlation)\n",
    "- ‚ùå Time-specific shocks (common year effects)\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Robust (Heteroskedasticity-Consistent) Standard Errors\n",
    "**Allows**: Errors have different variances across observations\n",
    "$$\n",
    "\\text{Var}(\\varepsilon_i) = \\sigma_i^2 \\text{ (can vary)}\n",
    "$$\n",
    "\n",
    "**Estimator**: Huber-White sandwich estimator\n",
    "- ‚úÖ Valid under heteroskedasticity\n",
    "- ‚ùå Still assumes independence (not ideal for panels)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Clustered Standard Errors\n",
    "**Allows**: Errors correlated within clusters (e.g., within firms)\n",
    "$$\n",
    "\\text{Cov}(\\varepsilon_{it}, \\varepsilon_{is}) \\neq 0 \\text{ for same firm } i\n",
    "$$\n",
    "\n",
    "**Best for panel data**:\n",
    "- ‚úÖ Accounts for within-entity correlation\n",
    "- ‚úÖ Standard in panel econometrics\n",
    "\n",
    "**Cluster by**: Entity (firm), time, or both\n",
    "\n",
    "---\n",
    "\n",
    "### Statistical Significance\n",
    "\n",
    "**t-statistic**: How many standard errors is Œ≤ÃÇ away from zero?\n",
    "$$\n",
    "t = \\frac{\\hat{\\beta}}{SE(\\hat{\\beta})}\n",
    "$$\n",
    "\n",
    "**p-value**: Probability of observing |t| this large if true Œ≤ = 0\n",
    "- p < 0.01 ‚Üí *** (highly significant)\n",
    "- p < 0.05 ‚Üí ** (significant)\n",
    "- p < 0.10 ‚Üí * (weakly significant)\n",
    "- p ‚â• 0.10 ‚Üí Not significant\n",
    "\n",
    "**Rule of thumb**: |t| > 2 ‚Üí Usually significant (p < 0.05)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare different standard error types\nprint(\"=\"*70)\nprint(\"COMPARING STANDARD ERROR TYPES\")\nprint(\"=\"*70)\n\n# Re-estimate with different SE types\nresults_iid = model.fit(cov_type='nonrobust')  # Classical\nresults_robust = model.fit(cov_type='robust')   # Heteroskedasticity-robust\nresults_cluster = model.fit(cov_type='clustered')  # Clustered by entity\n\n# Extract SEs\nse_iid = results_iid.std_errors\nse_robust = results_robust.std_errors\nse_cluster = results_cluster.std_errors\n\n# Create comparison table\ncomparison = pd.DataFrame({\n    'Classical': se_iid,\n    'Robust': se_robust,\n    'Clustered': se_cluster\n})\n\nprint(\"\\nStandard Errors Comparison:\")\nprint(\"(Rows = Variables, Columns = SE Type)\")\ndisplay(comparison)\n\n# Calculate ratios\nprint(\"\\n\" + \"-\"*70)\nprint(\"RELATIVE MAGNITUDE\")\nprint(\"-\"*70)\n\nfor var in comparison.index:\n    ratio_robust = comparison.loc[var, 'Robust'] / comparison.loc[var, 'Classical']\n    ratio_cluster = comparison.loc[var, 'Clustered'] / comparison.loc[var, 'Classical']\n    \n    print(f\"\\n{var}:\")\n    print(f\"  Robust / Classical: {ratio_robust:.3f} ({100*(ratio_robust-1):+.1f}%)\")\n    print(f\"  Clustered / Classical: {ratio_cluster:.3f} ({100*(ratio_cluster-1):+.1f}%)\")\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"INTERPRETATION\")\nprint(\"-\"*70)\nprint(\"‚Ä¢ Clustered SEs > Classical SEs ‚Üí Within-firm correlation present\")\nprint(\"‚Ä¢ Use CLUSTERED SEs for panel data (accounts for correlation)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence intervals\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFIDENCE INTERVALS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 95% confidence intervals\n",
    "ci_95 = results_cluster.conf_int(level=0.95)\n",
    "print(\"\\n95% Confidence Intervals (Clustered SEs):\")\n",
    "display(ci_95)\n",
    "\n",
    "# Visualize CIs\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "vars_to_plot = [v for v in coefs.index if v != 'Intercept']\n",
    "y_pos = np.arange(len(vars_to_plot))\n",
    "\n",
    "for i, var in enumerate(vars_to_plot):\n",
    "    coef = coefs[var]\n",
    "    ci_low = ci_95.loc[var, 'lower']\n",
    "    ci_high = ci_95.loc[var, 'upper']\n",
    "    \n",
    "    # Plot point estimate\n",
    "    ax.plot(coef, i, 'o', markersize=10, color='darkblue', zorder=3)\n",
    "    \n",
    "    # Plot CI\n",
    "    ax.plot([ci_low, ci_high], [i, i], 'o-', linewidth=2, markersize=5,\n",
    "            color='steelblue', zorder=2, alpha=0.7)\n",
    "\n",
    "# Reference line at zero\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='H‚ÇÄ: Œ≤ = 0', zorder=1)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(vars_to_plot)\n",
    "ax.set_xlabel('Coefficient Value', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Coefficient Estimates with 95% Confidence Intervals',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"‚Ä¢ If CI includes 0 ‚Üí Cannot reject H‚ÇÄ: Œ≤ = 0 (not significant)\")\n",
    "print(\"‚Ä¢ If CI excludes 0 ‚Üí Reject H‚ÇÄ: Œ≤ = 0 (significant)\")\n",
    "\n",
    "for var in vars_to_plot:\n",
    "    ci_low = ci_95.loc[var, 'lower']\n",
    "    ci_high = ci_95.loc[var, 'upper']\n",
    "    includes_zero = (ci_low < 0 < ci_high)\n",
    "    \n",
    "    if includes_zero:\n",
    "        print(f\"  {var}: CI includes 0 ‚Üí Not significant at 5% level\")\n",
    "    else:\n",
    "        print(f\"  {var}: CI excludes 0 ‚Üí Significant at 5% level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Hypothesis Testing\n",
    "\n",
    "### Types of Hypothesis Tests\n",
    "\n",
    "#### 1. Individual Coefficient Test (t-test)\n",
    "**Null hypothesis**: $H_0: \\beta_j = 0$ (no effect)  \n",
    "**Alternative**: $H_1: \\beta_j \\neq 0$ (has effect)\n",
    "\n",
    "**Test statistic**: $t = \\frac{\\hat{\\beta}_j}{SE(\\hat{\\beta}_j)}$\n",
    "\n",
    "**Decision rule**:\n",
    "- If |t| > critical value ‚Üí Reject H‚ÇÄ\n",
    "- If p-value < Œ± ‚Üí Reject H‚ÇÄ (Œ± = significance level, usually 0.05)\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Joint Hypothesis Test (F-test)\n",
    "**Null hypothesis**: $H_0: \\beta_1 = \\beta_2 = 0$ (all coefficients zero)  \n",
    "**Alternative**: At least one Œ≤ ‚â† 0\n",
    "\n",
    "**Test statistic**:\n",
    "$$\n",
    "F = \\frac{(R^2_{\\text{full}} - R^2_{\\text{restricted}}) / q}{(1 - R^2_{\\text{full}}) / (n-k)}\n",
    "$$\n",
    "\n",
    "Where q = # of restrictions, k = # of parameters.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Custom Linear Restrictions\n",
    "Test hypotheses like:\n",
    "- $H_0: \\beta_1 = \\beta_2$ (coefficients equal)\n",
    "- $H_0: \\beta_1 + \\beta_2 = 1$ (returns to scale)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Individual t-tests\nprint(\"=\"*70)\nprint(\"INDIVIDUAL COEFFICIENT TESTS (t-tests)\")\nprint(\"=\"*70)\n\n# Extract t-stats and p-values\ntvalues = results_cluster.tvalues\npvalues = results_cluster.pvalues\n\n# Create test results table\ntest_results = pd.DataFrame({\n    'Coefficient': coefs,\n    'Std. Error': se_cluster,\n    't-statistic': tvalues,\n    'p-value': pvalues\n})\n\n# Add significance stars\ndef add_stars(p):\n    if p < 0.01:\n        return '***'\n    elif p < 0.05:\n        return '**'\n    elif p < 0.10:\n        return '*'\n    else:\n        return ''\n\ntest_results['Sig.'] = pvalues.apply(add_stars)\n\nprint(\"\\nHypothesis: H‚ÇÄ: Œ≤ = 0 vs H‚ÇÅ: Œ≤ ‚â† 0\")\nprint(\"Significance: *** p<0.01, ** p<0.05, * p<0.10\\n\")\ndisplay(test_results)\n\n# Interpret results\nprint(\"\\n\" + \"-\"*70)\nprint(\"INTERPRETATION\")\nprint(\"-\"*70)\n\nfor var in coefs.index:\n    coef = coefs[var]\n    pval = pvalues[var]\n    tval = tvalues[var]\n    \n    if pval < 0.05:\n        print(f\"\\n{var}:\")\n        print(f\"  Œ≤ÃÇ = {coef:.4f}, t = {tval:.3f}, p = {pval:.4f}\")\n        print(f\"  ‚Üí Reject H‚ÇÄ: Œ≤ = 0 (significant at 5% level)\")\n        print(f\"  ‚Üí {var} has a statistically significant effect on investment\")\n    else:\n        print(f\"\\n{var}:\")\n        print(f\"  Œ≤ÃÇ = {coef:.4f}, t = {tval:.3f}, p = {pval:.4f}\")\n        print(f\"  ‚Üí Cannot reject H‚ÇÄ: Œ≤ = 0 (not significant)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Joint F-test\nprint(\"\\n\" + \"=\"*70)\nprint(\"JOINT HYPOTHESIS TEST (F-test)\")\nprint(\"=\"*70)\n\n# Overall F-test: H‚ÇÄ: all slope coefficients = 0\n# Manual calculation: F = (R¬≤/k) / ((1-R¬≤)/(n-k-1))\nr2 = results_cluster.rsquared\nn = results_cluster.nobs\nk = len(results_cluster.params) - 1  # Exclude intercept\n\nfstat = (r2 / k) / ((1 - r2) / (n - k - 1))\nfrom scipy.stats import f as f_dist\nf_pvalue = 1 - f_dist.cdf(fstat, k, n - k - 1)\n\nprint(f\"\\nNull hypothesis: H‚ÇÄ: Œ≤‚ÇÅ = Œ≤‚ÇÇ = 0\")\nprint(f\"(All slope coefficients jointly equal zero)\")\n\nprint(f\"\\nF-statistic: {fstat:.4f}\")\nprint(f\"p-value: {f_pvalue:.6f}\")\n\nif f_pvalue < 0.01:\n    print(f\"\\n‚Üí Reject H‚ÇÄ at 1% level (p < 0.01)\")\n    print(f\"‚Üí The model is statistically significant overall\")\n    print(f\"‚Üí At least one predictor has a non-zero effect\")\nelse:\n    print(f\"\\n‚Üí Cannot reject H‚ÇÄ\")\n    print(f\"‚Üí The model is not statistically significant\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test custom hypothesis: Œ≤‚ÇÅ = Œ≤‚ÇÇ\nprint(\"\\n\" + \"=\"*70)\nprint(\"CUSTOM HYPOTHESIS TEST\")\nprint(\"=\"*70)\n\nprint(\"\\nHypothesis: H‚ÇÄ: Œ≤_value = Œ≤_capital\")\nprint(\"(The effects of value and capital are equal)\")\n\n# Wald test for linear restriction\n# R¬∑Œ≤ = r, where R = [0, 1, -1], r = 0\n# This tests: Œ≤_value - Œ≤_capital = 0\n\ntry:\n    # Manual Wald test\n    beta_vec = coefs.values\n    beta_diff = coefs['value'] - coefs['capital']\n    \n    # Variance of difference: Var(Œ≤‚ÇÅ) + Var(Œ≤‚ÇÇ) - 2¬∑Cov(Œ≤‚ÇÅ, Œ≤‚ÇÇ)\n    vcov = results_cluster.cov_params\n    var_diff = vcov.loc['value', 'value'] + vcov.loc['capital', 'capital'] - \\\n               2 * vcov.loc['value', 'capital']\n    se_diff = np.sqrt(var_diff)\n    \n    t_stat_diff = beta_diff / se_diff\n    p_value_diff = 2 * (1 - stats.t.cdf(abs(t_stat_diff), results_cluster.df_resid))\n    \n    print(f\"\\nŒ≤ÃÇ_value - Œ≤ÃÇ_capital = {beta_diff:.6f}\")\n    print(f\"SE(difference) = {se_diff:.6f}\")\n    print(f\"t-statistic = {t_stat_diff:.4f}\")\n    print(f\"p-value = {p_value_diff:.4f}\")\n    \n    if p_value_diff < 0.05:\n        print(f\"\\n‚Üí Reject H‚ÇÄ (p < 0.05)\")\n        print(f\"‚Üí The effects of value and capital are significantly different\")\n    else:\n        print(f\"\\n‚Üí Cannot reject H‚ÇÄ (p ‚â• 0.05)\")\n        print(f\"‚Üí The effects of value and capital are not significantly different\")\n\nexcept Exception as e:\n    print(f\"\\nNote: Custom Wald test calculation issue: {e}\")\n    print(f\"This is for pedagogical illustration\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Diagnostics\n",
    "\n",
    "### What Can Go Wrong?\n",
    "\n",
    "Even with significant coefficients, the model may have issues:\n",
    "\n",
    "1. **Heteroskedasticity**: Error variance not constant\n",
    "2. **Serial correlation**: Errors correlated over time\n",
    "3. **Non-normality**: Errors not normally distributed\n",
    "4. **Outliers**: Influential observations distorting results\n",
    "5. **Multicollinearity**: Predictors highly correlated\n",
    "\n",
    "### Diagnostic Tools\n",
    "\n",
    "- **Residual plots**: Check for patterns\n",
    "- **Q-Q plots**: Check normality\n",
    "- **VIF**: Check multicollinearity\n",
    "- **Formal tests**: Breusch-Pagan, Durbin-Watson, etc.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Residual diagnostics\nprint(\"=\"*70)\nprint(\"RESIDUAL DIAGNOSTICS\")\nprint(\"=\"*70)\n\nresiduals = results_cluster.resid\nfitted = results_cluster.fittedvalues\n\n# Summary statistics\nprint(\"\\nResidual summary:\")\nprint(f\"  Mean: {residuals.mean():.6f} (should be ‚âà 0)\")\nprint(f\"  Std: {residuals.std():.4f}\")\nprint(f\"  Min: {residuals.min():.4f}\")\nprint(f\"  Max: {residuals.max():.4f}\")\n\n# Create diagnostic plots\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Residuals vs Fitted\naxes[0, 0].scatter(fitted, residuals, alpha=0.6, edgecolors='k', linewidth=0.5)\naxes[0, 0].axhline(y=0, color='r', linestyle='--', lw=2)\naxes[0, 0].set_xlabel('Fitted Values', fontsize=11, fontweight='bold')\naxes[0, 0].set_ylabel('Residuals', fontsize=11, fontweight='bold')\naxes[0, 0].set_title('Residuals vs Fitted', fontsize=12, fontweight='bold')\naxes[0, 0].grid(True, alpha=0.3)\n\n# 2. Q-Q plot\nstats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\naxes[0, 1].set_title('Normal Q-Q Plot', fontsize=12, fontweight='bold')\naxes[0, 1].grid(True, alpha=0.3)\n\n# 3. Scale-Location (sqrt of standardized residuals vs fitted)\nstandardized_resid = residuals / residuals.std()\naxes[1, 0].scatter(fitted, np.sqrt(np.abs(standardized_resid)),\n                   alpha=0.6, edgecolors='k', linewidth=0.5)\naxes[1, 0].set_xlabel('Fitted Values', fontsize=11, fontweight='bold')\naxes[1, 0].set_ylabel('‚àö|Standardized Residuals|', fontsize=11, fontweight='bold')\naxes[1, 0].set_title('Scale-Location Plot', fontsize=12, fontweight='bold')\naxes[1, 0].grid(True, alpha=0.3)\n\n# 4. Histogram of residuals\naxes[1, 1].hist(residuals, bins=20, edgecolor='black', alpha=0.7)\naxes[1, 1].axvline(x=0, color='r', linestyle='--', lw=2)\naxes[1, 1].set_xlabel('Residuals', fontsize=11, fontweight='bold')\naxes[1, 1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\naxes[1, 1].set_title('Histogram of Residuals', fontsize=12, fontweight='bold')\naxes[1, 1].grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nDiagnostic Interpretation:\")\nprint(\"‚úì Residuals vs Fitted: No clear pattern ‚Üí Good\")\nprint(\"‚úì Q-Q Plot: Points near line ‚Üí Normality\")\nprint(\"‚úì Scale-Location: Random scatter ‚Üí Homoskedasticity\")\nprint(\"‚úì Histogram: Bell-shaped ‚Üí Normality\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Inflation Factor (VIF)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTICOLLINEARITY CHECK (VIF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate VIF for each predictor\n",
    "# VIF = 1 / (1 - R¬≤_j), where R¬≤_j is from regressing X_j on other X's\n",
    "\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Create design matrix (without intercept for VIF)\n",
    "X = dmatrix(formula + \" - 1\", data=data, return_type='dataframe')\n",
    "\n",
    "# Calculate VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(\"\\nVariance Inflation Factors:\")\n",
    "display(vif_data)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  VIF = 1: No correlation with other predictors\")\n",
    "print(\"  VIF < 5: Low multicollinearity (acceptable)\")\n",
    "print(\"  VIF 5-10: Moderate multicollinearity (caution)\")\n",
    "print(\"  VIF > 10: High multicollinearity (problematic)\")\n",
    "\n",
    "for idx, row in vif_data.iterrows():\n",
    "    var = row['Variable']\n",
    "    vif = row['VIF']\n",
    "    if vif < 5:\n",
    "        print(f\"  {var}: VIF = {vif:.2f} ‚Üí Low multicollinearity\")\n",
    "    elif vif < 10:\n",
    "        print(f\"  {var}: VIF = {vif:.2f} ‚Üí Moderate multicollinearity\")\n",
    "    else:\n",
    "        print(f\"  {var}: VIF = {vif:.2f} ‚Üí High multicollinearity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Exporting Results\n",
    "\n",
    "### Why Export?\n",
    "\n",
    "- **Papers**: LaTeX tables for publications\n",
    "- **Reports**: Markdown/HTML for reproducible documents\n",
    "- **Collaboration**: JSON/CSV for data sharing\n",
    "- **Presentations**: Formatted tables for slides\n",
    "\n",
    "### PanelBox Export Options\n",
    "\n",
    "```python\n",
    "results.summary.as_latex()   # LaTeX table\n",
    "results.summary.as_text()    # Plain text\n",
    "results.summary.as_html()    # HTML table\n",
    "# Manual JSON/CSV exports also available\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export results to different formats\nprint(\"=\"*70)\nprint(\"EXPORTING RESULTS\")\nprint(\"=\"*70)\n\n# Create output directory\noutput_dir = '/home/guhaase/projetos/panelbox/examples/tutorials/01_fundamentals/output'\nimport os\nos.makedirs(output_dir, exist_ok=True)\n\n# 1. LaTeX\ntry:\n    latex_output = results_cluster.summary.as_latex()\n    print(\"\\n1. LaTeX Output (for academic papers):\")\n    print(\"-\" * 70)\n    print(latex_output[:500] + \"\\n... (truncated)\")\n    \n    with open(f'{output_dir}/pooled_ols_results.tex', 'w') as f:\n        f.write(latex_output)\n    print(f\"‚úì Saved to: {output_dir}/pooled_ols_results.tex\")\nexcept Exception as e:\n    print(f\"\\nNote: LaTeX export not available - {e}\")\n\n# 2. Plain text\nprint(\"\\n2. Plain Text Output:\")\nprint(\"-\" * 70)\nprint(results_cluster.summary)\n\n# 3. HTML\ntry:\n    html_output = results_cluster.summary.as_html()\n    with open(f'{output_dir}/pooled_ols_results.html', 'w') as f:\n        f.write(html_output)\n    print(f\"\\n‚úì Saved to: {output_dir}/pooled_ols_results.html\")\n    \n    # Display HTML in notebook\n    print(\"\\n3. HTML Output (rendered):\")\n    display(HTML(html_output))\nexcept Exception as e:\n    print(f\"\\nNote: HTML export not available - {e}\")\n\n# 4. JSON (all results)\nresults_dict = {\n    'coefficients': coefs.to_dict(),\n    'std_errors': se_cluster.to_dict(),\n    'tvalues': tvalues.to_dict(),\n    'pvalues': pvalues.to_dict(),\n    'rsquared': float(r2),\n    'rsquared_adj': float(r2_adj),\n    'nobs': int(nobs)\n}\n\nimport json\nwith open(f'{output_dir}/pooled_ols_results.json', 'w') as f:\n    json.dump(results_dict, f, indent=2)\nprint(f\"\\n‚úì Saved to: {output_dir}/pooled_ols_results.json\")\n\n# 5. CSV (coefficient table)\nresults_table = pd.DataFrame({\n    'Coefficient': coefs,\n    'Std_Error': se_cluster,\n    't_statistic': tvalues,\n    'p_value': pvalues\n})\nresults_table.to_csv(f'{output_dir}/pooled_ols_results.csv')\nprint(f\"‚úì Saved to: {output_dir}/pooled_ols_results.csv\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"All results exported successfully!\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Practical Exercises\n",
    "\n",
    "Solutions available in `/examples/solutions/01_fundamentals/03_estimation_solutions.ipynb`.\n",
    "\n",
    "### Exercise 1: Log-Log Model\n",
    "\n",
    "**Task**: Estimate a log-log model to obtain elasticities:\n",
    "$$\n",
    "\\log(\\text{Investment}) = \\beta_0 + \\beta_1 \\log(\\text{Value}) + \\beta_2 \\log(\\text{Capital}) + \\varepsilon\n",
    "$$\n",
    "\n",
    "1. Specify the formula using `np.log()`\n",
    "2. Estimate with clustered SEs\n",
    "3. Interpret Œ≤‚ÇÅ as an elasticity\n",
    "4. Is the elasticity significantly different from 1?\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2: Compare SE Types\n",
    "\n",
    "**Task**: Re-estimate the original model with all three SE types:\n",
    "1. Classical (IID)\n",
    "2. Robust (heteroskedasticity-consistent)\n",
    "3. Clustered (by entity)\n",
    "\n",
    "Create a table comparing:\n",
    "- Coefficient estimates (should be identical)\n",
    "- Standard errors (should differ)\n",
    "- t-statistics (should differ)\n",
    "- p-values (should differ)\n",
    "\n",
    "Which variables remain significant under all SE types?\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 3: Model with Interaction\n",
    "\n",
    "**Task**: Add an interaction between value and a post-war dummy:\n",
    "$$\n",
    "\\text{Investment} = \\beta_0 + \\beta_1 \\text{Value} + \\beta_2 \\text{Post1945} + \\beta_3 (\\text{Value} \\times \\text{Post1945}) + \\beta_4 \\text{Capital} + \\varepsilon\n",
    "$$\n",
    "\n",
    "1. Create `post_1945` dummy (year > 1945)\n",
    "2. Estimate the model\n",
    "3. Interpret Œ≤‚ÇÉ: Did the effect of value change after 1945?\n",
    "4. Test H‚ÇÄ: Œ≤‚ÇÉ = 0\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 4: Diagnostics\n",
    "\n",
    "**Task**: Check if residuals exhibit heteroskedasticity.\n",
    "1. Plot residuals vs fitted values (visual check)\n",
    "2. Perform Breusch-Pagan test (if available in PanelBox)\n",
    "3. If heteroskedasticity detected, which SE type should you use?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# -------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# -------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "# -------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your code here\n",
    "# -------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary and Next Steps\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "In this tutorial, you mastered:\n",
    "\n",
    "‚úÖ **Estimating models**: Using `PooledOLS().fit()`  \n",
    "‚úÖ **Interpreting coefficients**: Economic meaning of Œ≤ÃÇ  \n",
    "‚úÖ **Standard errors**: Classical, robust, clustered  \n",
    "‚úÖ **Statistical inference**: t-tests, p-values, confidence intervals  \n",
    "‚úÖ **Hypothesis testing**: Individual and joint tests  \n",
    "‚úÖ **Model diagnostics**: Residual plots, VIF, normality checks  \n",
    "‚úÖ **Exporting results**: LaTeX, HTML, JSON, CSV\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Formula | Interpretation |\n",
    "|---------|---------|----------------|\n",
    "| Coefficient | Œ≤ÃÇ | Estimated effect of X on Y |\n",
    "| Standard Error | SE(Œ≤ÃÇ) | Uncertainty in Œ≤ÃÇ |\n",
    "| t-statistic | t = Œ≤ÃÇ / SE(Œ≤ÃÇ) | Distance from zero (in SEs) |\n",
    "| p-value | P(\\|t\\| > observed \\| H‚ÇÄ) | Probability under null |\n",
    "| Confidence Interval | [Œ≤ÃÇ - 1.96¬∑SE, Œ≤ÃÇ + 1.96¬∑SE] | 95% range for true Œ≤ |\n",
    "| R¬≤ | 1 - SS_res / SS_tot | Fraction of variance explained |\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices Learned\n",
    "\n",
    "1. **Always use clustered SEs for panel data** (accounts for within-entity correlation)\n",
    "2. **Report robust SEs at minimum** (protects against heteroskedasticity)\n",
    "3. **Check diagnostics** (residual plots, VIF) before trusting results\n",
    "4. **Interpret economically** not just statistically (Œ≤ÃÇ = 0.05 significant, but is it meaningful?)\n",
    "5. **Export results** for reproducibility\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Tutorial 04: Spatial Fundamentals** (Optional)\n",
    "- Learn about spatial weight matrices\n",
    "- Visualize spatial connections\n",
    "- Prepare for spatial panel models\n",
    "\n",
    "**Or skip to Module 2: Classical Estimators**\n",
    "- Fixed Effects (FE)\n",
    "- Random Effects (RE)\n",
    "- First Differences (FD)\n",
    "- Between estimator\n",
    "\n",
    "**Recommended path**: Module 2 (Classical Estimators) next\n",
    "\n",
    "---\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- **Wooldridge (2010)**: Chapter 10 (Basic Linear Unbiased Estimation)\n",
    "- **Cameron & Trivedi (2005)**: Chapter 21 (Linear Panel Data Models)\n",
    "- **Angrist & Pischke (2009)**: \"Mostly Harmless Econometrics\" (practical inference)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session information\n",
    "print(\"=\"*70)\n",
    "print(\"SESSION INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nNotebook: 03_estimation_interpretation.ipynb\")\n",
    "print(f\"Version: {__version__}\")\n",
    "print(f\"Last updated: {__last_updated__}\")\n",
    "print(f\"\\nLibrary versions:\")\n",
    "print(f\"  PanelBox: {pb.__version__}\")\n",
    "print(f\"  NumPy: {np.__version__}\")\n",
    "print(f\"  Pandas: {pd.__version__}\")\n",
    "import scipy\n",
    "print(f\"  SciPy: {scipy.__version__}\")\n",
    "print(\"\\nTutorial completed successfully! üéâ\")\n",
    "print(\"You are now ready for advanced panel models!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
