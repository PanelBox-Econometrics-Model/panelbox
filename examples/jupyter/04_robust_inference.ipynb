{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Inference and Advanced Techniques",
    "",
    "This notebook covers **robust inference methods** for panel data, including robust standard errors, bootstrap, sensitivity analysis, and outlier detection.",
    "",
    "## What You'll Learn",
    "",
    "- \u2705 8 types of robust standard errors",
    "- \u2705 When to use each standard error type",
    "- \u2705 4 bootstrap methods for panels",
    "- \u2705 Sensitivity analysis (leave-one-out, subset stability)",
    "- \u2705 Outlier detection and influence diagnostics",
    "- \u2705 Jackknife resampling",
    "- \u2705 Practical guidelines and comparisons",
    "",
    "## Table of Contents",
    "",
    "1. [Introduction](#introduction)",
    "2. [Robust Standard Errors](#robust-se)",
    "3. [Bootstrap Inference](#bootstrap)",
    "4. [Sensitivity Analysis](#sensitivity)",
    "5. [Outlier Detection](#outliers)",
    "6. [Jackknife Methods](#jackknife)",
    "7. [Practical Guidelines](#guidelines)",
    "",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Robust Inference {#introduction}",
    "",
    "### Why Robust Inference?",
    "",
    "Standard inference assumes:",
    "- Homoskedasticity (constant variance)",
    "- No serial correlation",
    "- No cross-sectional dependence",
    "- No outliers",
    "",
    "**Reality**: These assumptions are often violated!",
    "",
    "**Solution**: Robust inference methods provide valid inference even when assumptions fail.",
    "",
    "### What We'll Cover",
    "",
    "| Method | Purpose | When to Use |",
    "|--------|---------|-------------|",
    "| **Robust SE** | Adjust for heteroskedasticity/correlation | Always recommended |",
    "| **Bootstrap** | Distribution-free inference | Small samples, complex estimators |",
    "| **Sensitivity** | Check robustness to specification | Before finalizing results |",
    "| **Outliers** | Detect influential observations | Data quality concerns |",
    "",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries",
    "import numpy as np",
    "import pandas as pd",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "from scipy import stats",
    "",
    "import panelbox as pb",
    "",
    "# Configuration",
    "pd.set_option('display.max_columns', None)",
    "pd.set_option('display.precision', 4)",
    "np.random.seed(42)",
    "",
    "plt.style.use('seaborn-v0_8-darkgrid')",
    "sns.set_palette(\"husl\")",
    "",
    "print(f\"PanelBox version: {pb.__version__}\")",
    "print(\"Robust inference toolkit ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data",
    "data = pb.load_grunfeld()",
    "",
    "print(\"Dataset loaded:\")",
    "print(f\"Shape: {data.shape}\")",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## 2. Robust Standard Errors {#robust-se}",
    "",
    "PanelBox supports **8 types of robust standard errors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Standard (Non-Robust) Baseline",
    "",
    "First, let's see standard (non-robust) errors for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Effects with standard errors",
    "fe_standard = pb.FixedEffects(",
    "    formula=\"invest ~ value + capital\",",
    "    data=data,",
    "    entity_col=\"firm\",",
    "    time_col=\"year\"",
    ")",
    "results_standard = fe_standard.fit()",
    "",
    "print(\"FIXED EFFECTS - Standard Errors\")",
    "print(\"=\"*60)",
    "print(results_standard.summary())",
    "",
    "# Extract for comparison",
    "se_standard = results_standard.std_errors",
    "print(f\"\\nStandard errors:\")",
    "print(se_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Heteroskedasticity-Robust (HC0-HC3)",
    "",
    "**White standard errors** adjust for heteroskedasticity.",
    "",
    "Four variants with different finite-sample adjustments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare HC0-HC3",
    "hc_types = ['HC0', 'HC1', 'HC2', 'HC3']",
    "hc_results = {}",
    "",
    "for hc in hc_types:",
    "    model = pb.FixedEffects(",
    "        formula=\"invest ~ value + capital\",",
    "        data=data,",
    "        entity_col=\"firm\",",
    "        time_col=\"year\"",
    "    )",
    "    result = model.fit(cov_type=hc)",
    "    hc_results[hc] = result.std_errors",
    "",
    "# Create comparison table",
    "hc_comparison = pd.DataFrame(hc_results)",
    "hc_comparison['Standard'] = se_standard",
    "",
    "print(\"\\nHETEROSKEDASTICITY-ROBUST SE COMPARISON\")",
    "print(\"=\"*60)",
    "print(hc_comparison)",
    "",
    "print(\"\\n\ud83d\udca1 Interpretation:\")",
    "print(\"- HC0: Basic White SE (no finite-sample correction)\")",
    "print(\"- HC1: Degrees of freedom correction\")",
    "print(\"- HC2: Leverage-based correction\")",
    "print(\"- HC3: More conservative (recommended for small samples)\")",
    "print(\"\\nGenerally: HC0 < HC1 < HC2 < HC3 (conservativeness)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clustered Standard Errors",
    "",
    "**Clustered SE** allow for arbitrary correlation within clusters.",
    "",
    "Most common for panel data: cluster by entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustered by entity (firm)",
    "fe_clustered = pb.FixedEffects(",
    "    formula=\"invest ~ value + capital\",",
    "    data=data,",
    "    entity_col=\"firm\",",
    "    time_col=\"year\"",
    ")",
    "results_clustered = fe_clustered.fit(cov_type='clustered', cluster_entity=True)",
    "",
    "print(\"\\nCLUSTERED STANDARD ERRORS (by entity)\")",
    "print(\"=\"*60)",
    "print(f\"\\nStandard errors:\")",
    "print(results_clustered.std_errors)",
    "",
    "print(\"\\nComparison:\")",
    "comparison = pd.DataFrame({",
    "    'Standard': se_standard,",
    "    'Clustered': results_clustered.std_errors",
    "})",
    "print(comparison)",
    "print(\"\\n\ud83d\udca1 Clustered SE are typically larger (more conservative)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Driscoll-Kraay Standard Errors",
    "",
    "**Driscoll-Kraay SE** robust to:",
    "- Heteroskedasticity",
    "- Serial correlation",
    "- Cross-sectional dependence (spatial correlation)",
    "",
    "**Recommended** for macro panels (countries, regions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driscoll-Kraay",
    "fe_dk = pb.FixedEffects(",
    "    formula=\"invest ~ value + capital\",",
    "    data=data,",
    "    entity_col=\"firm\",",
    "    time_col=\"year\"",
    ")",
    "results_dk = fe_dk.fit(cov_type='driscoll_kraay')",
    "",
    "print(\"\\nDRISCOLL-KRAAY STANDARD ERRORS\")",
    "print(\"=\"*60)",
    "print(f\"\\nStandard errors:\")",
    "print(results_dk.std_errors)",
    "",
    "print(\"\\n\ud83d\udca1 Driscoll-Kraay:\")",
    "print(\"- Robust to both serial and spatial correlation\")",
    "print(\"- Works for T \u2192 \u221e (long panels)\")",
    "print(\"- Commonly used in macro/finance panels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Newey-West (HAC) Standard Errors",
    "",
    "**Newey-West SE** (Heteroskedasticity and Autocorrelation Consistent):",
    "- Adjusts for heteroskedasticity",
    "- Adjusts for serial correlation up to lag L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newey-West with 2 lags",
    "fe_nw = pb.FixedEffects(",
    "    formula=\"invest ~ value + capital\",",
    "    data=data,",
    "    entity_col=\"firm\",",
    "    time_col=\"year\"",
    ")",
    "results_nw = fe_nw.fit(cov_type='newey_west', lags=2)",
    "",
    "print(\"\\nNEWEY-WEST (HAC) STANDARD ERRORS\")",
    "print(\"=\"*60)",
    "print(f\"Lags: 2\")",
    "print(f\"\\nStandard errors:\")",
    "print(results_nw.std_errors)",
    "",
    "print(\"\\n\ud83d\udca1 Newey-West:\")",
    "print(\"- Choose lags based on data frequency\")",
    "print(\"- Rule of thumb: L = floor(4*(T/100)^(2/9))\")",
    "print(\"- For T=20: L \u2248 2-3 lags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Panel-Corrected Standard Errors (PCSE)",
    "",
    "**PCSE** (Parks 1967):",
    "- Accounts for panel-specific heteroskedasticity",
    "- Accounts for contemporaneous correlation",
    "- Accounts for serial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCSE",
    "fe_pcse = pb.FixedEffects(",
    "    formula=\"invest ~ value + capital\",",
    "    data=data,",
    "    entity_col=\"firm\",",
    "    time_col=\"year\"",
    ")",
    "results_pcse = fe_pcse.fit(cov_type='pcse')",
    "",
    "print(\"\\nPANEL-CORRECTED STANDARD ERRORS (PCSE)\")",
    "print(\"=\"*60)",
    "print(f\"\\nStandard errors:\")",
    "print(results_pcse.std_errors)",
    "",
    "print(\"\\n\ud83d\udca1 PCSE:\")",
    "print(\"- Good for: N < T (few entities, many time periods)\")",
    "print(\"- Estimates full variance-covariance matrix\")",
    "print(\"- Can be unstable if N is large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Comprehensive Comparison",
    "",
    "Let's compare all SE types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison",
    "se_comparison = pd.DataFrame({",
    "    'Standard': se_standard,",
    "    'HC1': hc_results['HC1'],",
    "    'HC3': hc_results['HC3'],",
    "    'Clustered': results_clustered.std_errors,",
    "    'Driscoll-Kraay': results_dk.std_errors,",
    "    'Newey-West': results_nw.std_errors,",
    "    'PCSE': results_pcse.std_errors",
    "})",
    "",
    "print(\"\\nCOMPREHENSIVE SE COMPARISON\")",
    "print(\"=\"*70)",
    "print(se_comparison.round(4))",
    "",
    "# Visualize",
    "fig, ax = plt.subplots(figsize=(12, 6))",
    "",
    "x = np.arange(len(se_comparison.index))",
    "width = 0.1",
    "",
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink']",
    "for i, col in enumerate(se_comparison.columns):",
    "    offset = (i - len(se_comparison.columns)/2) * width",
    "    ax.bar(x + offset, se_comparison[col], width, label=col, alpha=0.8, color=colors[i])",
    "",
    "ax.set_xlabel('Variables', fontsize=12)",
    "ax.set_ylabel('Standard Error', fontsize=12)",
    "ax.set_title('Comparison of Standard Error Types', fontsize=14, fontweight='bold')",
    "ax.set_xticks(x)",
    "ax.set_xticklabels(se_comparison.index, rotation=45, ha='right')",
    "ax.legend()",
    "ax.grid(True, alpha=0.3, axis='y')",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(\"\\n\ud83d\udcca Observations:\")",
    "print(\"- Robust SE typically larger than standard SE\")",
    "print(\"- Clustered and Driscoll-Kraay most conservative\")",
    "print(\"- Choice affects t-statistics and p-values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Which SE?",
    "",
    "| Situation | Recommended SE | Reason |",
    "|-----------|---------------|---------|",
    "| **Default** | Clustered (entity) | Safe, allows within-entity correlation |",
    "| **Heteroskedasticity only** | HC1 or HC3 | Simpler, efficient |",
    "| **Serial correlation** | Newey-West or Driscoll-Kraay | HAC properties |",
    "| **Macro panels** | Driscoll-Kraay | Handles spatial correlation |",
    "| **Small N, large T** | PCSE | Efficient estimation |",
    "| **Short panels (small T)** | HC3 or Clustered | Finite-sample robust |",
    "",
    "**Rule of thumb**: When in doubt, use **clustered SE** (conservative and safe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## 3. Bootstrap Inference {#bootstrap}",
    "",
    "**Bootstrap** provides distribution-free inference:",
    "- No normality assumption needed",
    "- Works for complex estimators",
    "- Provides confidence intervals and standard errors",
    "",
    "PanelBox supports **4 bootstrap methods** for panels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pairs Bootstrap",
    "",
    "**Method**: Resample (i,t) pairs with replacement",
    "",
    "**Use**: General purpose, maintains dependence structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairs bootstrap",
    "bootstrap = pb.PanelBootstrap(",
    "    model=fe_standard,",
    "    method='pairs',",
    "    n_bootstrap=1000,",
    "    seed=42",
    ")",
    "",
    "bootstrap_results = bootstrap.run()",
    "",
    "print(\"PAIRS BOOTSTRAP\")",
    "print(\"=\"*60)",
    "print(f\"Bootstrap iterations: 1000\")",
    "print(f\"\\nBootstrap standard errors:\")",
    "print(bootstrap_results.std_errors)",
    "",
    "print(f\"\\n95% Confidence intervals (percentile method):\")",
    "print(bootstrap_results.conf_int())",
    "",
    "print(\"\\nComparison with clustered SE:\")",
    "comparison_boot = pd.DataFrame({",
    "    'Clustered SE': results_clustered.std_errors,",
    "    'Bootstrap SE': bootstrap_results.std_errors",
    "})",
    "print(comparison_boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Wild Bootstrap",
    "",
    "**Method**: Multiplies residuals by random weights",
    "",
    "**Use**: Heteroskedasticity-robust, preserves X",
    "",
    "**Advantage**: Doesn't require resampling X (good for small N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wild bootstrap",
    "bootstrap_wild = pb.PanelBootstrap(",
    "    model=fe_standard,",
    "    method='wild',",
    "    n_bootstrap=1000,",
    "    seed=42",
    ")",
    "",
    "wild_results = bootstrap_wild.run()",
    "",
    "print(\"\\nWILD BOOTSTRAP\")",
    "print(\"=\"*60)",
    "print(f\"\\nBootstrap standard errors:\")",
    "print(wild_results.std_errors)",
    "",
    "print(\"\\n\ud83d\udca1 Wild Bootstrap:\")",
    "print(\"- Better for heteroskedasticity\")",
    "print(\"- Preserves X (no resampling of regressors)\")",
    "print(\"- Good for small N, large T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Block Bootstrap",
    "",
    "**Method**: Resample blocks of time periods",
    "",
    "**Use**: Preserves within-entity serial correlation",
    "",
    "**Important**: Block length affects results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block bootstrap with block length 5",
    "bootstrap_block = pb.PanelBootstrap(",
    "    model=fe_standard,",
    "    method='block',",
    "    block_length=5,",
    "    n_bootstrap=1000,",
    "    seed=42",
    ")",
    "",
    "block_results = bootstrap_block.run()",
    "",
    "print(\"\\nBLOCK BOOTSTRAP\")",
    "print(\"=\"*60)",
    "print(f\"Block length: 5\")",
    "print(f\"\\nBootstrap standard errors:\")",
    "print(block_results.std_errors)",
    "",
    "print(\"\\n\ud83d\udca1 Block Bootstrap:\")",
    "print(\"- Preserves serial correlation within blocks\")",
    "print(\"- Block length choice matters:\")",
    "print(\"  - Too small: Doesn't capture dependence\")",
    "print(\"  - Too large: Few effective resamples\")",
    "print(\"  - Rule of thumb: L = T^(1/3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Residual Bootstrap",
    "",
    "**Method**: Resample residuals (assumes homoskedasticity)",
    "",
    "**Use**: If you're confident about homoskedasticity",
    "",
    "**Advantage**: More efficient under correct assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual bootstrap",
    "bootstrap_resid = pb.PanelBootstrap(",
    "    model=fe_standard,",
    "    method='residual',",
    "    n_bootstrap=1000,",
    "    seed=42",
    ")",
    "",
    "resid_results = bootstrap_resid.run()",
    "",
    "print(\"\\nRESIDUAL BOOTSTRAP\")",
    "print(\"=\"*60)",
    "print(f\"\\nBootstrap standard errors:\")",
    "print(resid_results.std_errors)",
    "",
    "print(\"\\n\u26a0 Caution:\")",
    "print(\"- Assumes homoskedasticity!\")",
    "print(\"- Invalid if heteroskedasticity present\")",
    "print(\"- Use wild bootstrap instead if uncertain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Bootstrap Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all bootstrap methods",
    "bootstrap_comparison = pd.DataFrame({",
    "    'Pairs': bootstrap_results.std_errors,",
    "    'Wild': wild_results.std_errors,",
    "    'Block': block_results.std_errors,",
    "    'Residual': resid_results.std_errors,",
    "    'Clustered SE': results_clustered.std_errors",
    "})",
    "",
    "print(\"\\nBOOTSTRAP METHODS COMPARISON\")",
    "print(\"=\"*60)",
    "print(bootstrap_comparison.round(4))",
    "",
    "# Plot",
    "fig, ax = plt.subplots(figsize=(10, 6))",
    "",
    "bootstrap_comparison.T.plot(kind='bar', ax=ax, rot=45, alpha=0.8)",
    "ax.set_xlabel('Method', fontsize=12)",
    "ax.set_ylabel('Standard Error', fontsize=12)",
    "ax.set_title('Bootstrap Methods Comparison', fontsize=14, fontweight='bold')",
    "ax.legend(title='Variables')",
    "ax.grid(True, alpha=0.3, axis='y')",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(\"\\n\ud83d\udcca Which bootstrap to use?\")",
    "print(\"- Pairs: Default, general purpose\")",
    "print(\"- Wild: Heteroskedasticity present\")",
    "print(\"- Block: Serial correlation present\")",
    "print(\"- Residual: Only if homoskedasticity certain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## 4. Sensitivity Analysis {#sensitivity}",
    "",
    "**Sensitivity analysis** checks if results are robust to specification changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Leave-One-Out Analysis",
    "",
    "Check if results driven by specific entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-one-out sensitivity",
    "sensitivity = pb.SensitivityAnalysis(fe_standard)",
    "",
    "loo_results = sensitivity.leave_one_out()",
    "",
    "print(\"LEAVE-ONE-OUT ANALYSIS\")",
    "print(\"=\"*60)",
    "print(f\"\\nCoefficient ranges when dropping each firm:\")",
    "print(loo_results.summary())",
    "",
    "# Plot coefficient stability",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))",
    "",
    "for i, var in enumerate(['value', 'capital']):",
    "    coef_range = loo_results.coefficient_range(var)",
    "    ",
    "    axes[i].scatter(range(len(coef_range)), coef_range, alpha=0.6)",
    "    axes[i].axhline(y=results_standard.params[var], color='red', linestyle='--', ",
    "                    label='Full sample', linewidth=2)",
    "    axes[i].set_xlabel('Dropped Firm', fontsize=12)",
    "    axes[i].set_ylabel(f'{var} Coefficient', fontsize=12)",
    "    axes[i].set_title(f'Leave-One-Out: {var}', fontsize=13, fontweight='bold')",
    "    axes[i].legend()",
    "    axes[i].grid(True, alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(\"\\n\ud83d\udca1 Interpretation:\")",
    "print(\"- If coefficient stable \u2192 Results robust\")",
    "print(\"- If large jumps \u2192 Driven by specific entities\")",
    "print(\"- Investigate outliers if unstable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Subset Stability Analysis",
    "",
    "Check stability across different subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset stability (e.g., by time period)",
    "stability = sensitivity.subset_stability(split_var='year', n_splits=2)",
    "",
    "print(\"\\nSUBSET STABILITY ANALYSIS\")",
    "print(\"=\"*60)",
    "print(f\"\\nCoefficients by time period:\")",
    "print(stability.summary())",
    "",
    "print(\"\\n\ud83d\udca1 Check if coefficients stable over time\")",
    "print(\"- Stable \u2192 No structural break\")",
    "print(\"- Unstable \u2192 Consider time interactions or break points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Influence Diagnostics",
    "",
    "Identify influential observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Influence diagnostics",
    "influence = pb.InfluenceDiagnostics(fe_standard)",
    "",
    "influence_results = influence.compute()",
    "",
    "print(\"\\nINFLUENCE DIAGNOSTICS\")",
    "print(\"=\"*60)",
    "print(f\"\\nTop 10 influential observations:\")",
    "print(influence_results.top_influential(n=10))",
    "",
    "# Plot influence measures",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))",
    "",
    "# Cook's distance",
    "axes[0].scatter(range(len(influence_results.cooks_d)), ",
    "                influence_results.cooks_d, alpha=0.6)",
    "axes[0].axhline(y=4/len(data), color='red', linestyle='--', ",
    "                label='Threshold (4/n)')",
    "axes[0].set_xlabel('Observation', fontsize=12)",
    "axes[0].set_ylabel(\"Cook's Distance\", fontsize=12)",
    "axes[0].set_title(\"Cook's Distance\", fontsize=13, fontweight='bold')",
    "axes[0].legend()",
    "axes[0].grid(True, alpha=0.3)",
    "",
    "# DFBETAS",
    "axes[1].scatter(range(len(influence_results.dfbetas)), ",
    "                influence_results.dfbetas[:, 0], alpha=0.6)",
    "axes[1].axhline(y=2/np.sqrt(len(data)), color='red', linestyle='--', ",
    "                label='Threshold (2/\u221an)')",
    "axes[1].axhline(y=-2/np.sqrt(len(data)), color='red', linestyle='--')",
    "axes[1].set_xlabel('Observation', fontsize=12)",
    "axes[1].set_ylabel('DFBETAS (value)', fontsize=12)",
    "axes[1].set_title('DFBETAS for value coefficient', fontsize=13, fontweight='bold')",
    "axes[1].legend()",
    "axes[1].grid(True, alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(\"\\n\ud83d\udca1 Influence measures:\")",
    "print(\"- Cook's D: Overall influence on fitted values\")",
    "print(\"- DFBETAS: Influence on specific coefficients\")",
    "print(\"- Large values \u2192 Potential outliers or leverage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## 5. Outlier Detection {#outliers}",
    "",
    "**Outlier detection** identifies unusual observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection",
    "outlier_detector = pb.OutlierDetector(fe_standard)",
    "",
    "outlier_results = outlier_detector.detect()",
    "",
    "print(\"OUTLIER DETECTION\")",
    "print(\"=\"*60)",
    "print(f\"\\nOutliers detected: {outlier_results.n_outliers}\")",
    "print(f\"\\nOutlier observations:\")",
    "print(outlier_results.outliers)",
    "",
    "# Visualize residuals",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))",
    "",
    "# Residuals vs fitted",
    "axes[0].scatter(fe_standard.fitted_values, fe_standard.residuals, alpha=0.6)",
    "axes[0].axhline(y=0, color='red', linestyle='--')",
    "axes[0].set_xlabel('Fitted Values', fontsize=12)",
    "axes[0].set_ylabel('Residuals', fontsize=12)",
    "axes[0].set_title('Residuals vs Fitted', fontsize=13, fontweight='bold')",
    "axes[0].grid(True, alpha=0.3)",
    "",
    "# Mark outliers in red",
    "outlier_idx = outlier_results.outlier_indices",
    "axes[0].scatter(fe_standard.fitted_values[outlier_idx], ",
    "                fe_standard.residuals[outlier_idx], ",
    "                color='red', s=100, alpha=0.7, label='Outliers')",
    "axes[0].legend()",
    "",
    "# Q-Q plot",
    "stats.probplot(fe_standard.residuals, dist=\"norm\", plot=axes[1])",
    "axes[1].set_title('Q-Q Plot', fontsize=13, fontweight='bold')",
    "axes[1].grid(True, alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(\"\\n\ud83d\udca1 What to do with outliers?\")",
    "print(\"1. Investigate: Data entry errors?\")",
    "print(\"2. Keep if genuine: Use robust methods\")",
    "print(\"3. Report sensitivity: Results with/without outliers\")",
    "print(\"4. Consider robust estimation (M-estimators)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## 6. Jackknife Methods {#jackknife}",
    "",
    "**Jackknife** systematically drops observations to estimate variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jackknife",
    "jackknife = pb.PanelJackknife(fe_standard)",
    "",
    "jackknife_results = jackknife.run()",
    "",
    "print(\"JACKKNIFE ANALYSIS\")",
    "print(\"=\"*60)",
    "print(f\"\\nJackknife standard errors:\")",
    "print(jackknife_results.std_errors)",
    "",
    "print(\"\\nComparison:\")",
    "comparison_jack = pd.DataFrame({",
    "    'Standard': se_standard,",
    "    'Clustered': results_clustered.std_errors,",
    "    'Bootstrap': bootstrap_results.std_errors,",
    "    'Jackknife': jackknife_results.std_errors",
    "})",
    "print(comparison_jack.round(4))",
    "",
    "print(\"\\n\ud83d\udca1 Jackknife vs Bootstrap:\")",
    "print(\"- Jackknife: Deterministic, faster\")",
    "print(\"- Bootstrap: More flexible, better properties\")",
    "print(\"- Often give similar results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## 7. Practical Guidelines {#guidelines}",
    "",
    "### Decision Tree: Which Method to Use?",
    "",
    "```",
    "Choose robust inference method:",
    "\u2502",
    "\u251c\u2500 Standard errors",
    "\u2502  \u2502",
    "\u2502  \u251c\u2500 Default \u2192 Clustered (entity)",
    "\u2502  \u251c\u2500 Heteroskedasticity only \u2192 HC1 or HC3",
    "\u2502  \u251c\u2500 Serial correlation \u2192 Newey-West or Driscoll-Kraay",
    "\u2502  \u251c\u2500 Spatial correlation \u2192 Driscoll-Kraay",
    "\u2502  \u2514\u2500 Small N, large T \u2192 PCSE",
    "\u2502",
    "\u251c\u2500 Bootstrap",
    "\u2502  \u2502",
    "\u2502  \u251c\u2500 General \u2192 Pairs",
    "\u2502  \u251c\u2500 Heteroskedasticity \u2192 Wild",
    "\u2502  \u251c\u2500 Serial correlation \u2192 Block",
    "\u2502  \u2514\u2500 Small sample \u2192 Wild or Block",
    "\u2502",
    "\u251c\u2500 Sensitivity",
    "\u2502  \u2502",
    "\u2502  \u251c\u2500 Check robustness \u2192 Leave-one-out",
    "\u2502  \u251c\u2500 Time stability \u2192 Subset analysis",
    "\u2502  \u2514\u2500 Influential obs \u2192 Influence diagnostics",
    "\u2502",
    "\u2514\u2500 Outliers",
    "   \u2502",
    "   \u251c\u2500 Detect \u2192 OutlierDetector",
    "   \u2514\u2500 Handle \u2192 Report sensitivity",
    "```",
    "",
    "### Recommended Workflow",
    "",
    "1. \u2705 **Start with clustered SE** (conservative default)",
    "2. \u2705 **Check for violations** (use validation tests)",
    "3. \u2705 **Apply appropriate SE** based on test results",
    "4. \u2705 **Run sensitivity analysis** (leave-one-out)",
    "5. \u2705 **Check for outliers** (influence diagnostics)",
    "6. \u2705 **Bootstrap if needed** (small samples, complex models)",
    "7. \u2705 **Report multiple specifications** (show robustness)",
    "",
    "### Quick Reference Table",
    "",
    "| Concern | Method | PanelBox Code |",
    "|---------|--------|---------------|",
    "| **Heteroskedasticity** | HC1/HC3 | `fit(cov_type='HC1')` |",
    "| **Serial correlation** | Newey-West | `fit(cov_type='newey_west')` |",
    "| **Spatial correlation** | Driscoll-Kraay | `fit(cov_type='driscoll_kraay')` |",
    "| **Small sample** | Bootstrap | `PanelBootstrap(method='wild')` |",
    "| **Outliers** | Sensitivity | `OutlierDetector()` |",
    "| **Robustness check** | Leave-one-out | `SensitivityAnalysis()` |",
    "",
    "### Best Practices",
    "",
    "1. \u2705 **Always use robust SE** - Standard SE rarely appropriate",
    "2. \u2705 **Cluster by entity** - Safe default for panels",
    "3. \u2705 **Bootstrap for complex models** - GMM, IV, etc.",
    "4. \u2705 **Check sensitivity** - Don't rely on single specification",
    "5. \u2705 **Investigate outliers** - But don't automatically drop",
    "6. \u2705 **Report multiple SE types** - Show robustness in papers",
    "",
    "---",
    "",
    "## Summary",
    "",
    "You learned:",
    "",
    "\u2705 **8 Robust SE Types**: HC0-HC3, clustered, Driscoll-Kraay, Newey-West, PCSE",
    "\u2705 **4 Bootstrap Methods**: Pairs, wild, block, residual",
    "\u2705 **Sensitivity Analysis**: Leave-one-out, subset stability, influence",
    "\u2705 **Outlier Detection**: Multiple methods and visualization",
    "\u2705 **Jackknife**: Alternative to bootstrap",
    "\u2705 **Practical Guidelines**: When to use what",
    "",
    "### Key Takeaways",
    "",
    "1. **Clustered SE** are the safe default for panel data",
    "2. **Bootstrap** when you need distribution-free inference",
    "3. **Always check sensitivity** to outliers and specification",
    "4. **Report multiple methods** to demonstrate robustness",
    "",
    "### Next Steps",
    "",
    "- **[05_report_generation.ipynb](./05_report_generation.ipynb)**: Create publication-ready reports",
    "- **[03_validation_complete.ipynb](./03_validation_complete.ipynb)**: Comprehensive testing",
    "- **[02_dynamic_gmm_complete.ipynb](./02_dynamic_gmm_complete.ipynb)**: Dynamic panels",
    "",
    "---",
    "",
    "*Robust inference with confidence using PanelBox!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
