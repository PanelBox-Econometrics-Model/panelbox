{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Guide to Static Panel Models\n",
    "\n",
    "This notebook provides a comprehensive guide to **static panel data models** in PanelBox, covering all five estimators and when to use each.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- ✅ All 5 static panel models (Pooled OLS, Between, Fixed Effects, Random Effects, First Difference)\n",
    "- ✅ When to use each model\n",
    "- ✅ Specification tests (F-test, Hausman test)\n",
    "- ✅ Robust standard errors (8 types)\n",
    "- ✅ Model comparison and interpretation\n",
    "- ✅ Report generation (HTML, Markdown, LaTeX)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Static Panel Models](#introduction)\n",
    "2. [Data Preparation](#data-preparation)\n",
    "3. [The Five Models](#five-models)\n",
    "   - 3.1 [Pooled OLS](#pooled-ols)\n",
    "   - 3.2 [Between Estimator](#between)\n",
    "   - 3.3 [Fixed Effects](#fixed-effects)\n",
    "   - 3.4 [Random Effects](#random-effects)\n",
    "   - 3.5 [First Difference](#first-difference)\n",
    "4. [Specification Tests](#specification-tests)\n",
    "5. [Robust Standard Errors](#robust-se)\n",
    "6. [Model Comparison](#model-comparison)\n",
    "7. [Report Generation](#report-generation)\n",
    "8. [Decision Guide](#decision-guide)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Static Panel Models {#introduction}\n",
    "\n",
    "### What are Static Panel Models?\n",
    "\n",
    "**Static panel models** are used when:\n",
    "- No lagged dependent variable on the right-hand side\n",
    "- Focus on contemporaneous relationships\n",
    "- Want to control for unobserved heterogeneity\n",
    "\n",
    "### General Form:\n",
    "\n",
    "$$y_{it} = \\alpha + \\beta' X_{it} + u_{it}$$\n",
    "\n",
    "Where:\n",
    "- $y_{it}$: Dependent variable for entity $i$ at time $t$\n",
    "- $X_{it}$: Vector of independent variables\n",
    "- $u_{it}$: Error term\n",
    "\n",
    "### Error Structure:\n",
    "\n",
    "The key difference between models is how they handle the error term:\n",
    "\n",
    "$$u_{it} = \\alpha_i + \\varepsilon_{it}$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha_i$: Entity-specific time-invariant effect (unobserved heterogeneity)\n",
    "- $\\varepsilon_{it}$: Idiosyncratic error\n",
    "\n",
    "### The Five Models:\n",
    "\n",
    "| Model | Assumption about $\\alpha_i$ | Use Case |\n",
    "|-------|------------------------|----------|\n",
    "| **Pooled OLS** | $\\alpha_i = 0$ | Baseline (usually biased) |\n",
    "| **Between** | Uses cross-sectional variation only | Long-run effects |\n",
    "| **Fixed Effects** | $\\alpha_i$ correlated with $X_{it}$ | Control for unobserved heterogeneity |\n",
    "| **Random Effects** | $\\alpha_i$ uncorrelated with $X_{it}$ | Efficient if assumption holds |\n",
    "| **First Difference** | Differences out $\\alpha_i$ | Short-run effects |\n",
    "\n",
    "Let's dive into each model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# PanelBox\n",
    "import panelbox as pb\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"PanelBox version: {pb.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Preparation {#data-preparation}\n",
    "\n",
    "We'll use the **Grunfeld dataset** throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pb.load_grunfeld()\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"\\nVariables: {list(data.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Panel Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel structure analysis\n",
    "print(\"Panel Structure:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Number of firms (N): {data['firm'].nunique()}\")\n",
    "print(f\"Number of years (T): {data['year'].nunique()}\")\n",
    "print(f\"Total observations (N×T): {len(data)}\")\n",
    "print(f\"Panel type: Balanced\")\n",
    "print(f\"\\nTime span: {data['year'].min()} - {data['year'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(\"=\"*60)\n",
    "data[['invest', 'value', 'capital']].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose variation: between vs within\n",
    "variables = ['invest', 'value', 'capital']\n",
    "\n",
    "print(\"\\nVariance Decomposition (Between vs Within):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for var in variables:\n",
    "    # Total variance\n",
    "    total_var = data[var].var()\n",
    "    \n",
    "    # Between variance (across firms)\n",
    "    firm_means = data.groupby('firm')[var].mean()\n",
    "    between_var = firm_means.var()\n",
    "    \n",
    "    # Within variance (within firms over time)\n",
    "    data[f'{var}_demeaned'] = data.groupby('firm')[var].transform(lambda x: x - x.mean())\n",
    "    within_var = data[f'{var}_demeaned'].var()\n",
    "    \n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"  Total Variance:   {total_var:10.2f}\")\n",
    "    print(f\"  Between Variance: {between_var:10.2f} ({100*between_var/total_var:.1f}%)\")\n",
    "    print(f\"  Within Variance:  {within_var:10.2f} ({100*within_var/total_var:.1f}%)\")\n",
    "\n",
    "# Clean up temporary columns\n",
    "data = data.drop(columns=[col for col in data.columns if '_demeaned' in col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight**: If between variance >> within variance, Fixed Effects may remove too much variation. If within variance is substantial, FE can be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investment trends by firm\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for firm_id in data['firm'].unique():\n",
    "    firm_data = data[data['firm'] == firm_id]\n",
    "    ax.plot(firm_data['year'], firm_data['invest'], marker='o', label=f'Firm {firm_id}', alpha=0.7, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Investment', fontsize=12)\n",
    "ax.set_title('Investment Over Time by Firm', fontsize=14, fontweight='bold')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- Clear firm-specific levels (between variation)\")\n",
    "print(\"- Temporal trends within firms (within variation)\")\n",
    "print(\"- This suggests Fixed Effects could be appropriate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. The Five Models {#five-models}\n",
    "\n",
    "We'll estimate all five models on the same specification:\n",
    "\n",
    "$$\\text{invest}_{it} = \\beta_0 + \\beta_1 \\text{value}_{it} + \\beta_2 \\text{capital}_{it} + u_{it}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pooled OLS {#pooled-ols}\n",
    "\n",
    "**Pooled OLS** treats all observations as independent, ignoring the panel structure.\n",
    "\n",
    "**Assumption**: $\\alpha_i = 0$ (no firm-specific effects)\n",
    "\n",
    "**Pros**:\n",
    "- Simple\n",
    "- Uses all variation (between + within)\n",
    "- Baseline for comparison\n",
    "\n",
    "**Cons**:\n",
    "- ❌ Ignores unobserved heterogeneity\n",
    "- ❌ Biased if $\\alpha_i$ correlated with $X_{it}$\n",
    "- ❌ Standard errors incorrect (need clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Pooled OLS\n",
    "pooled = pb.PooledOLS(\n",
    "    formula=\"invest ~ value + capital\",\n",
    "    data=data,\n",
    "    entity_col=\"firm\",\n",
    "    time_col=\"year\"\n",
    ")\n",
    "\n",
    "pooled_results = pooled.fit()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 1: POOLED OLS\")\n",
    "print(\"=\"*70)\n",
    "print(pooled_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "- Both `value` and `capital` are highly significant\n",
    "- R² is high, suggesting good fit\n",
    "- **BUT**: This assumes no firm-specific effects (likely violated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Between Estimator {#between}\n",
    "\n",
    "**Between Estimator** uses only cross-sectional variation by averaging over time for each firm.\n",
    "\n",
    "**Method**: \n",
    "1. Calculate firm-specific means: $\\bar{y}_i = \\frac{1}{T}\\sum_t y_{it}$\n",
    "2. Run OLS on these means: $\\bar{y}_i = \\beta_0 + \\beta' \\bar{X}_i + u_i$\n",
    "\n",
    "**Pros**:\n",
    "- Captures long-run relationships\n",
    "- Uses between variation\n",
    "- Simple interpretation\n",
    "\n",
    "**Cons**:\n",
    "- ❌ Throws away all within variation\n",
    "- ❌ Only N observations (not N×T)\n",
    "- ❌ Inefficient compared to other estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Between model\n",
    "between = pb.BetweenEstimator(\n",
    "    formula=\"invest ~ value + capital\",\n",
    "    data=data,\n",
    "    entity_col=\"firm\",\n",
    "    time_col=\"year\"\n",
    ")\n",
    "\n",
    "between_results = between.fit()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 2: BETWEEN ESTIMATOR\")\n",
    "print(\"=\"*70)\n",
    "print(between_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "- Uses only 10 observations (firm averages)\n",
    "- Captures differences between firms (long-run)\n",
    "- Compare coefficients with Pooled OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fixed Effects (FE) {#fixed-effects}\n",
    "\n",
    "**Fixed Effects** is the workhorse of panel econometrics.\n",
    "\n",
    "**Method**: Include firm dummies to control for $\\alpha_i$\n",
    "\n",
    "$$y_{it} = \\alpha_i + \\beta' X_{it} + \\varepsilon_{it}$$\n",
    "\n",
    "**Equivalently**: \"Within\" transformation (demean by firm)\n",
    "\n",
    "$$(y_{it} - \\bar{y}_i) = \\beta' (X_{it} - \\bar{X}_i) + (\\varepsilon_{it} - \\bar{\\varepsilon}_i)$$\n",
    "\n",
    "**Pros**:\n",
    "- ✅ Controls for all time-invariant unobserved heterogeneity\n",
    "- ✅ Consistent even if $\\alpha_i$ correlated with $X_{it}$\n",
    "- ✅ Uses within variation\n",
    "- ✅ No distributional assumptions on $\\alpha_i$\n",
    "\n",
    "**Cons**:\n",
    "- ❌ Cannot estimate time-invariant variables\n",
    "- ❌ May remove too much variation\n",
    "- ❌ Less efficient than RE if RE assumptions hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Fixed Effects\n",
    "fe = pb.FixedEffects(\n",
    "    formula=\"invest ~ value + capital\",\n",
    "    data=data,\n",
    "    entity_col=\"firm\",\n",
    "    time_col=\"year\"\n",
    ")\n",
    "\n",
    "fe_results = fe.fit()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 3: FIXED EFFECTS (WITHIN ESTIMATOR)\")\n",
    "print(\"=\"*70)\n",
    "print(fe_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "- Coefficients differ from Pooled OLS (controlling for $\\alpha_i$)\n",
    "- Within R² shows fit after removing firm effects\n",
    "- This is often the preferred estimator in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Random Effects (RE) {#random-effects}\n",
    "\n",
    "**Random Effects** uses GLS estimation, treating $\\alpha_i$ as random.\n",
    "\n",
    "**Assumption**: $\\alpha_i$ is **uncorrelated** with $X_{it}$\n",
    "\n",
    "$$\\mathbb{E}[\\alpha_i | X_{i1}, ..., X_{iT}] = 0$$\n",
    "\n",
    "**Method**: Quasi-demeaning with optimal weight $\\theta$\n",
    "\n",
    "$$(y_{it} - \\theta\\bar{y}_i) = \\beta_0(1-\\theta) + \\beta'(X_{it} - \\theta\\bar{X}_i) + v_{it}$$\n",
    "\n",
    "Where $\\theta$ is chosen to minimize variance.\n",
    "\n",
    "**Pros**:\n",
    "- ✅ More efficient than FE (if assumption holds)\n",
    "- ✅ Can estimate time-invariant variables\n",
    "- ✅ Uses both between and within variation\n",
    "- ✅ Better for small T\n",
    "\n",
    "**Cons**:\n",
    "- ❌ Inconsistent if $\\alpha_i$ correlated with $X_{it}$\n",
    "- ❌ Strong assumption (use Hausman test to check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Random Effects\n",
    "re = pb.RandomEffects(\n",
    "    formula=\"invest ~ value + capital\",\n",
    "    data=data,\n",
    "    entity_col=\"firm\",\n",
    "    time_col=\"year\"\n",
    ")\n",
    "\n",
    "re_results = re.fit()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 4: RANDOM EFFECTS (GLS ESTIMATOR)\")\n",
    "print(\"=\"*70)\n",
    "print(re_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "- Coefficients typically between Pooled OLS and FE\n",
    "- More efficient than FE (smaller standard errors) if assumption holds\n",
    "- **Critical**: Use Hausman test to check if RE is valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 First Difference (FD) {#first-difference}\n",
    "\n",
    "**First Difference** eliminates $\\alpha_i$ by taking first differences.\n",
    "\n",
    "**Method**: Transform to differences\n",
    "\n",
    "$$\\Delta y_{it} = y_{it} - y_{it-1} = \\beta' \\Delta X_{it} + \\Delta \\varepsilon_{it}$$\n",
    "\n",
    "The $\\alpha_i$ term drops out!\n",
    "\n",
    "**Pros**:\n",
    "- ✅ Eliminates $\\alpha_i$ without demeaning\n",
    "- ✅ Focuses on short-run changes\n",
    "- ✅ Can handle non-stationarity\n",
    "- ✅ Robust to certain forms of measurement error\n",
    "\n",
    "**Cons**:\n",
    "- ❌ Loses N observations (one per entity)\n",
    "- ❌ Amplifies measurement error\n",
    "- ❌ Less efficient than FE if errors are serially uncorrelated\n",
    "- ❌ More efficient than FE if errors are random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate First Difference\n",
    "fd = pb.FirstDifferenceEstimator(\n",
    "    formula=\"invest ~ value + capital\",\n",
    "    data=data,\n",
    "    entity_col=\"firm\",\n",
    "    time_col=\"year\"\n",
    ")\n",
    "\n",
    "fd_results = fd.fit()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 5: FIRST DIFFERENCE\")\n",
    "print(\"=\"*70)\n",
    "print(fd_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "- Estimates effect of **changes** in X on **changes** in y\n",
    "- Lost 10 observations (one per firm from differencing)\n",
    "- Compare with FE to see if results are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Specification Tests {#specification-tests}\n",
    "\n",
    "How do we choose between models? Use **specification tests**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 F-Test: Pooled OLS vs Fixed Effects\n",
    "\n",
    "**Null hypothesis**: $\\alpha_1 = \\alpha_2 = ... = \\alpha_N$ (Pooled OLS is adequate)\n",
    "\n",
    "**Alternative**: At least one $\\alpha_i$ differs (need Fixed Effects)\n",
    "\n",
    "The F-statistic is automatically included in FE output. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The F-test is in the FE results\n",
    "print(\"F-Test: Pooled OLS vs Fixed Effects\")\n",
    "print(\"=\"*60)\n",
    "print(f\"F-statistic: {fe_results.f_statistic:.4f}\")\n",
    "print(f\"P-value: {fe_results.f_pvalue:.4e}\")\n",
    "print(f\"\\nDecision: \", end=\"\")\n",
    "\n",
    "if fe_results.f_pvalue < 0.05:\n",
    "    print(\"Reject H₀ → Use Fixed Effects (firm effects are significant)\")\n",
    "else:\n",
    "    print(\"Fail to reject H₀ → Pooled OLS is adequate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Hausman Test: Fixed Effects vs Random Effects\n",
    "\n",
    "**Null hypothesis**: $\\mathbb{E}[\\alpha_i | X_{it}] = 0$ (RE is consistent and efficient)\n",
    "\n",
    "**Alternative**: $\\mathbb{E}[\\alpha_i | X_{it}] \\neq 0$ (RE is inconsistent, use FE)\n",
    "\n",
    "**Test statistic**:\n",
    "\n",
    "$$H = (\\hat{\\beta}_{FE} - \\hat{\\beta}_{RE})' [Var(\\hat{\\beta}_{FE}) - Var(\\hat{\\beta}_{RE})]^{-1} (\\hat{\\beta}_{FE} - \\hat{\\beta}_{RE}) \\sim \\chi^2_k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hausman Test\n",
    "hausman = pb.HausmanTest(fe_results, re_results)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HAUSMAN TEST: Fixed Effects vs Random Effects\")\n",
    "print(\"=\"*60)\n",
    "print(hausman)\n",
    "\n",
    "print(f\"\\n\\nDecision: \", end=\"\")\n",
    "if hausman.pvalue < 0.05:\n",
    "    print(\"Reject H₀ → Use Fixed Effects\")\n",
    "    print(\"(Random effects assumption violated)\")\n",
    "else:\n",
    "    print(\"Fail to reject H₀ → Can use Random Effects\")\n",
    "    print(\"(RE is consistent and more efficient)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practical Note**: \n",
    "- If Hausman test rejects (p < 0.05): Use **Fixed Effects**\n",
    "- If Hausman test doesn't reject: Use **Random Effects** (more efficient)\n",
    "- When in doubt: Use **Fixed Effects** (safer, always consistent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Robust Standard Errors {#robust-se}\n",
    "\n",
    "PanelBox supports **8 types of robust standard errors**:\n",
    "\n",
    "1. **HC0-HC3**: Heteroskedasticity-robust (White standard errors)\n",
    "2. **clustered**: Cluster-robust (by entity or time)\n",
    "3. **driscoll_kraay**: Robust to spatial and temporal correlation\n",
    "4. **newey_west**: HAC (heteroskedasticity and autocorrelation consistent)\n",
    "5. **pcse**: Panel-corrected standard errors (Parks 1967)\n",
    "\n",
    "Let's demonstrate the most common: **clustered standard errors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Clustered Standard Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Effects with clustered SE (by firm)\n",
    "fe_clustered = pb.FixedEffects(\n",
    "    formula=\"invest ~ value + capital\",\n",
    "    data=data,\n",
    "    entity_col=\"firm\",\n",
    "    time_col=\"year\"\n",
    ")\n",
    "\n",
    "fe_clustered_results = fe_clustered.fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FIXED EFFECTS WITH CLUSTERED STANDARD ERRORS\")\n",
    "print(\"=\"*70)\n",
    "print(fe_clustered_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Compare Different Standard Errors\n",
    "\n",
    "Let's see how different SE types affect inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate FE with different SE types\n",
    "se_types = ['standard', 'HC0', 'HC1', 'HC2', 'HC3', 'clustered']\n",
    "se_comparison = []\n",
    "\n",
    "for se_type in se_types:\n",
    "    model = pb.FixedEffects(\n",
    "        formula=\"invest ~ value + capital\",\n",
    "        data=data,\n",
    "        entity_col=\"firm\",\n",
    "        time_col=\"year\"\n",
    "    )\n",
    "    \n",
    "    if se_type == 'standard':\n",
    "        results = model.fit()\n",
    "    elif se_type == 'clustered':\n",
    "        results = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "    else:\n",
    "        results = model.fit(cov_type=se_type)\n",
    "    \n",
    "    se_comparison.append({\n",
    "        'SE Type': se_type,\n",
    "        'value SE': results.std_errors['value'],\n",
    "        'capital SE': results.std_errors['capital']\n",
    "    })\n",
    "\n",
    "se_df = pd.DataFrame(se_comparison)\n",
    "print(\"\\nStandard Error Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(se_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Clustered SE are typically larger (more conservative)\")\n",
    "print(\"- HC variants adjust for heteroskedasticity\")\n",
    "print(\"- Choice matters for inference (t-stats, p-values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to use each:**\n",
    "\n",
    "- **Standard**: Only if you're confident errors are i.i.d. (rare in panel data)\n",
    "- **HC0-HC3**: Heteroskedasticity but no serial correlation\n",
    "- **Clustered**: ⭐ **Recommended for panel data** (allows within-entity correlation)\n",
    "- **Driscoll-Kraay**: Cross-sectional dependence (spatial correlation)\n",
    "- **Newey-West**: Serial correlation with known lag structure\n",
    "- **PCSE**: Panel-specific heteroskedasticity and serial correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Model Comparison {#model-comparison}\n",
    "\n",
    "Let's create a comprehensive comparison table of all five models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['Pooled OLS', 'Between', 'Fixed Effects', 'Random Effects', 'First Diff'],\n",
    "    'value_coef': [\n",
    "        pooled_results.params['value'],\n",
    "        between_results.params['value'],\n",
    "        fe_results.params['value'],\n",
    "        re_results.params['value'],\n",
    "        fd_results.params['value']\n",
    "    ],\n",
    "    'value_se': [\n",
    "        pooled_results.std_errors['value'],\n",
    "        between_results.std_errors['value'],\n",
    "        fe_results.std_errors['value'],\n",
    "        re_results.std_errors['value'],\n",
    "        fd_results.std_errors['value']\n",
    "    ],\n",
    "    'capital_coef': [\n",
    "        pooled_results.params['capital'],\n",
    "        between_results.params['capital'],\n",
    "        fe_results.params['capital'],\n",
    "        re_results.params['capital'],\n",
    "        fd_results.params['capital']\n",
    "    ],\n",
    "    'capital_se': [\n",
    "        pooled_results.std_errors['capital'],\n",
    "        between_results.std_errors['capital'],\n",
    "        fe_results.std_errors['capital'],\n",
    "        re_results.std_errors['capital'],\n",
    "        fd_results.std_errors['capital']\n",
    "    ],\n",
    "    'R²': [\n",
    "        pooled_results.rsquared,\n",
    "        between_results.rsquared,\n",
    "        fe_results.rsquared_within,\n",
    "        re_results.rsquared,\n",
    "        fd_results.rsquared\n",
    "    ],\n",
    "    'N_obs': [\n",
    "        pooled_results.nobs,\n",
    "        between_results.nobs,\n",
    "        fe_results.nobs,\n",
    "        re_results.nobs,\n",
    "        fd_results.nobs\n",
    "    ]\n",
    "}\n",
    "\n",
    "comp_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(comp_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTES:\")\n",
    "print(\"- Standard errors in parentheses\")\n",
    "print(\"- FE R² is within R² (after removing firm effects)\")\n",
    "print(\"- FD lost 10 observations from differencing\")\n",
    "print(\"- Between uses only 10 observations (firm means)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Coefficient Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coefficients across models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "models = ['Pooled', 'Between', 'FE', 'RE', 'FD']\n",
    "\n",
    "# Value coefficient\n",
    "value_coefs = comp_df['value_coef'].values\n",
    "value_ses = comp_df['value_se'].values\n",
    "y_pos = np.arange(len(models))\n",
    "\n",
    "axes[0].errorbar(value_coefs, y_pos, xerr=1.96*value_ses, fmt='o', markersize=10, capsize=5, capthick=2)\n",
    "axes[0].set_yticks(y_pos)\n",
    "axes[0].set_yticklabels(models)\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('Coefficient Estimate', fontsize=12)\n",
    "axes[0].set_title('Value Coefficient Across Models', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Capital coefficient\n",
    "capital_coefs = comp_df['capital_coef'].values\n",
    "capital_ses = comp_df['capital_se'].values\n",
    "\n",
    "axes[1].errorbar(capital_coefs, y_pos, xerr=1.96*capital_ses, fmt='o', markersize=10, capsize=5, capthick=2, color='green')\n",
    "axes[1].set_yticks(y_pos)\n",
    "axes[1].set_yticklabels(models)\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].set_xlabel('Coefficient Estimate', fontsize=12)\n",
    "axes[1].set_title('Capital Coefficient Across Models', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Observations:\")\n",
    "print(\"- Pooled OLS often differs from FE/RE (omitted variable bias)\")\n",
    "print(\"- FE and RE are often similar (but Hausman test is definitive)\")\n",
    "print(\"- FD can differ if dynamics are important\")\n",
    "print(\"- Between uses only cross-sectional variation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Report Generation {#report-generation}\n",
    "\n",
    "PanelBox can export results to HTML, Markdown, and LaTeX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTML report (example - would save to file in practice)\n",
    "print(\"HTML Export Example:\")\n",
    "print(\"=\"*60)\n",
    "print(\"# To export to HTML:\")\n",
    "print(\"fe_results.to_html('fixed_effects_results.html')\")\n",
    "print(\"\\n# This creates a professional, publication-ready HTML report\")\n",
    "print(\"# with tables, statistics, and formatting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 LaTeX Export (for Academic Papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table (example)\n",
    "print(\"LaTeX Export Example:\")\n",
    "print(\"=\"*60)\n",
    "print(\"# To export to LaTeX:\")\n",
    "print(\"fe_results.to_latex('table1.tex')\")\n",
    "print(\"\\n# This creates a LaTeX table that can be directly\")\n",
    "print(\"# included in your paper with \\\\input{table1.tex}\")\n",
    "print(\"\\n# You can also create comparison tables:\")\n",
    "print(\"from panelbox.report import create_comparison_table\")\n",
    "print(\"create_comparison_table([fe_results, re_results], 'comparison.tex')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Decision Guide: Which Model to Use? {#decision-guide}\n",
    "\n",
    "### Decision Tree:\n",
    "\n",
    "```\n",
    "Start Here\n",
    "    |\n",
    "    v\n",
    "[Do you have panel data?]\n",
    "    |\n",
    "    YES --> [Are there unobserved entity effects?]\n",
    "    |           |\n",
    "    |           YES --> [Run F-test: Pooled vs FE]\n",
    "    |           |           |\n",
    "    |           |           Reject H₀ --> [Use FE or RE]\n",
    "    |           |           |                  |\n",
    "    |           |           |                  v\n",
    "    |           |           |           [Run Hausman Test]\n",
    "    |           |           |                  |\n",
    "    |           |           |           Reject --> Fixed Effects ✓\n",
    "    |           |           |           Don't Reject --> Random Effects ✓\n",
    "    |           |           |\n",
    "    |           |           Don't Reject --> Pooled OLS ✓\n",
    "    |           |\n",
    "    |           NO --> Pooled OLS ✓\n",
    "    |\n",
    "    NO --> Use standard regression\n",
    "```\n",
    "\n",
    "### Quick Reference Table:\n",
    "\n",
    "| Situation | Recommended Model | Reason |\n",
    "|-----------|------------------|--------|\n",
    "| Just starting / exploratory | Pooled OLS | Baseline |\n",
    "| Unobserved heterogeneity suspected | Fixed Effects | Safe, always consistent |\n",
    "| Hausman test fails to reject | Random Effects | More efficient |\n",
    "| Need to estimate time-invariant vars | Random Effects or Between | FE can't identify these |\n",
    "| Short-run effects matter | First Difference | Focus on changes |\n",
    "| Long-run effects matter | Between | Cross-sectional variation |\n",
    "| Small T, large N | Random Effects | More efficient |\n",
    "| Large T, small N | Fixed Effects | Asymptotic properties |\n",
    "| When in doubt | Fixed Effects | Conservative choice |\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Always start with Fixed Effects** in applied work (unless you have strong reasons not to)\n",
    "2. **Use clustered standard errors** (by entity) to be conservative\n",
    "3. **Report multiple specifications** in papers (robustness)\n",
    "4. **Test your assumptions** (F-test, Hausman test)\n",
    "5. **Check diagnostics** (serial correlation, heteroskedasticity)\n",
    "6. **Consider dynamics** (if lagged y matters, use GMM - see next notebook)\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "✅ **5 Static Panel Models**:\n",
    "   - Pooled OLS (baseline)\n",
    "   - Between (cross-sectional)\n",
    "   - Fixed Effects (workhorse)\n",
    "   - Random Effects (efficient if valid)\n",
    "   - First Difference (short-run)\n",
    "\n",
    "✅ **Specification Tests**:\n",
    "   - F-test (Pooled vs FE)\n",
    "   - Hausman test (FE vs RE)\n",
    "\n",
    "✅ **Robust Standard Errors**:\n",
    "   - 8 types available\n",
    "   - When to use each\n",
    "   - Clustered SE recommended\n",
    "\n",
    "✅ **Model Comparison**:\n",
    "   - How to compare models\n",
    "   - Visualize differences\n",
    "   - Interpretation\n",
    "\n",
    "✅ **Report Generation**:\n",
    "   - HTML, Markdown, LaTeX export\n",
    "   - Publication-ready tables\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **[02_dynamic_gmm_complete.ipynb](./02_dynamic_gmm_complete.ipynb)**: Learn about dynamic panels and GMM\n",
    "- **[03_validation_complete.ipynb](./03_validation_complete.ipynb)**: Deep dive into validation tests\n",
    "- **[04_robust_inference.ipynb](./04_robust_inference.ipynb)**: Advanced inference techniques\n",
    "\n",
    "---\n",
    "\n",
    "*Happy modeling with PanelBox!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
