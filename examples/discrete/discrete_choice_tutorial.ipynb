{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Panel Discrete Choice Models with PanelBox\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates how to use PanelBox for estimating discrete choice models with panel data. We'll work through a practical example of labor force participation, covering:\n",
    "\n",
    "1. **Pooled models** (Logit and Probit)\n",
    "2. **Fixed Effects Logit** (Conditional Maximum Likelihood)\n",
    "3. **Random Effects Probit** (Butler & Moffitt quadrature)\n",
    "4. **Marginal Effects** interpretation\n",
    "5. **Model Selection** using specification tests\n",
    "6. **Common pitfalls** and best practices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, let's import the necessary libraries and generate some example data for labor force participation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import PanelBox discrete choice models\n",
    "import panelbox as pb\n",
    "from panelbox.models.discrete import (\n",
    "    PooledLogit,\n",
    "    PooledProbit,\n",
    "    FixedEffectsLogit,\n",
    "    RandomEffectsProbit\n",
    ")\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"PanelBox version: {pb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Panel Data\n",
    "\n",
    "For this tutorial, we'll simulate data on labor force participation with the following variables:\n",
    "\n",
    "- **labor_force**: Binary outcome (1 = in labor force, 0 = not)\n",
    "- **age**: Age of individual\n",
    "- **education**: Years of education\n",
    "- **married**: Marital status (1 = married, 0 = not)\n",
    "- **children**: Number of children under 6\n",
    "- **health**: Self-reported health status (1-5 scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labor_data(n_individuals=500, n_periods=8, seed=42):\n",
    "    \"\"\"Generate synthetic panel data for labor force participation.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create panel structure\n",
    "    person_id = np.repeat(range(1, n_individuals + 1), n_periods)\n",
    "    year = np.tile(range(2015, 2015 + n_periods), n_individuals)\n",
    "    \n",
    "    # Individual-specific effects (unobserved heterogeneity)\n",
    "    alpha_i = np.repeat(np.random.normal(0, 0.8, n_individuals), n_periods)\n",
    "    \n",
    "    # Time-invariant characteristics\n",
    "    education_i = np.repeat(np.random.normal(12, 3, n_individuals), n_periods)\n",
    "    \n",
    "    # Time-varying characteristics\n",
    "    age_base = np.repeat(np.random.uniform(25, 55, n_individuals), n_periods)\n",
    "    age = age_base + np.tile(range(n_periods), n_individuals)\n",
    "    \n",
    "    # Marital status (can change over time)\n",
    "    married = np.random.binomial(1, 0.6, len(person_id))\n",
    "    \n",
    "    # Number of young children (changes over time)\n",
    "    children = np.random.poisson(0.8, len(person_id))\n",
    "    children = np.minimum(children, 4)  # Cap at 4\n",
    "    \n",
    "    # Health status (1-5 scale)\n",
    "    health = np.random.choice([1, 2, 3, 4, 5], len(person_id), p=[0.05, 0.15, 0.40, 0.30, 0.10])\n",
    "    \n",
    "    # Generate labor force participation (latent variable model)\n",
    "    # True coefficients\n",
    "    beta_age = -0.02\n",
    "    beta_age2 = -0.0002\n",
    "    beta_education = 0.15\n",
    "    beta_married = -0.3  # Negative for women (traditional effect)\n",
    "    beta_children = -0.5  # Strong negative effect\n",
    "    beta_health = 0.3\n",
    "    \n",
    "    # Latent variable\n",
    "    y_star = (alpha_i + \n",
    "              beta_age * age + \n",
    "              beta_age2 * age**2 +\n",
    "              beta_education * education_i + \n",
    "              beta_married * married + \n",
    "              beta_children * children + \n",
    "              beta_health * health +\n",
    "              np.random.normal(0, 1, len(person_id)))\n",
    "    \n",
    "    # Binary outcome\n",
    "    labor_force = (y_star > 0).astype(int)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'person_id': person_id,\n",
    "        'year': year,\n",
    "        'labor_force': labor_force,\n",
    "        'age': age,\n",
    "        'age_squared': age**2,\n",
    "        'education': education_i,\n",
    "        'married': married,\n",
    "        'children': children,\n",
    "        'health': health\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate the data\n",
    "data = generate_labor_data(n_individuals=500, n_periods=8)\n",
    "data = data.set_index(['person_id', 'year'])\n",
    "\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"\\nFirst few observations:\")\n",
    "print(data.head(10))\n",
    "print(\"\\nLabor force participation rate:\", data['labor_force'].mean())\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "Before modeling, let's explore the data to understand patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize labor force participation by key variables\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# By age\n",
    "age_bins = pd.cut(data['age'], bins=5)\n",
    "age_participation = data.groupby(age_bins)['labor_force'].mean()\n",
    "axes[0, 0].bar(range(len(age_participation)), age_participation.values)\n",
    "axes[0, 0].set_xticklabels([str(i) for i in age_participation.index], rotation=45)\n",
    "axes[0, 0].set_title('Participation by Age')\n",
    "axes[0, 0].set_ylabel('Participation Rate')\n",
    "\n",
    "# By education\n",
    "edu_bins = pd.cut(data['education'], bins=5)\n",
    "edu_participation = data.groupby(edu_bins)['labor_force'].mean()\n",
    "axes[0, 1].bar(range(len(edu_participation)), edu_participation.values)\n",
    "axes[0, 1].set_xticklabels([str(i) for i in edu_participation.index], rotation=45)\n",
    "axes[0, 1].set_title('Participation by Education')\n",
    "\n",
    "# By marital status\n",
    "marital_participation = data.groupby('married')['labor_force'].mean()\n",
    "axes[0, 2].bar(['Not Married', 'Married'], marital_participation.values)\n",
    "axes[0, 2].set_title('Participation by Marital Status')\n",
    "\n",
    "# By number of children\n",
    "children_participation = data.groupby('children')['labor_force'].mean()\n",
    "axes[1, 0].bar(children_participation.index, children_participation.values)\n",
    "axes[1, 0].set_title('Participation by Number of Children')\n",
    "axes[1, 0].set_xlabel('Number of Children')\n",
    "axes[1, 0].set_ylabel('Participation Rate')\n",
    "\n",
    "# By health status\n",
    "health_participation = data.groupby('health')['labor_force'].mean()\n",
    "axes[1, 1].bar(health_participation.index, health_participation.values)\n",
    "axes[1, 1].set_title('Participation by Health Status')\n",
    "axes[1, 1].set_xlabel('Health (1=Poor, 5=Excellent)')\n",
    "\n",
    "# Time trend\n",
    "time_participation = data.groupby(data.index.get_level_values('year'))['labor_force'].mean()\n",
    "axes[1, 2].plot(time_participation.index, time_participation.values, marker='o')\n",
    "axes[1, 2].set_title('Participation Over Time')\n",
    "axes[1, 2].set_xlabel('Year')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Within-individual variation\n",
    "within_variation = data.groupby(level='person_id')['labor_force'].agg(['mean', 'std'])\n",
    "print(f\"\\nProportion with no within-variation: {(within_variation['std'] == 0).mean():.1%}\")\n",
    "print(f\"Average within-person variation: {within_variation['std'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pooled Logit Model (Baseline)\n",
    "\n",
    "We start with a pooled logit model that ignores the panel structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Pooled Logit\n",
    "pooled_logit = PooledLogit.from_formula(\n",
    "    'labor_force ~ age + age_squared + education + married + children + health',\n",
    "    data=data\n",
    ")\n",
    "pooled_logit_result = pooled_logit.fit()\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*60)\n",
    "print(\"POOLED LOGIT RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(pooled_logit_result.summary())\n",
    "\n",
    "# Key statistics\n",
    "print(f\"\\nMcFadden Pseudo R²: {pooled_logit_result.pseudo_r2('mcfadden'):.4f}\")\n",
    "print(f\"Log-likelihood: {pooled_logit_result.llf:.2f}\")\n",
    "print(f\"AIC: {pooled_logit_result.aic:.2f}\")\n",
    "print(f\"BIC: {pooled_logit_result.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pooled Probit Model\n",
    "\n",
    "For comparison, let's also estimate a pooled probit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Pooled Probit\n",
    "pooled_probit = PooledProbit.from_formula(\n",
    "    'labor_force ~ age + age_squared + education + married + children + health',\n",
    "    data=data\n",
    ")\n",
    "pooled_probit_result = pooled_probit.fit()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"POOLED PROBIT RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(pooled_probit_result.summary())\n",
    "\n",
    "# Compare with Logit\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: LOGIT vs PROBIT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Logit Coef': pooled_logit_result.params,\n",
    "    'Probit Coef': pooled_probit_result.params,\n",
    "    'Ratio': pooled_logit_result.params / pooled_probit_result.params\n",
    "})\n",
    "print(comparison)\n",
    "print(f\"\\nAverage ratio (Logit/Probit): {comparison['Ratio'].mean():.3f}\")\n",
    "print(\"(Theory suggests ~1.6 for the ratio)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fixed Effects Logit\n",
    "\n",
    "Now let's control for unobserved individual heterogeneity using Fixed Effects Logit.\n",
    "\n",
    "**Important:** FE Logit drops individuals with no within-variation in the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: age and education don't vary within individuals in our setup,\n",
    "# so we exclude them from the FE model\n",
    "fe_logit = FixedEffectsLogit.from_formula(\n",
    "    'labor_force ~ married + children + health',\n",
    "    data=data\n",
    ")\n",
    "fe_logit_result = fe_logit.fit()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FIXED EFFECTS LOGIT RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(fe_logit_result.summary())\n",
    "\n",
    "print(f\"\\nNumber of groups: {fe_logit_result.n_groups}\")\n",
    "print(f\"Groups dropped (no within variation): {fe_logit_result.n_dropped_groups}\")\n",
    "print(f\"Observations used: {fe_logit_result.nobs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Effects Probit\n",
    "\n",
    "Random Effects models allow us to include time-invariant variables while still accounting for individual heterogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Effects Probit\n",
    "re_probit = RandomEffectsProbit.from_formula(\n",
    "    'labor_force ~ age + age_squared + education + married + children + health',\n",
    "    data=data\n",
    ")\n",
    "re_probit_result = re_probit.fit()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM EFFECTS PROBIT RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(re_probit_result.summary())\n",
    "\n",
    "# Variance decomposition\n",
    "sigma_alpha = re_probit_result.sigma_alpha\n",
    "rho = sigma_alpha**2 / (sigma_alpha**2 + 1)  # For probit, error variance = 1\n",
    "print(f\"\\nSigma_alpha (RE std dev): {sigma_alpha:.4f}\")\n",
    "print(f\"Rho (intraclass correlation): {rho:.4f}\")\n",
    "print(f\"Proportion of variance due to individual effects: {rho:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Marginal Effects\n",
    "\n",
    "For nonlinear models, coefficients don't directly represent marginal effects. Let's calculate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Marginal Effects (AME) for Pooled Logit\n",
    "ame_logit = pooled_logit_result.marginal_effects(kind='average')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AVERAGE MARGINAL EFFECTS - POOLED LOGIT\")\n",
    "print(\"=\"*60)\n",
    "print(ame_logit.summary())\n",
    "\n",
    "# Marginal Effects at Means (MEM)\n",
    "mem_logit = pooled_logit_result.marginal_effects(kind='at_means')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MARGINAL EFFECTS AT MEANS - POOLED LOGIT\")\n",
    "print(\"=\"*60)\n",
    "print(mem_logit.summary())\n",
    "\n",
    "# Compare AME vs MEM\n",
    "comparison = pd.DataFrame({\n",
    "    'AME': ame_logit.effects,\n",
    "    'MEM': mem_logit.effects,\n",
    "    'Difference': ame_logit.effects - mem_logit.effects\n",
    "})\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: AME vs MEM\")\n",
    "print(\"=\"*60)\n",
    "print(comparison)\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION OF MARGINAL EFFECTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"One additional child reduces the probability of labor force participation by {abs(ame_logit.effects['children']*100):.1f} percentage points on average.\")\n",
    "print(f\"Being married reduces the probability by {abs(ame_logit.effects['married']*100):.1f} percentage points.\")\n",
    "print(f\"One year of additional education increases the probability by {ame_logit.effects['education']*100:.1f} percentage points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison and Selection\n",
    "\n",
    "Let's compare the different models and perform specification tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "models = {\n",
    "    'Pooled Logit': pooled_logit_result,\n",
    "    'Pooled Probit': pooled_probit_result,\n",
    "    'FE Logit': fe_logit_result,\n",
    "    'RE Probit': re_probit_result\n",
    "}\n",
    "\n",
    "# Extract common coefficients for comparison\n",
    "common_vars = ['married', 'children', 'health']\n",
    "comparison = pd.DataFrame()\n",
    "\n",
    "for name, result in models.items():\n",
    "    coefs = []\n",
    "    ses = []\n",
    "    for var in common_vars:\n",
    "        if var in result.params.index:\n",
    "            coefs.append(result.params[var])\n",
    "            ses.append(result.bse[var])\n",
    "        else:\n",
    "            coefs.append(np.nan)\n",
    "            ses.append(np.nan)\n",
    "    \n",
    "    comparison[name] = coefs\n",
    "    comparison[name + ' SE'] = ses\n",
    "\n",
    "comparison.index = common_vars\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON - COEFFICIENTS\")\n",
    "print(\"=\"*80)\n",
    "print(comparison)\n",
    "\n",
    "# Model fit statistics\n",
    "fit_stats = pd.DataFrame()\n",
    "for name, result in models.items():\n",
    "    stats = {\n",
    "        'Log-Likelihood': result.llf,\n",
    "        'AIC': result.aic if hasattr(result, 'aic') else np.nan,\n",
    "        'BIC': result.bic if hasattr(result, 'bic') else np.nan,\n",
    "        'N': result.nobs\n",
    "    }\n",
    "    fit_stats[name] = stats\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL FIT STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(fit_stats.T)\n",
    "\n",
    "# Hausman test (FE vs RE) - would typically be done here\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPECIFICATION TESTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"Note: Hausman test for FE vs RE would be performed here.\")\n",
    "print(\"If p < 0.05, reject RE in favor of FE (correlation between effects and regressors).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Predictions and Classification\n",
    "\n",
    "Let's evaluate model performance using predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from Pooled Logit\n",
    "predictions = pooled_logit_result.predict(data)\n",
    "\n",
    "# Classification at different thresholds\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "for threshold in thresholds:\n",
    "    predicted_class = (predictions > threshold).astype(int)\n",
    "    accuracy = (predicted_class == data['labor_force']).mean()\n",
    "    sensitivity = ((predicted_class == 1) & (data['labor_force'] == 1)).sum() / (data['labor_force'] == 1).sum()\n",
    "    specificity = ((predicted_class == 0) & (data['labor_force'] == 0)).sum() / (data['labor_force'] == 0).sum()\n",
    "    \n",
    "    print(f\"\\nThreshold = {threshold}\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Sensitivity: {sensitivity:.3f}\")\n",
    "    print(f\"  Specificity: {specificity:.3f}\")\n",
    "\n",
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(data['labor_force'], predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Pooled Logit Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Classification table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION TABLE (Threshold = 0.5)\")\n",
    "print(\"=\"*60)\n",
    "print(pooled_logit_result.classification_table(threshold=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Common Pitfalls and Best Practices\n",
    "\n",
    "### Common Pitfalls to Avoid:\n",
    "\n",
    "1. **Interpreting coefficients as marginal effects**\n",
    "   - In nonlinear models, coefficients ≠ marginal effects\n",
    "   - Always calculate AME or MEM for interpretation\n",
    "\n",
    "2. **Ignoring panel structure**\n",
    "   - Pooled models assume independence across observations\n",
    "   - Use cluster-robust standard errors at minimum\n",
    "\n",
    "3. **Fixed Effects with time-invariant variables**\n",
    "   - FE models cannot identify effects of time-invariant variables\n",
    "   - Use RE or Mundlak correction if these are important\n",
    "\n",
    "4. **Ignoring incidental parameters problem**\n",
    "   - FE Probit is inconsistent with fixed T\n",
    "   - Use FE Logit (conditional MLE) instead\n",
    "\n",
    "5. **Not checking within-variation**\n",
    "   - FE models drop units with no within-variation\n",
    "   - Check how many observations are actually used\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Start with pooled models as baseline**\n",
    "2. **Use Hausman test to choose between FE and RE**\n",
    "3. **Report marginal effects for interpretation**\n",
    "4. **Check robustness with different link functions**\n",
    "5. **Use cluster-robust standard errors**\n",
    "6. **Validate with out-of-sample predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Cluster-robust standard errors for pooled model\n",
    "pooled_logit_robust = PooledLogit.from_formula(\n",
    "    'labor_force ~ age + age_squared + education + married + children + health',\n",
    "    data=data\n",
    ")\n",
    "pooled_logit_robust_result = pooled_logit_robust.fit(cov_type='cluster', cov_kwds={'groups': data.index.get_level_values('person_id')})\n",
    "\n",
    "# Compare standard errors\n",
    "se_comparison = pd.DataFrame({\n",
    "    'Default SE': pooled_logit_result.bse,\n",
    "    'Cluster-Robust SE': pooled_logit_robust_result.bse,\n",
    "    'Ratio': pooled_logit_robust_result.bse / pooled_logit_result.bse\n",
    "})\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STANDARD ERRORS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(se_comparison)\n",
    "print(\"\\nCluster-robust SEs are typically larger, accounting for within-person correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "This tutorial covered the main discrete choice models available in PanelBox:\n",
    "\n",
    "- **Pooled Logit/Probit**: Simple but ignores panel structure\n",
    "- **Fixed Effects Logit**: Controls for unobserved heterogeneity\n",
    "- **Random Effects Probit**: Allows time-invariant variables while accounting for heterogeneity\n",
    "\n",
    "Key takeaways:\n",
    "1. Choice of model depends on assumptions about correlation between individual effects and regressors\n",
    "2. Marginal effects are essential for interpretation\n",
    "3. Panel structure matters - ignoring it can lead to biased inference\n",
    "4. Different models may lead to different conclusions - robustness checks are important\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try ordered choice models for ordinal outcomes (`OrderedLogit`, `OrderedProbit`)\n",
    "- Explore count models for count data (`PoissonFixedEffects`, `NegativeBinomial`)\n",
    "- Use `PanelExperiment` for systematic model comparison\n",
    "- Apply these methods to your own data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for reporting\n",
    "print(\"Saving results...\")\n",
    "\n",
    "# Export to LaTeX (for papers)\n",
    "# pooled_logit_result.to_latex('pooled_logit_results.tex')\n",
    "\n",
    "# Export to HTML (for presentations)\n",
    "# pooled_logit_result.to_html('pooled_logit_results.html')\n",
    "\n",
    "print(\"Tutorial complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
