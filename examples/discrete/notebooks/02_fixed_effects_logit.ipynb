{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 02: Fixed Effects Logit Models\n",
    "\n",
    "**Version**: 1.0  \n",
    "**Date**: 2026-02-16  \n",
    "**Estimated Duration**: 90 minutes  \n",
    "**Difficulty Level**: Intermediate\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand the problem of unobserved heterogeneity in binary choice models\n",
    "2. Recognize why the incidental parameters problem makes standard FE estimation infeasible\n",
    "3. Explain Chamberlain's conditional MLE solution for Logit models\n",
    "4. Understand why Fixed Effects Probit doesn't work\n",
    "5. Estimate Fixed Effects Logit models using PanelBox\n",
    "6. Identify which observations contribute to estimation (switchers)\n",
    "7. Interpret within-variation effects\n",
    "8. Compare Pooled and FE Logit results appropriately\n",
    "9. Recognize limitations and when not to use FE Logit\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Required\n",
    "- **Notebook 01**: Binary Choice Introduction (Pooled Logit/Probit)\n",
    "- Understanding of fixed effects in linear models\n",
    "- Panel data structure concepts\n",
    "\n",
    "### Recommended\n",
    "- Static panel models tutorials (PooledOLS, FixedEffectsOLS)\n",
    "- Maximum Likelihood Estimation basics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PanelBox imports\n",
    "from panelbox.models.discrete.binary import PooledLogit, PooledProbit, FixedEffectsLogit\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = Path(\"..\") / \"data\"\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 1: The Problem of Unobserved Heterogeneity\n",
    "\n",
    "## Why Pooled Logit Can Be Biased\n",
    "\n",
    "In **Notebook 01**, we learned about Pooled Logit models:\n",
    "\n",
    "$$P(y_{it}=1|X_{it}) = \\Lambda(X_{it}'\\beta)$$\n",
    "\n",
    "where $\\Lambda(z) = \\frac{e^z}{1+e^z}$ is the logistic CDF.\n",
    "\n",
    "**Critical Assumption**: The model assumes that all individual-specific characteristics affecting $y_{it}$ are either:\n",
    "1. Included in $X_{it}$, or\n",
    "2. Independent of $X_{it}$\n",
    "\n",
    "But what if there are **unobserved individual characteristics** $\\alpha_i$ that:\n",
    "- Affect the outcome $y_{it}$\n",
    "- Correlate with the regressors $X_{it}$?\n",
    "\n",
    "This leads to **omitted variable bias**.\n",
    "\n",
    "### Example: Labor Force Participation\n",
    "\n",
    "Consider modeling whether person $i$ participates in job training at time $t$:\n",
    "- $y_{it}$ = 1 if person $i$ participates in training at time $t$\n",
    "- $X_{it}$ = (age, prior wage, experience)\n",
    "- $\\alpha_i$ = unobserved work motivation, ability, career orientation\n",
    "\n",
    "**Problem**: If high-ability individuals ($\\alpha_i$) tend to have higher prior wages AND are more likely to seek training, then the coefficient on prior wage will be biased.\n",
    "\n",
    "Let's demonstrate this with a simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SIMULATION: Omitted Variable Bias in Pooled Logit\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Simulate data with correlated alpha_i\n",
    "np.random.seed(42)\n",
    "n_individuals = 500\n",
    "n_periods = 5\n",
    "\n",
    "# Generate unobserved heterogeneity\n",
    "alpha_i = np.random.normal(0, 1, n_individuals)\n",
    "\n",
    "# Education correlates with alpha_i (ability)\n",
    "education = 12 + 2*alpha_i + np.random.normal(0, 1, n_individuals)\n",
    "\n",
    "# Generate panel data\n",
    "data_list = []\n",
    "for i in range(n_individuals):\n",
    "    for t in range(n_periods):\n",
    "        age = 30 + t\n",
    "        # TRUE MODEL: y* = 0.5*educ + 2.0*alpha_i + noise\n",
    "        y_star = 0.5*education[i] + 2.0*alpha_i[i] + np.random.logistic(0, 1)\n",
    "        y = int(y_star > 0)\n",
    "        data_list.append({\n",
    "            'id': i,\n",
    "            'year': t,\n",
    "            'y': y,\n",
    "            'educ': education[i],\n",
    "            'age': age,\n",
    "            'true_alpha': alpha_i[i]\n",
    "        })\n",
    "\n",
    "sim_data = pd.DataFrame(data_list)\n",
    "\n",
    "# Estimate Pooled Logit (ignoring alpha_i)\n",
    "pooled_model = PooledLogit(\"y ~ educ + age\", sim_data, \"id\", \"year\")\n",
    "pooled_results = pooled_model.fit()\n",
    "\n",
    "print(\"\\nData Generation:\")\n",
    "print(f\"  True model: y* = 0.5*educ + 2.0*alpha_i + logistic_error\")\n",
    "print(f\"  Correlation(educ, alpha_i) = {np.corrcoef(education, alpha_i)[0,1]:.3f}\")\n",
    "print(f\"  → Education and ability are positively correlated!\")\n",
    "\n",
    "print(\"\\nEstimation Results:\")\n",
    "print(f\"  True β_educ: 0.500\")\n",
    "print(f\"  Pooled estimate: {pooled_results.params['educ']:.4f}\")\n",
    "print(f\"  Bias: {pooled_results.params['educ'] - 0.50:.4f}\")\n",
    "print(f\"  Bias percentage: {100*(pooled_results.params['educ'] - 0.50)/0.50:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION: Pooled Logit is BIASED when α_i correlates with X_it\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation between alpha_i and education\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Scatter plot showing correlation\n",
    "individual_data = sim_data.groupby('id').first()\n",
    "axes[0].scatter(individual_data['true_alpha'], individual_data['educ'], \n",
    "                alpha=0.5, s=30)\n",
    "axes[0].set_xlabel('Unobserved Ability (α_i)')\n",
    "axes[0].set_ylabel('Education (years)')\n",
    "axes[0].set_title(f'Correlation between α_i and Education\\nr = {np.corrcoef(education, alpha_i)[0,1]:.3f}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Average outcome by alpha_i quartile\n",
    "individual_data['alpha_quartile'] = pd.qcut(individual_data['true_alpha'], q=4, \n",
    "                                             labels=['Q1 (Low)', 'Q2', 'Q3', 'Q4 (High)'])\n",
    "quartile_means = individual_data.groupby('alpha_quartile')[['y', 'educ']].mean()\n",
    "\n",
    "x = np.arange(len(quartile_means))\n",
    "width = 0.35\n",
    "axes[1].bar(x - width/2, quartile_means['educ'] - quartile_means['educ'].mean(), \n",
    "            width, label='Education (demeaned)', alpha=0.7)\n",
    "axes[1].bar(x + width/2, quartile_means['y'], width, label='P(y=1)', alpha=0.7)\n",
    "axes[1].set_xlabel('Ability Quartile')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_title('Both Education and Outcome Increase with α_i')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(quartile_means.index)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The plots show:\")\n",
    "print(\"  LEFT: Education increases with unobserved ability α_i\")\n",
    "print(\"  RIGHT: Both education AND the outcome increase with α_i\")\n",
    "print(\"  → This confounds the causal effect of education!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Why Not Use Within Transformation?\n",
    "\n",
    "In **linear panel models**, we solve this problem with the **within transformation**:\n",
    "\n",
    "$$y_{it} - \\bar{y}_i = (X_{it} - \\bar{X}_i)'\\beta + (\\epsilon_{it} - \\bar{\\epsilon}_i)$$\n",
    "\n",
    "This eliminates $\\alpha_i$ because it doesn't vary over time.\n",
    "\n",
    "**But this doesn't work for binary choice models!**\n",
    "\n",
    "Why not?\n",
    "- Logit/Probit are **nonlinear** models\n",
    "- $E[y_{it} | X_{it}, \\alpha_i] = \\Lambda(X_{it}'\\beta + \\alpha_i)$\n",
    "- Subtracting means doesn't eliminate $\\alpha_i$ due to nonlinearity:\n",
    "  - $E[y_{it}] - E[\\bar{y}_i] \\neq \\Lambda(X_{it}'\\beta) - \\Lambda(\\bar{X}_i'\\beta)$\n",
    "\n",
    "We need a different solution!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: The Incidental Parameters Problem\n",
    "\n",
    "## Naive Approach: Add Dummy Variables\n",
    "\n",
    "A natural idea: just estimate $\\alpha_i$ along with $\\beta$!\n",
    "\n",
    "$$P(y_{it}=1|X_{it}, \\alpha_i) = \\Lambda(X_{it}'\\beta + \\alpha_i)$$\n",
    "\n",
    "Estimate with dummy variables:\n",
    "- $N$ individual dummies (one for each person)\n",
    "- $K$ slope coefficients $\\beta$\n",
    "- Total parameters: $N + K$\n",
    "\n",
    "### The Neyman-Scott Problem (1948)\n",
    "\n",
    "**Problem**: As $N \\to \\infty$ with fixed $T$, the number of parameters grows with the sample size!\n",
    "\n",
    "This causes **inconsistency**:\n",
    "- MLE of $\\beta$ is biased\n",
    "- Bias doesn't disappear as $N \\to \\infty$ (with fixed $T$)\n",
    "- Bias is $O(1/T)$ - only disappears as $T \\to \\infty$\n",
    "\n",
    "This is called the **incidental parameters problem**.\n",
    "\n",
    "The $\\alpha_i$ are \"incidental\" parameters:\n",
    "- Not of direct interest\n",
    "- But cause bias in estimating $\\beta$ (the parameters we care about)\n",
    "\n",
    "### Simulation: Incidental Parameters Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"SIMULATION: Incidental Parameters Bias for Different T\")\nprint(\"=\"*70)\n\ndef estimate_logit_with_dummies(data, T):\n    \"\"\"\n    Estimate Logit with individual dummies.\n    This is the WRONG approach - we're doing it to show the bias!\n    \"\"\"\n    import statsmodels.api as sm\n    from statsmodels.discrete.discrete_model import Logit\n    \n    # Filter to first T periods\n    data_subset = data[data['year'] < T].copy()\n    \n    # Create dummy variables for individuals\n    data_with_dummies = pd.get_dummies(data_subset, columns=['id'], \n                                       prefix='id', drop_first=True)\n    \n    # Prepare X and y\n    y = data_with_dummies['y'].values\n    X_cols = ['educ', 'age'] + [col for col in data_with_dummies.columns \n                                 if col.startswith('id_')]\n    X = data_with_dummies[X_cols].values\n    \n    # Estimate\n    try:\n        model = Logit(y, X)\n        results = model.fit(disp=0, maxiter=100)\n        beta_educ = results.params[0]  # First coefficient is education\n        return beta_educ\n    except:\n        return np.nan\n\n# Test for different T\nT_values = [3, 5, 10, 20]\nresults_bias = []\n\nprint(\"\\nEstimating models for different T values...\")\nfor T in T_values:\n    print(f\"  T = {T}...\", end=\" \")\n    beta_est = estimate_logit_with_dummies(sim_data, T)\n    bias = beta_est - 0.50\n    bias_pct = 100 * bias / 0.50\n    results_bias.append({\n        'T': T, \n        'β_estimate': beta_est, \n        'Bias': bias,\n        'Bias_%': bias_pct\n    })\n    print(f\"β = {beta_est:.4f}\")\n\nbias_df = pd.DataFrame(results_bias)\nprint(\"\\nIncidental Parameters Bias by Panel Length:\")\nprint(bias_df.to_string(index=False))\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"CONCLUSION: Bias decreases as T increases, but remains for fixed T\")\nprint(\"This approach is INCONSISTENT for fixed T as N → ∞\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bias vs T\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Bias vs T\n",
    "axes[0].plot(bias_df['T'], bias_df['Bias'], 'o-', linewidth=2, markersize=8)\n",
    "axes[0].axhline(y=0, color='red', linestyle='--', label='No bias')\n",
    "axes[0].set_xlabel('Panel Length (T)')\n",
    "axes[0].set_ylabel('Bias in β_educ')\n",
    "axes[0].set_title('Incidental Parameters Bias Decreases with T')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Right: Show O(1/T) relationship\n",
    "axes[1].plot(1/bias_df['T'], np.abs(bias_df['Bias']), 'o-', \n",
    "             linewidth=2, markersize=8, label='|Bias|')\n",
    "axes[1].set_xlabel('1/T')\n",
    "axes[1].set_ylabel('|Bias|')\n",
    "axes[1].set_title('Bias is O(1/T) - Linear in 1/T')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: Cannot simply add dummy variables in nonlinear models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why This Matters\n",
    "\n",
    "The incidental parameters problem means:\n",
    "1. We cannot use the standard \"fixed effects\" approach from linear models\n",
    "2. Simply adding individual dummies gives biased estimates\n",
    "3. We need a fundamentally different approach\n",
    "\n",
    "**The solution**: Conditional Maximum Likelihood (Section 4)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Why FE Probit Doesn't Work\n",
    "\n",
    "## The Difference Between Logit and Probit\n",
    "\n",
    "Both Logit and Probit are binary choice models, but they use different distributions:\n",
    "\n",
    "| Model | CDF | Distribution |\n",
    "|-------|-----|-------------|\n",
    "| **Logit** | $\\Lambda(z) = \\frac{e^z}{1+e^z}$ | Logistic (Type I Extreme Value) |\n",
    "| **Probit** | $\\Phi(z) = \\int_{-\\infty}^{z} \\phi(t)dt$ | Standard Normal |\n",
    "\n",
    "This seemingly small difference has huge implications for fixed effects!\n",
    "\n",
    "## Sufficient Statistics\n",
    "\n",
    "The key to eliminating $\\alpha_i$ is finding a **sufficient statistic**:\n",
    "\n",
    "**Definition**: A statistic $S(y_i)$ is sufficient for $\\alpha_i$ if the conditional distribution $P(y_i | S(y_i), X_i, \\beta)$ does not depend on $\\alpha_i$.\n",
    "\n",
    "### For Logit:\n",
    "- $S_i = \\sum_{t=1}^{T} y_{it}$ is a sufficient statistic for $\\alpha_i$\n",
    "- This is a **special property of the logistic distribution**\n",
    "- Allows conditional MLE to eliminate $\\alpha_i$\n",
    "\n",
    "### For Probit:\n",
    "- $\\sum_{t=1}^{T} y_{it}$ is **NOT** a sufficient statistic for $\\alpha_i$\n",
    "- No simple sufficient statistic exists\n",
    "- Conditional likelihood still depends on $\\alpha_i$\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "**Logit**: We can condition on $\\sum_t y_{it}$ to eliminate $\\alpha_i$ → FE Logit works!\n",
    "\n",
    "**Probit**: Conditioning doesn't eliminate $\\alpha_i$ → FE Probit has no simple solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FE Logit vs FE Probit: Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_data = {\n",
    "    'Property': [\n",
    "        'Distribution',\n",
    "        'Sufficient Statistic for α_i',\n",
    "        'Conditional Likelihood',\n",
    "        'FE Estimator',\n",
    "        'Consistency',\n",
    "        'PanelBox Support'\n",
    "    ],\n",
    "    'Logit': [\n",
    "        'Logistic',\n",
    "        'Σ_t y_it',\n",
    "        'Does not depend on α_i',\n",
    "        'Chamberlain (1980) Conditional MLE',\n",
    "        'Consistent for fixed T',\n",
    "        'FixedEffectsLogit'\n",
    "    ],\n",
    "    'Probit': [\n",
    "        'Normal',\n",
    "        'None (simple)',\n",
    "        'Still depends on α_i',\n",
    "        'No simple solution',\n",
    "        'Requires T → ∞',\n",
    "        'Not available'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\", comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION: Fixed Effects Probit does NOT have a simple estimator!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatives for Probit\n",
    "\n",
    "If you need a Probit-like model with unobserved heterogeneity, consider:\n",
    "\n",
    "### 1. Correlated Random Effects (CRE)\n",
    "- Model: $\\alpha_i = \\bar{X}_i'\\lambda + u_i$\n",
    "- Allows correlation between $\\alpha_i$ and time-varying $X_{it}$ through $\\bar{X}_i$\n",
    "- **See Notebook 03** for details\n",
    "\n",
    "### 2. Bias-Corrected FE Estimators\n",
    "- Fernández-Val (2009), Hahn & Kuersteiner (2002)\n",
    "- Correct the $O(1/T)$ bias\n",
    "- Advanced techniques, not yet in PanelBox\n",
    "\n",
    "### 3. Semiparametric Estimators\n",
    "- Manski (1987 Maximum score estimator\n",
    "- Honoré & Kyriazidou (2000) for dynamic models\n",
    "- Computationally intensive\n",
    "- Not in PanelBox\n",
    "\n",
    "**For this notebook, we focus on FE Logit - the workhorse for applied work.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Chamberlain's Conditional MLE Solution\n",
    "\n",
    "## The Conditioning Insight (Chamberlain, 1980)\n",
    "\n",
    "Instead of maximizing the marginal likelihood:\n",
    "$$L(\\beta, \\alpha) = \\prod_{i=1}^{N} P(y_{i1}, ..., y_{iT} | X_i, \\alpha_i, \\beta)$$\n",
    "\n",
    "Chamberlain proposed maximizing the **conditional likelihood**:\n",
    "$$L_c(\\beta) = \\prod_{i=1}^{N} P(y_{i1}, ..., y_{iT} | \\sum_t y_{it}, X_i, \\beta)$$\n",
    "\n",
    "**Key insight**: By conditioning on the sufficient statistic $\\sum_t y_{it}$, the individual effect $\\alpha_i$ cancels out!\n",
    "\n",
    "## Mathematical Intuition: T=2 Case\n",
    "\n",
    "Consider an individual with $\\sum_{t=1}^{2} y_{it} = 1$ (exactly one success in two periods).\n",
    "\n",
    "Two possible sequences:\n",
    "- Pattern A: $(y_1=0, y_2=1)$\n",
    "- Pattern B: $(y_1=1, y_2=0)$\n",
    "\n",
    "The conditional probability is:\n",
    "$$P(y_1=0, y_2=1 | \\sum_t y_t = 1, X, \\alpha_i) = \\frac{P(y_1=0, y_2=1)}{P(y_1=0, y_2=1) + P(y_1=1, y_2=0)}$$\n",
    "\n",
    "### The Magic: $\\alpha_i$ Cancels!\n",
    "\n",
    "After some algebra (see Wooldridge Ch. 15.8.3):\n",
    "\n",
    "$$P(0,1 | sum=1) = \\frac{\\exp(X_2'\\beta)}{\\exp(X_1'\\beta) + \\exp(X_2'\\beta)}$$\n",
    "\n",
    "Notice: **No $\\alpha_i$ appears!** It has been eliminated by the conditioning.\n",
    "\n",
    "This allows us to estimate $\\beta$ consistently without ever estimating $\\alpha_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Chamberlain's Conditional MLE (Intuition for T=2)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nSetup:\")\n",
    "print(\"  - Individual i has T=2 periods\")\n",
    "print(\"  - Outcome sum: Σ_t y_it = 1 (one success)\")\n",
    "print(\"  - Two possible patterns:\")\n",
    "print(\"      Pattern A: (y₁=0, y₂=1)\")\n",
    "print(\"      Pattern B: (y₁=1, y₂=0)\")\n",
    "\n",
    "print(\"\\nStandard (Marginal) Likelihood:\")\n",
    "print(\"  P(y₁, y₂ | X, α_i, β) depends on both β AND α_i\")\n",
    "print(\"  → Cannot estimate β without estimating α_i\")\n",
    "print(\"  → Incidental parameters problem!\")\n",
    "\n",
    "print(\"\\nConditional Likelihood:\")\n",
    "print(\"  P(y₁=0, y₂=1 | Σy=1, X, β) = exp(X₂'β) / [exp(X₁'β) + exp(X₂'β)]\")\n",
    "print(\"  → Depends ONLY on β, not α_i!\")\n",
    "print(\"  → α_i has been eliminated by conditioning\")\n",
    "\n",
    "print(\"\\nKey Property (Logistic Distribution):\")\n",
    "print(\"  Σ_t y_it is a SUFFICIENT STATISTIC for α_i\")\n",
    "print(\"  → This is special to the logistic distribution\")\n",
    "print(\"  → Does not work for Probit (normal distribution)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION: Conditional MLE gives consistent β without estimating α_i\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization to Arbitrary T\n",
    "\n",
    "The same principle extends to any $T$:\n",
    "1. Condition on $s_i = \\sum_{t=1}^{T} y_{it}$\n",
    "2. Consider all possible sequences with that sum\n",
    "3. Calculate conditional probabilities\n",
    "4. $\\alpha_i$ cancels in all cases!\n",
    "\n",
    "The conditional MLE maximizes:\n",
    "$$L_c(\\beta) = \\prod_{i: 0 < s_i < T} P(y_{i1}, ..., y_{iT} | s_i, X_i, \\beta)$$\n",
    "\n",
    "**Note**: Only individuals with $0 < s_i < T$ contribute! (More on this in Section 5)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Identification - Who Contributes to Estimation?\n",
    "\n",
    "## Switchers vs Non-Switchers\n",
    "\n",
    "Not all observations contribute to FE Logit estimation!\n",
    "\n",
    "Individuals fall into three categories:\n",
    "\n",
    "1. **Switchers**: $0 < \\sum_t y_{it} < T_i$ (some 0s, some 1s)\n",
    "   - Have temporal variation in $y_{it}$\n",
    "   - **Contribute to estimation**\n",
    "\n",
    "2. **Always 0**: $\\sum_t y_{it} = 0$ (never $y=1$)\n",
    "   - No variation in outcome\n",
    "   - **Dropped from estimation**\n",
    "\n",
    "3. **Always 1**: $\\sum_t y_{it} = T_i$ (always $y=1$)\n",
    "   - No variation in outcome\n",
    "   - **Dropped from estimation**\n",
    "\n",
    "## Why Non-Switchers Are Dropped\n",
    "\n",
    "**Intuition**: Without temporal variation in $y_{it}$, we cannot separate:\n",
    "- Individual effect $\\alpha_i$ (time-invariant)\n",
    "- Effect of changing $X_{it}$ (what $\\beta$ measures)\n",
    "\n",
    "FE models identify effects from **within-individual variation**. If $y_{it}$ never changes, there's nothing to identify!\n",
    "\n",
    "## Practical Implications\n",
    "\n",
    "Sample loss can be substantial if:\n",
    "- $T$ is small (fewer opportunities to switch)\n",
    "- $y_{it}$ is rare (few 1s) or very common (few 0s)\n",
    "- Outcome is very persistent\n",
    "\n",
    "### Analysis: Job Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load job training data\n",
    "data = pd.read_csv(DATA_DIR / \"job_training.csv\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Job Training Dataset\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal observations: {len(data)}\")\n",
    "print(f\"Individuals: {data['id'].nunique()}\")\n",
    "print(f\"Time periods: {data['year'].nunique()}\")\n",
    "print(f\"Years: {data['year'].min()} - {data['year'].max()}\")\n",
    "\n",
    "print(\"\\nVariables:\")\n",
    "print(\"  training: 1 if participated in training, 0 otherwise\")\n",
    "print(\"  employed: 1 if employed, 0 otherwise\")\n",
    "print(\"  age: age in years\")\n",
    "print(\"  prior_wage: hourly wage in previous job\")\n",
    "print(\"  experience: years of work experience\")\n",
    "print(\"  education: years of education (time-invariant)\")\n",
    "\n",
    "print(\"\\n\" + data.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum of training by individual\n",
    "switcher_analysis = data.groupby('id')['training'].agg([\n",
    "    ('sum_y', 'sum'),\n",
    "    ('n_periods', 'count')\n",
    "]).reset_index()\n",
    "\n",
    "# Classify individuals\n",
    "switcher_analysis['type'] = 'Switcher'\n",
    "switcher_analysis.loc[switcher_analysis['sum_y'] == 0, 'type'] = 'Always 0'\n",
    "switcher_analysis.loc[switcher_analysis['sum_y'] == switcher_analysis['n_periods'], 'type'] = 'Always 1'\n",
    "\n",
    "# Summary statistics\n",
    "print(\"=\"*70)\n",
    "print(\"Switcher Analysis: Training Participation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "type_counts = switcher_analysis['type'].value_counts()\n",
    "print(\"\\nDistribution of Individuals:\")\n",
    "for idx in ['Switcher', 'Always 0', 'Always 1']:\n",
    "    if idx in type_counts.index:\n",
    "        count = type_counts[idx]\n",
    "        pct = 100 * count / len(switcher_analysis)\n",
    "        status = \"✓ Used\" if idx == 'Switcher' else \"✗ Dropped\"\n",
    "        print(f\"  {idx:12s}: {count:4d} ({pct:5.1f}%)  [{status}]\")\n",
    "\n",
    "n_switchers = (switcher_analysis['type'] == 'Switcher').sum()\n",
    "n_total = len(switcher_analysis)\n",
    "utilization = 100 * n_switchers / n_total\n",
    "\n",
    "print(f\"\\nUtilization Rate: {utilization:.1f}% of individuals used\")\n",
    "print(f\"Sample Loss: {100 - utilization:.1f}% of individuals dropped\")\n",
    "\n",
    "if utilization < 30:\n",
    "    print(\"\\n⚠️  WARNING: Very low utilization! Consider alternatives to FE Logit.\")\n",
    "elif utilization < 50:\n",
    "    print(\"\\n⚠️  CAUTION: Moderate utilization. Check robustness.\")\n",
    "else:\n",
    "    print(\"\\n✓ Good utilization rate for FE Logit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize switcher distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Pie chart\n",
    "type_counts = switcher_analysis['type'].value_counts()\n",
    "colors = {'Switcher': '#2ecc71', 'Always 0': '#e74c3c', 'Always 1': '#e67e22'}\n",
    "pie_colors = [colors[t] for t in type_counts.index]\n",
    "\n",
    "axes[0].pie(type_counts, labels=type_counts.index, autopct='%1.1f%%', \n",
    "            startangle=90, colors=pie_colors, textprops={'fontsize': 12})\n",
    "axes[0].set_title('Distribution of Individual Types', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Right: Histogram of sum_y\n",
    "max_periods = switcher_analysis['n_periods'].max()\n",
    "bins = np.arange(-0.5, max_periods + 1.5, 1)\n",
    "axes[1].hist(switcher_analysis['sum_y'], bins=bins, edgecolor='black', \n",
    "             alpha=0.7, color='steelblue')\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2, \n",
    "                label='Dropped: sum = 0')\n",
    "axes[1].axvline(x=max_periods, color='orange', linestyle='--', linewidth=2,\n",
    "                label=f'Dropped: sum = {max_periods}')\n",
    "axes[1].set_xlabel('Σ_t y_it (Number of periods in training)', fontsize=11)\n",
    "axes[1].set_ylabel('Number of Individuals', fontsize=11)\n",
    "axes[1].set_title('Distribution of Training Sums\\n(Red/Orange lines show dropped individuals)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"  Only individuals with 0 < Σ_t y_it < T contribute to FE Logit\")\n",
    "print(\"  These 'switchers' provide within-individual variation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Individual Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual trajectories for each type\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "for idx, (cat, ax) in enumerate(zip(['Switcher', 'Always 0', 'Always 1'], axes)):\n",
    "    # Get individuals of this type\n",
    "    ids_in_cat = switcher_analysis[switcher_analysis['type'] == cat]['id'].values[:10]\n",
    "    \n",
    "    for id_val in ids_in_cat:\n",
    "        ind_data = data[data['id'] == id_val].sort_values('year')\n",
    "        ax.plot(ind_data['year'], ind_data['training'], alpha=0.6, marker='o', markersize=4)\n",
    "    \n",
    "    ax.set_title(f'{cat}\\n({type_counts.get(cat, 0)} individuals)', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Training (1=Yes, 0=No)')\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if cat == 'Switcher':\n",
    "        ax.set_facecolor('#e8f8f5')\n",
    "        ax.text(0.5, 0.95, 'USED in FE Logit', transform=ax.transAxes,\n",
    "                ha='center', va='top', fontweight='bold', color='green')\n",
    "    else:\n",
    "        ax.set_facecolor('#fadbd8')\n",
    "        ax.text(0.5, 0.95, 'DROPPED', transform=ax.transAxes,\n",
    "                ha='center', va='top', fontweight='bold', color='red')\n",
    "\n",
    "plt.suptitle('Individual Training Trajectories by Type (First 10 in each category)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Only switchers contribute**: FE Logit uses only individuals with $0 < \\sum_t y_{it} < T$\n",
    "2. **Sample loss**: Can be substantial, especially with:\n",
    "   - Short panels (small $T$)\n",
    "   - Rare or very common outcomes\n",
    "   - Persistent outcomes\n",
    "3. **Check utilization**: Always report what fraction of individuals are used\n",
    "4. **Within variation**: FE identifies effects from changes over time within same individual\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Within vs Between Variation\n",
    "\n",
    "## What FE Logit Identifies\n",
    "\n",
    "FE Logit uses **only within-individual variation**:\n",
    "- How changes in $X_{it}$ affect changes in $y_{it}$ **for the same individual**\n",
    "- Between-individual variation is absorbed by $\\alpha_i$\n",
    "\n",
    "### Decomposition of Variation\n",
    "\n",
    "For any variable $X_{it}$:\n",
    "$$X_{it} = \\underbrace{\\bar{X}_i}_{\\text{between}} + \\underbrace{(X_{it} - \\bar{X}_i)}_{\\text{within}}$$\n",
    "\n",
    "- **Between variation**: Differences across individuals ($\\bar{X}_i$)\n",
    "- **Within variation**: Changes over time within individual ($X_{it} - \\bar{X}_i$)\n",
    "\n",
    "**Pooled Logit**: Uses both within and between variation\n",
    "\n",
    "**FE Logit**: Uses only within variation\n",
    "\n",
    "## Time-Invariant Variables\n",
    "\n",
    "Variables that don't change over time have:\n",
    "- **Zero within variation**: $X_{it} - \\bar{X}_i = 0$ for all $t$\n",
    "- **Only between variation**: Differences across individuals\n",
    "\n",
    "These are **perfectly collinear** with $\\alpha_i$ and:\n",
    "- Cannot be identified in FE models\n",
    "- Will be automatically dropped or cause an error\n",
    "\n",
    "### Examples of Time-Invariant Variables\n",
    "- Gender, race, ethnicity\n",
    "- Place of birth\n",
    "- Education (if completed before panel starts)\n",
    "- Industry (if firms don't switch industries)\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Attempting to Include Time-Invariant Variable in FE Logit\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Education is time-invariant in our data\n",
    "print(\"\\nChecking if 'education' varies over time:\")\n",
    "edu_variation = data.groupby('id')['education'].agg(['min', 'max', 'std'])\n",
    "print(f\"  Max within-individual std dev: {edu_variation['std'].max():.6f}\")\n",
    "print(f\"  → Education does NOT vary over time (time-invariant)\")\n",
    "\n",
    "print(\"\\nAttempting FE Logit with time-invariant variable...\")\n",
    "try:\n",
    "    # This will fail or drop the variable\n",
    "    model_bad = FixedEffectsLogit(\n",
    "        \"training ~ age + prior_wage + education\",  # education is time-invariant!\n",
    "        data, \"id\", \"year\"\n",
    "    )\n",
    "    results_bad = model_bad.fit()\n",
    "    \n",
    "    # Check if education was dropped\n",
    "    if 'education' not in results_bad.params.index:\n",
    "        print(\"  ✗ Education was automatically DROPPED from the model\")\n",
    "        print(\"  Reason: No within-individual variation\")\n",
    "    else:\n",
    "        print(\"  Education coefficient:\", results_bad.params['education'])\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error: {type(e).__name__}\")\n",
    "    print(f\"  Message: {str(e)}\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION: Time-invariant variables cannot be included in FE models\")\n",
    "print(\"They are absorbed by the individual fixed effect α_i\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Correct specification: Only time-varying variables\nprint(\"\\n\" + \"=\"*70)\nprint(\"Correct FE Logit Specification (Time-Varying Only)\")\nprint(\"=\"*70)\n\nmodel_good = FixedEffectsLogit(\n    \"employed ~ training + age + prior_wage\",  # all time-varying\n    data, \"id\", \"year\"\n)\nresults_good = model_good.fit()\n\nprint(\"\\nModel: employed ~ training + age + prior_wage\")\nprint(\"\\nCoefficients:\")\nfor var in results_good.params.index:\n    print(f\"  {var:12s}: {results_good.params[var]:7.4f}  (SE: {results_good.std_errors[var]:.4f})\")\n    \nprint(f\"\\nNumber of individuals used: {model_good.n_used_entities}\")\nprint(\"\\n✓ Model estimated successfully with time-varying variables only\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation: Within Effects\n",
    "\n",
    "FE Logit coefficients measure **within effects**:\n",
    "\n",
    "**Example**: Coefficient on `training`\n",
    "- **NOT**: Difference in employment between trained vs untrained people\n",
    "- **YES**: Change in employment probability when **same person** starts training\n",
    "\n",
    "This is a **causal interpretation** (under standard assumptions):\n",
    "- Time-invariant confounders are controlled for\n",
    "- Unobserved heterogeneity $\\alpha_i$ is eliminated\n",
    "\n",
    "### Comparison with Pooled Logit\n",
    "\n",
    "| Model | Variation Used | Interpretation | Bias if $\\alpha_i$ correlates with $X$ |\n",
    "|-------|---------------|----------------|---------------------------------------|\n",
    "| **Pooled** | Within + Between | Cross-sectional comparison | Biased |\n",
    "| **FE** | Within only | Within-individual change | Unbiased |\n",
    "\n",
    "**Trade-off**: FE removes bias but loses efficiency (larger standard errors)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Implementation in PanelBox\n",
    "\n",
    "## Basic Usage\n",
    "\n",
    "Estimating FE Logit in PanelBox is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Fixed Effects Logit in PanelBox\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Estimate FE Logit\n",
    "fe_model = FixedEffectsLogit(\n",
    "    formula=\"employed ~ training + age + prior_wage\",\n",
    "    data=data,\n",
    "    entity_col=\"id\",\n",
    "    time_col=\"year\"\n",
    ")\n",
    "\n",
    "fe_results = fe_model.fit()\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\", fe_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Diagnostic information\nprint(\"=\"*70)\nprint(\"Diagnostic Information\")\nprint(\"=\"*70)\n\nprint(f\"\\nSample Information:\")\nprint(f\"  Total individuals in data: {data['id'].nunique()}\")\nprint(f\"  Individuals used (switchers): {fe_model.n_used_entities}\")\n\nn_dropped = data['id'].nunique() - fe_model.n_used_entities\nutilization = 100 * fe_model.n_used_entities / data['id'].nunique()\n\nprint(f\"  Individuals dropped: {n_dropped}\")\nprint(f\"  Utilization rate: {utilization:.1f}%\")\n\n# Dropped entities (first few)\nif hasattr(fe_model, 'dropped_entities') and len(fe_model.dropped_entities) > 0:\n    print(f\"\\nFirst 10 dropped entity IDs: {fe_model.dropped_entities[:10]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Error Options\n",
    "\n",
    "PanelBox supports various standard error calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"Standard Error Options\")\nprint(\"=\"*70)\n\nprint(\"\\nPanelBox supports various standard error types:\")\nprint(\"  - 'cluster': Cluster-robust SE (clustered by entity) - RECOMMENDED\")\nprint(\"  - 'robust': Heteroskedasticity-robust SE\")\nprint(\"  - 'nonrobust': Classical SE (not recommended for panel data)\")\n\nprint(\"\\nOur FE model was estimated with cluster-robust SE:\")\nprint(\"\\nCoefficients and Standard Errors:\")\nse_table = pd.DataFrame({\n    'Coefficient': fe_results.params,\n    'SE (Cluster-Robust)': fe_results.std_errors,\n    't-value': fe_results.tvalues,\n    'p-value': fe_results.pvalues\n})\nprint(se_table)\n\nprint(\"\\nRecommendation: Use cluster-robust SE for panel data\")\nprint(\"  - Accounts for within-individual correlation\")\nprint(\"  - More conservative (larger SE)\")\nprint(\"  - Reduces risk of over-rejection\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Methods and Attributes\n\n```python\n# Model attributes\nfe_model.n_entities          # Total number of entities\nfe_model.n_used_entities     # Number of switchers (used)\nfe_model.dropped_entities    # List of dropped entity IDs\nfe_model.formula             # Model formula\n\n# Results methods\nfe_results.summary()         # Print summary table\nfe_results.params            # Coefficient estimates\nfe_results.std_errors        # Standard errors\nfe_results.pvalues           # P-values\nfe_results.conf_int()        # Confidence intervals\n```\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8: Comparing Pooled vs FE Logit\n",
    "\n",
    "## Why Compare?\n",
    "\n",
    "Comparing Pooled and FE estimates helps us understand:\n",
    "1. **Magnitude of bias** from unobserved heterogeneity\n",
    "2. **Whether FE is necessary** for this application\n",
    "3. **Robustness** of findings\n",
    "\n",
    "**Large differences** suggest important unobserved heterogeneity → FE is needed\n",
    "\n",
    "**Small differences** suggest Pooled may be adequate (more efficient)\n",
    "\n",
    "## Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Pooled vs Fixed Effects Logit Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Estimate Pooled Logit\n",
    "pooled_model = PooledLogit(\n",
    "    \"employed ~ training + age + prior_wage\", \n",
    "    data, \"id\", \"year\"\n",
    ")\n",
    "pooled_results = pooled_model.fit(cov_type='cluster')\n",
    "\n",
    "# FE Logit (already estimated)\n",
    "fe_results = fe_model.fit(cov_type='cluster')\n",
    "\n",
    "# Create comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Pooled_β': pooled_results.params,\n",
    "    'Pooled_SE': pooled_results.std_errors,\n",
    "    'FE_β': fe_results.params,\n",
    "    'FE_SE': fe_results.std_errors,\n",
    "})\n",
    "comparison['Difference'] = comparison['Pooled_β'] - comparison['FE_β']\n",
    "comparison['Diff_%'] = 100 * comparison['Difference'] / comparison['Pooled_β'].abs()\n",
    "\n",
    "print(\"\\nCoefficient Comparison:\")\n",
    "print(comparison.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Interpretation:\")\n",
    "for var in comparison.index:\n",
    "    diff_pct = comparison.loc[var, 'Diff_%']\n",
    "    if abs(diff_pct) > 20:\n",
    "        print(f\"  {var}: LARGE difference ({diff_pct:.1f}%) → unobserved heterogeneity important!\")\n",
    "    else:\n",
    "        print(f\"  {var}: Small difference ({diff_pct:.1f}%) → Pooled may be adequate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Comparison: Forest Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest plot comparing Pooled vs FE estimates\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "variables = comparison.index\n",
    "y_pos = np.arange(len(variables))\n",
    "\n",
    "# Plot coefficients with 95% confidence intervals\n",
    "offset = 0.15\n",
    "ax.errorbar(comparison['Pooled_β'], y_pos - offset,\n",
    "            xerr=1.96 * comparison['Pooled_SE'],\n",
    "            fmt='o', label='Pooled Logit', capsize=5,\n",
    "            color='#3498db', markersize=8, linewidth=2)\n",
    "ax.errorbar(comparison['FE_β'], y_pos + offset,\n",
    "            xerr=1.96 * comparison['FE_SE'],\n",
    "            fmt='s', label='FE Logit', capsize=5,\n",
    "            color='#e74c3c', markersize=8, linewidth=2)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(variables, fontsize=11)\n",
    "ax.set_xlabel('Coefficient Estimate', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Comparison: Pooled vs Fixed Effects Logit (95% CI)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.legend(fontsize=11, loc='best')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nForest Plot Interpretation:\")\n",
    "print(\"  - Points show coefficient estimates\")\n",
    "print(\"  - Lines show 95% confidence intervals\")\n",
    "print(\"  - Non-overlapping intervals suggest significant difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informal Hausman-Type Test\n",
    "\n",
    "The Hausman test formally tests whether Pooled and FE estimates differ systematically.\n",
    "\n",
    "**Null hypothesis**: No unobserved heterogeneity correlated with X (Pooled is consistent)\n",
    "\n",
    "**Note**: Formal Hausman test for nonlinear models is complex. Here we provide informal comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Informal Hausman-Type Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nCoefficient Differences:\")\n",
    "for var in comparison.index:\n",
    "    pooled_coef = comparison.loc[var, 'Pooled_β']\n",
    "    fe_coef = comparison.loc[var, 'FE_β']\n",
    "    diff = comparison.loc[var, 'Difference']\n",
    "    diff_pct = comparison.loc[var, 'Diff_%']\n",
    "    \n",
    "    # Approximate z-test (informal)\n",
    "    se_diff = np.sqrt(comparison.loc[var, 'Pooled_SE']**2 + \n",
    "                      comparison.loc[var, 'FE_SE']**2)\n",
    "    z_stat = diff / se_diff\n",
    "    \n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"  Difference: {diff:.4f} ({diff_pct:.1f}%)\")\n",
    "    print(f\"  Informal z-stat: {z_stat:.2f}\")\n",
    "    \n",
    "    if abs(z_stat) > 1.96:\n",
    "        print(f\"  → Statistically significant difference (|z| > 1.96)\")\n",
    "    else:\n",
    "        print(f\"  → Not statistically different\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Note: This is an INFORMAL test. Proper Hausman test for\")\n",
    "print(\"nonlinear models requires careful implementation.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Framework\n",
    "\n",
    "**Use FE Logit if**:\n",
    "- Coefficients differ substantially from Pooled (>20%)\n",
    "- Strong theoretical reason to expect $\\alpha_i$ correlates with $X_{it}$\n",
    "- Sufficient switchers (>30% utilization)\n",
    "- Causal interpretation is critical\n",
    "\n",
    "**Consider Pooled Logit if**:\n",
    "- Coefficients similar to FE\n",
    "- Few switchers (low utilization)\n",
    "- Need to estimate effects of time-invariant variables\n",
    "- Efficiency more important than bias\n",
    "\n",
    "**Best practice**: Report both and discuss differences!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 9: Application - Technology Adoption by Firms\n",
    "\n",
    "## Research Question\n",
    "\n",
    "**Does firm size causally affect technology adoption, or is the correlation due to unobserved factors (e.g., management quality)?**\n",
    "\n",
    "- $y_{it}$ = 1 if firm $i$ adopted new technology at time $t$\n",
    "- $X_{it}$ = log(firm size), profit margin, firm age\n",
    "- $\\alpha_i$ = unobserved management quality, innovation culture\n",
    "\n",
    "**Problem**: High-quality management may lead to both:\n",
    "- Larger firm size\n",
    "- Greater technology adoption\n",
    "\n",
    "This confounds the causal effect of size.\n",
    "\n",
    "**Solution**: FE Logit controls for time-invariant management quality.\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load firm technology data\n",
    "firm_data = pd.read_csv(DATA_DIR / \"firm_technology.csv\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Firm Technology Adoption Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nSample:\")\n",
    "print(f\"  Total observations: {len(firm_data)}\")\n",
    "print(f\"  Firms: {firm_data['firm_id'].nunique()}\")\n",
    "print(f\"  Time periods: {firm_data['year'].nunique()}\")\n",
    "print(f\"  Years: {firm_data['year'].min()} - {firm_data['year'].max()}\")\n",
    "\n",
    "print(\"\\nVariables:\")\n",
    "print(\"  adopted: 1 if firm adopted new technology, 0 otherwise\")\n",
    "print(\"  log_size: log of firm size (number of employees)\")\n",
    "print(\"  profit_margin: profit as % of revenue\")\n",
    "print(\"  age: firm age in years\")\n",
    "print(\"  industry: industry code (time-invariant)\")\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(firm_data[['adopted', 'log_size', 'profit_margin', 'age']].describe())\n",
    "\n",
    "print(\"\\nAdoption Rate:\")\n",
    "print(f\"  Overall: {100*firm_data['adopted'].mean():.1f}%\")\n",
    "print(\"\\nFirst 10 observations:\")\n",
    "print(firm_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switcher Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze switchers for technology adoption\n",
    "firm_switcher = firm_data.groupby('firm_id')['adopted'].agg([\n",
    "    ('sum_y', 'sum'),\n",
    "    ('n_periods', 'count')\n",
    "]).reset_index()\n",
    "\n",
    "firm_switcher['type'] = 'Switcher'\n",
    "firm_switcher.loc[firm_switcher['sum_y'] == 0, 'type'] = 'Never Adopted'\n",
    "firm_switcher.loc[firm_switcher['sum_y'] == firm_switcher['n_periods'], 'type'] = 'Always Adopted'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Switcher Analysis: Technology Adoption\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "type_counts_firm = firm_switcher['type'].value_counts()\n",
    "print(\"\\nFirm Types:\")\n",
    "for idx in ['Switcher', 'Never Adopted', 'Always Adopted']:\n",
    "    if idx in type_counts_firm.index:\n",
    "        count = type_counts_firm[idx]\n",
    "        pct = 100 * count / len(firm_switcher)\n",
    "        status = \"✓ Used\" if idx == 'Switcher' else \"✗ Dropped\"\n",
    "        print(f\"  {idx:16s}: {count:4d} ({pct:5.1f}%)  [{status}]\")\n",
    "\n",
    "utilization_firm = 100 * type_counts_firm.get('Switcher', 0) / len(firm_switcher)\n",
    "print(f\"\\nUtilization Rate: {utilization_firm:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled Logit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Pooled Logit: Firm Technology Adoption\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Pooled Logit (can include industry)\n",
    "pooled_tech = PooledLogit(\n",
    "    \"adopted ~ log_size + profit_margin + age\",  # Removed C(industry) for simplicity\n",
    "    firm_data, \"firm_id\", \"year\"\n",
    ")\n",
    "pooled_tech_results = pooled_tech.fit(cov_type='cluster')\n",
    "\n",
    "print(\"\\n\", pooled_tech_results.summary())\n",
    "\n",
    "# Odds ratio for log_size\n",
    "or_size = np.exp(pooled_tech_results.params['log_size'])\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Interpretation (Pooled):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nlog_size coefficient: {pooled_tech_results.params['log_size']:.4f}\")\n",
    "print(f\"Odds ratio: {or_size:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  A 10% increase in firm size is associated with a\")\n",
    "pct_change = 100 * ((1.1 ** pooled_tech_results.params['log_size']) - 1)\n",
    "print(f\"  {pct_change:.2f}% change in the odds of technology adoption\")\n",
    "print(f\"\\n⚠️  But is this causal? Or driven by unobserved management quality?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Effects Logit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Fixed Effects Logit: Firm Technology Adoption\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# FE Logit (cannot include industry - time invariant)\n",
    "fe_tech = FixedEffectsLogit(\n",
    "    \"adopted ~ log_size + profit_margin + age\",\n",
    "    firm_data, \"firm_id\", \"year\"\n",
    ")\n",
    "fe_tech_results = fe_tech.fit()\n",
    "\n",
    "print(\"\\n\", fe_tech_results.summary())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Sample Information:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Firms in data: {firm_data['firm_id'].nunique()}\")\n",
    "print(f\"Firms used (switchers): {fe_tech.n_used_entities}\")\n",
    "print(f\"Firms dropped: {firm_data['firm_id'].nunique() - fe_tech.n_used_entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison and Causal Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Pooled vs FE: Technology Adoption\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Comparison table\n",
    "tech_comparison = pd.DataFrame({\n",
    "    'Pooled': pooled_tech_results.params,\n",
    "    'Pooled_SE': pooled_tech_results.std_errors,\n",
    "    'FE': fe_tech_results.params,\n",
    "    'FE_SE': fe_tech_results.std_errors,\n",
    "    'Difference': pooled_tech_results.params - fe_tech_results.params\n",
    "})\n",
    "tech_comparison['Diff_%'] = 100 * tech_comparison['Difference'] / tech_comparison['Pooled'].abs()\n",
    "\n",
    "print(\"\\n\", tech_comparison.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Causal Interpretation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pooled_coef = pooled_tech_results.params['log_size']\n",
    "fe_coef = fe_tech_results.params['log_size']\n",
    "diff_pct = tech_comparison.loc['log_size', 'Diff_%']\n",
    "\n",
    "print(f\"\\nEffect of Firm Size on Technology Adoption:\")\n",
    "print(f\"  Pooled Logit: β = {pooled_coef:.4f}\")\n",
    "print(f\"  FE Logit: β = {fe_coef:.4f}\")\n",
    "print(f\"  Difference: {pooled_coef - fe_coef:.4f} ({diff_pct:.1f}%)\")\n",
    "\n",
    "if abs(diff_pct) > 20:\n",
    "    print(f\"\\n✓ LARGE DIFFERENCE ({diff_pct:.1f}%)!\")\n",
    "    print(f\"\\nInterpretation:\")\n",
    "    print(f\"  - Much of the pooled correlation is due to unobserved\")\n",
    "    print(f\"    firm characteristics (e.g., management quality)\")\n",
    "    print(f\"  - FE estimate gives the causal effect of size changes\")\n",
    "    print(f\"    WITHIN the same firm (controlling for α_i)\")\n",
    "else:\n",
    "    print(f\"\\n✓ Small difference ({diff_pct:.1f}%)\")\n",
    "    print(f\"\\nInterpretation:\")\n",
    "    print(f\"  - Unobserved heterogeneity less important\")\n",
    "    print(f\"  - Pooled and FE estimates are similar\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"Economic Conclusion\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nWithin-firm causal effect (FE Logit):\")\n",
    "print(f\"  As a firm grows by 10%, its probability of adopting\")\n",
    "print(f\"  new technology changes by approximately:\")\n",
    "pct_effect_fe = 100 * ((1.1 ** fe_coef) - 1)\n",
    "print(f\"  {pct_effect_fe:.2f}% (in odds)\")\n",
    "print(f\"\\nThis is the causal effect, holding constant time-invariant\")\n",
    "print(f\"firm characteristics like management quality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights from Application\n",
    "\n",
    "1. **Unobserved heterogeneity matters**: Large difference between Pooled and FE suggests $\\alpha_i$ (management quality) is important\n",
    "\n",
    "2. **Causal interpretation**: FE Logit identifies within-firm effect:\n",
    "   - NOT: Large firms vs small firms (confounded by management)\n",
    "   - YES: Same firm becoming larger over time\n",
    "\n",
    "3. **Sample loss**: Some firms dropped due to no variation\n",
    "   - Trade-off: lose observations but gain unbiased estimates\n",
    "\n",
    "4. **Policy implications**: Results tell us whether firm **growth** (not just size) affects technology adoption\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 10: Limitations and When NOT to Use FE Logit\n",
    "\n",
    "While FE Logit is a powerful tool, it has important limitations. Understanding when NOT to use it is as important as knowing when to use it.\n",
    "\n",
    "## Limitation 1: Loss of Observations\n",
    "\n",
    "### Problem\n",
    "FE Logit drops all non-switchers, potentially losing many observations.\n",
    "\n",
    "### When This Is Serious\n",
    "- $T < 3$ (very short panels)\n",
    "- Rare outcomes ($P(y=1)$ very small)\n",
    "- Very persistent outcomes (little temporal variation)\n",
    "- Can lose >50% of sample!\n",
    "\n",
    "### Solution\n",
    "- **Random Effects Logit**: Uses all observations (but assumes $\\alpha_i \\perp X_{it}$)\n",
    "- **Correlated Random Effects**: Allows some correlation (see Notebook 03)\n",
    "- **Pooled with controls**: Include rich set of observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Limitation 1: Sample Loss\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate sample loss for our data\n",
    "total_firms = firm_data['firm_id'].nunique()\n",
    "used_firms = fe_tech.n_used_entities\n",
    "lost_pct = 100 * (1 - used_firms / total_firms)\n",
    "\n",
    "print(f\"\\nOur Data (Firm Technology):\")\n",
    "print(f\"  Total firms: {total_firms}\")\n",
    "print(f\"  Firms used in FE: {used_firms}\")\n",
    "print(f\"  Sample loss: {lost_pct:.1f}%\")\n",
    "\n",
    "if lost_pct > 50:\n",
    "    print(f\"\\n⚠️  WARNING: Losing more than half the sample!\")\n",
    "    print(f\"     Consider alternatives:\")\n",
    "    print(f\"       - Correlated Random Effects (Notebook 03)\")\n",
    "    print(f\"       - Pooled Logit with rich controls\")\n",
    "elif lost_pct > 30:\n",
    "    print(f\"\\n⚠️  CAUTION: Substantial sample loss\")\n",
    "    print(f\"     Report as limitation and check robustness\")\n",
    "else:\n",
    "    print(f\"\\n✓ Acceptable sample loss for FE Logit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitation 2: Time-Invariant Variables\n",
    "\n",
    "### Problem\n",
    "Cannot estimate effects of variables that don't vary over time.\n",
    "\n",
    "### Examples That CANNOT Be Estimated\n",
    "- Demographic: gender, race, ethnicity, place of birth\n",
    "- Education (if completed before panel)\n",
    "- Industry (if no switching)\n",
    "- Geographic location (if no migration)\n",
    "\n",
    "### Solution\n",
    "If you need these effects:\n",
    "- **Pooled Logit**: Can estimate them (but may be biased)\n",
    "- **Correlated Random Effects**: Can estimate them while allowing some $\\alpha_i$ correlation\n",
    "- **Hybrid models**: Combine within and between variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Limitation 2: Time-Invariant Variables\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nVariables That CANNOT Be Estimated in FE Logit:\")\n",
    "print(\"  ✗ Gender\")\n",
    "print(\"  ✗ Race/Ethnicity\")\n",
    "print(\"  ✗ Place of birth\")\n",
    "print(\"  ✗ Education (if completed before panel)\")\n",
    "print(\"  ✗ Industry (if no switching)\")\n",
    "print(\"\\nThese are absorbed by the individual fixed effect α_i\")\n",
    "\n",
    "print(\"\\nAlternatives if You Need Time-Invariant Effects:\")\n",
    "print(\"  1. Correlated Random Effects (Notebook 03)\")\n",
    "print(\"     → Allows correlation through time-averages\")\n",
    "print(\"  2. Pooled Logit with controls\")\n",
    "print(\"     → Can estimate effects but may be biased\")\n",
    "print(\"  3. Hybrid models\")\n",
    "print(\"     → Combine within (FE) and between (RE) variation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitation 3: Remaining Bias for Small T\n",
    "\n",
    "### Problem\n",
    "FE Logit has bias of order $O(1/T)$:\n",
    "- Smaller than Pooled or dummy variable bias\n",
    "- But doesn't disappear for fixed $T$\n",
    "- Only vanishes as $T \\to \\infty$\n",
    "\n",
    "### Rule of Thumb\n",
    "- $T \\geq 8$: Bias usually negligible\n",
    "- $5 \\leq T < 8$: Bias may be small but check\n",
    "- $T < 5$: Bias can be substantial\n",
    "\n",
    "### Solution\n",
    "- **Bias-corrected estimators**: Fernández-Val (2009), Hahn-Kuersteiner (2002)\n",
    "  - Advanced, not yet in PanelBox\n",
    "- **Jackknife**: Bias correction through resampling\n",
    "- **Analytical correction**: Correct the $O(1/T)$ bias analytically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Limitation 3: Finite-T Bias\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "T_in_data = data.groupby('id').size().mean()\n",
    "print(f\"\\nAverage T in our data: {T_in_data:.1f}\")\n",
    "\n",
    "if T_in_data >= 8:\n",
    "    print(f\"✓ T ≥ 8: Bias likely negligible\")\n",
    "elif T_in_data >= 5:\n",
    "    print(f\"⚠️  5 ≤ T < 8: Some bias may remain\")\n",
    "    print(f\"   Consider bias correction (advanced)\")\n",
    "else:\n",
    "    print(f\"⚠️  T < 5: Substantial bias possible\")\n",
    "    print(f\"   FE Logit may not be appropriate\")\n",
    "    print(f\"   Consider alternatives or bias correction\")\n",
    "\n",
    "print(\"\\nNote: Bias is O(1/T), so:\")\n",
    "print(f\"  Approximate bias proportion: ~{1/T_in_data:.3f}\")\n",
    "print(f\"  This shrinks as panels get longer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitation 4: Computational Complexity\n",
    "\n",
    "### Problem\n",
    "Conditional likelihood computation grows with $T$:\n",
    "- $T \\leq 10$: Fast (enumeration of sequences)\n",
    "- $10 < T \\leq 20$: Moderate (dynamic programming)\n",
    "- $T > 20$: Can be slow\n",
    "\n",
    "### Solution\n",
    "- **Approximations**: For very long panels\n",
    "- **Subsampling**: If $T$ varies, focus on moderate-$T$ subsample\n",
    "- **Patience**: Modern computers can handle $T \\leq 30$ reasonably well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Limitation 4: Computational Cost\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nComputational Complexity by T:\")\n",
    "print(\"  T ≤ 10:    Fast (seconds)\")\n",
    "print(\"  10 < T ≤ 20: Moderate (minutes for large N)\")\n",
    "print(\"  T > 20:    Slow (may require patience)\")\n",
    "print(\"  T > 30:    Very slow (consider approximations)\")\n",
    "\n",
    "print(f\"\\nYour data: T = {T_in_data:.1f}\")\n",
    "if T_in_data <= 10:\n",
    "    print(\"  ✓ Should be fast\")\n",
    "elif T_in_data <= 20:\n",
    "    print(\"  ✓ Moderate speed, acceptable\")\n",
    "else:\n",
    "    print(\"  ⚠️  May be slow, be patient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Framework: When to Use FE Logit?\n",
    "\n",
    "Use this checklist to decide whether FE Logit is appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_estimator(T, pct_switchers, need_time_invariant, outcome_rare=False):\n",
    "    \"\"\"\n",
    "    Decision framework for choosing binary choice estimator.\n",
    "    \n",
    "    Parameters:\n",
    "    - T: Average panel length\n",
    "    - pct_switchers: Percentage of individuals who are switchers (0-1)\n",
    "    - need_time_invariant: Do you need to estimate time-invariant effects?\n",
    "    - outcome_rare: Is the outcome very rare or very common?\n",
    "    \"\"\"\n",
    "    reasons = []\n",
    "    \n",
    "    # Check conditions\n",
    "    if T < 3:\n",
    "        return \"❌ FE Logit NOT recommended\", [\"T < 3: Too few periods\", \n",
    "                                             \"Use: Pooled or Random Effects\"]\n",
    "    \n",
    "    if need_time_invariant:\n",
    "        return \"❌ FE Logit NOT recommended\", [\"Need time-invariant effects\",\n",
    "                                             \"Use: Correlated Random Effects (Notebook 03)\"]\n",
    "    \n",
    "    if pct_switchers < 0.20:\n",
    "        return \"⚠️  FE Logit PROBLEMATIC\", [f\"Only {100*pct_switchers:.0f}% switchers\",\n",
    "                                           \"Sample loss too high\",\n",
    "                                           \"Consider: Random Effects or Pooled\"]\n",
    "    \n",
    "    if outcome_rare and pct_switchers < 0.30:\n",
    "        return \"⚠️  FE Logit QUESTIONABLE\", [\"Rare outcome + few switchers\",\n",
    "                                            \"Check robustness carefully\"]\n",
    "    \n",
    "    if T >= 5 and pct_switchers >= 0.30:\n",
    "        reasons = [f\"T = {T:.0f} ≥ 5: Sufficient periods\",\n",
    "                  f\"{100*pct_switchers:.0f}% switchers: Good utilization\",\n",
    "                  \"Controls for unobserved heterogeneity\"]\n",
    "        return \"✓ FE Logit RECOMMENDED\", reasons\n",
    "    \n",
    "    if T >= 3 and pct_switchers >= 0.25:\n",
    "        reasons = [f\"T = {T:.0f}: Acceptable but bias may remain\",\n",
    "                  f\"{100*pct_switchers:.0f}% switchers: Moderate utilization\",\n",
    "                  \"FE Logit possible, compare with Pooled\"]\n",
    "        return \"⚠️  FE Logit POSSIBLE\", reasons\n",
    "    \n",
    "    return \"⚠️  FE Logit UNCERTAIN\", [\"Borderline case\",\n",
    "                                     \"Estimate both Pooled and FE\",\n",
    "                                     \"Compare and report both\"]\n",
    "\n",
    "# Example usage\n",
    "print(\"=\"*70)\n",
    "print(\"Decision Framework: Should You Use FE Logit?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Our firm data\n",
    "T_example = firm_data.groupby('firm_id').size().mean()\n",
    "switchers_example = utilization_firm / 100\n",
    "time_invariant_example = False  # We don't need industry effects\n",
    "\n",
    "recommendation, reasons = recommend_estimator(\n",
    "    T_example, switchers_example, time_invariant_example\n",
    ")\n",
    "\n",
    "print(f\"\\nYour Data:\")\n",
    "print(f\"  T (avg) = {T_example:.1f}\")\n",
    "print(f\"  Switchers = {100*switchers_example:.0f}%\")\n",
    "print(f\"  Need time-invariant effects = {time_invariant_example}\")\n",
    "\n",
    "print(f\"\\n{recommendation}\")\n",
    "for reason in reasons:\n",
    "    print(f\"  • {reason}\")\n",
    "\n",
    "# Test other scenarios\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Other Scenarios:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scenarios = [\n",
    "    (\"Short panel, few switchers\", 2, 0.15, False, False),\n",
    "    (\"Long panel, many switchers\", 10, 0.60, False, False),\n",
    "    (\"Need time-invariant effects\", 7, 0.50, True, False),\n",
    "    (\"Rare outcome, moderate switchers\", 6, 0.28, False, True),\n",
    "]\n",
    "\n",
    "for name, T, sw, ti, rare in scenarios:\n",
    "    rec, _ = recommend_estimator(T, sw, ti, rare)\n",
    "    print(f\"\\n{name}: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: FE Logit Checklist\n",
    "\n",
    "### ✓ Use FE Logit When:\n",
    "- $T \\geq 5$ (preferably $T \\geq 8$)\n",
    "- $\\geq 30\\%$ of individuals are switchers\n",
    "- Strong theoretical reason to expect $\\alpha_i$ correlates with $X_{it}$\n",
    "- Only need effects of time-varying variables\n",
    "- Causal interpretation is critical\n",
    "\n",
    "### ✗ Do NOT Use FE Logit When:\n",
    "- $T < 3$ (too short)\n",
    "- $< 20\\%$ switchers (too much sample loss)\n",
    "- Need to estimate time-invariant variable effects\n",
    "- Outcome is extremely rare/common with few switchers\n",
    "\n",
    "### ⚠️  Use with Caution When:\n",
    "- $3 \\leq T < 5$ (check finite-T bias)\n",
    "- $20\\% \\leq$ switchers $< 30\\%$ (check robustness)\n",
    "- $T > 20$ (computational cost)\n",
    "\n",
    "### Best Practice:\n",
    "1. **Always report switcher statistics**\n",
    "2. **Compare Pooled vs FE** and discuss differences\n",
    "3. **Report both** if differences are substantial\n",
    "4. **Acknowledge limitations** in interpretation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Exercise 1: Switcher Analysis (Easy)\n",
    "\n",
    "**Goal**: Understand who contributes to FE Logit estimation.\n",
    "\n",
    "**Tasks**:\n",
    "1. Load the job training dataset\n",
    "2. Calculate $\\sum_t employed_{it}$ for each individual\n",
    "3. Classify individuals as: \"Always 0\", \"Switcher\", or \"Always 1\"\n",
    "4. Create:\n",
    "   - Pie chart showing distribution of types\n",
    "   - Histogram of $\\sum_t y_{it}$\n",
    "5. Calculate utilization rate for employment outcome\n",
    "\n",
    "**Questions**:\n",
    "- What percentage of individuals are switchers for employment?\n",
    "- How does this compare to training participation?\n",
    "- Would FE Logit be appropriate for modeling employment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "print(\"Exercise 1: Switcher Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# TODO: Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Incidental Parameters Simulation (Medium)\n",
    "\n",
    "**Goal**: Replicate the incidental parameters bias simulation.\n",
    "\n",
    "**Tasks**:\n",
    "1. Generate panel data with:\n",
    "   - $N = 1000$ individuals\n",
    "   - $T \\in \\{3, 5, 10, 20\\}$ time periods\n",
    "   - True $\\beta = 1.0$\n",
    "   - Individual effects $\\alpha_i \\sim N(0, 1)$\n",
    "   - $X_{it} \\sim N(0, 1)$ independent\n",
    "   - $y_{it}^* = X_{it}\\beta + \\alpha_i + \\varepsilon_{it}$, where $\\varepsilon_{it} \\sim$ Logistic(0,1)\n",
    "2. For each $T$:\n",
    "   - Estimate Logit with individual dummies (\"naive FE\")\n",
    "   - Estimate Pooled Logit\n",
    "   - Estimate FE Logit (PanelBox)\n",
    "3. Calculate bias for each estimator\n",
    "4. Create plot showing bias vs $T$ for all three methods\n",
    "\n",
    "**Expected Result**:\n",
    "- Naive FE: bias decreases with $T$ but substantial for small $T$\n",
    "- Pooled: constant bias (doesn't improve with $T$)\n",
    "- FE Logit: smallest bias, decreases with $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here  \n",
    "print(\"Exercise 2: Incidental Parameters Simulation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# TODO: Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Pooled vs FE Comparison (Medium)\n",
    "\n",
    "**Goal**: Conduct comprehensive comparison of Pooled vs FE Logit.\n",
    "\n",
    "**Tasks**:\n",
    "1. Using the firm technology data, estimate:\n",
    "   - Pooled Logit: `adopted ~ log_size + profit_margin + age`\n",
    "   - FE Logit: same specification\n",
    "2. Create comparison table with:\n",
    "   - Coefficients\n",
    "   - Standard errors (cluster-robust)\n",
    "   - Difference (Pooled - FE)\n",
    "   - Percent difference\n",
    "3. Create forest plot showing both estimates with 95% CIs\n",
    "4. Calculate informal z-statistic for differences\n",
    "5. Interpret results:\n",
    "   - Which variables show large differences?\n",
    "   - What does this imply about unobserved heterogeneity?\n",
    "   - Which model would you recommend?\n",
    "\n",
    "**Bonus**: Repeat for employment outcome in job training data and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "print(\"Exercise 3: Pooled vs FE Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# TODO: Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Decision Framework Application (Hard)\n",
    "\n",
    "**Goal**: Apply the decision framework to determine appropriate estimator.\n",
    "\n",
    "**Scenario**: You have data on individual health insurance choices:\n",
    "- $y_{it}$ = 1 if person $i$ has private insurance at time $t$\n",
    "- $X_{it}$ = (age, income, health status, employment)\n",
    "- Time-invariant: gender, education\n",
    "- $N = 5000$, $T = 4$, years 2018-2021\n",
    "\n",
    "**Tasks**:\n",
    "1. Simulate data matching this scenario with:\n",
    "   - Unobserved health consciousness $\\alpha_i$ correlated with income\n",
    "   - Moderate switcher rate (~35%)\n",
    "   - Insurance rate ~60%\n",
    "2. Calculate switcher statistics\n",
    "3. Apply decision framework:\n",
    "   - Check $T$ requirement\n",
    "   - Check switcher percentage\n",
    "   - Consider need for time-invariant effects (gender, education)\n",
    "4. Estimate all reasonable models:\n",
    "   - Pooled (with and without gender/education)\n",
    "   - FE (only time-varying)\n",
    "5. Compare results and make recommendation\n",
    "6. Write 1-paragraph interpretation for applied paper\n",
    "\n",
    "**Key Question**: Even if FE Logit is technically feasible, should you use it if you care about gender/education effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your code here\n",
    "print(\"Exercise 4: Decision Framework Application\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# TODO: Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary and Next Steps\n",
    "\n",
    "## What You've Learned\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **The Problem**: Unobserved heterogeneity causes bias in Pooled Logit\n",
    "2. **Why Simple FE Fails**: Incidental parameters problem in nonlinear models\n",
    "3. **Chamberlain's Solution**: Conditional MLE eliminates $\\alpha_i$\n",
    "4. **Logit vs Probit**: Why FE works for Logit but not Probit\n",
    "5. **Identification**: Only switchers contribute to estimation\n",
    "6. **Within Variation**: FE identifies within-individual effects\n",
    "7. **Implementation**: How to use PanelBox FixedEffectsLogit\n",
    "8. **Comparison**: How to compare Pooled and FE results\n",
    "9. **Application**: Real-world example with firm technology adoption\n",
    "10. **Limitations**: When NOT to use FE Logit\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **FE Logit controls for time-invariant unobserved heterogeneity**\n",
    "- **Only switchers contribute** - check utilization rate!\n",
    "- **Cannot estimate time-invariant effects**\n",
    "- **Compare with Pooled** to understand magnitude of bias\n",
    "- **Report both** if they differ substantially\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Notebook 03: Random Effects and Correlated Random Effects\n",
    "- Alternative to FE when sample loss is too high\n",
    "- Can estimate time-invariant effects\n",
    "- Allows correlation through Mundlak-Chamberlain device\n",
    "\n",
    "### Notebook 04: Marginal Effects\n",
    "- Calculate and interpret marginal effects\n",
    "- Average Marginal Effects (AME)\n",
    "- Marginal Effects at the Mean (MEM)\n",
    "- Special considerations for FE Logit\n",
    "\n",
    "### Notebook 08: Dynamic Binary Choice\n",
    "- Models with lagged dependent variable\n",
    "- Initial conditions problem\n",
    "- Dynamic panel bias\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "### Essential\n",
    "1. **Chamberlain, G. (1980)**: \"Analysis of Covariance with Qualitative Data\", *Review of Economic Studies*, 47(1), 225-238.\n",
    "   - Original conditional MLE paper\n",
    "\n",
    "2. **Wooldridge, J.M. (2010)**: *Econometric Analysis of Cross Section and Panel Data*, 2nd ed., MIT Press, Chapter 15.8.\n",
    "   - Excellent textbook treatment\n",
    "\n",
    "3. **Cameron, A.C. & Trivedi, P.K. (2005)**: *Microeconometrics: Methods and Applications*, Cambridge University Press, Chapter 23.4.\n",
    "   - Comprehensive coverage with applications\n",
    "\n",
    "### Advanced\n",
    "4. **Neyman, J. & Scott, E.L. (1948)**: \"Consistent Estimates Based on Partially Consistent Observations\", *Econometrica*, 16(1), 1-32.\n",
    "   - Original incidental parameters problem paper\n",
    "\n",
    "5. **Fernández-Val, I. (2009)**: \"Fixed Effects Estimation of Structural Parameters and Marginal Effects in Panel Probit Models\", *Journal of Econometrics*, 150(1), 71-85.\n",
    "   - Bias-corrected FE for Probit\n",
    "\n",
    "6. **Hahn, J. & Kuersteiner, G. (2002)**: \"Asymptotically Unbiased Inference for a Dynamic Panel Model with Fixed Effects When Both $n$ and $T$ Are Large\", *Econometrica*, 70(4), 1639-1657.\n",
    "   - Bias correction methods\n",
    "\n",
    "---\n",
    "\n",
    "## Feedback\n",
    "\n",
    "Questions or suggestions? Please open an issue on the PanelBox GitHub repository!\n",
    "\n",
    "---\n",
    "\n",
    "**End of Tutorial**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
