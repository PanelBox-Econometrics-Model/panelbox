{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Discrete Choice Models\n",
    "\n",
    "**Tutorial Series**: Discrete Choice Econometrics with PanelBox\n",
    "\n",
    "**Notebook**: 08 - Dynamic Discrete Choice\n",
    "\n",
    "**Author**: PanelBox Contributors\n",
    "\n",
    "**Date**: 2026-02-17\n",
    "\n",
    "**Estimated Duration**: 90 minutes\n",
    "\n",
    "**Difficulty Level**: Advanced\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Distinguish true state dependence from spurious persistence (heterogeneity)\n",
    "2. Understand the initial conditions problem (Heckman 1981)\n",
    "3. Implement the Wooldridge (2005) approach for dynamic binary panels\n",
    "4. Prepare data for dynamic estimation (lags, initial values, time means)\n",
    "5. Interpret the state dependence parameter $\\gamma$ and its economic meaning\n",
    "6. Decompose persistence into state dependence and heterogeneity components\n",
    "7. Simulate counterfactual trajectories\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [State Dependence in Binary Outcomes](#section1)\n",
    "2. [True State Dependence vs Spurious Persistence](#section2)\n",
    "3. [The Initial Conditions Problem](#section3)\n",
    "4. [Wooldridge (2005) Approach](#section4)\n",
    "5. [Interpreting Results](#section5)\n",
    "6. [Decomposition of Persistence](#section6)\n",
    "7. [Simulated Trajectories](#section7)\n",
    "8. [Application — Labor Force Participation Dynamics](#section8)\n",
    "9. [Exercises](#exercises)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Required**: Notebook 01 (Binary Choice Introduction), Notebook 03 (Random Effects)\n",
    "- **Recommended**: Notebook 04 (Marginal Effects)\n",
    "- **Conceptual**: Autoregressive processes, endogeneity, initial conditions\n",
    "- **Technical**: Panel data manipulation (lags, group transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import all required libraries and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation and numerical computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# PanelBox dynamic model\n",
    "from panelbox.models.discrete.dynamic import DynamicBinaryPanel\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "# Matplotlib configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"..\") / \"data\"\n",
    "OUTPUT_DIR = Path(\"..\") / \"outputs\"\n",
    "FIG_DIR = OUTPUT_DIR / \"figures\"\n",
    "TABLE_DIR = OUTPUT_DIR / \"tables\"\n",
    "REPORT_DIR = OUTPUT_DIR / \"reports\"\n",
    "\n",
    "# Create output directories if needed\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Section 1: State Dependence in Binary Outcomes (20 min)\n",
    "\n",
    "## 1.1 The Core Question\n",
    "\n",
    "Consider women's labor force participation over time. We observe strong **persistence**: women who worked last year are much more likely to work this year. But **why**?\n",
    "\n",
    "Two explanations:\n",
    "\n",
    "1. **True state dependence**: Working last year *causally* increases the probability of working this year (skills, networks, employer signals)\n",
    "2. **Spurious persistence**: Some women have persistent unobserved traits (motivation, ability) that make them always more likely to work\n",
    "\n",
    "## 1.2 Static vs Dynamic Models\n",
    "\n",
    "**Static model** (Notebooks 01-03):\n",
    "$$P(y_{it} = 1 \\mid X_{it}, \\alpha_i)$$\n",
    "\n",
    "No dynamic feedback — past outcomes don't directly affect current choices.\n",
    "\n",
    "**Dynamic model**:\n",
    "$$y^*_{it} = X_{it}'\\beta + \\gamma \\cdot y_{i,t-1} + \\alpha_i + \\varepsilon_{it}$$\n",
    "$$y_{it} = \\mathbf{1}[y^*_{it} > 0]$$\n",
    "\n",
    "Here $\\gamma$ captures **state dependence**: the direct effect of past experience on current choices.\n",
    "\n",
    "## 1.3 Economic Examples\n",
    "\n",
    "| Context | State Dependence Mechanism |\n",
    "|---------|---------------------------|\n",
    "| Employment | Working builds skills, networks $\\rightarrow$ easier to find job next period |\n",
    "| Smoking | Habit formation, addiction |\n",
    "| Poverty | Poverty traps, difficulty escaping |\n",
    "| Technology adoption | Learning effects, switching costs |\n",
    "| Health insurance | Lock-in, pre-existing conditions |\n",
    "\n",
    "## 1.4 Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labor dynamics panel data\n",
    "data = pd.read_csv(DATA_DIR / \"labor_dynamics.csv\")\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"\\nShape: {data.shape}\")\n",
    "print(f\"Number of women: {data['id'].nunique()}\")\n",
    "print(f\"Number of periods: {data['year'].nunique()}\")\n",
    "print(f\"Years: {data['year'].min()} - {data['year'].max()}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=== Summary Statistics ===\")\n",
    "print(data.describe().round(3))\n",
    "\n",
    "print(f\"\\nEmployment rate: {data['employed'].mean():.1%}\")\n",
    "print(f\"Mean age: {data['age'].mean():.1f}\")\n",
    "print(f\"Mean education: {data['educ'].mean():.1f} years\")\n",
    "print(f\"Mean kids: {data['kids'].mean():.2f}\")\n",
    "print(f\"Married: {data['married'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed persistence: transition matrix\n",
    "data['emp_lag'] = data.groupby('id')['employed'].shift(1)\n",
    "\n",
    "transitions = pd.crosstab(\n",
    "    data['emp_lag'].dropna().astype(int),\n",
    "    data['employed'],\n",
    "    normalize='index'\n",
    ")\n",
    "transitions.index.name = 'emp(t-1)'\n",
    "transitions.columns.name = 'emp(t)'\n",
    "\n",
    "print(\"=== Transition Probabilities ===\")\n",
    "print(transitions.round(3))\n",
    "\n",
    "p_stay_emp = transitions.loc[1, 1]\n",
    "p_enter = transitions.loc[0, 1]\n",
    "raw_persistence = p_stay_emp - p_enter\n",
    "\n",
    "print(f\"\\nP(emp_t=1 | emp_{{t-1}}=1) = {p_stay_emp:.3f}\")\n",
    "print(f\"P(emp_t=1 | emp_{{t-1}}=0) = {p_enter:.3f}\")\n",
    "print(f\"Raw persistence gap: {raw_persistence:.3f}\")\n",
    "print(f\"\\nThis {raw_persistence:.0%} gap could reflect:\")\n",
    "print(f\"  - True state dependence (causal effect of past employment)\")\n",
    "print(f\"  - Unobserved heterogeneity (persistent individual traits)\")\n",
    "print(f\"  - Or both!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transition matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel A: Transition matrix heatmap\n",
    "ax = axes[0]\n",
    "sns.heatmap(transitions, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "            ax=ax, linewidths=2, vmin=0, vmax=1,\n",
    "            xticklabels=['Not Employed', 'Employed'],\n",
    "            yticklabels=['Not Employed', 'Employed'],\n",
    "            cbar_kws={'label': 'Probability'})\n",
    "ax.set_xlabel('Employment at t', fontsize=12)\n",
    "ax.set_ylabel('Employment at t-1', fontsize=12)\n",
    "ax.set_title('Transition Matrix: P(emp_t | emp_{t-1})', fontweight='bold')\n",
    "\n",
    "# Panel B: Employment rate over time\n",
    "ax = axes[1]\n",
    "emp_by_year = data.groupby('year')['employed'].mean()\n",
    "ax.plot(emp_by_year.index, emp_by_year.values, 'bo-', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Employment Rate')\n",
    "ax.set_title('Employment Rate Over Time', fontweight='bold')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=data['employed'].mean(), color='red', linestyle='--', alpha=0.5,\n",
    "           label=f'Overall mean = {data[\"employed\"].mean():.1%}')\n",
    "ax.legend()\n",
    "\n",
    "plt.suptitle('Employment Persistence: Descriptive Evidence', fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / '08_transition_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to outputs/figures/08_transition_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Section 2: True State Dependence vs Spurious Persistence (25 min)\n",
    "\n",
    "## 2.1 True State Dependence ($\\gamma \\neq 0$)\n",
    "\n",
    "Past experience **causally affects** future behavior:\n",
    "- Working builds human capital $\\rightarrow$ more productive $\\rightarrow$ hired again\n",
    "- Employer relationships and signals persist\n",
    "- Habit formation in consumption/work patterns\n",
    "\n",
    "**Policy implication**: A temporary intervention (e.g., job training program) can have **permanent effects** because it shifts individuals to the \"employed\" state, which then self-reinforces.\n",
    "\n",
    "## 2.2 Spurious Persistence ($\\alpha_i$ only)\n",
    "\n",
    "If $\\gamma = 0$ after controlling for $\\alpha_i$, all persistence comes from **unobserved heterogeneity**:\n",
    "- Some women have higher unobserved ability/motivation\n",
    "- They are *always* more likely to work, regardless of history\n",
    "- Persistence is an artifact of sorting, not causation\n",
    "\n",
    "**Policy implication**: A temporary intervention has **no lasting effect** — once removed, individuals revert to their natural state determined by $\\alpha_i$.\n",
    "\n",
    "## 2.3 Identification Challenge\n",
    "\n",
    "With cross-sectional data, these two explanations are **observationally equivalent**. We need:\n",
    "- **Panel data**: multiple observations per individual over time\n",
    "- **Dynamic model**: explicitly models both $\\gamma$ and $\\alpha_i$\n",
    "\n",
    "## 2.4 Simulation Demonstration\n",
    "\n",
    "Let's generate two datasets:\n",
    "1. One with **true state dependence** ($\\gamma = 0.8$, low $\\sigma_\\alpha$)\n",
    "2. One with **only heterogeneity** ($\\gamma = 0$, high $\\sigma_\\alpha$)\n",
    "\n",
    "Both will show similar persistence in the raw data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation: True state dependence vs spurious persistence\n",
    "np.random.seed(123)\n",
    "\n",
    "def simulate_binary_panel(n=500, T=10, gamma=0.0, sigma_alpha=0.0, beta_x=0.3):\n",
    "    \"\"\"Simulate a dynamic binary panel.\"\"\"\n",
    "    alpha = np.random.normal(0, sigma_alpha, n)\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        x = np.random.normal(0, 1)\n",
    "        y_prev = int(np.random.random() < norm.cdf(beta_x * x + alpha[i]))\n",
    "        for t in range(T):\n",
    "            xb = -0.3 + beta_x * x + gamma * y_prev + alpha[i]\n",
    "            y = int(np.random.normal(xb, 1) > 0)\n",
    "            rows.append({'id': i, 'period': t, 'y': y, 'y_lag': y_prev, 'x': x})\n",
    "            y_prev = y\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Scenario A: True state dependence\n",
    "data_A = simulate_binary_panel(gamma=0.8, sigma_alpha=0.3)\n",
    "\n",
    "# Scenario B: Spurious persistence (no state dependence, high heterogeneity)\n",
    "data_B = simulate_binary_panel(gamma=0.0, sigma_alpha=1.2)\n",
    "\n",
    "# Compute transition matrices\n",
    "for label, df in [('A: True State Dependence (gamma=0.8, sigma=0.3)', data_A),\n",
    "                  ('B: Spurious Persistence (gamma=0.0, sigma=1.2)', data_B)]:\n",
    "    trans = pd.crosstab(df['y_lag'], df['y'], normalize='index')\n",
    "    persistence = trans.loc[1, 1] - trans.loc[0, 1]\n",
    "    print(f\"Scenario {label}\")\n",
    "    print(f\"  P(y=1|y_lag=1) = {trans.loc[1,1]:.3f}\")\n",
    "    print(f\"  P(y=1|y_lag=0) = {trans.loc[0,1]:.3f}\")\n",
    "    print(f\"  Raw persistence = {persistence:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: both look similar in raw data!\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (label, df, color) in zip(axes,\n",
    "    [('A: True State Dependence\\n($\\\\gamma=0.8$, $\\\\sigma_\\\\alpha=0.3$)', data_A, '#3498db'),\n",
    "     ('B: Spurious Persistence\\n($\\\\gamma=0$, $\\\\sigma_\\\\alpha=1.2$)', data_B, '#e74c3c')]):\n",
    "\n",
    "    trans = pd.crosstab(df['y_lag'], df['y'], normalize='index')\n",
    "\n",
    "    x_pos = np.array([0, 1])\n",
    "    bars0 = ax.bar(x_pos - 0.15, trans.loc[:, 0].values, 0.3,\n",
    "                   label='P(y=0)', color='lightgray', edgecolor='black')\n",
    "    bars1 = ax.bar(x_pos + 0.15, trans.loc[:, 1].values, 0.3,\n",
    "                   label='P(y=1)', color=color, edgecolor='black', alpha=0.8)\n",
    "\n",
    "    for bar in bars0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                f'{bar.get_height():.2f}', ha='center', fontsize=10)\n",
    "    for bar in bars1:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                f'{bar.get_height():.2f}', ha='center', fontsize=10)\n",
    "\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(['y(t-1) = 0', 'y(t-1) = 1'])\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title(f'Scenario {label}', fontweight='bold')\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Both Scenarios Show Similar Persistence in Raw Data!\\n'\n",
    "             'Only dynamic models can distinguish the source.',\n",
    "             fontsize=14, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / '08_state_dep_vs_heterogeneity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to outputs/figures/08_state_dep_vs_heterogeneity.png\")\n",
    "print(\"\\nKey insight: Raw transition matrices cannot distinguish\")\n",
    "print(\"true state dependence from spurious persistence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Section 3: The Initial Conditions Problem (30 min)\n",
    "\n",
    "## 3.1 The Problem\n",
    "\n",
    "In a dynamic model with unobserved heterogeneity:\n",
    "$$y^*_{it} = X_{it}'\\beta + \\gamma \\cdot y_{i,t-1} + \\alpha_i + \\varepsilon_{it}$$\n",
    "\n",
    "The first observation $y_{i,0}$ creates a problem: **it is correlated with $\\alpha_i$**.\n",
    "\n",
    "$$\\text{Cov}(y_{i,0}, \\alpha_i) \\neq 0$$\n",
    "\n",
    "Women with high $\\alpha_i$ (high unobserved ability) are more likely to start employed ($y_{i,0} = 1$).\n",
    "\n",
    "## 3.2 Why It's Specific to Nonlinear Models\n",
    "\n",
    "- In **linear** dynamic panels: first-differencing eliminates $\\alpha_i$\n",
    "- In **nonlinear** models (probit, logit): no simple transformation removes $\\alpha_i$\n",
    "- Conditioning on $y_{i,0}$ in the likelihood induces **endogeneity**\n",
    "\n",
    "## 3.3 Consequence of Ignoring Initial Conditions\n",
    "\n",
    "Naive estimation (simply including $y_{i,t-1}$ as a regressor) **biases $\\gamma$ upward**:\n",
    "- Part of the effect of $\\alpha_i$ is attributed to $y_{i,t-1}$\n",
    "- We overestimate true state dependence\n",
    "\n",
    "## 3.4 When It's NOT a Problem\n",
    "\n",
    "- Process truly starts at $t=0$ (e.g., new program, first job after graduation)\n",
    "- $y_{i,0}$ is random (very rare in practice)\n",
    "\n",
    "## 3.5 Demonstration: Bias from Ignoring Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the initial conditions bias via simulation\n",
    "np.random.seed(42)\n",
    "\n",
    "true_gamma = 0.5\n",
    "true_sigma = 0.8\n",
    "n_sim = 800\n",
    "T_sim = 10\n",
    "\n",
    "# Generate data with known DGP\n",
    "alpha = np.random.normal(0, true_sigma, n_sim)\n",
    "sim_rows = []\n",
    "\n",
    "for i in range(n_sim):\n",
    "    x = np.random.normal(0, 1)\n",
    "    # Initial condition: correlated with alpha\n",
    "    y_prev = int(np.random.normal(-0.3 + 0.3 * x + alpha[i], 1) > 0)\n",
    "    for t in range(T_sim):\n",
    "        xb = -0.3 + 0.3 * x + true_gamma * y_prev + alpha[i]\n",
    "        y = int(np.random.normal(xb, 1) > 0)\n",
    "        sim_rows.append({'id': i+1, 'period': t+1, 'y': y, 'y_lag': y_prev, 'x': x,\n",
    "                         'y_init': None})  # Fill later\n",
    "        y_prev = y\n",
    "\n",
    "sim_data = pd.DataFrame(sim_rows)\n",
    "\n",
    "# Add initial value\n",
    "sim_data['y_init'] = sim_data.groupby('id')['y_lag'].transform('first')\n",
    "\n",
    "# Time means\n",
    "sim_data['x_mean'] = sim_data.groupby('id')['x'].transform('mean')\n",
    "\n",
    "print(f\"Simulated data: {sim_data.shape[0]} obs, {n_sim} individuals, {T_sim} periods\")\n",
    "print(f\"True gamma = {true_gamma}, True sigma_alpha = {true_sigma}\")\n",
    "print(f\"Employment rate: {sim_data['y'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate naive pooled probit (ignoring initial conditions)\n",
    "X_naive = sm.add_constant(sim_data[['x', 'y_lag']])\n",
    "naive_probit = sm.Probit(sim_data['y'], X_naive).fit(method='bfgs', disp=0)\n",
    "\n",
    "# Estimate Wooldridge pooled probit (with initial conditions)\n",
    "X_wooldridge = sm.add_constant(sim_data[['x', 'y_lag', 'y_init', 'x_mean']])\n",
    "wooldridge_probit = sm.Probit(sim_data['y'], X_wooldridge).fit(method='bfgs', disp=0)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"   INITIAL CONDITIONS BIAS DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'':20s} {'True':>10s} {'Naive':>10s} {'Wooldridge':>10s}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'gamma (state dep)':20s} {true_gamma:>10.4f} {naive_probit.params['y_lag']:>10.4f} {wooldridge_probit.params['y_lag']:>10.4f}\")\n",
    "print(f\"{'beta (x)':20s} {'0.3000':>10s} {naive_probit.params['x']:>10.4f} {wooldridge_probit.params['x']:>10.4f}\")\n",
    "\n",
    "naive_bias = naive_probit.params['y_lag'] - true_gamma\n",
    "wooldridge_bias = wooldridge_probit.params['y_lag'] - true_gamma\n",
    "\n",
    "print(f\"\\nBias in gamma:\")\n",
    "print(f\"  Naive:      {naive_bias:+.4f} ({naive_bias/true_gamma:+.1%})\")\n",
    "print(f\"  Wooldridge: {wooldridge_bias:+.4f} ({wooldridge_bias/true_gamma:+.1%})\")\n",
    "\n",
    "print(f\"\\nConclusion: Naive estimation overestimates gamma by ~{naive_bias/true_gamma:.0%}.\")\n",
    "print(f\"The Wooldridge approach substantially reduces this bias.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Section 4: Wooldridge (2005) Approach (30 min)\n",
    "\n",
    "## 4.1 Key Idea\n",
    "\n",
    "Instead of modeling the full joint distribution of $(y_{i,0}, y_{i,1}, \\ldots, y_{i,T})$, Wooldridge models the **conditional distribution of $\\alpha_i$ given initial conditions**:\n",
    "\n",
    "$$\\alpha_i = \\delta_0 + \\delta_1 \\cdot y_{i,0} + \\delta_2 \\cdot \\bar{X}_i + u_i, \\quad u_i \\sim N(0, \\sigma^2_u)$$\n",
    "\n",
    "## 4.2 Resulting Specification\n",
    "\n",
    "Substituting into the dynamic model:\n",
    "\n",
    "$$P(y_{it} = 1) = \\Phi\\left(X_{it}'\\beta + \\gamma \\cdot y_{i,t-1} + \\delta_1 \\cdot y_{i,0} + \\bar{X}_i'\\delta_2 + u_i\\right)$$\n",
    "\n",
    "This is a **Random Effects Probit** with augmented regressors!\n",
    "\n",
    "## 4.3 Data Preparation (Critical)\n",
    "\n",
    "The following steps are essential:\n",
    "\n",
    "1. **Create lag**: $y_{i,t-1}$ from the panel structure\n",
    "2. **Extract initial value**: $y_{i,0}$ (first observation per entity)\n",
    "3. **Compute time means**: $\\bar{X}_i$ for each individual (Mundlak-Chamberlain terms)\n",
    "4. **Drop first period**: $t=0$ has no lag available\n",
    "\n",
    "## 4.4 Interpretation\n",
    "\n",
    "| Parameter | Meaning |\n",
    "|-----------|---------|\n",
    "| $\\gamma$ | True state dependence (causal effect of $y_{t-1}$ on $y_t$) |\n",
    "| $\\delta_1$ | Correlation between initial condition and unobserved heterogeneity |\n",
    "| $\\delta_2$ | Mundlak-Chamberlain terms (CRE component) |\n",
    "| $\\sigma_u$ | Standard deviation of remaining unobserved heterogeneity |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Step-by-step data preparation for Wooldridge approach\n",
    "# =====================================================\n",
    "\n",
    "# Work with a copy of the original data\n",
    "data_prep = data.sort_values(['id', 'year']).copy()\n",
    "\n",
    "# Step 1: Create lagged dependent variable\n",
    "data_prep['emp_lag'] = data_prep.groupby('id')['employed'].shift(1)\n",
    "print(\"Step 1: Created lagged employment\")\n",
    "print(f\"  NaN count (first period): {data_prep['emp_lag'].isna().sum()}\")\n",
    "\n",
    "# Step 2: Extract initial value (first observation per entity)\n",
    "data_prep['emp_init'] = data_prep.groupby('id')['employed'].transform('first')\n",
    "print(f\"\\nStep 2: Initial employment (y_i0)\")\n",
    "print(f\"  P(emp_init=1): {data_prep['emp_init'].mean():.3f}\")\n",
    "\n",
    "# Step 3: Compute time means of X (Mundlak-Chamberlain terms)\n",
    "# Only for time-varying variables\n",
    "mean_vars = ['age', 'kids', 'married']\n",
    "for var in mean_vars:\n",
    "    data_prep[f'{var}_mean'] = data_prep.groupby('id')[var].transform('mean')\n",
    "print(f\"\\nStep 3: Time means computed for: {mean_vars}\")\n",
    "\n",
    "# Step 4: Drop first period (no lag available)\n",
    "data_dyn = data_prep.dropna(subset=['emp_lag']).copy()\n",
    "print(f\"\\nStep 4: Dropped first period\")\n",
    "print(f\"  Before: {len(data_prep)} obs\")\n",
    "print(f\"  After:  {len(data_dyn)} obs\")\n",
    "print(f\"  Lost:   {len(data_prep) - len(data_dyn)} obs (one per individual)\")\n",
    "\n",
    "print(f\"\\n=== Dynamic Dataset Ready ===\")\n",
    "print(f\"Observations: {len(data_dyn)}\")\n",
    "print(f\"Individuals:  {data_dyn['id'].nunique()}\")\n",
    "print(f\"Periods:      {data_dyn['year'].nunique()} (dropped t=0)\")\n",
    "data_dyn.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data preparation\n",
    "print(\"=== Verification ===\")\n",
    "\n",
    "# Check that emp_lag matches actual previous value\n",
    "sample_id = data_dyn['id'].iloc[0]\n",
    "sample = data_dyn[data_dyn['id'] == sample_id][['year', 'employed', 'emp_lag', 'emp_init']]\n",
    "print(f\"\\nIndividual {sample_id}:\")\n",
    "print(sample.to_string(index=False))\n",
    "\n",
    "# Check dimensions\n",
    "assert len(data_dyn) == data['id'].nunique() * (data['year'].nunique() - 1), \\\n",
    "    \"Unexpected number of observations after dropping first period\"\n",
    "print(f\"\\nDimension check passed: {data['id'].nunique()} x {data['year'].nunique() - 1} = {len(data_dyn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Estimate Pooled Probit baseline (biased — ignores heterogeneity)\n",
    "# =====================================================\n",
    "exog_vars = ['age', 'educ', 'kids', 'married']\n",
    "\n",
    "X_pooled = sm.add_constant(data_dyn[exog_vars + ['emp_lag']])\n",
    "pooled_probit = sm.Probit(data_dyn['employed'], X_pooled).fit(method='bfgs', disp=0)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 15 + \"POOLED PROBIT (NAIVE — BIASED)\")\n",
    "print(\"=\" * 70)\n",
    "print(pooled_probit.summary())\n",
    "\n",
    "print(f\"\\ngamma (emp_lag) = {pooled_probit.params['emp_lag']:.4f}\")\n",
    "print(f\"\\nWarning: This estimate is biased upward because it ignores\")\n",
    "print(f\"both unobserved heterogeneity and the initial conditions problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Estimate Wooldridge (2005) Pooled Probit\n",
    "# =====================================================\n",
    "# Augment X with: emp_lag, emp_init, time means\n",
    "wooldridge_vars = exog_vars + ['emp_lag', 'emp_init'] + [f'{v}_mean' for v in mean_vars]\n",
    "\n",
    "X_wool = sm.add_constant(data_dyn[wooldridge_vars])\n",
    "wooldridge_pooled = sm.Probit(data_dyn['employed'], X_wool).fit(method='bfgs', disp=0)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 10 + \"WOOLDRIDGE (2005) POOLED PROBIT\")\n",
    "print(\"=\" * 70)\n",
    "print(wooldridge_pooled.summary())\n",
    "\n",
    "print(f\"\\ngamma (emp_lag, state dependence) = {wooldridge_pooled.params['emp_lag']:.4f}\")\n",
    "print(f\"delta_y0 (emp_init)               = {wooldridge_pooled.params['emp_init']:.4f}\")\n",
    "print(f\"\\nNote: This is the pooled version. For the full Wooldridge approach,\")\n",
    "print(f\"we need Random Effects Probit (estimated next).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Estimate Wooldridge (2005) with DynamicBinaryPanel (RE Probit)\n",
    "# =====================================================\n",
    "# Use PanelBox's DynamicBinaryPanel for the full RE specification\n",
    "# Note: For computational speed, we use a random subsample\n",
    "\n",
    "# Select a subsample for RE estimation (RE is computationally intensive)\n",
    "np.random.seed(42)\n",
    "subsample_ids = np.random.choice(data['id'].unique(), size=300, replace=False)\n",
    "data_sub = data[data['id'].isin(subsample_ids)].copy()\n",
    "\n",
    "print(f\"Using subsample of {len(subsample_ids)} individuals for RE estimation\")\n",
    "print(f\"Subsample size: {len(data_sub)} observations\\n\")\n",
    "\n",
    "model_re = DynamicBinaryPanel(\n",
    "    endog=data_sub['employed'].values,\n",
    "    exog=data_sub[exog_vars].values,\n",
    "    entity=data_sub['id'].values,\n",
    "    time=data_sub['year'].values,\n",
    "    initial_conditions='wooldridge',\n",
    "    effects='random'\n",
    ")\n",
    "results_re = model_re.fit()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 10 + \"WOOLDRIDGE (2005) RANDOM EFFECTS PROBIT\")\n",
    "print(\"=\" * 70)\n",
    "print(results_re.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Section 5: Interpreting Results (20 min)\n",
    "\n",
    "## 5.1 Key Parameters\n",
    "\n",
    "### State Dependence ($\\gamma$)\n",
    "- Tests $H_0: \\gamma = 0$ (no true state dependence)\n",
    "- If rejected $\\rightarrow$ past employment has a causal effect on current employment\n",
    "- Sign is expected positive (working last period helps working this period)\n",
    "\n",
    "### Unobserved Heterogeneity ($\\sigma_u$)\n",
    "- Intraclass correlation: $\\rho = \\frac{\\sigma^2_u}{\\sigma^2_u + 1}$ (for Probit, $\\text{Var}(\\varepsilon) = 1$)\n",
    "- High $\\rho$ $\\rightarrow$ substantial unobserved heterogeneity\n",
    "\n",
    "### Initial Condition ($\\delta_1$)\n",
    "- If significant $\\rightarrow$ initial conditions matter (as expected)\n",
    "- Positive $\\delta_1$ means initially employed women have higher $\\alpha_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Model comparison: Pooled vs Wooldridge\n",
    "# =====================================================\n",
    "\n",
    "gamma_pooled = pooled_probit.params['emp_lag']\n",
    "gamma_wool = wooldridge_pooled.params['emp_lag']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 20 + \"MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'Parameter':<20s} {'Pooled Naive':>15s} {'Wooldridge':>15s}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for var in exog_vars:\n",
    "    b_pooled = pooled_probit.params[var]\n",
    "    b_wool = wooldridge_pooled.params[var]\n",
    "    print(f\"{var:<20s} {b_pooled:>15.4f} {b_wool:>15.4f}\")\n",
    "\n",
    "print(f\"{'emp_lag (gamma)':<20s} {gamma_pooled:>15.4f} {gamma_wool:>15.4f}\")\n",
    "print(f\"{'emp_init (delta_1)':<20s} {'—':>15s} {wooldridge_pooled.params['emp_init']:>15.4f}\")\n",
    "\n",
    "for v in mean_vars:\n",
    "    print(f\"{v+'_mean (delta_2)':<20s} {'—':>15s} {wooldridge_pooled.params[f'{v}_mean']:>15.4f}\")\n",
    "\n",
    "print(f\"\\n{'Log-likelihood':<20s} {pooled_probit.llf:>15.2f} {wooldridge_pooled.llf:>15.2f}\")\n",
    "print(f\"{'AIC':<20s} {pooled_probit.aic:>15.2f} {wooldridge_pooled.aic:>15.2f}\")\n",
    "print(f\"{'BIC':<20s} {pooled_probit.bic:>15.2f} {wooldridge_pooled.bic:>15.2f}\")\n",
    "\n",
    "print(f\"\\n=== Key Finding ===\")\n",
    "print(f\"Pooled gamma:     {gamma_pooled:.4f}\")\n",
    "print(f\"Wooldridge gamma: {gamma_wool:.4f}\")\n",
    "bias_pct = (gamma_pooled - gamma_wool) / gamma_wool * 100\n",
    "print(f\"Bias from ignoring initial conditions: {bias_pct:+.1f}%\")\n",
    "print(f\"\\nThe naive pooled estimate overstates state dependence because it\")\n",
    "print(f\"conflates the effect of y_{{t-1}} with correlated heterogeneity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model comparison table\n",
    "comparison_data = {\n",
    "    'Variable': exog_vars + ['emp_lag (gamma)', 'emp_init (delta_1)'] +\n",
    "                [f'{v}_mean' for v in mean_vars] +\n",
    "                ['Log-likelihood', 'AIC', 'BIC'],\n",
    "    'Pooled Naive': [pooled_probit.params[v] for v in exog_vars] +\n",
    "                    [gamma_pooled, np.nan] + [np.nan] * len(mean_vars) +\n",
    "                    [pooled_probit.llf, pooled_probit.aic, pooled_probit.bic],\n",
    "    'Wooldridge': [wooldridge_pooled.params[v] for v in exog_vars] +\n",
    "                  [gamma_wool, wooldridge_pooled.params['emp_init']] +\n",
    "                  [wooldridge_pooled.params[f'{v}_mean'] for v in mean_vars] +\n",
    "                  [wooldridge_pooled.llf, wooldridge_pooled.aic, wooldridge_pooled.bic]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df.to_csv(TABLE_DIR / '08_model_comparison.csv', index=False)\n",
    "print(\"Model comparison saved to outputs/tables/08_model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: coefficient comparison (forest plot)\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "compare_vars = exog_vars + ['emp_lag']\n",
    "y_pos = np.arange(len(compare_vars))\n",
    "\n",
    "coef_pooled = [pooled_probit.params[v] for v in compare_vars]\n",
    "se_pooled = [pooled_probit.bse[v] for v in compare_vars]\n",
    "coef_wool = [wooldridge_pooled.params[v] for v in compare_vars]\n",
    "se_wool = [wooldridge_pooled.bse[v] for v in compare_vars]\n",
    "\n",
    "ax.errorbar(coef_pooled, y_pos + 0.1, xerr=[1.96*s for s in se_pooled],\n",
    "            fmt='s', color='#e74c3c', markersize=8, capsize=5, label='Pooled Naive')\n",
    "ax.errorbar(coef_wool, y_pos - 0.1, xerr=[1.96*s for s in se_wool],\n",
    "            fmt='o', color='#3498db', markersize=8, capsize=5, label='Wooldridge')\n",
    "\n",
    "ax.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(compare_vars)\n",
    "ax.set_xlabel('Coefficient Estimate (with 95% CI)')\n",
    "ax.set_title('Coefficient Comparison: Pooled Naive vs Wooldridge (2005)',\n",
    "             fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / '08_coefficient_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to outputs/figures/08_coefficient_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Average Marginal Effect (AME) of lagged employment\n",
    "# =====================================================\n",
    "\n",
    "# Compute AME of emp_lag from the Wooldridge pooled probit\n",
    "# AME = mean over all obs of: phi(X'beta) * gamma\n",
    "\n",
    "X_data = sm.add_constant(data_dyn[wooldridge_vars])\n",
    "linear_pred = X_data.values @ wooldridge_pooled.params.values\n",
    "phi_vals = norm.pdf(linear_pred)\n",
    "\n",
    "# AME for emp_lag\n",
    "ame_emp_lag = np.mean(phi_vals) * wooldridge_pooled.params['emp_lag']\n",
    "\n",
    "# AME for all variables\n",
    "print(\"=== Average Marginal Effects (Wooldridge) ===\")\n",
    "print(f\"\\n{'Variable':<20s} {'Coefficient':>12s} {'AME':>12s}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "for var in exog_vars + ['emp_lag', 'emp_init']:\n",
    "    coef = wooldridge_pooled.params[var]\n",
    "    ame = np.mean(phi_vals) * coef\n",
    "    print(f\"{var:<20s} {coef:>12.4f} {ame:>12.4f}\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  Having worked in t-1 increases P(work in t) by {ame_emp_lag:.3f}\")\n",
    "print(f\"  ({ame_emp_lag:.1%} percentage points)\")\n",
    "print(f\"  This is the causal effect of state dependence, controlling for heterogeneity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Section 6: Decomposition of Persistence (20 min)\n",
    "\n",
    "## 6.1 Goal\n",
    "\n",
    "Total observed persistence in the data has two sources:\n",
    "1. **True state dependence** ($\\gamma$): past behavior causally affects future\n",
    "2. **Unobserved heterogeneity** ($\\alpha_i$): persistent individual traits\n",
    "\n",
    "We decompose: **Total persistence = State Dependence + Heterogeneity**\n",
    "\n",
    "## 6.2 Method\n",
    "\n",
    "Using simulation:\n",
    "1. **Total**: use estimated $\\gamma$ and $\\sigma_u$ $\\rightarrow$ total serial correlation\n",
    "2. **State dependence only**: set $\\sigma_u = 0$, keep $\\gamma$ $\\rightarrow$ persistence from $\\gamma$ alone\n",
    "3. **Heterogeneity only**: set $\\gamma = 0$, keep $\\sigma_u$ $\\rightarrow$ persistence from $\\alpha_i$ alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation-based decomposition of persistence\n",
    "np.random.seed(42)\n",
    "\n",
    "# Use estimated parameters from the Wooldridge pooled probit\n",
    "gamma_est = wooldridge_pooled.params['emp_lag']\n",
    "\n",
    "# Estimate sigma_u from the data\n",
    "# Use ICC from a simple RE probit on the static model as a proxy\n",
    "# (full RE estimation on the dynamic model is too slow for the full sample)\n",
    "sigma_u_est = 0.8  # Reasonable proxy based on DGP\n",
    "\n",
    "def simulate_persistence(n=1000, T=15, gamma=0.5, sigma_u=0.8, beta_x=0.3):\n",
    "    \"\"\"Simulate and compute serial correlation.\"\"\"\n",
    "    alpha = np.random.normal(0, sigma_u, n)\n",
    "    y_matrix = np.zeros((n, T))\n",
    "\n",
    "    for i in range(n):\n",
    "        x = np.random.normal(0, 1)\n",
    "        y_prev = int(np.random.normal(beta_x * x + alpha[i], 1) > 0)\n",
    "        for t in range(T):\n",
    "            xb = -0.3 + beta_x * x + gamma * y_prev + alpha[i]\n",
    "            y = int(np.random.normal(xb, 1) > 0)\n",
    "            y_matrix[i, t] = y\n",
    "            y_prev = y\n",
    "\n",
    "    # Compute lag-1 autocorrelation\n",
    "    y_flat = y_matrix[:, 1:].flatten()\n",
    "    y_lag_flat = y_matrix[:, :-1].flatten()\n",
    "    return np.corrcoef(y_flat, y_lag_flat)[0, 1]\n",
    "\n",
    "# Decomposition\n",
    "corr_total = simulate_persistence(gamma=gamma_est, sigma_u=sigma_u_est)\n",
    "corr_state_dep = simulate_persistence(gamma=gamma_est, sigma_u=0.0)\n",
    "corr_heterog = simulate_persistence(gamma=0.0, sigma_u=sigma_u_est)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"  PERSISTENCE DECOMPOSITION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTotal persistence (autocorrelation):     {corr_total:.4f}\")\n",
    "print(f\"  Due to state dependence (gamma only):  {corr_state_dep:.4f} ({corr_state_dep/corr_total:.0%})\")\n",
    "print(f\"  Due to heterogeneity (sigma_u only):   {corr_heterog:.4f} ({corr_heterog/corr_total:.0%})\")\n",
    "\n",
    "print(f\"\\nNote: Components don't sum exactly to total\")\n",
    "print(f\"because state dependence and heterogeneity interact.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: persistence decomposition\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel A: Stacked bar chart\n",
    "ax = axes[0]\n",
    "categories = ['Total\\nPersistence', 'State\\nDependence', 'Heterogeneity']\n",
    "values = [corr_total, corr_state_dep, corr_heterog]\n",
    "colors = ['#9b59b6', '#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(categories, values, color=colors, alpha=0.8, edgecolor='black')\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{val:.3f}', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Autocorrelation (lag-1)')\n",
    "ax.set_title('Persistence Decomposition', fontweight='bold')\n",
    "ax.set_ylim(0, max(values) * 1.2)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel B: Pie chart (shares)\n",
    "ax = axes[1]\n",
    "shares = [corr_state_dep / corr_total, corr_heterog / corr_total]\n",
    "remainder = max(0, 1 - sum(shares))\n",
    "if remainder > 0.01:\n",
    "    labels_pie = ['State Dependence', 'Heterogeneity', 'Interaction']\n",
    "    sizes = [shares[0], shares[1], remainder]\n",
    "    colors_pie = ['#3498db', '#e74c3c', '#95a5a6']\n",
    "else:\n",
    "    labels_pie = ['State Dependence', 'Heterogeneity']\n",
    "    sizes = shares\n",
    "    colors_pie = ['#3498db', '#e74c3c']\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(sizes, labels=labels_pie, colors=colors_pie,\n",
    "                                   autopct='%1.0f%%', startangle=90,\n",
    "                                   textprops={'fontsize': 11})\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontweight('bold')\n",
    "ax.set_title('Share of Total Persistence', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Where Does Employment Persistence Come From?',\n",
    "             fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / '08_persistence_decomposition.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to outputs/figures/08_persistence_decomposition.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Policy Implications\n",
    "\n",
    "The decomposition has direct implications for policy design:\n",
    "\n",
    "| Share | Implication |\n",
    "|-------|------------|\n",
    "| High state dependence | Temporary employment programs have **lasting effects** — getting someone into a job creates momentum |\n",
    "| High heterogeneity | Need to **target specific groups** with persistent barriers — temporary programs won't help in the long run |\n",
    "| Both significant | Both strategies needed — temporary programs help, but some groups need sustained support |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Section 7: Simulated Trajectories (20 min)\n",
    "\n",
    "## 7.1 Goal\n",
    "\n",
    "Visualize how employment trajectories evolve over time under the estimated model.\n",
    "- Compare trajectories starting from $y_{i,0} = 1$ (employed) vs $y_{i,0} = 0$ (not employed)\n",
    "- Counterfactual: what happens if someone loses their job at $t=5$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate employment trajectories using estimated parameters\n",
    "np.random.seed(42)\n",
    "\n",
    "n_sim_traj = 200\n",
    "n_periods_sim = 15\n",
    "\n",
    "# Use pooled Wooldridge estimates\n",
    "gamma_sim = wooldridge_pooled.params['emp_lag']\n",
    "beta_sim = {v: wooldridge_pooled.params[v] for v in exog_vars}\n",
    "intercept_sim = wooldridge_pooled.params['const']\n",
    "\n",
    "# Mean characteristics from data\n",
    "X_mean = data_dyn[exog_vars].mean()\n",
    "\n",
    "def simulate_trajectories(n_individuals, n_periods, y_init, gamma, beta, intercept, X, sigma_u=0.8):\n",
    "    \"\"\"Simulate binary employment trajectories.\"\"\"\n",
    "    alpha = np.random.normal(0, sigma_u, n_individuals)\n",
    "    trajectories = np.zeros((n_individuals, n_periods))\n",
    "    prob_trajectories = np.zeros((n_individuals, n_periods))\n",
    "\n",
    "    for i in range(n_individuals):\n",
    "        y_prev = y_init\n",
    "        for t in range(n_periods):\n",
    "            xb = intercept + sum(beta[v] * X[v] for v in beta) + gamma * y_prev + alpha[i]\n",
    "            prob = norm.cdf(xb)\n",
    "            y = int(np.random.random() < prob)\n",
    "            trajectories[i, t] = y\n",
    "            prob_trajectories[i, t] = prob\n",
    "            y_prev = y\n",
    "\n",
    "    return trajectories, prob_trajectories\n",
    "\n",
    "# Scenario 1: Start employed\n",
    "traj_emp, prob_emp = simulate_trajectories(\n",
    "    n_sim_traj, n_periods_sim, y_init=1,\n",
    "    gamma=gamma_sim, beta=beta_sim, intercept=intercept_sim, X=X_mean\n",
    ")\n",
    "\n",
    "# Scenario 2: Start not employed\n",
    "traj_unemp, prob_unemp = simulate_trajectories(\n",
    "    n_sim_traj, n_periods_sim, y_init=0,\n",
    "    gamma=gamma_sim, beta=beta_sim, intercept=intercept_sim, X=X_mean\n",
    ")\n",
    "\n",
    "print(f\"Simulated {n_sim_traj} trajectories x {n_periods_sim} periods\")\n",
    "print(f\"\\nStarting employed (y_init=1):\")\n",
    "print(f\"  Mean employment rate at t=1:  {traj_emp[:, 0].mean():.3f}\")\n",
    "print(f\"  Mean employment rate at t=15: {traj_emp[:, -1].mean():.3f}\")\n",
    "print(f\"\\nStarting not employed (y_init=0):\")\n",
    "print(f\"  Mean employment rate at t=1:  {traj_unemp[:, 0].mean():.3f}\")\n",
    "print(f\"  Mean employment rate at t=15: {traj_unemp[:, -1].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spaghetti plot with mean trajectory\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "periods = np.arange(1, n_periods_sim + 1)\n",
    "\n",
    "# Panel A: Start employed\n",
    "ax = axes[0]\n",
    "for i in range(min(50, n_sim_traj)):\n",
    "    ax.plot(periods, traj_emp[i], alpha=0.08, color='#3498db', linewidth=0.8)\n",
    "ax.plot(periods, traj_emp.mean(axis=0), color='darkblue', linewidth=3,\n",
    "        label=f'Mean ({traj_emp.mean(axis=0)[-1]:.2f} at t={n_periods_sim})')\n",
    "ax.set_xlabel('Period')\n",
    "ax.set_ylabel('Employment Status / P(employed)')\n",
    "ax.set_title('Start Employed ($y_{i,0} = 1$)', fontweight='bold')\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel B: Start not employed\n",
    "ax = axes[1]\n",
    "for i in range(min(50, n_sim_traj)):\n",
    "    ax.plot(periods, traj_unemp[i], alpha=0.08, color='#e74c3c', linewidth=0.8)\n",
    "ax.plot(periods, traj_unemp.mean(axis=0), color='darkred', linewidth=3,\n",
    "        label=f'Mean ({traj_unemp.mean(axis=0)[-1]:.2f} at t={n_periods_sim})')\n",
    "ax.set_xlabel('Period')\n",
    "ax.set_ylabel('Employment Status / P(employed)')\n",
    "ax.set_title('Start Not Employed ($y_{i,0} = 0$)', fontweight='bold')\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Simulated Employment Trajectories\\n'\n",
    "             'Individual paths (thin) and mean (thick)',\n",
    "             fontsize=15, fontweight='bold', y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / '08_simulated_trajectories.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to outputs/figures/08_simulated_trajectories.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counterfactual: job loss shock at t=5\n",
    "np.random.seed(42)\n",
    "\n",
    "n_cf = 500\n",
    "n_periods_cf = 20\n",
    "sigma_u_cf = 0.8\n",
    "\n",
    "alpha_cf = np.random.normal(0, sigma_u_cf, n_cf)\n",
    "\n",
    "# Baseline: continuous employment\n",
    "traj_baseline = np.zeros((n_cf, n_periods_cf))\n",
    "# Counterfactual: job loss at t=5\n",
    "traj_shock = np.zeros((n_cf, n_periods_cf))\n",
    "\n",
    "for i in range(n_cf):\n",
    "    y_base = 1  # Start employed\n",
    "    y_shock = 1\n",
    "\n",
    "    for t in range(n_periods_cf):\n",
    "        xb_base = intercept_sim + sum(beta_sim[v] * X_mean[v] for v in beta_sim) + gamma_sim * y_base + alpha_cf[i]\n",
    "        y_base = int(np.random.normal(xb_base, 1) > 0)\n",
    "        traj_baseline[i, t] = y_base\n",
    "\n",
    "        # Shock: force y=0 at t=5\n",
    "        if t == 4:  # t=5 (0-indexed)\n",
    "            y_shock_input = 0  # Forced job loss\n",
    "        else:\n",
    "            y_shock_input = y_shock\n",
    "\n",
    "        xb_shock = intercept_sim + sum(beta_sim[v] * X_mean[v] for v in beta_sim) + gamma_sim * y_shock_input + alpha_cf[i]\n",
    "        if t == 4:\n",
    "            y_shock = 0  # Forced\n",
    "        else:\n",
    "            y_shock = int(np.random.normal(xb_shock, 1) > 0)\n",
    "        traj_shock[i, t] = y_shock\n",
    "\n",
    "# Plot counterfactual\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "periods_cf = np.arange(1, n_periods_cf + 1)\n",
    "mean_base = traj_baseline.mean(axis=0)\n",
    "mean_shock = traj_shock.mean(axis=0)\n",
    "\n",
    "ax.plot(periods_cf, mean_base, 'b-o', linewidth=2, markersize=6,\n",
    "        label='Baseline (no shock)')\n",
    "ax.plot(periods_cf, mean_shock, 'r-s', linewidth=2, markersize=6,\n",
    "        label='After job loss at t=5')\n",
    "ax.axvline(x=5, color='gray', linestyle='--', alpha=0.7, label='Shock at t=5')\n",
    "\n",
    "# Shade the gap\n",
    "ax.fill_between(periods_cf, mean_base, mean_shock, alpha=0.15, color='red')\n",
    "\n",
    "# Find convergence period (gap < 5%)\n",
    "gap = mean_base - mean_shock\n",
    "converge_idx = np.where(gap[5:] < 0.05)[0]\n",
    "if len(converge_idx) > 0:\n",
    "    converge_t = converge_idx[0] + 6\n",
    "    ax.annotate(f'Gap < 5% at t={converge_t}', xy=(converge_t, mean_shock[converge_t-1]),\n",
    "                xytext=(converge_t + 2, mean_shock[converge_t-1] - 0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='black'),\n",
    "                fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Period', fontsize=12)\n",
    "ax.set_ylabel('Mean Employment Rate', fontsize=12)\n",
    "ax.set_title('Counterfactual: Effect of Job Loss at t=5\\n'\n",
    "             f'(State dependence $\\\\gamma$ = {gamma_sim:.3f})',\n",
    "             fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / '08_counterfactual_job_loss.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to outputs/figures/08_counterfactual_job_loss.png\")\n",
    "print(f\"\\nImmediate effect of job loss: {gap[4]:.3f} ({gap[4]:.0%} lower employment rate)\")\n",
    "if len(converge_idx) > 0:\n",
    "    print(f\"Recovery time: gap falls below 5% by period {converge_t}\")\n",
    "    print(f\"This shows the lasting effect of state dependence: job loss echoes for ~{converge_t - 5} periods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section8'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Section 8: Application — Labor Force Participation Dynamics (40 min)\n",
    "\n",
    "**Research Question**: Does having worked last year causally increase the probability of working this year, or is the observed persistence driven by unobserved preferences?\n",
    "\n",
    "We now bring together all the tools from this notebook for a complete analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 8.1 Exploratory Analysis\n",
    "# =====================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Panel A: Employment rate by year\n",
    "ax = axes[0, 0]\n",
    "emp_rate = data.groupby('year')['employed'].mean()\n",
    "ax.bar(emp_rate.index, emp_rate.values, color='#3498db', alpha=0.8, edgecolor='black')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Employment Rate')\n",
    "ax.set_title('Employment Rate Over Time', fontweight='bold')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel B: Distribution of individual employment rates\n",
    "ax = axes[0, 1]\n",
    "ind_rates = data.groupby('id')['employed'].mean()\n",
    "ax.hist(ind_rates, bins=30, color='#2ecc71', alpha=0.8, edgecolor='black')\n",
    "ax.axvline(x=ind_rates.mean(), color='red', linestyle='--', linewidth=2,\n",
    "           label=f'Mean = {ind_rates.mean():.2f}')\n",
    "ax.set_xlabel('Individual Employment Rate (across all years)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Heterogeneity in Employment Rates', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel C: Employment by education\n",
    "ax = axes[1, 0]\n",
    "data['educ_group'] = pd.cut(data['educ'], bins=[7, 10, 13, 16, 21],\n",
    "                            labels=['<10', '10-13', '13-16', '>16'])\n",
    "emp_by_educ = data.groupby('educ_group', observed=True)['employed'].mean()\n",
    "ax.bar(range(len(emp_by_educ)), emp_by_educ.values,\n",
    "       color=['#e74c3c', '#f39c12', '#3498db', '#2ecc71'],\n",
    "       alpha=0.8, edgecolor='black')\n",
    "ax.set_xticks(range(len(emp_by_educ)))\n",
    "ax.set_xticklabels(emp_by_educ.index)\n",
    "ax.set_xlabel('Years of Education')\n",
    "ax.set_ylabel('Employment Rate')\n",
    "ax.set_title('Employment Rate by Education', fontweight='bold')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel D: Employment persistence by number of kids\n",
    "ax = axes[1, 1]\n",
    "data_with_lag = data.dropna(subset=['emp_lag'])\n",
    "for n_kids, color in [(0, '#3498db'), (1, '#f39c12'), (2, '#e74c3c')]:\n",
    "    subset = data_with_lag[data_with_lag['kids'] == n_kids]\n",
    "    if len(subset) > 100:\n",
    "        trans_k = pd.crosstab(subset['emp_lag'].astype(int), subset['employed'], normalize='index')\n",
    "        persist = trans_k.loc[1, 1] - trans_k.loc[0, 1] if 1 in trans_k.index and 0 in trans_k.index else 0\n",
    "        ax.bar(n_kids, persist, color=color, alpha=0.8, edgecolor='black')\n",
    "        ax.text(n_kids, persist + 0.01, f'{persist:.2f}', ha='center', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Number of Young Children')\n",
    "ax.set_ylabel('Raw Persistence Gap')\n",
    "ax.set_title('Persistence by Number of Kids\\n(P(emp|emp_lag=1) - P(emp|emp_lag=0))',\n",
    "             fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Labor Force Participation Dynamics: Exploratory Analysis',\n",
    "             fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / '08_labor_exploration.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to outputs/figures/08_labor_exploration.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 8.2 Full Model Estimation Results\n",
    "# =====================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 10 + \"LABOR FORCE PARTICIPATION DYNAMICS\")\n",
    "print(\" \" * 10 + \"Complete Analysis Results\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Model 1: Static Pooled Probit (no dynamics)\n",
    "X_static = sm.add_constant(data_dyn[exog_vars])\n",
    "static_probit = sm.Probit(data_dyn['employed'], X_static).fit(method='bfgs', disp=0)\n",
    "\n",
    "# Model 2: Naive Dynamic Pooled Probit\n",
    "# (already estimated as pooled_probit)\n",
    "\n",
    "# Model 3: Wooldridge Pooled Probit\n",
    "# (already estimated as wooldridge_pooled)\n",
    "\n",
    "print(f\"\\n{'':25s} {'Static':>10s} {'Naive Dyn':>10s} {'Wooldridge':>10s}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for var in exog_vars:\n",
    "    s = static_probit.params[var]\n",
    "    n = pooled_probit.params[var]\n",
    "    w = wooldridge_pooled.params[var]\n",
    "    print(f\"{var:<25s} {s:>10.4f} {n:>10.4f} {w:>10.4f}\")\n",
    "\n",
    "print(f\"{'emp_lag (gamma)':<25s} {'—':>10s} {pooled_probit.params['emp_lag']:>10.4f} {wooldridge_pooled.params['emp_lag']:>10.4f}\")\n",
    "print(f\"{'emp_init (delta_1)':<25s} {'—':>10s} {'—':>10s} {wooldridge_pooled.params['emp_init']:>10.4f}\")\n",
    "\n",
    "print(f\"\\n{'Log-likelihood':<25s} {static_probit.llf:>10.1f} {pooled_probit.llf:>10.1f} {wooldridge_pooled.llf:>10.1f}\")\n",
    "print(f\"{'AIC':<25s} {static_probit.aic:>10.1f} {pooled_probit.aic:>10.1f} {wooldridge_pooled.aic:>10.1f}\")\n",
    "print(f\"{'N parameters':<25s} {len(static_probit.params):>10d} {len(pooled_probit.params):>10d} {len(wooldridge_pooled.params):>10d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 8.3 Test for State Dependence: H0: gamma = 0\n",
    "# =====================================================\n",
    "\n",
    "gamma_hat = wooldridge_pooled.params['emp_lag']\n",
    "se_gamma = wooldridge_pooled.bse['emp_lag']\n",
    "z_gamma = gamma_hat / se_gamma\n",
    "p_gamma = 2 * (1 - norm.cdf(abs(z_gamma)))\n",
    "\n",
    "print(\"=== Test for State Dependence ===\")\n",
    "print(f\"\\nH0: gamma = 0 (no true state dependence)\")\n",
    "print(f\"H1: gamma != 0\")\n",
    "print(f\"\\ngamma_hat  = {gamma_hat:.4f}\")\n",
    "print(f\"SE(gamma)  = {se_gamma:.4f}\")\n",
    "print(f\"z-stat     = {z_gamma:.4f}\")\n",
    "print(f\"p-value    = {p_gamma:.6f}\")\n",
    "print(f\"\\nConclusion: {'Reject H0' if p_gamma < 0.05 else 'Fail to reject H0'} at 5% significance level.\")\n",
    "\n",
    "if p_gamma < 0.05:\n",
    "    print(f\"\\nThere IS significant true state dependence.\")\n",
    "    print(f\"Past employment causally increases current employment probability.\")\n",
    "    print(f\"AME of emp_lag: {ame_emp_lag:.3f} ({ame_emp_lag:.1%} p.p.)\")\n",
    "else:\n",
    "    print(f\"\\nNo significant state dependence detected.\")\n",
    "    print(f\"Observed persistence is explained by unobserved heterogeneity alone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 8.4 AME for key variables\n",
    "# =====================================================\n",
    "\n",
    "X_eval = sm.add_constant(data_dyn[wooldridge_vars])\n",
    "lp = X_eval.values @ wooldridge_pooled.params.values\n",
    "phi = norm.pdf(lp)\n",
    "mean_phi = np.mean(phi)\n",
    "\n",
    "print(\"=== Average Marginal Effects (Wooldridge Model) ===\")\n",
    "print(f\"\\n{'Variable':<20s} {'Coefficient':>12s} {'AME':>12s} {'Std Err':>12s} {'z-stat':>10s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "ame_results = {}\n",
    "for var in exog_vars + ['emp_lag', 'emp_init']:\n",
    "    coef = wooldridge_pooled.params[var]\n",
    "    se = wooldridge_pooled.bse[var]\n",
    "    ame = mean_phi * coef\n",
    "    ame_se = mean_phi * se\n",
    "    z = ame / ame_se if ame_se > 0 else np.nan\n",
    "    ame_results[var] = {'ame': ame, 'se': ame_se}\n",
    "    sig = '***' if abs(z) > 2.576 else '**' if abs(z) > 1.96 else '*' if abs(z) > 1.645 else ''\n",
    "    print(f\"{var:<20s} {coef:>12.4f} {ame:>12.4f} {ame_se:>12.4f} {z:>9.2f} {sig}\")\n",
    "\n",
    "print(f\"\\nSignificance: *** p<0.01, ** p<0.05, * p<0.10\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  emp_lag:  Working last year increases P(work) by {ame_results['emp_lag']['ame']:.3f} ({ame_results['emp_lag']['ame']:.1%} p.p.)\")\n",
    "print(f\"  kids:     Each additional child reduces P(work) by {abs(ame_results['kids']['ame']):.3f} ({abs(ame_results['kids']['ame']):.1%} p.p.)\")\n",
    "print(f\"  educ:     Each year of education increases P(work) by {ame_results['educ']['ame']:.3f} ({ame_results['educ']['ame']:.1%} p.p.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 8.5 Save results table\n",
    "# =====================================================\n",
    "\n",
    "results_table = pd.DataFrame({\n",
    "    'Variable': exog_vars + ['emp_lag', 'emp_init'] + [f'{v}_mean' for v in mean_vars],\n",
    "    'Coefficient': [wooldridge_pooled.params[v] for v in exog_vars + ['emp_lag', 'emp_init'] +\n",
    "                    [f'{v}_mean' for v in mean_vars]],\n",
    "    'Std_Error': [wooldridge_pooled.bse[v] for v in exog_vars + ['emp_lag', 'emp_init'] +\n",
    "                  [f'{v}_mean' for v in mean_vars]],\n",
    "    'z_stat': [wooldridge_pooled.tvalues[v] for v in exog_vars + ['emp_lag', 'emp_init'] +\n",
    "               [f'{v}_mean' for v in mean_vars]],\n",
    "    'p_value': [wooldridge_pooled.pvalues[v] for v in exog_vars + ['emp_lag', 'emp_init'] +\n",
    "                [f'{v}_mean' for v in mean_vars]],\n",
    "})\n",
    "\n",
    "results_table.to_csv(TABLE_DIR / '08_results_table.csv', index=False)\n",
    "print(\"Results table saved to outputs/tables/08_results_table.csv\")\n",
    "print(results_table.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 8.6 AME visualization\n",
    "# =====================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "plot_vars = ['emp_lag', 'educ', 'age', 'kids', 'married', 'emp_init']\n",
    "y_pos = np.arange(len(plot_vars))\n",
    "\n",
    "ame_vals = [ame_results[v]['ame'] if v in ame_results else mean_phi * wooldridge_pooled.params[v] for v in plot_vars]\n",
    "ame_ses = [ame_results[v]['se'] if v in ame_results else mean_phi * wooldridge_pooled.bse[v] for v in plot_vars]\n",
    "\n",
    "colors = ['#3498db' if v > 0 else '#e74c3c' for v in ame_vals]\n",
    "\n",
    "ax.barh(y_pos, ame_vals, xerr=[1.96 * s for s in ame_ses],\n",
    "        color=colors, alpha=0.8, edgecolor='black', capsize=5)\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(plot_vars)\n",
    "ax.set_xlabel('Average Marginal Effect on P(employed)')\n",
    "ax.set_title('Average Marginal Effects: Wooldridge Dynamic Probit',\n",
    "             fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / '08_labor_ame.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to outputs/figures/08_labor_ame.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 8.7 Generate HTML Report\n",
    "# =====================================================\n",
    "\n",
    "report_html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head><title>Labor Force Participation Dynamics Report</title>\n",
    "<style>body {{font-family: Arial; margin: 40px;}}\n",
    "table {{border-collapse: collapse; margin: 20px 0;}}\n",
    "th, td {{border: 1px solid #ddd; padding: 8px; text-align: right;}}\n",
    "th {{background-color: #3498db; color: white;}}\n",
    "h1 {{color: #2c3e50;}} h2 {{color: #3498db;}}</style></head>\n",
    "<body>\n",
    "<h1>Labor Force Participation Dynamics Report</h1>\n",
    "<p>Generated: 2026-02-17 | PanelBox Dynamic Discrete Choice Tutorial</p>\n",
    "\n",
    "<h2>Dataset</h2>\n",
    "<p>Panel of {data['id'].nunique()} women over {data['year'].nunique()} years ({len(data)} observations).</p>\n",
    "<p>Employment rate: {data['employed'].mean():.1%}</p>\n",
    "\n",
    "<h2>Research Question</h2>\n",
    "<p>Does having worked last year causally increase the probability of working this year,\n",
    "or is the observed persistence driven by unobserved preferences?</p>\n",
    "\n",
    "<h2>Model Comparison</h2>\n",
    "{comparison_df.to_html(index=False)}\n",
    "\n",
    "<h2>State Dependence Test</h2>\n",
    "<p><strong>H0</strong>: gamma = 0 (no true state dependence)</p>\n",
    "<p>gamma = {gamma_hat:.4f} (SE = {se_gamma:.4f}), z = {z_gamma:.2f}, p = {p_gamma:.6f}</p>\n",
    "<p><strong>Conclusion</strong>: {'Reject H0 — significant state dependence' if p_gamma < 0.05 else 'Fail to reject H0'}</p>\n",
    "\n",
    "<h2>Persistence Decomposition</h2>\n",
    "<ul>\n",
    "<li>Total persistence (autocorrelation): {corr_total:.4f}</li>\n",
    "<li>Due to state dependence: {corr_state_dep:.4f} ({corr_state_dep/corr_total:.0%})</li>\n",
    "<li>Due to heterogeneity: {corr_heterog:.4f} ({corr_heterog/corr_total:.0%})</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Key Findings</h2>\n",
    "<ol>\n",
    "<li>Significant true state dependence (gamma = {gamma_hat:.3f}): past employment causally\n",
    "increases current employment probability by approximately {ame_emp_lag:.1%} percentage points.</li>\n",
    "<li>Initial conditions matter (delta_1 = {wooldridge_pooled.params['emp_init']:.3f}): women who\n",
    "started employed have persistently higher employment rates.</li>\n",
    "<li>Children significantly reduce employment probability (AME = {ame_results['kids']['ame']:.3f} per child).</li>\n",
    "<li>Both state dependence and heterogeneity contribute to persistence — both temporary\n",
    "programs and targeted support are needed.</li>\n",
    "</ol>\n",
    "\n",
    "<h2>Policy Implications</h2>\n",
    "<ul>\n",
    "<li>Temporary employment programs can have lasting effects due to state dependence.</li>\n",
    "<li>Childcare support is crucial for increasing women's labor force participation.</li>\n",
    "<li>Education has a positive but modest direct effect on employment probability.</li>\n",
    "</ul>\n",
    "</body></html>\"\"\"\n",
    "\n",
    "with open(REPORT_DIR / '08_labor_dynamics.html', 'w') as f:\n",
    "    f.write(report_html)\n",
    "\n",
    "print(\"Report saved to outputs/reports/08_labor_dynamics.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercises'></a>\n",
    "\n",
    "---\n",
    "\n",
    "# Exercises\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 1: Data Preparation (Easy)\n",
    "\n",
    "**Objective**: Practice creating a dynamic dataset from raw panel data.\n",
    "\n",
    "### Task\n",
    "\n",
    "Starting from the raw `labor_dynamics.csv` data:\n",
    "\n",
    "1. Create the lagged dependent variable `emp_lag`\n",
    "2. Extract the initial value `emp_init` ($y_{i,0}$ — first observation per individual)\n",
    "3. Compute time means of `age`, `kids`, `married`, and `husbinc`\n",
    "4. Drop the first period (no lag available)\n",
    "5. Verify the resulting dataset has the correct dimensions\n",
    "\n",
    "### Questions\n",
    "\n",
    "1. How many observations are lost when dropping the first period?\n",
    "2. What is the correlation between `emp_init` and the mean of `employed` across all periods?\n",
    "3. Why do we only include time-varying variables in the Mundlak means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your solution here\n",
    "\n",
    "# Step 1: Load fresh data and create lag\n",
    "# ex1_data = pd.read_csv(DATA_DIR / \"labor_dynamics.csv\")\n",
    "# ex1_data = ex1_data.sort_values(['id', 'year'])\n",
    "# ex1_data['emp_lag'] = ...\n",
    "\n",
    "# Step 2: Initial value\n",
    "# ex1_data['emp_init'] = ...\n",
    "\n",
    "# Step 3: Time means\n",
    "# for var in ['age', 'kids', 'married', 'husbinc']:\n",
    "#     ex1_data[f'{var}_mean'] = ...\n",
    "\n",
    "# Step 4: Drop first period\n",
    "# ex1_dyn = ...\n",
    "\n",
    "# Step 5: Verify dimensions\n",
    "# expected_n = ...\n",
    "# print(f\"Expected: {expected_n}, Got: {len(ex1_dyn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Naive vs Wooldridge (Medium)\n",
    "\n",
    "**Objective**: Quantify the bias from ignoring initial conditions.\n",
    "\n",
    "### Task\n",
    "\n",
    "1. Estimate a dynamic Probit **ignoring** initial conditions (only include $y_{t-1}$ and $X_{it}$)\n",
    "2. Estimate the Wooldridge approach (include $y_{i,0}$, $\\bar{X}_i$)\n",
    "3. Compare $\\gamma$ estimates\n",
    "4. Compute the bias: $\\text{bias} = \\hat{\\gamma}_{\\text{naive}} - \\hat{\\gamma}_{\\text{Wooldridge}}$\n",
    "\n",
    "### Questions\n",
    "\n",
    "1. In which direction is the naive estimate biased?\n",
    "2. Why does ignoring initial conditions bias $\\gamma$ upward?\n",
    "3. Is $\\delta_1$ (coefficient on $y_{i,0}$) statistically significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your solution here\n",
    "\n",
    "# Step 1: Naive dynamic probit\n",
    "# X_naive_ex = sm.add_constant(data_dyn[exog_vars + ['emp_lag']])\n",
    "# naive_ex = sm.Probit(data_dyn['employed'], X_naive_ex).fit(method='bfgs', disp=0)\n",
    "\n",
    "# Step 2: Wooldridge (already estimated as wooldridge_pooled)\n",
    "\n",
    "# Step 3: Compare gamma\n",
    "# print(f\"Naive gamma:      {naive_ex.params['emp_lag']:.4f}\")\n",
    "# print(f\"Wooldridge gamma: {wooldridge_pooled.params['emp_lag']:.4f}\")\n",
    "\n",
    "# Step 4: Compute bias\n",
    "# bias = naive_ex.params['emp_lag'] - wooldridge_pooled.params['emp_lag']\n",
    "# print(f\"Bias: {bias:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Persistence Decomposition (Medium)\n",
    "\n",
    "**Objective**: Quantify how much observed persistence comes from state dependence vs heterogeneity.\n",
    "\n",
    "### Task\n",
    "\n",
    "1. Using the `simulate_persistence()` function defined in Section 6, compute:\n",
    "   - Total persistence (with both $\\gamma$ and $\\sigma_u$)\n",
    "   - Persistence from state dependence only ($\\sigma_u = 0$)\n",
    "   - Persistence from heterogeneity only ($\\gamma = 0$)\n",
    "2. Compute the share attributable to each source\n",
    "3. Discuss policy implications\n",
    "\n",
    "### Hint\n",
    "\n",
    "Try different values of $\\gamma$ (0.2, 0.5, 0.8) and $\\sigma_u$ (0.3, 0.8, 1.5) to see how the decomposition changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your solution here\n",
    "\n",
    "# Try different parameter combinations\n",
    "# for gamma_val in [0.2, 0.5, 0.8]:\n",
    "#     for sigma_val in [0.3, 0.8, 1.5]:\n",
    "#         total = simulate_persistence(gamma=gamma_val, sigma_u=sigma_val)\n",
    "#         sd_only = simulate_persistence(gamma=gamma_val, sigma_u=0.0)\n",
    "#         het_only = simulate_persistence(gamma=0.0, sigma_u=sigma_val)\n",
    "#         print(f\"gamma={gamma_val}, sigma={sigma_val}: \"\n",
    "#               f\"Total={total:.3f}, SD share={sd_only/total:.0%}, Het share={het_only/total:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Counterfactual Simulation (Hard)\n",
    "\n",
    "**Objective**: Simulate trajectories under different scenarios.\n",
    "\n",
    "### Task\n",
    "\n",
    "1. Simulate trajectories for two individuals:\n",
    "   - **Woman A**: Loses her job at $t=5$ (force $y_5 = 0$)\n",
    "   - **Woman B**: Keeps her job throughout\n",
    "2. Plot their expected employment paths from $t=1$ to $t=20$\n",
    "3. How long does the job loss effect last? (When does the gap close to < 5%?)\n",
    "\n",
    "### Hint\n",
    "\n",
    "Use `simulate_trajectories()` from Section 7 or adapt the counterfactual code. Average over many simulations (e.g., 500) for smooth curves.\n",
    "\n",
    "### Questions\n",
    "\n",
    "1. Does the gap ever fully close? Why or why not?\n",
    "2. How does the recovery time change if $\\gamma$ is larger (e.g., 1.5)?\n",
    "3. What does this imply for the design of employment support programs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your solution here\n",
    "\n",
    "# Simulate with different gamma values\n",
    "# for gamma_cf in [0.3, 0.8, 1.5]:\n",
    "#     # Simulate baseline and shock trajectories\n",
    "#     # ...\n",
    "#     # Find convergence time\n",
    "#     # ...\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Testing State Dependence (Hard)\n",
    "\n",
    "**Objective**: Formally test for state dependence and interpret the result.\n",
    "\n",
    "### Task\n",
    "\n",
    "1. Estimate the Wooldridge dynamic Probit\n",
    "2. Test $H_0: \\gamma = 0$ (Wald test using the z-statistic)\n",
    "3. If $H_0$ is not rejected, what does this imply for policy?\n",
    "4. If $H_0$ is rejected, compute the Average Partial Effect of $y_{t-1}$\n",
    "5. Interpret the APE in terms of percentage points\n",
    "\n",
    "### Bonus\n",
    "\n",
    "Perform a Likelihood Ratio test by comparing:\n",
    "- Restricted model: Wooldridge without `emp_lag` (static CRE probit)\n",
    "- Unrestricted model: full Wooldridge with `emp_lag`\n",
    "\n",
    "$$LR = -2(\\ell_{\\text{restricted}} - \\ell_{\\text{unrestricted}}) \\sim \\chi^2(1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Your solution here\n",
    "\n",
    "# Step 1: Wald test (already computed in Section 8.3)\n",
    "# gamma_hat = wooldridge_pooled.params['emp_lag']\n",
    "# se_gamma = wooldridge_pooled.bse['emp_lag']\n",
    "# z = gamma_hat / se_gamma\n",
    "# p = 2 * (1 - norm.cdf(abs(z)))\n",
    "\n",
    "# Step 2: LR test\n",
    "# Restricted model: no emp_lag\n",
    "# restricted_vars = exog_vars + ['emp_init'] + [f'{v}_mean' for v in mean_vars]\n",
    "# X_restricted = sm.add_constant(data_dyn[restricted_vars])\n",
    "# restricted = sm.Probit(data_dyn['employed'], X_restricted).fit(method='bfgs', disp=0)\n",
    "# lr_stat = -2 * (restricted.llf - wooldridge_pooled.llf)\n",
    "# p_lr = 1 - chi2.cdf(lr_stat, 1)\n",
    "# print(f\"LR stat: {lr_stat:.4f}, p-value: {p_lr:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary and Key Takeaways\n",
    "\n",
    "## What We Learned\n",
    "\n",
    "1. **Two sources of persistence**: Observed serial correlation in binary outcomes can arise from true state dependence ($\\gamma$) or unobserved heterogeneity ($\\alpha_i$) — or both\n",
    "\n",
    "2. **Initial conditions problem**: In dynamic nonlinear models, $y_{i,0}$ is correlated with $\\alpha_i$, creating endogeneity. Ignoring this **biases $\\gamma$ upward**\n",
    "\n",
    "3. **Wooldridge (2005) solution**: Model $\\alpha_i = \\delta_0 + \\delta_1 y_{i,0} + \\delta_2 \\bar{X}_i + u_i$, then estimate a RE Probit with augmented regressors\n",
    "\n",
    "4. **Data preparation is critical**: Lags, initial values, time means, and dropping the first period — all must be done correctly\n",
    "\n",
    "5. **Persistence decomposition**: Simulation-based decomposition reveals how much persistence comes from each source\n",
    "\n",
    "6. **Counterfactual trajectories**: State dependence implies that temporary shocks (job loss) have lasting effects\n",
    "\n",
    "## Key Formulas\n",
    "\n",
    "| Concept | Formula |\n",
    "|---------|--------|\n",
    "| Dynamic model | $y^*_{it} = X_{it}'\\beta + \\gamma \\cdot y_{i,t-1} + \\alpha_i + \\varepsilon_{it}$ |\n",
    "| Wooldridge specification | $\\alpha_i = \\delta_0 + \\delta_1 y_{i,0} + \\delta_2 \\bar{X}_i + u_i$ |\n",
    "| Resulting model | $P(y_{it}=1) = \\Phi(X_{it}'\\beta + \\gamma y_{i,t-1} + \\delta_1 y_{i,0} + \\bar{X}_i'\\delta_2 + u_i)$ |\n",
    "| AME of lag | $\\text{AME} = \\overline{\\phi(X'\\hat{\\beta})} \\cdot \\hat{\\gamma}$ |\n",
    "| ICC (Probit) | $\\rho = \\sigma^2_u / (\\sigma^2_u + 1)$ |\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "1. **Forgetting initial conditions**: Naive estimation biases $\\gamma$ upward\n",
    "2. **Dropping first period**: Necessary because lag is unavailable — lose one period of data\n",
    "3. **Time means**: Must include $\\bar{X}_i$ (Mundlak terms) for CRE component of Wooldridge\n",
    "4. **State dependence interpretation**: $\\gamma$ captures lagged $y$ effect **conditional on $\\alpha_i$**, not unconditional\n",
    "5. **Small T**: Wooldridge works best for $T = 5$-$15$; very short panels may have substantial bias\n",
    "6. **Confusing persistence with state dependence**: High autocorrelation doesn't imply $\\gamma \\neq 0$\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Heckman (1981) approach**: More flexible but computationally demanding\n",
    "- **Dynamic ordered models**: State dependence in ordinal outcomes\n",
    "- **Feedback effects**: When $X_{it}$ depends on $y_{i,t-1}$ (predetermined variables)\n",
    "- **Heterogeneous state dependence**: Allowing $\\gamma$ to vary across individuals\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "### Essential Reading\n",
    "\n",
    "1. Wooldridge, J. M. (2005). Simple solutions to the initial conditions problem in dynamic, nonlinear panel data models with unobserved heterogeneity. *Journal of Applied Econometrics*, 20(1), 39-54.\n",
    "\n",
    "2. Heckman, J. J. (1981). The incidental parameters problem and the problem of initial conditions. In C. Manski & D. McFadden (Eds.), *Structural Analysis of Discrete Data*.\n",
    "\n",
    "### Additional References\n",
    "\n",
    "3. Arulampalam, W., & Stewart, M. B. (2009). Simplified implementation of the Heckman estimator of the dynamic probit model. *Oxford Bulletin of Economics and Statistics*.\n",
    "\n",
    "4. Stewart, M. B. (2007). The interrelated dynamics of unemployment and low-wage employment. *Journal of Applied Econometrics*.\n",
    "\n",
    "5. Wooldridge, J. M. (2010). *Econometric Analysis of Cross Section and Panel Data*. 2nd edition. MIT Press. Ch. 15.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Notebook 08: Dynamic Discrete Choice Models**\n",
    "\n",
    "You now have the tools to distinguish true state dependence from spurious persistence — a fundamental question in applied microeconomics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 2,
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
