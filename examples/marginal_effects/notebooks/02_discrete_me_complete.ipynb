{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal Effects in Discrete Choice Models\n",
    "\n",
    "This notebook covers four types of discrete choice models and shows how to compute and interpret marginal effects for each:\n",
    "\n",
    "1. **Binary Choice (Logit vs Probit)** — AME, MEM, and comparison of the two families\n",
    "2. **Discrete Change for Dummy Variables** — automatic detection of binary regressors\n",
    "3. **Multinomial Logit** — ME as a matrix (variables x alternatives); zero-sum property\n",
    "4. **Ordered Models (Logit/Probit)** — per-category ME; sign reversal; zero-sum across categories\n",
    "5. **Fixed Effects Logit** — within-entity identification; effective sample loss\n",
    "6. **Cross-Specification Comparison** — forest plots across Pooled Logit, Probit, and FE Logit\n",
    "7. **Visualization Best Practices** — publication-ready forest plots with significance stars\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "- [Section 1: Binary Choice — Logit vs Probit](#section-1)\n",
    "- [Section 2: Discrete Change for Binary Explanatory Variables](#section-2)\n",
    "- [Section 3: Multinomial Logit — Effects on Multiple Outcomes](#section-3)\n",
    "- [Section 4: Ordered Models — Effects by Category](#section-4)\n",
    "- [Section 5: Fixed Effects Logit — Within Effects](#section-5)\n",
    "- [Section 6: Comparing Marginal Effects Across Specifications](#section-6)\n",
    "- [Section 7: Visualization Best Practices for Discrete ME](#section-7)\n",
    "\n",
    "**Prerequisites**: Notebook 01 (ME Fundamentals), knowledge of discrete choice models.\n",
    "\n",
    "**Datasets**: Mroz (binary LFP), job_satisfaction (ordered), synthetic multinomial.\n",
    "\n",
    "---\n",
    "**Level**: Intermediate-Advanced | **Duration**: 90-120 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/home/guhaase/projetos/panelbox')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core discrete models\n",
    "from panelbox.models.discrete.binary import PooledLogit, PooledProbit, FixedEffectsLogit\n",
    "from panelbox.models.discrete.ordered import OrderedLogit, OrderedProbit\n",
    "from panelbox.models.discrete.multinomial import MultinomialLogit\n",
    "\n",
    "# Marginal effects\n",
    "from panelbox.marginal_effects.discrete_me import (\n",
    "    compute_ame, compute_mem,\n",
    "    compute_ordered_ame, compute_ordered_mem,\n",
    "    MarginalEffectsResult, OrderedMarginalEffectsResult,\n",
    "    _is_binary\n",
    ")\n",
    "\n",
    "# Utils from the tutorial series\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'marginal_effects'))\n",
    "utils_path = '/home/guhaase/projetos/panelbox/examples/marginal_effects/utils'\n",
    "sys.path.insert(0, utils_path)\n",
    "from data_loaders import load_dataset\n",
    "from me_helpers import format_me_table\n",
    "\n",
    "# Output directories\n",
    "os.makedirs('/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/plots', exist_ok=True)\n",
    "os.makedirs('/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/tables', exist_ok=True)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Binary Choice — Logit vs Probit <a name=\"section-1\"></a>\n",
    "\n",
    "In binary choice models, the **marginal effect** of variable $x_k$ on $P(Y=1|X)$ is:\n",
    "\n",
    "$$\\text{ME}_k = \\frac{\\partial P(Y=1|X)}{\\partial x_k} = \\beta_k \\cdot f(X'\\beta)$$\n",
    "\n",
    "where $f$ is the PDF of the assumed error distribution:\n",
    "- **Logit**: $f(z) = \\Lambda(z)[1 - \\Lambda(z)]$, with $\\Lambda$ the logistic CDF\n",
    "- **Probit**: $f(z) = \\phi(z)$, the standard normal PDF\n",
    "\n",
    "**Key insight**: Logit coefficients are approximately 1.6–1.8× larger than Probit coefficients (due to scale normalization), but **AMEs are very similar** because the PDFs compensate for the scale difference.\n",
    "\n",
    "Comparing AMEs from Logit and Probit is a standard robustness check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Load Mroz dataset and estimate Logit and Probit\n",
    "#\n",
    "# Mroz (1987): 753 married women. Outcome: inlf (in labor force)\n",
    "# Note: column is 'inlf' (not 'lfp'), 'kidslt6' and 'kidsge6' (not kids_lt6/kids_618)\n",
    "\n",
    "df = load_dataset('mroz')\n",
    "print(f\"Mroz dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nOutcome distribution (inlf):\")\n",
    "print(df['inlf'].value_counts())\n",
    "print(f\"\\nSample statistics:\")\n",
    "print(df[['inlf', 'educ', 'age', 'kidslt6', 'kidsge6', 'nwifeinc']].describe())\n",
    "\n",
    "# Add panel identifiers (cross-section treated as 1-period panel)\n",
    "df = df.reset_index(drop=True)\n",
    "df['id'] = range(len(df))\n",
    "df['time'] = 1\n",
    "\n",
    "# Formula using actual column names\n",
    "formula = 'inlf ~ educ + age + kidslt6 + kidsge6 + nwifeinc'\n",
    "\n",
    "# Fit both models\n",
    "logit  = PooledLogit(formula, df, entity_col='id', time_col='time').fit(cov_type='nonrobust')\n",
    "probit = PooledProbit(formula, df, entity_col='id', time_col='time').fit(cov_type='nonrobust')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POOLED LOGIT — Summary\")\n",
    "print(\"=\"*60)\n",
    "print(logit.summary())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POOLED PROBIT — Summary\")\n",
    "print(\"=\"*60)\n",
    "print(probit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — Compare AME: Logit vs Probit\n",
    "\n",
    "# Exclude intercept from marginal effects computation\n",
    "key_vars = ['educ', 'age', 'kidslt6', 'kidsge6', 'nwifeinc']\n",
    "\n",
    "ame_logit  = compute_ame(logit,  varlist=key_vars)\n",
    "ame_probit = compute_ame(probit, varlist=key_vars)\n",
    "\n",
    "# Side-by-side comparison\n",
    "comparison = pd.DataFrame({\n",
    "    'Logit AME':  ame_logit.marginal_effects,\n",
    "    'Probit AME': ame_probit.marginal_effects,\n",
    "    'Difference': ame_logit.marginal_effects - ame_probit.marginal_effects,\n",
    "    'Logit p':    ame_logit.pvalues,\n",
    "    'Probit p':   ame_probit.pvalues,\n",
    "})\n",
    "\n",
    "print(\"=== AME Comparison: Logit vs Probit ===\")\n",
    "print(comparison.round(5))\n",
    "\n",
    "# Coefficient ratio (Logit / Probit)\n",
    "logit_params  = logit.params\n",
    "probit_params = probit.params\n",
    "\n",
    "# Filter to common variables\n",
    "common_vars = [v for v in key_vars if v in logit_params.index and v in probit_params.index]\n",
    "ratios = logit_params[common_vars] / probit_params[common_vars]\n",
    "print(f\"\\nCoefficient ratios (Logit/Probit) — should be ~1.6-1.8:\")\n",
    "print(ratios.round(3))\n",
    "\n",
    "print(\"\\nNote: AMEs are very similar even though coefficients differ by ~1.6-1.8x.\")\n",
    "print(\"The scale difference is absorbed by the PDF evaluated at the linear predictor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Discrete Change for Binary Explanatory Variables <a name=\"section-2\"></a>\n",
    "\n",
    "For **continuous** variables, the marginal effect is the partial derivative $\\partial P/\\partial x_k$.\n",
    "\n",
    "For **dummy (0/1) variables**, the derivative is not economically meaningful — instead, use the **discrete change**:\n",
    "\n",
    "$$\\text{DC}_k = P(Y=1 \\mid x_k=1, X_{-k}=\\bar{X}_{-k}) - P(Y=1 \\mid x_k=0, X_{-k}=\\bar{X}_{-k})$$\n",
    "\n",
    "PanelBox automatically detects binary variables (using `_is_binary()`) and applies the discrete change formula for them. The output still appears in the same AME table.\n",
    "\n",
    "**Example in this dataset**: `kidslt6` takes values 0, 1, 2, 3 — not a pure dummy, so the derivative is used. If we had `female` (0/1), the discrete change would be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — Discrete Change Demonstration\n",
    "\n",
    "print(\"=== Binary Variable Detection (_is_binary) ===\")\n",
    "print(f\"{'Variable':<15} {'is_binary':<12} {'Unique values (first 6)'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "demo_vars = ['inlf', 'kidslt6', 'kidsge6', 'educ', 'age', 'nwifeinc']\n",
    "for col in demo_vars:\n",
    "    if col in df.columns:\n",
    "        is_bin = _is_binary(df[col].values)\n",
    "        unique_vals = sorted(df[col].unique())[:6]\n",
    "        print(f\"  {col:<13} {str(is_bin):<12} {unique_vals}\")\n",
    "\n",
    "print(\"\\n--- Interpretation ---\")\n",
    "print(\"Variables detected as binary (0/1): use P(y=1|x=1) - P(y=1|x=0) [discrete change]\")\n",
    "print(\"Variables with more unique values  : use derivative formula ∂P/∂x\")\n",
    "\n",
    "# Manually demonstrate discrete change for a binary variable\n",
    "# Create a synthetic binary version of kidslt6 for illustration\n",
    "df_demo = df.copy()\n",
    "df_demo['has_young_kid'] = (df_demo['kidslt6'] >= 1).astype(float)\n",
    "\n",
    "print(f\"\\n'has_young_kid' is_binary: {_is_binary(df_demo['has_young_kid'].values)}\")\n",
    "print(f\"Unique values: {sorted(df_demo['has_young_kid'].unique())}\")\n",
    "\n",
    "# Fit logit with binary dummy\n",
    "formula_bin = 'inlf ~ educ + age + has_young_kid + kidsge6 + nwifeinc'\n",
    "logit_bin = PooledLogit(formula_bin, df_demo, entity_col='id', time_col='time').fit(cov_type='nonrobust')\n",
    "ame_bin = compute_ame(logit_bin, varlist=['educ', 'age', 'has_young_kid', 'kidsge6', 'nwifeinc'])\n",
    "\n",
    "print(\"\\n=== AME with binary dummy 'has_young_kid' ===\")\n",
    "print(\"(discrete change applied automatically for binary variables)\")\n",
    "df_ame = ame_bin.summary()\n",
    "print(df_ame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Multinomial Logit — Effects on Multiple Outcomes <a name=\"section-3\"></a>\n",
    "\n",
    "In Multinomial Logit with $J$ alternatives, the ME is a **matrix** of shape $(K \\times J)$ (variables × alternatives). For variable $k$ and alternative $j$:\n",
    "\n",
    "$$\\frac{\\partial P(Y=j|X)}{\\partial x_k} = P(Y=j|X) \\left[ \\beta_{kj} - \\sum_{m} P(Y=m|X) \\beta_{km} \\right]$$\n",
    "\n",
    "**Key property — Zero-sum across alternatives**: for any variable $k$,\n",
    "$$\\sum_{j} \\frac{\\partial P(Y=j|X)}{\\partial x_k} = 0$$\n",
    "\n",
    "Increasing $x_k$ raises the probability of some alternatives and decreases others — the effects are zero-sum. This makes sense because probabilities must sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 — Generate Synthetic Multinomial Dataset (Transport Mode Choice)\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 1000\n",
    "\n",
    "income = np.random.normal(40, 15, N)    # income in thousands\n",
    "age    = np.random.normal(38, 10, N)\n",
    "urban  = np.random.binomial(1, 0.6, N).astype(float)\n",
    "\n",
    "# Latent utilities for 3 alternatives (car=0, bus=1, bike=2)\n",
    "u_car  =  0.02 * income + 0.01 * age + 0.5  * urban + np.random.gumbel(size=N)\n",
    "u_bus  = -0.01 * income - 0.005* age - 0.3  * urban + np.random.gumbel(size=N)\n",
    "u_bike = -0.005* income - 0.02 * age + 0.1  * urban + np.random.gumbel(size=N)\n",
    "\n",
    "# Observed choice: argmax of utilities\n",
    "choice = np.argmax(np.column_stack([u_car, u_bus, u_bike]), axis=1)\n",
    "\n",
    "df_mnl = pd.DataFrame({\n",
    "    'id': range(N), 'time': 1,\n",
    "    'choice': choice.astype(float),\n",
    "    'income': income,\n",
    "    'age': age,\n",
    "    'urban': urban\n",
    "})\n",
    "\n",
    "print(\"=== Synthetic Transport Mode Choice Dataset ===\")\n",
    "print(f\"N = {N} observations, 3 alternatives: 0=Car, 1=Bus, 2=Bike\")\n",
    "print(f\"\\nMode shares:\")\n",
    "shares = df_mnl['choice'].value_counts(normalize=True).sort_index()\n",
    "shares.index = shares.index.map({0.0: 'Car (0)', 1.0: 'Bus (1)', 2.0: 'Bike (2)'})\n",
    "print(shares.round(3))\n",
    "print(f\"\\nCovariate summary:\")\n",
    "print(df_mnl[['income', 'age', 'urban']].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 — Estimate Multinomial Logit and Compute ME Matrix\n",
    "#\n",
    "# MultinomialLogit takes: endog, exog, n_alternatives, base_alternative\n",
    "# (does NOT use formula/PanelData interface — uses array interface)\n",
    "\n",
    "endog_mnl = df_mnl['choice'].values\n",
    "exog_mnl  = df_mnl[['income', 'age', 'urban']].values\n",
    "\n",
    "mnl = MultinomialLogit(\n",
    "    endog=endog_mnl,\n",
    "    exog=exog_mnl,\n",
    "    n_alternatives=3,\n",
    "    base_alternative=0   # car is the reference category\n",
    ")\n",
    "mnl_result = mnl.fit()\n",
    "\n",
    "print(mnl_result.summary())\n",
    "\n",
    "# Compute ME matrix using the built-in method (AME: 'overall')\n",
    "me_matrix = mnl_result.marginal_effects(at='overall')  # shape: (J, K)\n",
    "se_matrix = mnl_result.marginal_effects_se(at='overall')\n",
    "\n",
    "var_names = ['income', 'age', 'urban']\n",
    "alt_names = ['Car (0)', 'Bus (1)', 'Bike (2)']\n",
    "\n",
    "me_df = pd.DataFrame(me_matrix, index=alt_names, columns=var_names)\n",
    "se_df = pd.DataFrame(se_matrix, index=alt_names, columns=var_names)\n",
    "\n",
    "print(\"\\n=== Multinomial AME Matrix (rows=alternatives, cols=variables) ===\")\n",
    "print(me_df.round(4))\n",
    "\n",
    "# Verify zero-sum property (sum across alternatives for each variable = 0)\n",
    "print(\"\\nColumn sums (should be ~0 for each variable):\")\n",
    "print(me_df.sum(axis=0).round(8))\n",
    "print(\"\\nInterpretation: rows sum to ~0 because probabilities must add to 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 — Multinomial ME Heatmap\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "# Left: heatmap of ME matrix\n",
    "ax = axes[0]\n",
    "im = ax.imshow(me_df.values, cmap='RdBu_r', aspect='auto')\n",
    "ax.set_xticks(range(me_df.shape[1]))\n",
    "ax.set_xticklabels(me_df.columns, fontsize=10)\n",
    "ax.set_yticks(range(me_df.shape[0]))\n",
    "ax.set_yticklabels(me_df.index, fontsize=10)\n",
    "ax.set_title(\"Multinomial Logit — AME Matrix\\n(red=positive, blue=negative)\")\n",
    "\n",
    "# Annotate cells\n",
    "for i in range(me_df.shape[0]):\n",
    "    for j in range(me_df.shape[1]):\n",
    "        ax.text(j, i, f\"{me_df.iloc[i, j]:.4f}\", ha='center', va='center',\n",
    "                fontsize=9, color='black')\n",
    "\n",
    "plt.colorbar(im, ax=ax, label=\"Average Marginal Effect\")\n",
    "\n",
    "# Right: bar chart of column sums (zero-sum verification)\n",
    "ax2 = axes[1]\n",
    "col_sums = me_df.sum(axis=0)\n",
    "colors = ['tomato' if v < 0 else 'steelblue' for v in col_sums]\n",
    "ax2.bar(var_names, col_sums.values, color=colors, alpha=0.8)\n",
    "ax2.axhline(0, color='black', lw=1.5, ls='--')\n",
    "ax2.set_title(\"Zero-Sum Check\\n(column sums across alternatives)\")\n",
    "ax2.set_ylabel(\"Sum of ME across alternatives\")\n",
    "ax2.set_xlabel(\"Variable\")\n",
    "\n",
    "# Add value labels\n",
    "for i, (v, lbl) in enumerate(zip(col_sums.values, var_names)):\n",
    "    ax2.text(i, v + 0.0001 if v >= 0 else v - 0.0002, f\"{v:.2e}\",\n",
    "             ha='center', va='bottom' if v >= 0 else 'top', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/plots/02_mnl_ame_heatmap.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Figure saved: 02_mnl_ame_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Ordered Models — Effects by Category <a name=\"section-4\"></a>\n",
    "\n",
    "In **Ordered Logit/Probit** (e.g., satisfaction scale 1–5), the ME of variable $x_k$ varies across categories $j$:\n",
    "\n",
    "$$\\frac{\\partial P(Y=j|X)}{\\partial x_k} = \\beta_k \\left[ f(\\kappa_{j-1} - X'\\beta) - f(\\kappa_j - X'\\beta) \\right]$$\n",
    "\n",
    "where $\\kappa$ are cutpoint parameters and $f$ is the PDF.\n",
    "\n",
    "**Key property — Zero-sum across categories**: for each variable $k$,\n",
    "$$\\sum_j \\frac{\\partial P(Y=j|X)}{\\partial x_k} = 0$$\n",
    "\n",
    "**Implications**:\n",
    "- A positive $\\beta_k$ means $x_k$ shifts probability mass towards **higher** categories\n",
    "- Middle categories can have positive or negative ME depending on the cutpoint spacing\n",
    "- The lowest and highest categories always have **opposite signs**\n",
    "\n",
    "**Ordered Logit vs Ordered Probit**: The ME should be similar — if they differ greatly, it may indicate model misspecification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13 — Load Job Satisfaction Data\n",
    "#\n",
    "# Columns: satisfaction (1-5), age, female, educ, tenure, log_wage\n",
    "# Note: column is 'log_wage' (not 'wage')\n",
    "\n",
    "df_ord = load_dataset('job_satisfaction')\n",
    "print(f\"Dataset shape: {df_ord.shape}\")\n",
    "print(f\"Columns: {list(df_ord.columns)}\")\n",
    "\n",
    "print(\"\\nSatisfaction distribution (1=very dissatisfied, 5=very satisfied):\")\n",
    "sat_dist = df_ord['satisfaction'].value_counts().sort_index()\n",
    "print(sat_dist)\n",
    "print(f\"\\nPercentages:\")\n",
    "print((sat_dist / len(df_ord) * 100).round(1).astype(str) + '%')\n",
    "\n",
    "print(\"\\nSample statistics:\")\n",
    "print(df_ord[['satisfaction', 'log_wage', 'tenure', 'educ', 'female']].describe().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14 — Estimate Ordered Logit\n",
    "#\n",
    "# OrderedLogit takes: endog (array), exog (array), groups (entity IDs)\n",
    "# It does NOT use the formula/PanelData interface\n",
    "# Outcome must be 0-based integers; satisfaction is 1-5 → remap to 0-4\n",
    "\n",
    "df_ord = df_ord.reset_index(drop=True)\n",
    "\n",
    "# Remap satisfaction: 1-5 → 0-4\n",
    "sat_raw = df_ord['satisfaction'].values.astype(int)\n",
    "sat_vals = sat_raw - 1  # now 0-based\n",
    "\n",
    "# Regressors (log_wage, tenure, educ, female) — using actual column names\n",
    "exog_vars = ['log_wage', 'tenure', 'educ', 'female']\n",
    "exog_ord = df_ord[exog_vars].values\n",
    "groups_ord = np.arange(len(df_ord))  # cross-section, unique entity per row\n",
    "\n",
    "ologit = OrderedLogit(\n",
    "    endog=sat_vals,\n",
    "    exog=exog_ord,\n",
    "    groups=groups_ord\n",
    ")\n",
    "\n",
    "print(\"Fitting Ordered Logit... (may take a moment)\")\n",
    "ologit = ologit.fit(options={'disp': False})\n",
    "print(\"Done.\")\n",
    "\n",
    "print(f\"\\nBeta coefficients (variables: {exog_vars}):\")\n",
    "for name, coef in zip(exog_vars, ologit.beta):\n",
    "    print(f\"  {name:<12}: {coef:+.4f}\")\n",
    "\n",
    "print(f\"\\nCutpoint parameters (thresholds between categories):\")\n",
    "for j, cp in enumerate(ologit.cutpoints):\n",
    "    print(f\"  kappa_{j+1}: {cp:.4f}  [between cat {j} and {j+1}]\")\n",
    "\n",
    "print(f\"\\nLog-likelihood: {ologit.llf:.4f}\")\n",
    "print(f\"Converged: {ologit.converged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15 — Ordered AME\n",
    "#\n",
    "# compute_ordered_ame(model) takes the fitted model object (not result)\n",
    "# Returns OrderedMarginalEffectsResult:\n",
    "#   .marginal_effects : DataFrame  index=category_names, columns=variables\n",
    "#   .std_errors       : DataFrame  same shape\n",
    "\n",
    "# Attach exog_names so the result uses interpretable names\n",
    "ologit.exog_names = exog_vars\n",
    "\n",
    "ame_ord = compute_ordered_ame(ologit, varlist=exog_vars)\n",
    "\n",
    "print(\"=== Ordered Logit AME by Category (rows=categories, cols=variables) ===\")\n",
    "print()\n",
    "\n",
    "# Relabel categories from 'Category_0..4' to 'Sat.1..5'\n",
    "cat_labels = [f'Sat.{i+1}' for i in range(ologit.n_categories)]\n",
    "ame_ord.marginal_effects.index = cat_labels\n",
    "ame_ord.std_errors.index = cat_labels\n",
    "\n",
    "print(\"Marginal Effects (AME):\")\n",
    "print(ame_ord.marginal_effects.round(4))\n",
    "\n",
    "print(\"\\nStandard Errors:\")\n",
    "print(ame_ord.std_errors.round(4))\n",
    "\n",
    "# Verify zero-sum property (sum across categories for each variable)\n",
    "print(\"\\nColumn sums (should be ~0 for each variable):\")\n",
    "print(ame_ord.marginal_effects.sum(axis=0).round(8))\n",
    "\n",
    "verified = ame_ord.verify_sum_to_zero(tol=1e-6)\n",
    "print(f\"\\nZero-sum verified (tol=1e-6): {verified}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16 — Ordered ME Bar Plots by Category\n",
    "\n",
    "# Categories from the result index; fallback to range if attribute missing\n",
    "try:\n",
    "    cats = list(ame_ord.marginal_effects.index)\n",
    "except AttributeError:\n",
    "    cats = [f'Cat.{i}' for i in range(ologit.n_categories)]\n",
    "\n",
    "variables = list(ame_ord.marginal_effects.columns)\n",
    "n_vars = len(variables)\n",
    "\n",
    "fig, axes = plt.subplots(1, n_vars, figsize=(4 * n_vars, 4), sharey=False)\n",
    "if n_vars == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    ax = axes[i]\n",
    "    me_vals = ame_ord.marginal_effects[var].values\n",
    "    se_vals = ame_ord.std_errors[var].values\n",
    "\n",
    "    # Handle NaN SEs gracefully\n",
    "    se_vals = np.where(np.isnan(se_vals), 0, se_vals)\n",
    "\n",
    "    colors = ['tomato' if v < 0 else 'steelblue' for v in me_vals]\n",
    "    x_pos = np.arange(len(cats))\n",
    "\n",
    "    ax.bar(x_pos, me_vals, color=colors, alpha=0.75, width=0.6)\n",
    "    ax.errorbar(x_pos, me_vals, yerr=1.96 * se_vals,\n",
    "                fmt='none', color='black', capsize=4, lw=1.5)\n",
    "    ax.axhline(0, color='black', lw=0.8)\n",
    "    ax.set_title(f'AME of {var}', fontsize=11)\n",
    "    ax.set_xlabel(\"Satisfaction Category\")\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(cats, rotation=30, ha='right', fontsize=8)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Average Marginal Effect\")\n",
    "\n",
    "plt.suptitle(\"Ordered Logit: AME by Category\", y=1.02, fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/plots/02_ordered_ame_by_category.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Figure saved: 02_ordered_ame_by_category.png\")\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(\"  log_wage > 0: higher wage → more likely to be very satisfied (Sat.5), less likely Sat.1\")\n",
    "print(\"  Signs for middle categories can go either way depending on cutpoint spacing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17 — Compare Ordered Logit vs Ordered Probit\n",
    "\n",
    "oprobit = OrderedProbit(\n",
    "    endog=sat_vals,\n",
    "    exog=exog_ord,\n",
    "    groups=groups_ord\n",
    ")\n",
    "\n",
    "print(\"Fitting Ordered Probit...\")\n",
    "oprobit = oprobit.fit(options={'disp': False})\n",
    "print(\"Done.\")\n",
    "\n",
    "# Attach variable names\n",
    "oprobit.exog_names = exog_vars\n",
    "\n",
    "ame_oprobit = compute_ordered_ame(oprobit, varlist=exog_vars)\n",
    "\n",
    "# Relabel categories\n",
    "ame_oprobit.marginal_effects.index = cat_labels\n",
    "ame_oprobit.std_errors.index = cat_labels\n",
    "\n",
    "print(\"\\n=== Ordered Logit vs Ordered Probit AME — Highest Category (Sat.5) ===\")\n",
    "cat_top = cat_labels[-1]\n",
    "cat_low = cat_labels[0]\n",
    "\n",
    "comp = pd.DataFrame({\n",
    "    'OLogit AME (Sat.5)':  ame_ord.marginal_effects.loc[cat_top],\n",
    "    'OProbit AME (Sat.5)': ame_oprobit.marginal_effects.loc[cat_top],\n",
    "    'Difference':          ame_ord.marginal_effects.loc[cat_top] - ame_oprobit.marginal_effects.loc[cat_top]\n",
    "})\n",
    "print(comp.round(5))\n",
    "\n",
    "print(f\"\\n=== Lowest Category ({cat_low}) ===\")\n",
    "comp2 = pd.DataFrame({\n",
    "    'OLogit AME (Sat.1)':  ame_ord.marginal_effects.loc[cat_low],\n",
    "    'OProbit AME (Sat.1)': ame_oprobit.marginal_effects.loc[cat_low],\n",
    "    'Difference':          ame_ord.marginal_effects.loc[cat_low] - ame_oprobit.marginal_effects.loc[cat_low]\n",
    "})\n",
    "print(comp2.round(5))\n",
    "\n",
    "print(\"\\nNote: Logit and Probit AMEs should be similar. Large differences suggest model sensitivity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Fixed Effects Logit — Within Effects <a name=\"section-5\"></a>\n",
    "\n",
    "**Fixed Effects Logit** (Chamberlain 1980) conditions out the individual fixed effect $\\alpha_i$ using a conditional likelihood:\n",
    "\n",
    "$$P\\left(Y_{it} = 1 \\mid \\sum_t Y_{it}, X_i\\right) = \\frac{\\exp\\left(\\sum_t Y_{it} X_{it}' \\beta\\right)}{\\sum_{\\mathbf{d}: \\sum d_t = \\sum_t Y_{it}} \\exp\\left(\\sum_t d_t X_{it}' \\beta\\right)}$$\n",
    "\n",
    "**Key properties**:\n",
    "1. **Within interpretation**: ME measures the effect of a change in $x$ on $P(Y=1|\\alpha_i, X)$, holding the individual effect constant\n",
    "2. **Sample loss**: Individuals with no variation in $Y$ (always 0 or always 1) are dropped — they provide no information about $\\beta$\n",
    "3. **Consistent under strict exogeneity** even with arbitrary correlation between $\\alpha_i$ and $X_i$\n",
    "\n",
    "**Limitation**: Cannot estimate effects of time-invariant variables (e.g., gender), since they are absorbed by the fixed effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19 — FE Logit with Two-Period Panel\n",
    "#\n",
    "# FixedEffectsLogit requires genuine panel data (T >= 2)\n",
    "# We create a synthetic 2-period panel from the Mroz cross-section\n",
    "# Period 2 adds small random transitions in/out of the labor force\n",
    "\n",
    "np.random.seed(123)\n",
    "n_women = len(df)\n",
    "\n",
    "# Create period 2 by applying small random transitions\n",
    "transitions_in  = np.random.binomial(1, 0.08, n_women)  # some non-participants join\n",
    "transitions_out = np.random.binomial(1, 0.08, n_women)  # some participants leave\n",
    "\n",
    "inlf_t2 = df['inlf'].values.copy()\n",
    "inlf_t2 = np.where(df['inlf'].values == 0, transitions_in,\n",
    "                   np.where(transitions_out == 1, 0, inlf_t2))\n",
    "inlf_t2 = np.clip(inlf_t2, 0, 1)\n",
    "\n",
    "# Also add small changes in regressors over time (aging, children growing up)\n",
    "df_t1 = df.copy()\n",
    "df_t1['time'] = 1\n",
    "\n",
    "df_t2 = df.copy()\n",
    "df_t2['time'] = 2\n",
    "df_t2['inlf']   = inlf_t2\n",
    "df_t2['age']    = df['age']    + 1   # one year older\n",
    "df_t2['kidslt6'] = np.clip(df['kidslt6'] - np.random.binomial(1, 0.15, n_women), 0, None)\n",
    "df_t2['kidsge6'] = df['kidsge6'] + np.random.binomial(1, 0.15, n_women)\n",
    "\n",
    "df_panel = pd.concat([df_t1, df_t2], ignore_index=True)\n",
    "df_panel = df_panel.sort_values(['id', 'time']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Panel dataset: {len(df_panel)} observations ({n_women} women × 2 periods)\")\n",
    "print(f\"\\nWithin-entity variation in inlf:\")\n",
    "variation = df_panel.groupby('id')['inlf'].nunique()\n",
    "print(f\"  Women with variation (switchers): {(variation > 1).sum()}\")\n",
    "print(f\"  Women always in LF (no variation): {(df_panel.groupby('id')['inlf'].min() == 1).sum()}\")\n",
    "print(f\"  Women never in LF (no variation):  {(df_panel.groupby('id')['inlf'].max() == 0).sum()}\")\n",
    "\n",
    "# Fit FE Logit\n",
    "fe_formula = 'inlf ~ educ + age + kidslt6'\n",
    "print(f\"\\nFitting Fixed Effects Logit: {fe_formula}\")\n",
    "\n",
    "try:\n",
    "    fe_logit = FixedEffectsLogit(\n",
    "        formula=fe_formula,\n",
    "        data=df_panel,\n",
    "        entity_col='id',\n",
    "        time_col='time'\n",
    "    ).fit(cov_type='nonrobust')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FIXED EFFECTS LOGIT — Summary\")\n",
    "    print(\"=\"*60)\n",
    "    print(fe_logit.summary())\n",
    "\n",
    "    # Compute AME from FE Logit\n",
    "    fe_key_vars = ['educ', 'age', 'kidslt6']\n",
    "    ame_fe = compute_ame(fe_logit, varlist=fe_key_vars)\n",
    "\n",
    "    print(\"\\n=== FE Logit AME (Within Effect) ===\")\n",
    "    print(ame_fe.summary())\n",
    "    print(\"\\nNote: Only within-entity variation (switchers) identifies these effects.\")\n",
    "    fe_success = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nFE Logit failed: {e}\")\n",
    "    print(\"Falling back to Pooled Logit for comparison section.\")\n",
    "    fe_success = False\n",
    "    ame_fe = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Comparing Marginal Effects Across Specifications <a name=\"section-6\"></a>\n",
    "\n",
    "**Best practice in applied research**: estimate multiple specifications and compare their marginal effects. This demonstrates:\n",
    "1. **Robustness** — if AMEs are similar, the finding is not model-dependent\n",
    "2. **Sensitivity** — large differences may indicate omitted variable bias or heterogeneous effects\n",
    "3. **Model selection** — FE Logit is consistent under endogenous fixed effects; Pooled Logit is not\n",
    "\n",
    "Below we compare AMEs from Pooled Logit, Pooled Probit, and FE Logit for the same variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21 — Comparison Table: Logit, Probit, FE Logit\n",
    "\n",
    "# Key variables available in all three models\n",
    "key_vars_comp = ['educ', 'age', 'kidslt6']\n",
    "\n",
    "# Gather AMEs (filter to key_vars)\n",
    "ame_logit_comp  = ame_logit.marginal_effects.reindex(key_vars_comp)\n",
    "ame_probit_comp = ame_probit.marginal_effects.reindex(key_vars_comp)\n",
    "\n",
    "if fe_success and ame_fe is not None:\n",
    "    # Only include variables present in FE result\n",
    "    fe_available = [v for v in key_vars_comp if v in ame_fe.marginal_effects.index]\n",
    "    ame_fe_comp = ame_fe.marginal_effects.reindex(key_vars_comp)\n",
    "else:\n",
    "    # If FE Logit failed, use placeholder NaNs\n",
    "    ame_fe_comp = pd.Series([np.nan]*len(key_vars_comp), index=key_vars_comp)\n",
    "\n",
    "comparison_table = pd.DataFrame({\n",
    "    'Pooled Logit':  ame_logit_comp,\n",
    "    'Pooled Probit': ame_probit_comp,\n",
    "    'FE Logit':      ame_fe_comp\n",
    "})\n",
    "\n",
    "print(\"=== AME Comparison: Binary Models ===\")\n",
    "print(comparison_table.round(4))\n",
    "\n",
    "# Forest plot for comparison\n",
    "fig, axes = plt.subplots(1, len(key_vars_comp), figsize=(12, 4))\n",
    "models_list   = ['Pooled Logit', 'Pooled Probit', 'FE Logit']\n",
    "model_colors  = ['steelblue', 'tomato', 'forestgreen']\n",
    "\n",
    "for j, var in enumerate(key_vars_comp):\n",
    "    ax = axes[j]\n",
    "    me_by_model = comparison_table.loc[var].values\n",
    "    y_pos = np.arange(len(models_list))\n",
    "\n",
    "    # Handle NaN for FE Logit\n",
    "    valid_mask = ~np.isnan(me_by_model)\n",
    "    ax.barh(y_pos[valid_mask], me_by_model[valid_mask],\n",
    "            color=[c for c, v in zip(model_colors, valid_mask) if v],\n",
    "            alpha=0.8, height=0.5)\n",
    "\n",
    "    ax.set_yticks(list(y_pos))\n",
    "    ax.set_yticklabels(models_list, fontsize=9)\n",
    "    ax.axvline(0, color='black', lw=0.8)\n",
    "    ax.set_title(f'AME of {var}', fontsize=11)\n",
    "    ax.set_xlabel(\"Marginal Effect\")\n",
    "\n",
    "plt.suptitle(\"AME Comparison: Pooled Logit vs Probit vs FE Logit\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/plots/02_comparison_binary_models.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Figure saved: 02_comparison_binary_models.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Visualization Best Practices for Discrete ME <a name=\"section-7\"></a>\n",
    "\n",
    "**Choosing the right visualization**:\n",
    "\n",
    "| Model type | Recommended plot |\n",
    "|------------|------------------|\n",
    "| Binary (single model) | Forest plot with 95% CIs |\n",
    "| Binary (multiple models) | Side-by-side forest plot |\n",
    "| Ordered | Bar plots per category (one subplot per variable) |\n",
    "| Multinomial | Heatmap (alternatives × variables) |\n",
    "\n",
    "**Guidelines**:\n",
    "- Always include **confidence intervals** ($\\pm 1.96 \\times \\text{SE}$)\n",
    "- Use **color coding**: blue = positive, red = negative\n",
    "- Include **significance stars**: $^*p < .05$, $^{**}p < .01$, $^{***}p < .001$\n",
    "- Label axes in **probability units** (pp) or fractions\n",
    "- Report the method (AME vs MEM) and any restrictions applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23 — Publication-Ready Forest Plot (Pooled Logit)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "me_vals  = ame_logit.marginal_effects.values\n",
    "se_vals  = ame_logit.std_errors.values\n",
    "labels   = list(ame_logit.marginal_effects.index)\n",
    "y_pos    = np.arange(len(labels))\n",
    "pvals    = ame_logit.pvalues.values\n",
    "\n",
    "def significance_stars(p):\n",
    "    if np.isnan(p):   return ''\n",
    "    if p < 0.001: return '***'\n",
    "    if p < 0.01:  return '**'\n",
    "    if p < 0.05:  return '*'\n",
    "    return ''\n",
    "\n",
    "colors     = ['tomato' if v < 0 else 'steelblue' for v in me_vals]\n",
    "sig_stars  = [significance_stars(p) for p in pvals]\n",
    "\n",
    "bars = ax.barh(y_pos, me_vals, xerr=1.96 * se_vals,\n",
    "               color=colors, alpha=0.75, capsize=5, height=0.5,\n",
    "               error_kw={'elinewidth': 1.5, 'capthick': 1.5})\n",
    "\n",
    "# Significance stars\n",
    "for i, (v, sig, se) in enumerate(zip(me_vals, sig_stars, se_vals)):\n",
    "    if sig:\n",
    "        x_star = v + 1.96*se + 0.002 if v >= 0 else v - 1.96*se - 0.002\n",
    "        ha = 'left' if v >= 0 else 'right'\n",
    "        ax.text(x_star, i, sig, ha=ha, va='center', fontsize=11,\n",
    "                color='black', fontweight='bold')\n",
    "\n",
    "# Zero reference line\n",
    "ax.axvline(0, color='black', lw=1.0, ls='--', alpha=0.7)\n",
    "\n",
    "# Labels\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(labels, fontsize=11)\n",
    "ax.set_xlabel(\"Average Marginal Effect on P(inlf=1)\", fontsize=11)\n",
    "ax.set_title(\n",
    "    \"AME — Pooled Logit: Women's Labor Force Participation\\n\"\n",
    "    \"Mroz (1987) | 95% Confidence Intervals\\n\"\n",
    "    \"Significance: * p<.05  ** p<.01  *** p<.001\",\n",
    "    fontsize=11\n",
    ")\n",
    "\n",
    "# Legend for colors\n",
    "import matplotlib.patches as mpatches\n",
    "pos_patch = mpatches.Patch(color='steelblue', alpha=0.75, label='Positive effect')\n",
    "neg_patch = mpatches.Patch(color='tomato',    alpha=0.75, label='Negative effect')\n",
    "ax.legend(handles=[pos_patch, neg_patch], loc='lower right', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/plots/02_publication_forest_plot.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Figure saved: 02_publication_forest_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Binary models**: AME is nearly identical between Logit and Probit despite coefficient differences of ~1.6-1.8x — use both as a robustness check.\n",
    "\n",
    "2. **Dummy variables**: Always use **discrete change** (not derivative) for 0/1 regressors. PanelBox detects binary variables automatically via `_is_binary()`.\n",
    "\n",
    "3. **Multinomial Logit**: ME is a **matrix** ($J \\times K$); for any variable $k$, the sum of ME across all alternatives $j$ equals **zero**. Increasing $x_k$ creates a zero-sum redistribution of probability mass.\n",
    "\n",
    "4. **Ordered models**: ME is a **vector** (one value per category); effects must sum to **zero across categories**. Positive $\\beta_k$ shifts probability toward higher categories, but middle categories can have positive or negative ME.\n",
    "\n",
    "5. **FE Logit**: Only within-entity variation identifies the parameters; individuals with no variation in $Y$ are dropped. Interpret as **within-person** effects, controlling for time-invariant unobservables.\n",
    "\n",
    "6. **Comparison**: Reporting ME from multiple specifications demonstrates robustness. If Pooled Logit and FE Logit AMEs differ substantially, there may be unobserved heterogeneity biasing the pooled estimates.\n",
    "\n",
    "---\n",
    "\n",
    "**Bridge to Notebook 03**: Count data models (Poisson, Negative Binomial) have a different functional form — $E[Y|X] = \\exp(X'\\beta)$ — but the same ME logic applies. Marginal effects are $\\partial E[Y]/\\partial x_k = \\beta_k \\cdot \\exp(X'\\beta)$. Incidence Rate Ratios (IRR = $\\exp(\\beta_k)$) offer a multiplicative interpretation. See `03_count_me.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25 — Export All Results\n",
    "\n",
    "out_tables = '/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/tables'\n",
    "\n",
    "# Binary model AME tables\n",
    "try:\n",
    "    fmt_logit  = format_me_table(ame_logit)\n",
    "    fmt_probit = format_me_table(ame_probit)\n",
    "    fmt_logit.to_csv(f\"{out_tables}/02_ame_logit.csv\", index=False)\n",
    "    fmt_probit.to_csv(f\"{out_tables}/02_ame_probit.csv\", index=False)\n",
    "    print(\"Saved: 02_ame_logit.csv, 02_ame_probit.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning (binary tables): {e}\")\n",
    "    ame_logit.marginal_effects.to_frame('AME').to_csv(f\"{out_tables}/02_ame_logit.csv\")\n",
    "    ame_probit.marginal_effects.to_frame('AME').to_csv(f\"{out_tables}/02_ame_probit.csv\")\n",
    "    print(\"Saved (fallback): 02_ame_logit.csv, 02_ame_probit.csv\")\n",
    "\n",
    "# Comparison table\n",
    "comparison_table.to_csv(f\"{out_tables}/02_comparison_binary.csv\")\n",
    "print(\"Saved: 02_comparison_binary.csv\")\n",
    "\n",
    "# Ordered AME\n",
    "ame_ord.marginal_effects.to_csv(f\"{out_tables}/02_ordered_ame.csv\")\n",
    "ame_ord.std_errors.to_csv(f\"{out_tables}/02_ordered_se.csv\")\n",
    "print(\"Saved: 02_ordered_ame.csv, 02_ordered_se.csv\")\n",
    "\n",
    "# Multinomial AME\n",
    "me_df.to_csv(f\"{out_tables}/02_multinomial_ame.csv\")\n",
    "print(\"Saved: 02_multinomial_ame.csv\")\n",
    "\n",
    "print(\"\\nAll results saved to outputs/tables/\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Notebook 02 complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Summary of outputs:\")\n",
    "print(\"  Plots : 02_mnl_ame_heatmap.png\")\n",
    "print(\"          02_ordered_ame_by_category.png\")\n",
    "print(\"          02_comparison_binary_models.png\")\n",
    "print(\"          02_publication_forest_plot.png\")\n",
    "print(\"  Tables: 02_ame_logit.csv\")\n",
    "print(\"          02_ame_probit.csv\")\n",
    "print(\"          02_comparison_binary.csv\")\n",
    "print(\"          02_ordered_ame.csv\")\n",
    "print(\"          02_multinomial_ame.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
