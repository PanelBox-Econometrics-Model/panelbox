{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-01",
   "metadata": {},
   "source": [
    "# Marginal Effects in Nonlinear Models: Why Coefficients Are Not Enough\n",
    "\n",
    "**Series:** Marginal Effects Tutorial Series — Notebook 1 of 6  \n",
    "**Level:** Intermediate  \n",
    "**Estimated Duration:** 45–60 minutes  \n",
    "**Dataset:** Mroz (1987) — Women's Labor Force Participation\n",
    "\n",
    "---\n",
    "\n",
    "## The Problem\n",
    "\n",
    "In **linear regression**, the coefficient $\\beta_k$ *is* the marginal effect:\n",
    "$$\n",
    "E[Y \\mid X] = X\\beta \\implies \\frac{\\partial E[Y \\mid X]}{\\partial x_k} = \\beta_k\n",
    "$$\n",
    "\n",
    "In **nonlinear models** (Logit, Probit, Poisson, Tobit), this relationship breaks down. The coefficient $\\beta_k$ is **not** the marginal effect. Failing to compute and report proper marginal effects is one of the most common mistakes in applied econometrics.\n",
    "\n",
    "> **Motivating example:** Suppose you estimated a Logit model of women's labor force participation and found $\\hat{\\beta}_{education} = 0.82$. What does that mean? Does education increase the probability of working by 82 percentage points? **No.** The true marginal effect depends on all other variables — and it varies across individuals.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [The Interpretation Problem in Nonlinear Models](#section-1)\n",
    "2. [Formal Definition of a Marginal Effect](#section-2)\n",
    "3. [AME, MEM, and MER — Three Strategies](#section-3)\n",
    "4. [Standard Errors for Marginal Effects (Delta Method)](#section-4)\n",
    "5. [Complete Hands-on Example](#section-5)\n",
    "6. [Key Takeaways](#section-6)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "\n",
    "1. Explain why coefficients in nonlinear models are not directly interpretable as marginal effects.\n",
    "2. State the formal definition of a marginal effect: $\\partial E[Y \\mid X] / \\partial x_k$.\n",
    "3. Distinguish AME, MEM, and MER, and identify when to use each.\n",
    "4. Compute AME and MEM for a Pooled Logit using PanelBox.\n",
    "5. Interpret the magnitude of a marginal effect in plain language.\n",
    "6. Understand that marginal effects depend on $X$ (heterogeneity).\n",
    "7. Explain why marginal effects also have standard errors (delta method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Setup / Imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/home/guhaase/projetos/panelbox')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy import stats\n",
    "\n",
    "import panelbox as pb\n",
    "from panelbox.models.discrete.binary import PooledLogit, PooledProbit\n",
    "from panelbox.marginal_effects.discrete_me import compute_ame, compute_mem, compute_mer\n",
    "from panelbox.core import PanelData\n",
    "\n",
    "# Utilities from the series — add utils directory to path\n",
    "_notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "_utils_dir = os.path.join(\n",
    "    '/home/guhaase/projetos/panelbox/examples/marginal_effects', 'utils'\n",
    ")\n",
    "if _utils_dir not in sys.path:\n",
    "    sys.path.insert(0, _utils_dir)\n",
    "\n",
    "from data_loaders import load_dataset\n",
    "from me_helpers import plot_forest, format_me_table\n",
    "\n",
    "# Plot style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "except OSError:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Output directories\n",
    "_outputs_plots  = '/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/plots'\n",
    "_outputs_tables = '/home/guhaase/projetos/panelbox/examples/marginal_effects/outputs/tables'\n",
    "os.makedirs(_outputs_plots,  exist_ok=True)\n",
    "os.makedirs(_outputs_tables, exist_ok=True)\n",
    "\n",
    "print('Setup complete.')\n",
    "print(f'PanelBox version: {pb.__version__ if hasattr(pb, \"__version__\") else \"(unknown)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03",
   "metadata": {},
   "source": [
    "<a id='section-1'></a>\n",
    "## Section 1: The Interpretation Problem in Nonlinear Models\n",
    "\n",
    "### OLS: the easy case\n",
    "\n",
    "In Ordinary Least Squares the conditional expectation is *linear*:\n",
    "$$E[Y \\mid X] = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_K x_K$$\n",
    "\n",
    "Taking the derivative with respect to $x_k$ yields simply $\\beta_k$ — a **constant** that does not depend on $X$. One number, one interpretation.\n",
    "\n",
    "### Logit: the nonlinear case\n",
    "\n",
    "In the binary Logit model:\n",
    "$$P(Y=1 \\mid X) = \\Lambda(X\\beta) = \\frac{e^{X\\beta}}{1 + e^{X\\beta}}$$\n",
    "\n",
    "The marginal effect of $x_k$ is:\n",
    "$$\\frac{\\partial P(Y=1 \\mid X)}{\\partial x_k} = \\beta_k \\cdot \\Lambda(X\\beta)\\bigl[1 - \\Lambda(X\\beta)\\bigr]$$\n",
    "\n",
    "This expression depends on **all** explanatory variables through the index $X\\beta$. The same $\\beta_k$ therefore produces **different** effects for different individuals.\n",
    "\n",
    "### Probit: analogously\n",
    "\n",
    "$$\\frac{\\partial P(Y=1 \\mid X)}{\\partial x_k} = \\beta_k \\cdot \\phi(X\\beta)$$\n",
    "\n",
    "where $\\phi$ is the standard normal PDF. Again: depends on $X$.\n",
    "\n",
    "The cell below illustrates this numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Numerical illustration: ME varies with the linear index Xb\n",
    "\n",
    "xb = np.linspace(-4, 4, 300)\n",
    "logistic_pdf = np.exp(xb) / (1 + np.exp(xb))**2   # Λ(xb)[1 - Λ(xb)]\n",
    "\n",
    "beta = 1.5   # a fixed coefficient — same for everyone\n",
    "me_at_point = beta * logistic_pdf\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Left panel — the S-curve (logistic CDF)\n",
    "ax1.plot(xb, 1 / (1 + np.exp(-xb)), color='steelblue', lw=2)\n",
    "ax1.set_xlabel('Linear Index ($X\\\\beta$)')\n",
    "ax1.set_ylabel('$P(Y=1 \\\\mid X)$')\n",
    "ax1.set_title(\"Logistic CDF — the 'S curve'\")\n",
    "ax1.axhline(0.5, color='gray', ls='--', alpha=0.5, label='P = 0.5')\n",
    "ax1.legend()\n",
    "\n",
    "# Right panel — how the marginal effect changes with Xb\n",
    "ax2.plot(xb, me_at_point, color='tomato', lw=2)\n",
    "ax2.axhline(beta * 0.25, color='gray', ls='--', alpha=0.5,\n",
    "            label=f'Max ME = $\\\\beta$/4 = {beta/4:.3f}')\n",
    "ax2.set_xlabel('Linear Index ($X\\\\beta$)')\n",
    "ax2.set_ylabel(f'ME of $x$ ($\\\\beta$ = {beta})')\n",
    "ax2.set_title('Marginal Effect Varies with $X\\\\beta$')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(\n",
    "    f'Same coefficient $\\\\beta$ = {beta}, but the marginal effect is NOT constant',\n",
    "    y=1.02, fontsize=12\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(_outputs_plots, '01_me_varies_with_xb.png'),\n",
    "    dpi=150, bbox_inches='tight'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Three example values\n",
    "idx_neg2 = np.argmin(np.abs(xb - (-2)))\n",
    "idx_zero = np.argmin(np.abs(xb - 0))\n",
    "idx_pos2 = np.argmin(np.abs(xb - 2))\n",
    "\n",
    "print(f\"\\nFor beta = {beta}:\")\n",
    "print(f\"  Maximum ME (at Xβ = 0):  {beta * 0.25:.4f}\")\n",
    "print(f\"  ME at Xβ = -2:            {me_at_point[idx_neg2]:.4f}\")\n",
    "print(f\"  ME at Xβ =  0:            {me_at_point[idx_zero]:.4f}\")\n",
    "print(f\"  ME at Xβ = +2:            {me_at_point[idx_pos2]:.4f}\")\n",
    "print()\n",
    "print(\"Notice: the same beta produces very different effects depending on where\")\n",
    "print(\"individuals are located on the S-curve.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-05",
   "metadata": {},
   "source": [
    "### Key insight from Section 1\n",
    "\n",
    "The marginal effect in a nonlinear model **depends on the value of $X$ for each individual**. This heterogeneity is unavoidable — it is built into the functional form.\n",
    "\n",
    "Because the effect is different for every observation, we need a **summarization strategy**. Three standard approaches exist:\n",
    "\n",
    "| Strategy | Name | Description |\n",
    "|----------|------|-------------|\n",
    "| **AME** | Average Marginal Effect | Compute the ME at every observation, then average. |\n",
    "| **MEM** | Marginal Effect at Means | Evaluate the ME at $\\bar{X}$ (sample means). |\n",
    "| **MER** | Marginal Effect at Representative values | Evaluate the ME at a user-chosen $X^*$. |\n",
    "\n",
    "We explore all three in Section 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-06",
   "metadata": {},
   "source": [
    "<a id='section-2'></a>\n",
    "## Section 2: Formal Definition of a Marginal Effect\n",
    "\n",
    "### Continuous explanatory variables\n",
    "\n",
    "For a continuous variable $x_k$:\n",
    "\n",
    "$$\\text{ME}_k(X) = \\frac{\\partial E[Y \\mid X]}{\\partial x_k}$$\n",
    "\n",
    "Model-specific formulas:\n",
    "\n",
    "| Model | $E[Y \\mid X]$ | $\\text{ME}_k(X)$ |\n",
    "|-------|--------------|------------------|\n",
    "| OLS | $X\\beta$ | $\\beta_k$ |\n",
    "| Logit | $\\Lambda(X\\beta)$ | $\\beta_k \\cdot \\Lambda(X\\beta)[1 - \\Lambda(X\\beta)]$ |\n",
    "| Probit | $\\Phi(X\\beta)$ | $\\beta_k \\cdot \\phi(X\\beta)$ |\n",
    "| Poisson | $\\exp(X\\beta)$ | $\\beta_k \\cdot \\exp(X\\beta)$ |\n",
    "\n",
    "### Binary (dummy) explanatory variables\n",
    "\n",
    "When $x_k \\in \\{0, 1\\}$, the derivative does not apply. Use the **discrete change** instead:\n",
    "\n",
    "$$\\text{DC}_k = E[Y \\mid X, x_k = 1] - E[Y \\mid X, x_k = 0]$$\n",
    "\n",
    "This is the change in probability when the dummy switches from 0 to 1, holding all other variables constant.\n",
    "\n",
    "### Notation\n",
    "\n",
    "Throughout this series:\n",
    "- $\\Lambda(\\cdot)$ = logistic CDF: $\\Lambda(z) = e^z / (1 + e^z)$\n",
    "- $\\lambda(\\cdot)$ = logistic PDF: $\\lambda(z) = \\Lambda(z)[1 - \\Lambda(z)]$\n",
    "- $\\Phi(\\cdot)$ = standard normal CDF\n",
    "- $\\phi(\\cdot)$ = standard normal PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — Load Mroz dataset\n",
    "\n",
    "df = load_dataset('mroz')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df.describe().T[['count', 'mean', 'std', 'min', 'max']].round(4))\n",
    "\n",
    "print(f\"\\nOutcome variable (inlf):\")\n",
    "vc = df['inlf'].value_counts().sort_index()\n",
    "print(f\"  Not in labor force (0): {vc.get(0, 0):4d}  ({100*vc.get(0,0)/len(df):.1f}%)\")\n",
    "print(f\"  In labor force     (1): {vc.get(1, 0):4d}  ({100*vc.get(1,0)/len(df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 — Estimate Pooled Logit (cross-section treated as single-period panel)\n",
    "\n",
    "# Add panel identifiers (cross-section: each observation is its own entity)\n",
    "df = df.copy()\n",
    "df['id']   = range(len(df))\n",
    "df['time'] = 1\n",
    "\n",
    "panel = PanelData(df, entity='id', time='time')\n",
    "\n",
    "# Estimate model\n",
    "model = PooledLogit(\n",
    "    data=panel,\n",
    "    formula='inlf ~ educ + age + kidslt6 + kidsge6 + nwifeinc'\n",
    ")\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "# Pseudo-R2\n",
    "try:\n",
    "    prsq = result.prsquared\n",
    "except AttributeError:\n",
    "    try:\n",
    "        prsq = 1 - result.llf / result.llnull\n",
    "    except AttributeError:\n",
    "        prsq = float('nan')\n",
    "\n",
    "print(f\"\\nPseudo R² (McFadden): {prsq:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-09",
   "metadata": {},
   "source": [
    "<a id='section-3'></a>\n",
    "## Section 3: AME, MEM, and MER — Three Strategies\n",
    "\n",
    "Because the marginal effect varies across individuals, we need a single summary number. Three standard strategies exist.\n",
    "\n",
    "---\n",
    "\n",
    "### AME — Average Marginal Effects\n",
    "\n",
    "**Definition:** Compute the ME at *every* observation, then take the average:\n",
    "$$\\text{AME}_k = \\frac{1}{N} \\sum_{i=1}^{N} \\beta_k \\cdot \\lambda(X_i \\beta)$$\n",
    "\n",
    "**Pros:**\n",
    "- Accounts for the full distribution of $X$ in the sample.\n",
    "- Population-average interpretation: \"the average individual's response\".\n",
    "- Most common in published research and required by some journals.\n",
    "\n",
    "**When to use:** General-purpose; the recommended default.\n",
    "\n",
    "---\n",
    "\n",
    "### MEM — Marginal Effects at Means\n",
    "\n",
    "**Definition:** Evaluate the ME at the sample mean $\\bar{X}$:\n",
    "$$\\text{MEM}_k = \\beta_k \\cdot \\lambda(\\bar{X}\\beta)$$\n",
    "\n",
    "**Pros:** Simple to compute; useful for quick comparisons.\n",
    "\n",
    "**Cons:** The \"average individual\" ($\\bar{X}$) may not exist in the data. For example, if `kidslt6` has mean 0.4, no woman actually has 0.4 young children.\n",
    "\n",
    "**When to use:** Exploratory analysis; homogeneous samples where the mean is representative.\n",
    "\n",
    "---\n",
    "\n",
    "### MER — Marginal Effects at Representative values\n",
    "\n",
    "**Definition:** Evaluate the ME at a user-specified profile $X^*$:\n",
    "$$\\text{MER}_k = \\beta_k \\cdot \\lambda(X^* \\beta)$$\n",
    "\n",
    "Unspecified variables are set to their sample means.\n",
    "\n",
    "**When to use:** Scenario analysis; comparing subgroups (e.g., \"a college-educated woman with no young children\").\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison table\n",
    "\n",
    "| Method | Formula | Typical use case |\n",
    "|--------|---------|------------------|\n",
    "| **AME** | $\\mathbb{E}[\\partial P/\\partial x]$ | General; recommended default |\n",
    "| **MEM** | $\\partial P(\\bar{X})/\\partial x$ | Quick check; low heterogeneity |\n",
    "| **MER** | $\\partial P(X^*)/\\partial x$ | Specific profiles or scenarios |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 — Compute AME\n",
    "\n",
    "ame = compute_ame(result)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  Average Marginal Effects (AME)\")\n",
    "print(\"=\" * 65)\n",
    "ame_summary = ame.summary()\n",
    "print(ame_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 — Compute MEM\n",
    "\n",
    "mem = compute_mem(result)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  Marginal Effects at Means (MEM)\")\n",
    "print(\"=\" * 65)\n",
    "mem_summary = mem.summary()\n",
    "print(mem_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 — Compare AME vs MEM side by side\n",
    "\n",
    "ame_vals = ame.marginal_effects\n",
    "mem_vals = mem.marginal_effects\n",
    "\n",
    "# Align on common index\n",
    "common_vars = ame_vals.index.intersection(mem_vals.index)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'AME':          ame_vals[common_vars],\n",
    "    'MEM':          mem_vals[common_vars],\n",
    "    'Difference':   ame_vals[common_vars] - mem_vals[common_vars],\n",
    "    'Rel. Diff (%)': 100 * (ame_vals[common_vars] - mem_vals[common_vars])\n",
    "                    / ame_vals[common_vars].abs()\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  AME vs MEM Comparison\")\n",
    "print(\"=\" * 65)\n",
    "print(comparison.round(5))\n",
    "\n",
    "print(\"\"\"\n",
    "Interpretation:\n",
    "  - AME and MEM are close but not identical.\n",
    "  - Differences arise because the logistic density is concave: it attenuates\n",
    "    the effect of large values more than the linear average.\n",
    "  - AME is preferred because it integrates over the actual distribution\n",
    "    of X in the data, rather than relying on the (possibly non-existent)\n",
    "    'average individual'.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13 — Compute MER: college-educated woman, age 35, no young children\n",
    "\n",
    "# Representative profile\n",
    "# Variables not listed here will default to sample means inside compute_mer\n",
    "representative = {\n",
    "    'educ':    16,    # college degree (16 years of education)\n",
    "    'age':     35,\n",
    "    'kidslt6': 0,     # no children under 6\n",
    "    'kidsge6': 1,     # one school-age child\n",
    "    'nwifeinc': 20.0  # moderate non-wife household income\n",
    "}\n",
    "\n",
    "mer = compute_mer(result, at=representative)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  MER: College-Educated Woman, Age 35, No Young Children\")\n",
    "print(\"=\" * 65)\n",
    "mer_summary = mer.summary()\n",
    "print(mer_summary)\n",
    "\n",
    "print(\"\\nNote: variables not specified in 'at' are set to their sample means.\")\n",
    "print(\"The MER answers: 'What is the marginal effect for *this specific person*?'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "<a id='section-4'></a>\n",
    "## Section 4: Standard Errors for Marginal Effects (Delta Method)\n",
    "\n",
    "### Why do marginal effects have standard errors?\n",
    "\n",
    "Marginal effects are **functions of estimated parameters** $\\hat{\\beta}$. Because $\\hat{\\beta}$ is a random variable with estimation uncertainty, so are the marginal effects.\n",
    "\n",
    "### The Delta Method\n",
    "\n",
    "Let $g(\\theta)$ be any differentiable function of the parameter vector. The delta method gives:\n",
    "\n",
    "$$\\text{Var}\\bigl[g(\\hat{\\theta})\\bigr] \\approx \\nabla g(\\hat{\\theta})' \\cdot \\text{Var}[\\hat{\\theta}] \\cdot \\nabla g(\\hat{\\theta})$$\n",
    "\n",
    "where:\n",
    "- $g(\\theta)$ is the marginal effect as a function of all parameters,\n",
    "- $\\nabla g(\\theta)$ is the gradient vector (computed numerically in PanelBox),\n",
    "- $\\text{Var}[\\hat{\\theta}]$ is the estimated parameter covariance matrix.\n",
    "\n",
    "### Important warning\n",
    "\n",
    "> **A statistically significant coefficient does NOT guarantee a statistically significant marginal effect** (and vice versa). The transformations can amplify or dampen uncertainty differently. Always test the marginal effect directly.\n",
    "\n",
    "### What PanelBox does\n",
    "\n",
    "The function `compute_ame` (and `compute_mem`, `compute_mer`) internally calls `delta_method_se()` from `panelbox.marginal_effects.delta_method`. The gradient is computed numerically using finite differences. This is transparent to the user — you simply inspect the `std_errors` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15 — Confidence intervals from the AME\n",
    "\n",
    "ci = ame.conf_int(alpha=0.05)\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(\"  95% Confidence Intervals for AME\")\n",
    "print(\"=\" * 55)\n",
    "print(ci.round(5))\n",
    "\n",
    "print(\"\\nAME with SEs and p-values:\")\n",
    "ame_full = pd.DataFrame({\n",
    "    'AME':       ame.marginal_effects,\n",
    "    'Std. Err.': ame.std_errors,\n",
    "    'z':         ame.z_stats,\n",
    "    'P>|z|':     ame.pvalues,\n",
    "    'CI Lower':  ci['lower'],\n",
    "    'CI Upper':  ci['upper'],\n",
    "})\n",
    "print(ame_full.round(5))\n",
    "\n",
    "print(\"\"\"\n",
    "Significance codes:  *** p < 0.001  ** p < 0.01  * p < 0.05  . p < 0.1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "<a id='section-5'></a>\n",
    "## Section 5: Complete Hands-on Example\n",
    "\n",
    "Now let us run the **full pipeline** in one place and produce a complete, publication-ready interpretation.\n",
    "\n",
    "The pipeline is:\n",
    "1. Load data.\n",
    "2. Create panel structure (cross-section).\n",
    "3. Estimate Pooled Logit.\n",
    "4. Compute AME with standard errors.\n",
    "5. Inspect confidence intervals.\n",
    "6. Communicate results in plain language.\n",
    "7. Produce a forest plot.\n",
    "\n",
    "Steps 1–5 are already done above. Below we focus on steps 6–7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17 — Full pipeline: plain-language interpretation\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  COMPLETE MARGINAL EFFECTS PIPELINE\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# ── Step 1: Model summary ───────────────────────────────────────────────────\n",
    "print(\"\\n[1] Model: Pooled Logit — Women's Labor Force Participation (Mroz 1987)\")\n",
    "print(f\"    Observations: {len(df)}\")\n",
    "try:\n",
    "    prsq = result.prsquared\n",
    "except AttributeError:\n",
    "    try:\n",
    "        prsq = 1 - result.llf / result.llnull\n",
    "    except AttributeError:\n",
    "        prsq = float('nan')\n",
    "print(f\"    Pseudo R² (McFadden): {prsq:.4f}\")\n",
    "\n",
    "# ── Step 2: AME summary ─────────────────────────────────────────────────────\n",
    "print(\"\\n[2] Average Marginal Effects (AME):\")\n",
    "ame_summary = ame.summary()\n",
    "print(ame_summary)\n",
    "\n",
    "# ── Step 3: Plain-language interpretation ──────────────────────────────────\n",
    "print(\"\\n[3] Plain-language interpretation:\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "vars_to_report = ['educ', 'age', 'kidslt6', 'kidsge6', 'nwifeinc']\n",
    "ci95 = ame.conf_int(alpha=0.05)\n",
    "\n",
    "for var in vars_to_report:\n",
    "    if var not in ame.marginal_effects.index:\n",
    "        continue\n",
    "    me_val  = float(ame.marginal_effects[var])\n",
    "    se_val  = float(ame.std_errors[var])\n",
    "    pv_val  = float(ame.pvalues[var])\n",
    "    lo_val  = float(ci95.loc[var, 'lower'])\n",
    "    hi_val  = float(ci95.loc[var, 'upper'])\n",
    "    sig_str = '***' if pv_val < 0.001 else ('**' if pv_val < 0.01 else\n",
    "              ('*' if pv_val < 0.05 else ('.' if pv_val < 0.1 else 'n.s.')))\n",
    "\n",
    "    direction = 'increases' if me_val > 0 else 'decreases'\n",
    "    print(f\"  {var} ({sig_str}):\")\n",
    "    print(f\"    A one-unit increase {direction} P(LFP=1) by {abs(me_val):.1%}\")\n",
    "    print(f\"    [95% CI: {lo_val:.1%} to {hi_val:.1%}; SE = {se_val:.4f}]\")\n",
    "    print()\n",
    "\n",
    "# Focused interpretation for the two most salient variables\n",
    "if 'educ' in ame.marginal_effects.index and 'kidslt6' in ame.marginal_effects.index:\n",
    "    educ_ame = float(ame.marginal_effects['educ'])\n",
    "    educ_se  = float(ame.std_errors['educ'])\n",
    "    klt6_ame = float(ame.marginal_effects['kidslt6'])\n",
    "\n",
    "    print(\"-\" * 55)\n",
    "    print(\"  Highlight — Education:\")\n",
    "    print(f\"    An additional year of education raises the probability\")\n",
    "    print(f\"    of labor force participation by {educ_ame:.1%} on average\")\n",
    "    print(f\"    (SE = {educ_se:.4f}).\")\n",
    "    print()\n",
    "    print(\"  Highlight — Young children:\")\n",
    "    print(f\"    Having one more child under age 6 reduces participation\")\n",
    "    print(f\"    probability by {abs(klt6_ame):.1%} on average.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18 — Forest plot: AME with 95% confidence intervals\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "variables = list(ame.marginal_effects.index)\n",
    "me_vals   = ame.marginal_effects.values\n",
    "se_vals   = ame.std_errors.values\n",
    "ci95_plot = ame.conf_int(alpha=0.05)\n",
    "\n",
    "# Colour by sign\n",
    "colors = ['tomato' if v < 0 else 'steelblue' for v in me_vals]\n",
    "\n",
    "# Horizontal bar chart with error bars\n",
    "ax.barh(\n",
    "    variables, me_vals,\n",
    "    xerr=1.96 * se_vals,\n",
    "    color=colors,\n",
    "    alpha=0.75,\n",
    "    capsize=5,\n",
    "    error_kw={'lw': 1.5, 'ecolor': 'black'}\n",
    ")\n",
    "ax.axvline(0, color='black', lw=0.8, ls='--')\n",
    "ax.set_xlabel('Average Marginal Effect on P(LFP = 1)')\n",
    "ax.set_title(\"AME — Women's Labor Force Participation (Mroz 1987)\")\n",
    "\n",
    "# Format x-axis as percentages\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=1))\n",
    "\n",
    "# Significance stars\n",
    "pvals = ame.pvalues\n",
    "for i, var in enumerate(variables):\n",
    "    pv = float(pvals[var])\n",
    "    stars = '***' if pv < 0.001 else ('**' if pv < 0.01 else\n",
    "            ('*' if pv < 0.05 else ''))\n",
    "    if stars:\n",
    "        x_offset = me_vals[i] + 1.96 * se_vals[i]\n",
    "        ax.text(x_offset * 1.05, i, stars, va='center', fontsize=9, color='darkred')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(_outputs_plots, '01_ame_forest_plot.png'),\n",
    "    dpi=150, bbox_inches='tight'\n",
    ")\n",
    "plt.show()\n",
    "print(\"Forest plot saved to outputs/plots/01_ame_forest_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "<a id='section-6'></a>\n",
    "## Section 6: Key Takeaways\n",
    "\n",
    "1. **In nonlinear models, $\\beta \\neq$ marginal effect.** The Logit coefficient $\\beta_k$ must be multiplied by $\\lambda(X\\beta) = \\Lambda(X\\beta)[1-\\Lambda(X\\beta)]$ to obtain the actual marginal effect.\n",
    "\n",
    "2. **The marginal effect depends on $X$.** It is different for every individual in the sample. Reporting a single coefficient as if it were a marginal effect is incorrect.\n",
    "\n",
    "3. **AME averages over all observations** → preferred in most applications. It respects the actual distribution of covariates in the data.\n",
    "\n",
    "4. **MEM evaluates at the mean** → fast but may be misleading if the mean $\\bar{X}$ does not represent a real individual (e.g., fractional children).\n",
    "\n",
    "5. **MER evaluates at any specified point** → use for scenario analysis or subgroup comparisons.\n",
    "\n",
    "6. **Marginal effects have standard errors (delta method) — always report them.** A significant coefficient does not guarantee a significant marginal effect.\n",
    "\n",
    "7. **Communicate in plain language.** Instead of \"$\\hat{\\beta}_{educ} = 0.28$\", say \"An additional year of education increases the probability of labor force participation by approximately 3.8 percentage points (95% CI: ...)\".\n",
    "\n",
    "---\n",
    "\n",
    "### Bridge to Notebook 02\n",
    "\n",
    "In **Notebook 02** (`02_discrete_me_complete.ipynb`) we extend these concepts to the full range of discrete choice models:\n",
    "- Binary Probit (comparison with Logit)\n",
    "- Multinomial Logit (unordered multiple alternatives)\n",
    "- Ordered Logit / Probit (ordered categories)\n",
    "\n",
    "Each model type requires specific formulas for computing marginal effects, and PanelBox handles them all through a unified API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Knowledge Check\n",
    "\n",
    "Test your understanding with these four questions. Answers are in the solution notebook.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "A Probit coefficient for `education` is $\\hat{\\beta} = 0.15$. Can you directly interpret this as \"one more year of education increases the probability by 15 percentage points\"? Why or why not?\n",
    "\n",
    "*(Hint: think about the functional form $\\Phi(X\\beta)$ and what its derivative looks like.)*\n",
    "\n",
    "---\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "In the Mroz example above, why might AME and MEM differ for `kidslt6` but be nearly identical for `age`?\n",
    "\n",
    "*(Hint: consider how the distribution of `kidslt6` differs from that of `age`, and how that interacts with the nonlinearity of the logistic function.)*\n",
    "\n",
    "---\n",
    "\n",
    "**Question 3**\n",
    "\n",
    "When would you prefer MER over AME? Give a concrete research scenario.\n",
    "\n",
    "*(Example starting point: a policy analyst needs to predict the effect of a subsidy for a specific demographic group...)*\n",
    "\n",
    "---\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "Suppose the AME for `educ` is $0.038$ and its standard error is $0.010$.\n",
    "\n",
    "(a) What is the 95% confidence interval?  \n",
    "(b) Is the effect statistically significant at the 5% level?  \n",
    "(c) Is the effect economically significant? How would you judge this?\n",
    "\n",
    "*(Recall: 95% CI = estimate $\\pm$ 1.96 $\\times$ SE.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21 — Export results to CSV and LaTeX\n",
    "\n",
    "# ── Format table using the series helper ────────────────────────────────────\n",
    "ame_df = format_me_table(ame)\n",
    "\n",
    "# ── Save CSV ────────────────────────────────────────────────────────────────\n",
    "csv_path = os.path.join(_outputs_tables, '01_ame_logit_mroz.csv')\n",
    "ame_df.to_csv(csv_path, index=False)\n",
    "print(f\"CSV table saved to:\\n  {csv_path}\")\n",
    "\n",
    "# ── Print LaTeX ─────────────────────────────────────────────────────────────\n",
    "print(\"\\nLaTeX version (copy into your paper):\")\n",
    "print(\"-\" * 65)\n",
    "try:\n",
    "    latex_str = ame_df.to_latex(\n",
    "        index=False,\n",
    "        caption=\"Average Marginal Effects — Pooled Logit, Mroz (1987)\",\n",
    "        label=\"tab:ame_logit_mroz\",\n",
    "        escape=True\n",
    "    )\n",
    "except TypeError:\n",
    "    # Older pandas may not support caption/label in to_latex\n",
    "    latex_str = ame_df.to_latex(index=False)\n",
    "print(latex_str)\n",
    "\n",
    "# ── Summary ─────────────────────────────────────────────────────────────────\n",
    "print(\"-\" * 65)\n",
    "print(\"Outputs written in this notebook:\")\n",
    "print(f\"  plots/01_me_varies_with_xb.png\")\n",
    "print(f\"  plots/01_ame_forest_plot.png\")\n",
    "print(f\"  tables/01_ame_logit_mroz.csv\")"
   ]
  }
 ]
}
