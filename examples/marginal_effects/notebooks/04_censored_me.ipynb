{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-01-title",
   "metadata": {},
   "source": [
    "# Marginal Effects in Censored and Selection Models\n",
    "\n",
    "**Series:** Marginal Effects Tutorial — Notebook 4 of 6  \n",
    "**Level:** Advanced  \n",
    "**Estimated time:** 75–90 minutes  \n",
    "**Prerequisites:** Notebook 01 (ME Fundamentals), familiarity with Tobit/Heckman theory\n",
    "\n",
    "---\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Models where the dependent variable is **limited** — either censored (Tobit) or only observed\n",
    "for a selected subsample (Heckman) — require careful treatment of marginal effects.\n",
    "There are multiple valid definitions, each answering a **different economic question**.\n",
    "\n",
    "### Three questions a researcher may ask\n",
    "\n",
    "1. \"How does x affect the **latent** outcome (e.g., *desired* labor supply)?\"\n",
    "2. \"How does x affect the **observed** outcome (including zeros)?\"\n",
    "3. \"How does x affect the outcome **conditional on being non-zero**?\"\n",
    "\n",
    "Each question leads to a different formula. This notebook covers all three for the Tobit model,\n",
    "the McDonald-Moffitt decomposition, and the direct/indirect decomposition for Heckman.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Three Types of Marginal Effects in Tobit](#section1)\n",
    "2. [McDonald-Moffitt Decomposition: Extensive vs Intensive Margin](#section2)\n",
    "3. [Heckman Selection Model — Direct and Indirect Effects](#section3)\n",
    "4. [When to Use Tobit vs Heckman?](#section4)\n",
    "5. [Key Takeaways](#takeaways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/guhaase/projetos/panelbox')\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.stats import norm\n",
    "\n",
    "# PanelBox imports\n",
    "from panelbox.models.censored.tobit import PooledTobit\n",
    "from panelbox.marginal_effects.censored_me import (\n",
    "    compute_tobit_ame,\n",
    "    compute_tobit_mem,\n",
    ")\n",
    "\n",
    "# Utility imports\n",
    "from utils.data_loaders import load_dataset\n",
    "from utils.me_helpers import plot_forest, format_me_table\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-section1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section1'></a>\n",
    "## Section 1: Three Types of Marginal Effects in Tobit\n",
    "\n",
    "### Tobit latent-variable setup\n",
    "\n",
    "$$Y^* = X\\beta + \\varepsilon, \\quad \\varepsilon \\sim N(0, \\sigma^2)$$\n",
    "$$Y = \\max(Y^*, 0) \\quad \\text{[left-censored at zero]}$$\n",
    "\n",
    "Let $z = X\\beta / \\sigma$. Then:\n",
    "\n",
    "| Type | Formula | Interpretation | Use when |\n",
    "|------|---------|----------------|----------|\n",
    "| **Type 1** — Latent ME | $\\partial E[Y^*\\|X]/\\partial x_k = \\beta_k$ | Effect if censoring were lifted | Structural/theoretical interest |\n",
    "| **Type 2** — Unconditional ME | $\\partial E[Y\\|X]/\\partial x_k = \\beta_k \\cdot \\Phi(z)$ | Population-average effect incl. zeros | Policy / welfare analysis |\n",
    "| **Type 3** — Conditional ME | $\\partial E[Y\\|Y>0,X]/\\partial x_k = \\beta_k \\cdot [1 - \\lambda(z)(z+\\lambda(z))]$ | Effect for participants only | Intensive-margin analysis |\n",
    "\n",
    "where $\\Phi$ is the standard normal CDF and $\\lambda(z) = \\phi(z)/\\Phi(z)$ is the inverse Mills ratio.\n",
    "\n",
    "> **Note:** $\\Phi(z) \\leq 1$, so the unconditional ME is always **smaller in absolute value** than the latent ME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mroz hours dataset\n",
    "df = load_dataset('mroz_hours')\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nHours worked distribution:\")\n",
    "print(f\"  % zero (not working): {(df['hours'] == 0).mean():.1%}\")\n",
    "print(f\"  Mean hours (all):     {df['hours'].mean():.1f}\")\n",
    "print(f\"  Mean hours (workers): {df.loc[df['hours'] > 0, 'hours'].mean():.1f}\")\n",
    "\n",
    "# Visualize censoring\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(df['hours'], bins=40, color='steelblue', alpha=0.75, edgecolor='white')\n",
    "axes[0].set_xlabel(\"Hours Worked per Year\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Full Distribution (including zeros)\")\n",
    "\n",
    "axes[1].hist(df.loc[df['hours'] > 0, 'hours'], bins=35,\n",
    "             color='tomato', alpha=0.75, edgecolor='white')\n",
    "axes[1].set_xlabel(\"Hours Worked per Year\")\n",
    "axes[1].set_title(\"Conditional on Working (hours > 0)\")\n",
    "\n",
    "plt.suptitle(\"Mroz (1987) — Hours Worked: Evidence of Left Censoring at Zero\",\n",
    "             fontsize=12, y=1.01)\n",
    "plt.tight_layout()\n",
    "\n",
    "import os\n",
    "os.makedirs('../outputs/plots', exist_ok=True)\n",
    "plt.savefig('../outputs/plots/04_hours_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"\\nPlot saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05-tobit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Pooled Tobit using arrays directly\n",
    "covariates = ['educ', 'age', 'kidslt6', 'kidsge6', 'nwifeinc']\n",
    "\n",
    "y = df['hours'].values\n",
    "X = np.column_stack([np.ones(len(df))] + [df[v].values for v in covariates])\n",
    "exog_names = ['const'] + covariates\n",
    "\n",
    "print(\"Fitting Pooled Tobit (left-censored at 0) ...\")\n",
    "print(f\"  Observations: {len(y)}\")\n",
    "print(f\"  Censored (hours=0): {(y == 0).sum()} ({(y == 0).mean():.1%})\")\n",
    "print(f\"  Covariates: {covariates}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    tobit = PooledTobit(\n",
    "        endog=y,\n",
    "        exog=X,\n",
    "        censoring_point=0,\n",
    "        censoring_type='left'\n",
    "    ).fit()\n",
    "\n",
    "    # Set variable names manually\n",
    "    tobit.exog_names = exog_names\n",
    "\n",
    "    # Display results\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Pooled Tobit Results\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Variable':<15} {'Coef.':<12} {'Std.Err.':<12} {'z':<8} {'P>|z|':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    from scipy.stats import norm as norm_dist\n",
    "    for i, name in enumerate(exog_names):\n",
    "        coef = tobit.beta[i]\n",
    "        se_val = tobit.bse[i] if hasattr(tobit, 'bse') and not np.isnan(tobit.bse[i]) else np.nan\n",
    "        if not np.isnan(se_val) and se_val > 0:\n",
    "            z_stat = coef / se_val\n",
    "            p_val = 2 * norm_dist.sf(abs(z_stat))\n",
    "            print(f\"  {name:<13} {coef:>10.4f} {se_val:>10.4f} {z_stat:>7.2f} {p_val:>7.4f}\")\n",
    "        else:\n",
    "            print(f\"  {name:<13} {coef:>10.4f} {'n/a':>10} {'n/a':>7} {'n/a':>7}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"  sigma (sigma_eps): {tobit.sigma:.4f}\")\n",
    "    print(f\"  Log-likelihood:    {tobit.llf:.3f}\")\n",
    "    print(f\"  Converged:         {tobit.converged}\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"Interpretation:\")\n",
    "    print(f\"  sigma = {tobit.sigma:.2f} is the std dev of the latent variable error term.\")\n",
    "    tobit_fitted = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Tobit estimation failed: {e}\")\n",
    "    tobit_fitted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-06-me-types",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tobit_fitted:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"THREE TYPES OF TOBIT MARGINAL EFFECTS (AME)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Type 1: Effect on latent variable (= beta)\n",
    "    latent_me = pd.Series(\n",
    "        {name: tobit.beta[i] for i, name in enumerate(exog_names)},\n",
    "        name='Latent ME (=beta)'\n",
    "    )\n",
    "\n",
    "    # Type 2: Unconditional ME = beta * Phi(z)\n",
    "    try:\n",
    "        ame_uncond = compute_tobit_ame(tobit, which='unconditional', varlist=covariates)\n",
    "        print(\"\\n--- Type 2: Unconditional ME (includes zeros) ---\")\n",
    "        print(ame_uncond.summary())\n",
    "        ame_uncond_ok = True\n",
    "    except Exception as e:\n",
    "        print(f\"Unconditional ME failed: {e}\")\n",
    "        ame_uncond_ok = False\n",
    "\n",
    "    # Type 3: Conditional ME = beta * [1 - lambda(z)(z + lambda(z))]\n",
    "    try:\n",
    "        ame_cond = compute_tobit_ame(tobit, which='conditional', varlist=covariates)\n",
    "        print(\"\\n--- Type 3: Conditional ME (given hours > 0) ---\")\n",
    "        print(ame_cond.summary())\n",
    "        ame_cond_ok = True\n",
    "    except Exception as e:\n",
    "        print(f\"Conditional ME failed: {e}\")\n",
    "        ame_cond_ok = False\n",
    "\n",
    "    # Probability ME = (beta/sigma) * phi(z)\n",
    "    try:\n",
    "        ame_prob = compute_tobit_ame(tobit, which='probability', varlist=covariates)\n",
    "        print(\"\\n--- Effect on P(working) [Probability ME] ---\")\n",
    "        print(ame_prob.summary())\n",
    "        ame_prob_ok = True\n",
    "    except Exception as e:\n",
    "        print(f\"Probability ME failed: {e}\")\n",
    "        ame_prob_ok = False\n",
    "\n",
    "else:\n",
    "    print(\"Skipping ME computation — Tobit did not converge.\")\n",
    "    ame_uncond_ok = ame_cond_ok = ame_prob_ok = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tobit_fitted and ame_uncond_ok and ame_cond_ok and ame_prob_ok:\n",
    "    # Build comparison table\n",
    "    comparison = pd.DataFrame({\n",
    "        'Latent (beta)':  [tobit.beta[exog_names.index(v)] for v in covariates],\n",
    "        'Unconditional':  [ame_uncond.marginal_effects[v] for v in covariates],\n",
    "        'Conditional':    [ame_cond.marginal_effects[v]   for v in covariates],\n",
    "        'P(working)':     [ame_prob.marginal_effects[v]   for v in covariates],\n",
    "    }, index=covariates)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ALL THREE TOBIT ME TYPES — SIDE-BY-SIDE COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    print(comparison.round(4).to_string())\n",
    "\n",
    "    print(\"\\nKey insights:\")\n",
    "    print(\"  - |Unconditional| < |Latent|: because Phi(z) <= 1\")\n",
    "    print(\"  - |Conditional| < |Latent|:  because [1-lambda(z+lambda)] <= 1\")\n",
    "    print(\"  - P(working) ME gives a probability, not hours\")\n",
    "\n",
    "    # Quick forest plot — unconditional AME\n",
    "    fig = plot_forest(\n",
    "        ame_uncond,\n",
    "        title=\"Tobit Unconditional AME — Effect on Hours Worked\",\n",
    "        figsize=(8, 5)\n",
    "    )\n",
    "    plt.savefig('../outputs/plots/04_tobit_ame_unconditional.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "elif tobit_fitted:\n",
    "    # Manual fallback comparison\n",
    "    print(\"Computing ME manually for comparison...\")\n",
    "    z_i = (X @ tobit.beta - 0) / tobit.sigma\n",
    "    Phi_z = norm.cdf(z_i)\n",
    "    phi_z = norm.pdf(z_i)\n",
    "    lambda_z = phi_z / np.where(Phi_z > 1e-10, Phi_z, 1e-10)\n",
    "\n",
    "    rows = []\n",
    "    for v in covariates:\n",
    "        idx = exog_names.index(v)\n",
    "        bk = tobit.beta[idx]\n",
    "        rows.append({\n",
    "            'Variable': v,\n",
    "            'Latent (beta)': bk,\n",
    "            'Unconditional': np.mean(bk * Phi_z),\n",
    "            'Conditional':   np.mean(bk * (1 - lambda_z * (z_i + lambda_z))),\n",
    "            'P(working)':    np.mean((bk / tobit.sigma) * phi_z),\n",
    "        })\n",
    "    comparison = pd.DataFrame(rows).set_index('Variable')\n",
    "    print(comparison.round(4).to_string())\n",
    "\n",
    "else:\n",
    "    print(\"Skipping comparison — model not fitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-mcdonald",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section2'></a>\n",
    "## Section 2: McDonald-Moffitt Decomposition\n",
    "\n",
    "**McDonald & Moffitt (1980)** showed that the **unconditional ME** (Type 2) can be decomposed into two economically meaningful components:\n",
    "\n",
    "$$\n",
    "\\underbrace{\\frac{\\partial E[Y|X]}{\\partial x_k}}_{\\text{Unconditional ME}}\n",
    "=\n",
    "\\underbrace{\\frac{\\partial P(Y>0|X)}{\\partial x_k} \\cdot E[Y|Y>0, X]}_{\\text{Extensive Margin}}\n",
    "+\n",
    "\\underbrace{P(Y>0|X) \\cdot \\frac{\\partial E[Y|Y>0,X]}{\\partial x_k}}_{\\text{Intensive Margin}}\n",
    "$$\n",
    "\n",
    "**Extensive margin:** effect of $x_k$ on the **probability of participation** times the\n",
    "conditional mean hours  \n",
    "**Intensive margin:** probability of participation times the effect on **hours given working**\n",
    "\n",
    "These two always sum to the unconditional ME.\n",
    "\n",
    "### Economic interpretation (labor supply)\n",
    "\n",
    "- **Education** likely increases both LFP probability (extensive) and conditional hours (intensive)\n",
    "- **Young children** mainly reduce LFP (extensive) more than reducing hours of those who already work (intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-09-mcdonald-computation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tobit_fitted:\n",
    "    # McDonald-Moffitt decomposition at sample means\n",
    "    # Compute z at every observation, then average\n",
    "    xb = X @ tobit.beta\n",
    "    z_all = (xb - 0) / tobit.sigma  # censoring point = 0\n",
    "\n",
    "    phi_z_all = norm.pdf(z_all)\n",
    "    Phi_z_all = norm.cdf(z_all)\n",
    "    # Safe inverse Mills ratio\n",
    "    lambda_z_all = np.where(\n",
    "        Phi_z_all > 1e-10,\n",
    "        phi_z_all / Phi_z_all,\n",
    "        -z_all  # asymptotic approximation for extreme negatives\n",
    "    )\n",
    "\n",
    "    # Conditional mean E[Y|Y>0, X] at each observation\n",
    "    cond_mean_all = xb + tobit.sigma * lambda_z_all\n",
    "\n",
    "    # Decomposition for each covariate\n",
    "    rows = []\n",
    "    for v in covariates:\n",
    "        idx = exog_names.index(v)\n",
    "        bk = tobit.beta[idx]\n",
    "        sigma = tobit.sigma\n",
    "\n",
    "        # Extensive margin: (beta_k/sigma) * phi(z) * E[Y|Y>0, X]\n",
    "        extensive_i = (bk / sigma) * phi_z_all * cond_mean_all\n",
    "\n",
    "        # Intensive margin: Phi(z) * beta_k * [1 - lambda(z)(z + lambda(z))]\n",
    "        intensive_i = Phi_z_all * bk * (1 - lambda_z_all * (z_all + lambda_z_all))\n",
    "\n",
    "        # AME versions (average over sample)\n",
    "        ext_ame = np.mean(extensive_i)\n",
    "        int_ame = np.mean(intensive_i)\n",
    "        total_ame = ext_ame + int_ame\n",
    "\n",
    "        # Verify against compute_tobit_ame if available\n",
    "        if ame_uncond_ok:\n",
    "            verify = ame_uncond.marginal_effects[v]\n",
    "        else:\n",
    "            verify = np.nan\n",
    "\n",
    "        rows.append({\n",
    "            'Variable': v,\n",
    "            'Extensive Margin': ext_ame,\n",
    "            'Intensive Margin': int_ame,\n",
    "            'Total (McDonald-Moffitt)': total_ame,\n",
    "            'Unconditional ME (verify)': verify,\n",
    "        })\n",
    "\n",
    "    decomp = pd.DataFrame(rows).set_index('Variable')\n",
    "    print(\"=\" * 75)\n",
    "    print(\"McDonald-Moffitt Decomposition (AME version)\")\n",
    "    print(\"=\" * 75)\n",
    "    print(decomp.round(4).to_string())\n",
    "    print()\n",
    "    print(\"Check: Total should match Unconditional ME (within numerical precision).\")\n",
    "\n",
    "    # Store for later cells\n",
    "    extensive_series = pd.Series({r['Variable']: r['Extensive Margin'] for r in rows})\n",
    "    intensive_series = pd.Series({r['Variable']: r['Intensive Margin'] for r in rows})\n",
    "    total_series     = pd.Series({r['Variable']: r['Total (McDonald-Moffitt)'] for r in rows})\n",
    "\n",
    "    mcdonald_ok = True\n",
    "else:\n",
    "    print(\"Skipping McDonald-Moffitt — Tobit not fitted.\")\n",
    "    mcdonald_ok = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10-stacked-bar",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mcdonald_ok:\n",
    "    # Only plot variables with meaningful total ME\n",
    "    vars_plot = [v for v in covariates if abs(float(total_series[v])) > 0.1]\n",
    "    if not vars_plot:\n",
    "        vars_plot = covariates  # fallback: show all\n",
    "\n",
    "    x_pos = np.arange(len(vars_plot))\n",
    "    bars_ext = [float(extensive_series[v]) for v in vars_plot]\n",
    "    bars_int = [float(intensive_series[v]) for v in vars_plot]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "    # Stacked bars — handle negative values\n",
    "    pos_ext = np.maximum(bars_ext, 0)\n",
    "    neg_ext = np.minimum(bars_ext, 0)\n",
    "    pos_int = np.maximum(bars_int, 0)\n",
    "    neg_int = np.minimum(bars_int, 0)\n",
    "\n",
    "    ax.bar(x_pos, bars_ext, label='Extensive Margin', color='steelblue', alpha=0.85)\n",
    "    ax.bar(x_pos, bars_int, bottom=bars_ext, label='Intensive Margin', color='tomato', alpha=0.85)\n",
    "\n",
    "    # Add total labels\n",
    "    for i, v in enumerate(vars_plot):\n",
    "        total_val = float(total_series[v])\n",
    "        ax.text(i, total_val + (5 if total_val >= 0 else -15),\n",
    "                f'{total_val:.1f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "    ax.axhline(0, color='black', lw=0.8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(vars_plot, rotation=15, ha='right')\n",
    "    ax.set_ylabel(\"Marginal Effect on Hours Worked\")\n",
    "    ax.set_title(\n",
    "        \"McDonald-Moffitt Decomposition: Extensive vs Intensive Margin\\n\"\n",
    "        \"Tobit Model — Women's Labor Supply (Mroz 1987)\"\n",
    "    )\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../outputs/plots/04_mcdonald_moffitt_decomposition.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Plot saved.\")\n",
    "else:\n",
    "    print(\"Skipping plot — decomposition not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11-heckman",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section3'></a>\n",
    "## Section 3: Heckman Selection Model — Direct and Indirect Effects\n",
    "\n",
    "### The sample selection problem\n",
    "\n",
    "Heckman (1979) two-equation model:\n",
    "\n",
    "$$\n",
    "\\text{Selection: } D = \\mathbf{1}[Z\\gamma + u > 0] \\quad (\\text{observe }Y\\text{ only if }D=1)\n",
    "$$\n",
    "$$\n",
    "\\text{Outcome: } Y = X\\beta + \\varepsilon \\quad (\\text{only if }D=1)\n",
    "$$\n",
    "$$\n",
    "\\text{Corr}(u,\\varepsilon) = \\rho \\neq 0 \\quad (\\text{selection endogeneity})\n",
    "$$\n",
    "\n",
    "Two-stage correction using Inverse Mills Ratio (IMR):\n",
    "\n",
    "$$\n",
    "E[Y|D=1, X] = X\\beta + \\underbrace{\\rho\\sigma_\\varepsilon}_{\\delta} \\cdot \\lambda(Z\\gamma)\n",
    "$$\n",
    "\n",
    "where $\\lambda(Z\\gamma) = \\phi(Z\\gamma)/\\Phi(Z\\gamma)$ is the IMR.\n",
    "\n",
    "### Decomposition of ME\n",
    "\n",
    "For $x_k$ that appears in both $X$ and $Z$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E[Y|D=1,X]}{\\partial x_k}\n",
    "= \\underbrace{\\beta_k}_{\\text{Direct}}\n",
    "+ \\underbrace{\\delta \\cdot \\frac{\\partial \\lambda(Z\\gamma)}{\\partial x_k}}_{\\text{Indirect (selection)}}\n",
    "$$\n",
    "\n",
    "### Exclusion restriction\n",
    "\n",
    "For identification, $Z$ must contain at least one variable **not in** $X$.  \n",
    "Example: young children affect LFP (selection) but not the wage conditional on working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12-heckman-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt Heckman estimation — wrapped in try/except\n",
    "heckman_fitted = False\n",
    "heckman_result = None\n",
    "\n",
    "try:\n",
    "    from panelbox.models.selection.heckman import PanelHeckman\n",
    "\n",
    "    df_heck = load_dataset('mroz')\n",
    "    print(f\"Mroz dataset shape: {df_heck.shape}\")\n",
    "    print(f\"Columns: {list(df_heck.columns)}\")\n",
    "\n",
    "    # Selection equation: LFP ~ educ + age + kidslt6 + kidsge6 + nwifeinc\n",
    "    # Outcome equation:   log(wage) ~ educ + exper + expersq\n",
    "    # Exclusion variables: kidslt6, kidsge6, nwifeinc (selection only)\n",
    "\n",
    "    sel_covs = ['educ', 'age', 'kidslt6', 'kidsge6', 'nwifeinc']\n",
    "    out_covs  = ['educ', 'exper', 'expersq']\n",
    "\n",
    "    D = df_heck['inlf'].values  # selection indicator\n",
    "\n",
    "    # Outcome variable: log wage (only observed for D=1)\n",
    "    wage_col = 'wage'\n",
    "    df_heck['log_wage'] = np.where(df_heck[wage_col] > 0,\n",
    "                                    np.log(df_heck[wage_col].clip(lower=0.01)),\n",
    "                                    np.nan)\n",
    "    y_out = df_heck['log_wage'].values\n",
    "\n",
    "    # Build design matrices\n",
    "    X_sel = np.column_stack([np.ones(len(df_heck))] + [df_heck[v].values for v in sel_covs])\n",
    "    X_out = np.column_stack([np.ones(len(df_heck))] + [df_heck[v].values for v in out_covs])\n",
    "\n",
    "    heckman = PanelHeckman(\n",
    "        endog=y_out,\n",
    "        exog=X_out,\n",
    "        selection=D,\n",
    "        exog_selection=X_sel\n",
    "    ).fit()\n",
    "\n",
    "    heckman_result = heckman\n",
    "    heckman_fitted = True\n",
    "\n",
    "    print(\"\\nHeckman estimation successful.\")\n",
    "\n",
    "    # Display key attributes\n",
    "    if hasattr(heckman, 'params'):\n",
    "        print(f\"\\nOutcome equation parameters: {heckman.params}\")\n",
    "    if hasattr(heckman, 'imr_coef'):\n",
    "        print(f\"IMR coefficient (delta = rho*sigma_eps): {heckman.imr_coef:.4f}\")\n",
    "    if hasattr(heckman, 'rho'):\n",
    "        print(f\"Selection correlation (rho):              {heckman.rho:.4f}\")\n",
    "\n",
    "    if hasattr(heckman, 'summary'):\n",
    "        try:\n",
    "            print(\"\\n\" + str(heckman.summary()))\n",
    "        except Exception as se:\n",
    "            print(f\"(summary() not available: {se})\")\n",
    "\n",
    "except ImportError as ie:\n",
    "    print(f\"PanelHeckman import failed: {ie}\")\n",
    "    print(\"Proceeding with manual two-step Heckman for demonstration.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Heckman estimation failed: {e}\")\n",
    "    print(\"Proceeding with manual two-step Heckman for demonstration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-heckman-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual two-step Heckman (always runs as fallback or demonstration)\n",
    "print(\"=\" * 60)\n",
    "print(\"Manual Two-Step Heckman Estimator\")\n",
    "print(\"(for pedagogical clarity and as fallback)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    df_h = load_dataset('mroz')\n",
    "    df_h['log_wage'] = np.where(df_h['wage'] > 0,\n",
    "                                 np.log(df_h['wage'].clip(lower=0.01)),\n",
    "                                 np.nan)\n",
    "\n",
    "    sel_vars  = ['educ', 'age', 'kidslt6', 'kidsge6', 'nwifeinc']\n",
    "    out_vars  = ['educ', 'exper', 'expersq']\n",
    "    D_h       = df_h['inlf'].values\n",
    "\n",
    "    # ---- Step 1: Probit on full sample -----------------------------------\n",
    "    from scipy.optimize import minimize\n",
    "    from scipy.stats import norm as norm_dist\n",
    "\n",
    "    X_sel_h = np.column_stack([np.ones(len(df_h))] + [df_h[v].values for v in sel_vars])\n",
    "    sel_names = ['const'] + sel_vars\n",
    "\n",
    "    def neg_ll_probit(gamma):\n",
    "        xg = X_sel_h @ gamma\n",
    "        ll = D_h * norm_dist.logcdf(xg) + (1 - D_h) * norm_dist.logcdf(-xg)\n",
    "        return -ll.sum()\n",
    "\n",
    "    gamma0 = np.zeros(X_sel_h.shape[1])\n",
    "    res_probit = minimize(neg_ll_probit, gamma0, method='BFGS',\n",
    "                          options={'maxiter': 2000, 'disp': False})\n",
    "    gamma_hat = res_probit.x\n",
    "\n",
    "    # ---- Step 2: Compute IMR and OLS on selected sample -----------------\n",
    "    xg_hat = X_sel_h @ gamma_hat\n",
    "    phi_xg  = norm_dist.pdf(xg_hat)\n",
    "    Phi_xg  = norm_dist.cdf(xg_hat)\n",
    "    imr     = np.where(Phi_xg > 1e-10, phi_xg / Phi_xg, -xg_hat)\n",
    "\n",
    "    # Keep only selected observations (D=1)\n",
    "    sel_mask = D_h == 1\n",
    "    df_sel = df_h[sel_mask].copy()\n",
    "    imr_sel = imr[sel_mask]\n",
    "\n",
    "    X_out_h = np.column_stack(\n",
    "        [np.ones(sel_mask.sum())] + [df_sel[v].values for v in out_vars] + [imr_sel]\n",
    "    )\n",
    "    out_names = ['const'] + out_vars + ['IMR']\n",
    "    y_sel = df_sel['log_wage'].values\n",
    "\n",
    "    # OLS: beta = (X'X)^{-1} X'y\n",
    "    beta_heck = np.linalg.lstsq(X_out_h, y_sel, rcond=None)[0]\n",
    "    fitted_h  = X_out_h @ beta_heck\n",
    "    resid_h   = y_sel - fitted_h\n",
    "    sigma_h   = np.std(resid_h)\n",
    "    imr_coef  = beta_heck[-1]  # coefficient on IMR = delta = rho * sigma_eps\n",
    "\n",
    "    print(\"\\nStep 1 — Probit (selection equation):\")\n",
    "    for i, name in enumerate(sel_names):\n",
    "        print(f\"  {name:<15} gamma = {gamma_hat[i]:>8.4f}\")\n",
    "\n",
    "    print(f\"\\nStep 2 — OLS on selected sample (N={sel_mask.sum()}):\")\n",
    "    for i, name in enumerate(out_names):\n",
    "        print(f\"  {name:<15} beta  = {beta_heck[i]:>8.4f}\")\n",
    "\n",
    "    print(f\"\\nIMR coefficient (delta = rho * sigma):  {imr_coef:.4f}\")\n",
    "    rho_approx = imr_coef / sigma_h if sigma_h > 0 else np.nan\n",
    "    print(f\"Approx. selection correlation (rho):    {rho_approx:.4f}\")\n",
    "\n",
    "    if abs(imr_coef) > 0.05:\n",
    "        print(\"\\nIMR coef is non-negligible → selection bias present → Heckman preferred.\")\n",
    "    else:\n",
    "        print(\"\\nIMR coef is close to zero → weak selection → OLS may be adequate.\")\n",
    "\n",
    "    heckman_manual_ok = True\n",
    "\n",
    "    # Store for ME decomposition\n",
    "    heckman_gamma   = gamma_hat\n",
    "    heckman_beta    = beta_heck[:-1]   # excluding IMR\n",
    "    heckman_delta   = imr_coef\n",
    "    heckman_out_names = ['const'] + out_vars\n",
    "    heckman_sel_names = ['const'] + sel_vars\n",
    "    X_sel_full       = X_sel_h\n",
    "    xg_full          = xg_hat\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Manual Heckman failed: {e}\")\n",
    "    heckman_manual_ok = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14-heckman-decomp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heckman ME decomposition: Direct + Indirect\n",
    "if heckman_manual_ok:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Heckman ME Decomposition\")\n",
    "    print(\"Direct:   partial E[Y|D=1,X]/partial x_k = beta_k\")\n",
    "    print(\"Indirect: delta * partial lambda(Zg)/partial x_k\")\n",
    "    print(\"Total:    Direct + Indirect\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # d/dz [lambda(z)] = -lambda(z)*(z + lambda(z))\n",
    "    phi_xg_full  = norm.pdf(xg_full)\n",
    "    Phi_xg_full  = norm.cdf(xg_full)\n",
    "    lambda_full  = np.where(Phi_xg_full > 1e-10,\n",
    "                            phi_xg_full / Phi_xg_full,\n",
    "                            -xg_full)\n",
    "    dlambda_dz   = -lambda_full * (xg_full + lambda_full)  # d lambda/dz\n",
    "\n",
    "    # Variables that appear in BOTH selection and outcome\n",
    "    common_vars = [v for v in out_vars if v in sel_vars]\n",
    "    outcome_only = [v for v in out_vars if v not in sel_vars]\n",
    "\n",
    "    rows_heck = []\n",
    "    for v in out_vars:\n",
    "        out_idx = heckman_out_names.index(v) if v in heckman_out_names else None\n",
    "        sel_idx = heckman_sel_names.index(v) if v in heckman_sel_names else None\n",
    "\n",
    "        direct = heckman_beta[out_idx] if out_idx is not None else 0.0\n",
    "\n",
    "        if sel_idx is not None:\n",
    "            # AME version of indirect effect\n",
    "            gamma_k = heckman_gamma[sel_idx]\n",
    "            indirect = heckman_delta * np.mean(gamma_k * dlambda_dz)\n",
    "        else:\n",
    "            indirect = 0.0  # variable not in selection equation\n",
    "\n",
    "        rows_heck.append({\n",
    "            'Variable': v,\n",
    "            'Direct ME (beta_k)': direct,\n",
    "            'Indirect ME (selection)': indirect,\n",
    "            'Total ME': direct + indirect,\n",
    "            'Note': 'Both eqs' if sel_idx is not None else 'Outcome only'\n",
    "        })\n",
    "\n",
    "    decomp_heck = pd.DataFrame(rows_heck).set_index('Variable')\n",
    "    print()\n",
    "    print(decomp_heck.to_string())\n",
    "    print()\n",
    "    print(\"Note: Indirect ME is non-zero only for variables that appear\")\n",
    "    print(\"      in the selection equation.\")\n",
    "\n",
    "    heckman_decomp_ok = True\n",
    "    heckman_rows = rows_heck\n",
    "\n",
    "else:\n",
    "    print(\"Heckman decomposition not available.\")\n",
    "    heckman_decomp_ok = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15-heckman-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked bar: Direct + Indirect = Total\n",
    "if heckman_decomp_ok:\n",
    "    vars_h     = [r['Variable'] for r in heckman_rows]\n",
    "    direct_v   = [r['Direct ME (beta_k)']        for r in heckman_rows]\n",
    "    indirect_v = [r['Indirect ME (selection)']    for r in heckman_rows]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    x = np.arange(len(vars_h))\n",
    "\n",
    "    ax.bar(x, direct_v, label='Direct Effect ($\\\\beta_k$)',\n",
    "           color='steelblue', alpha=0.85)\n",
    "    ax.bar(x, indirect_v, bottom=direct_v,\n",
    "           label='Indirect / Selection Effect ($\\\\delta \\\\cdot \\\\partial\\\\lambda/\\\\partial x$)',\n",
    "           color='sandybrown', alpha=0.85)\n",
    "\n",
    "    # Total label\n",
    "    for i, r in enumerate(heckman_rows):\n",
    "        total_val = r['Total ME']\n",
    "        ax.text(i, total_val + 0.002,\n",
    "                f'{total_val:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "    ax.axhline(0, color='black', lw=0.8)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(vars_h, rotation=15, ha='right')\n",
    "    ax.set_ylabel(\"Marginal Effect on log(Wage)\")\n",
    "    ax.set_title(\n",
    "        \"Heckman ME Decomposition: Direct vs Selection Effect\\n\"\n",
    "        \"Wages conditional on LFP=1 — Mroz (1987)\"\n",
    "    )\n",
    "    ax.legend(fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../outputs/plots/04_heckman_decomposition.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Plot saved.\")\n",
    "else:\n",
    "    print(\"Skipping Heckman plot — decomposition not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16-tobit-vs-heckman",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section4'></a>\n",
    "## Section 4: When to Use Tobit vs Heckman?\n",
    "\n",
    "Both models address limited dependent variables, but the underlying economic situations differ:\n",
    "\n",
    "| Situation | Model | Key Assumption |\n",
    "|-----------|-------|----------------|\n",
    "| **Corner solution**: person actively chooses $Y=0$ (e.g., zero charitable giving; does not want to give) | **Tobit** | $Y^*$ (latent desired amount) exists for *all* individuals |\n",
    "| **Sample selection**: $Y$ is unobserved for non-participants (e.g., wage unobserved for non-workers) | **Heckman** | Selection process is *separate* from outcome process |\n",
    "\n",
    "### Decision rule\n",
    "\n",
    "> Ask: \"Does a person with $Y=0$ have a 'desired $Y$'?\"\n",
    "> - **Yes** (they chose zero) $\\Rightarrow$ **Tobit**\n",
    "> - **No** (they are simply excluded from observation) $\\Rightarrow$ **Heckman**\n",
    "\n",
    "### Empirical test\n",
    "\n",
    "If the IMR coefficient $\\delta$ is **significantly different from zero** $\\Rightarrow$ selection bias is present; use Heckman.  \n",
    "If $\\delta \\approx 0$ $\\Rightarrow$ no selection bias; Tobit or OLS may suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TOBIT vs HECKMAN: Summary Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if tobit_fitted:\n",
    "    print(f\"\\nTobit (Corner Solution):\")\n",
    "    print(f\"  Example dataset: Mroz hours worked\")\n",
    "    print(f\"  % censored at zero: {(df['hours'] == 0).mean():.1%}\")\n",
    "    print(f\"  Sigma (latent error): {tobit.sigma:.2f}\")\n",
    "\n",
    "    if mcdonald_ok:\n",
    "        educ_ext = float(extensive_series['educ'])\n",
    "        educ_int = float(intensive_series['educ'])\n",
    "        educ_tot = float(total_series['educ'])\n",
    "        if abs(educ_tot) > 1e-6:\n",
    "            print(f\"\\n  McDonald-Moffitt for 'educ':\")\n",
    "            print(f\"    Extensive margin: {educ_ext:.2f} \"\n",
    "                  f\"({100*educ_ext/educ_tot:.0f}% of total)\")\n",
    "            print(f\"    Intensive margin: {educ_int:.2f} \"\n",
    "                  f\"({100*educ_int/educ_tot:.0f}% of total)\")\n",
    "            print(f\"    Total:            {educ_tot:.2f}\")\n",
    "\n",
    "if heckman_manual_ok:\n",
    "    print(f\"\\nHeckman (Sample Selection):\")\n",
    "    print(f\"  Example dataset: Mroz wages (observed only for LFP=1)\")\n",
    "    print(f\"  IMR coefficient (delta): {heckman_delta:.4f}\")\n",
    "    print(f\"  Approx. rho:             {rho_approx:.4f}\")\n",
    "\n",
    "    # IMR significance test\n",
    "    print(f\"\\n  IMR significance test:\")\n",
    "    resid_std = np.std(y_sel - X_out_h @ beta_heck)\n",
    "\n",
    "    # Approximate SE for IMR coefficient via OLS vcov\n",
    "    try:\n",
    "        XtX_inv = np.linalg.inv(X_out_h.T @ X_out_h)\n",
    "        se_full  = np.sqrt(np.diag(XtX_inv) * resid_std ** 2)\n",
    "        se_imr   = se_full[-1]  # SE for IMR coefficient\n",
    "        t_imr    = heckman_delta / se_imr\n",
    "        p_imr    = 2 * (1 - norm.cdf(abs(t_imr)))\n",
    "        print(f\"    delta = {heckman_delta:.4f}\")\n",
    "        print(f\"    SE    = {se_imr:.4f}\")\n",
    "        print(f\"    t     = {t_imr:.2f}\")\n",
    "        print(f\"    p     = {p_imr:.4f}\")\n",
    "        if p_imr < 0.05:\n",
    "            print(f\"    --> Selection bias is statistically significant (p<0.05).\")\n",
    "            print(f\"        Heckman correction recommended over OLS.\")\n",
    "        else:\n",
    "            print(f\"    --> Selection bias is not significant (p>0.05).\")\n",
    "            print(f\"        OLS may be adequate here.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    (Cannot compute SE: {e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18-takeaways",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='takeaways'></a>\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Tobit Type 1** (latent ME = $\\beta$): answers the question \"what would happen if censoring were lifted?\"\n",
    "\n",
    "2. **Tobit Type 2** (unconditional = $\\beta \\cdot \\Phi(z)$): the population-average effect including\n",
    "   all observations — the right measure for **policy analysis**.\n",
    "\n",
    "3. **Tobit Type 3** (conditional = $\\beta \\cdot [1 - \\lambda(z+\\lambda)]$): effect for non-censored\n",
    "   observations — use for **intensive-margin analysis**.\n",
    "\n",
    "4. **McDonald-Moffitt decomposition**: unconditional ME = extensive margin + intensive margin.\n",
    "   Reveals *where* a variable's effect operates (participation decision vs amount decision).\n",
    "\n",
    "5. **Heckman ME**: total = direct ($\\beta_k$) + indirect (selection through IMR).  \n",
    "   The indirect component is **non-zero only when** the covariate also appears in the selection equation.\n",
    "\n",
    "6. **Tobit vs Heckman**: choose based on **economic theory**, not just statistics:\n",
    "   - Corner solution (agent actively chooses zero) → **Tobit**  \n",
    "   - Sample selection (outcome not observed for non-participants) → **Heckman**\n",
    "   - Test: IMR significance ($\\delta \\neq 0$) supports Heckman.\n",
    "\n",
    "---\n",
    "\n",
    "**Next notebook (05):** Interaction effects in nonlinear models require computing cross-partial derivatives.\n",
    "A common error is to simply interpret the interaction coefficient — this is incorrect for probit, logit,\n",
    "Tobit and other nonlinear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "import os\n",
    "os.makedirs('../outputs/tables', exist_ok=True)\n",
    "\n",
    "saved = []\n",
    "\n",
    "# Tobit AME tables\n",
    "if tobit_fitted and ame_uncond_ok:\n",
    "    try:\n",
    "        tbl = format_me_table(ame_uncond)\n",
    "        tbl.to_csv('../outputs/tables/04_tobit_ame_unconditional.csv', index=False)\n",
    "        saved.append('04_tobit_ame_unconditional.csv')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save unconditional AME table: {e}\")\n",
    "\n",
    "if tobit_fitted and ame_cond_ok:\n",
    "    try:\n",
    "        tbl = format_me_table(ame_cond)\n",
    "        tbl.to_csv('../outputs/tables/04_tobit_ame_conditional.csv', index=False)\n",
    "        saved.append('04_tobit_ame_conditional.csv')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save conditional AME table: {e}\")\n",
    "\n",
    "# McDonald-Moffitt decomposition\n",
    "if mcdonald_ok:\n",
    "    try:\n",
    "        decomp.to_csv('../outputs/tables/04_mcdonald_moffitt.csv')\n",
    "        saved.append('04_mcdonald_moffitt.csv')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save McDonald-Moffitt table: {e}\")\n",
    "\n",
    "# Heckman decomposition\n",
    "if heckman_decomp_ok:\n",
    "    try:\n",
    "        decomp_heck.to_csv('../outputs/tables/04_heckman_decomposition.csv')\n",
    "        saved.append('04_heckman_decomposition.csv')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save Heckman decomposition: {e}\")\n",
    "\n",
    "if saved:\n",
    "    print(\"Files saved to ../outputs/tables/:\")\n",
    "    for f in saved:\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    print(\"No tables saved (models may not have converged).\")\n",
    "\n",
    "print(\"\\nNotebook 04 complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
