{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Automated Report Generation with PanelBox\n",
    "\n",
    "In many real-world workflows, we need to:\n",
    "- Produce **consistent, reproducible** analysis reports\n",
    "- Share results with **non-technical stakeholders** (HTML)\n",
    "- Submit results to **academic journals** (LaTeX)\n",
    "- **Automate** monthly/weekly analyses without manual effort\n",
    "\n",
    "PanelBox's `ReportManager` integrates model results, charts, and validation tests\n",
    "into professional reports with a single function call.\n",
    "\n",
    "**Topics:**\n",
    "1. ReportManager architecture\n",
    "2. Single-model validation report (HTML)\n",
    "3. Multi-model comparison report (HTML)\n",
    "4. Full diagnostic report (charts + tests)\n",
    "5. Template customization (Jinja2)\n",
    "6. LaTeX and Markdown export\n",
    "7. Complete automated pipeline\n",
    "\n",
    "**Prerequisites:** Notebooks 01–03; Tutorial 03 and 06  \n",
    "**Duration:** ~180–200 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../../../')  # make panelbox importable\n",
    "sys.path.insert(0, '../')       # make utils importable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# PanelBox models\n",
    "from panelbox.models.static import PooledOLS, FixedEffects, RandomEffects\n",
    "\n",
    "# Visualization API\n",
    "from panelbox.visualization.api import create_residual_diagnostics, create_comparison_charts\n",
    "\n",
    "# Report system\n",
    "from panelbox.report import ReportManager\n",
    "from panelbox.report.validation_transformer import ValidationTransformer\n",
    "from panelbox.validation import ValidationReport\n",
    "from panelbox.report.exporters.latex_exporter import LaTeXExporter\n",
    "from panelbox.report.exporters.markdown_exporter import MarkdownExporter\n",
    "\n",
    "# Local data generators\n",
    "from utils.data_generators import generate_panel_data, generate_heteroskedastic_panel\n",
    "\n",
    "# Output directories\n",
    "os.makedirs('../outputs/charts/png', exist_ok=True)\n",
    "os.makedirs('../outputs/charts/pdf', exist_ok=True)\n",
    "os.makedirs('../outputs/reports/html', exist_ok=True)\n",
    "os.makedirs('../outputs/reports/latex', exist_ok=True)\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. ReportManager Architecture\n",
    "\n",
    "The PanelBox report system has three layers:\n",
    "\n",
    "```\n",
    "ReportManager (orchestrator)\n",
    "│\n",
    "├── TemplateManager — loads Jinja2 templates from panelbox/templates/\n",
    "├── AssetManager   — collects CSS/JS assets; inlines or links them\n",
    "└── CSSManager     — compiles and optionally minifies stylesheets\n",
    "```\n",
    "\n",
    "**Report types:**\n",
    "- `'validation'` → uses `templates/validation/interactive/index.html`\n",
    "- `'residuals'` → uses `templates/residuals/interactive/index.html`\n",
    "- `'comparison'` → uses `templates/comparison/interactive/index.html`\n",
    "- `'master'`     → uses `templates/master/index.html` (multi-section)\n",
    "\n",
    "**Convenience methods:**\n",
    "```python\n",
    "report_mgr = ReportManager()\n",
    "\n",
    "html = report_mgr.generate_validation_report(validation_data, title='...')\n",
    "html = report_mgr.generate_comparison_report(comparison_data, title='...')\n",
    "html = report_mgr.generate_residual_report(residual_data, title='...')\n",
    "\n",
    "report_mgr.save_report(html, '../outputs/reports/html/report.html')\n",
    "```\n",
    "\n",
    "Data preparation uses transformer classes:\n",
    "```python\n",
    "from panelbox.report.validation_transformer import ValidationTransformer\n",
    "val_data = ValidationTransformer(validation_report).transform()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect ReportManager — list available methods\n",
    "import inspect\n",
    "\n",
    "report_mgr = ReportManager()\n",
    "\n",
    "print('=== ReportManager public methods ===')\n",
    "for name, method in inspect.getmembers(report_mgr, predicate=inspect.ismethod):\n",
    "    if not name.startswith('_'):\n",
    "        sig = inspect.signature(method)\n",
    "        print(f'  {name}{sig}')\n",
    "\n",
    "# Inspect available templates\n",
    "import panelbox\n",
    "templates_dir = os.path.join(os.path.dirname(panelbox.__file__), 'templates')\n",
    "print(f'\\n=== Templates directory: {templates_dir} ===')\n",
    "for root, dirs, files in os.walk(templates_dir):\n",
    "    for fname in sorted(files):\n",
    "        rel = os.path.relpath(os.path.join(root, fname), templates_dir)\n",
    "        print(f'  • {rel}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Single-Model Validation Report\n",
    "\n",
    "The most common use case: estimate one model, prepare validation data,\n",
    "and produce a self-contained HTML report.\n",
    "\n",
    "The report includes:\n",
    "- Model summary (coefficients, standard errors, p-values, R²)\n",
    "- Validation test results\n",
    "- Residual diagnostic charts\n",
    "- Recommendations based on test outcomes\n",
    "\n",
    "**Workflow:**\n",
    "1. Estimate model → `results`\n",
    "2. Create `ValidationReport` (or use `results.validate()`)\n",
    "3. Transform via `ValidationTransformer(val_report).transform()`\n",
    "4. Pass to `report_mgr.generate_validation_report(val_data, ...)`\n",
    "5. Save with `report_mgr.save_report(html, path)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate data and estimate Fixed Effects model ---\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Panel: 40 entities, 15 periods (600 obs)\n",
    "n_ent, n_per = 40, 15\n",
    "entities = np.repeat(np.arange(1, n_ent + 1), n_per)\n",
    "periods  = np.tile(np.arange(1, n_per + 1), n_ent)\n",
    "alpha    = np.repeat(rng.normal(0, 1, n_ent), n_per)  # entity fixed effects\n",
    "x1 = rng.normal(0, 1, n_ent * n_per)\n",
    "x2 = rng.normal(0, 1, n_ent * n_per)\n",
    "y  = alpha + 1.5 * x1 - 0.8 * x2 + rng.normal(0, 1, n_ent * n_per)\n",
    "\n",
    "df = pd.DataFrame({'entity': entities, 'time': periods,\n",
    "                   'x1': x1, 'x2': x2, 'y': y})\n",
    "\n",
    "# Estimate Fixed Effects\n",
    "model_fe = FixedEffects(\n",
    "    formula='y ~ x1 + x2',\n",
    "    data=df,\n",
    "    entity_col='entity',\n",
    "    time_col='time',\n",
    "    entity_effects=True,\n",
    ")\n",
    "results_fe = model_fe.fit()\n",
    "\n",
    "print('Fixed Effects Model estimated.')\n",
    "print(f'Coefficients:\\n{results_fe.params}')\n",
    "print(f'R²: {results_fe.rsquared:.4f}')\n",
    "print(f'N:  {results_fe.nobs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# --- Run validation tests and transform to template data ---\n\n# Use results.validate() to run actual statistical tests\nval_report = results_fe.validate(tests='all', verbose=True)\n\n# Show the validation summary\nprint(val_report.summary(verbose=False))\n\n# Transform to template-ready dict\ntransformer = ValidationTransformer(val_report)\nval_data = transformer.transform(include_charts=True)\n\nprint('\\nValidation data keys:', list(val_data.keys()))\nprint('Summary keys:', list(val_data.get('summary', {}).keys()))\nprint(f\"Total tests: {val_data['summary']['total_tests']}\")\nprint(f\"Pass rate:   {val_data['summary']['pass_rate_formatted']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# --- Generate Single-Model HTML Report ---\n\nhtml_validation = report_mgr.generate_validation_report(\n    validation_data=val_data,\n    title='Fixed Effects Model — Validation Report',\n    subtitle='Simulated Panel Data (40 entities × 15 periods)',\n    interactive=True,\n)\n\n# Save report\noutput_path = '../outputs/reports/html/04_single_model_report.html'\nreport_mgr.save_report(html_validation, output_path, overwrite=True)\n\nprint(f'Report saved: {output_path}')\nprint(f'File size:    {os.path.getsize(output_path) / 1024:.1f} KB')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display report preview in notebook\n",
    "from IPython.display import IFrame, display, HTML\n",
    "\n",
    "display(HTML('<p><strong>Report preview (scroll to see all sections):</strong></p>'))\n",
    "try:\n",
    "    display(IFrame(src='../outputs/reports/html/04_single_model_report.html',\n",
    "                   width='100%', height=500))\n",
    "except Exception:\n",
    "    display(HTML(f'<a href=\"../outputs/reports/html/04_single_model_report.html\" target=\"_blank\">'\n",
    "                 f'Open report in new tab</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Multi-Model Comparison Report\n",
    "\n",
    "When selecting the best specification, comparing multiple models in a single report\n",
    "is more effective than switching between separate outputs.\n",
    "\n",
    "The comparison report includes:\n",
    "- Coefficient comparison chart (side-by-side bars)\n",
    "- Model fit comparison (R², within-R², adjusted R²)\n",
    "- Information criteria (AIC, BIC) comparison\n",
    "- Navigation tabs per model\n",
    "\n",
    "**Workflow:**\n",
    "1. Estimate multiple models\n",
    "2. `create_comparison_charts(results_list, names, theme)` → charts dict\n",
    "3. Build `comparison_data = {'comparison_charts': charts, 'models_info': [...], ...}`\n",
    "4. `report_mgr.generate_comparison_report(comparison_data, title='...')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Estimate OLS, FE, RE on the same dataset ---\n",
    "\n",
    "model_ols = PooledOLS(\n",
    "    formula='y ~ x1 + x2',\n",
    "    data=df,\n",
    "    entity_col='entity',\n",
    "    time_col='time',\n",
    ")\n",
    "results_ols = model_ols.fit()\n",
    "\n",
    "model_re = RandomEffects(\n",
    "    formula='y ~ x1 + x2',\n",
    "    data=df,\n",
    "    entity_col='entity',\n",
    "    time_col='time',\n",
    ")\n",
    "results_re = model_re.fit()\n",
    "\n",
    "print('Models estimated:')\n",
    "print(f'  OLS  β_x1 = {results_ols.params[\"x1\"]:.4f}')\n",
    "print(f'  FE   β_x1 = {results_fe.params[\"x1\"]:.4f}')\n",
    "print(f'  RE   β_x1 = {results_re.params[\"x1\"]:.4f}')\n",
    "print()\n",
    "print(f'  OLS  R²   = {results_ols.rsquared:.4f}')\n",
    "print(f'  FE   R²   = {results_fe.rsquared:.4f}')\n",
    "print(f'  RE   R²   = {results_re.rsquared:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "# --- Create comparison charts ---\n\nmodel_names = ['Pooled OLS', 'Fixed Effects', 'Random Effects']\n\ncomparison_charts = create_comparison_charts(\n    results_list=[results_ols, results_fe, results_re],\n    names=model_names,\n    theme='academic',\n)\n\nprint('Comparison chart types:', list(comparison_charts.keys()))\n\n# Chart objects expose .figure (a Plotly Figure) for display\ncomparison_charts['coefficients'].figure.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "# --- Build comparison_data and generate HTML report ---\n\ncomparison_data = {\n    'comparison_charts': comparison_charts,\n    'models_info': [\n        {'name': 'Pooled OLS', 'estimator': 'PooledOLS',\n         'nobs': results_ols.nobs, 'r_squared': results_ols.rsquared},\n        {'name': 'Fixed Effects', 'estimator': 'FixedEffects',\n         'nobs': results_fe.nobs, 'r_squared': results_fe.rsquared},\n        {'name': 'Random Effects', 'estimator': 'RandomEffects',\n         'nobs': results_re.nobs, 'r_squared': results_re.rsquared},\n    ],\n    'best_model_aic': 'Fixed Effects',\n    'best_model_bic': 'Fixed Effects',\n}\n\nhtml_comparison = report_mgr.generate_comparison_report(\n    comparison_data=comparison_data,\n    title='Panel Model Comparison Report',\n    subtitle='Pooled OLS vs. Fixed Effects vs. Random Effects',\n    interactive=True,\n)\n\noutput_path_cmp = '../outputs/reports/html/04_comparison_report.html'\nreport_mgr.save_report(html_comparison, output_path_cmp, overwrite=True)\n\nprint(f'Comparison report saved: {output_path_cmp}')\nprint(f'File size: {os.path.getsize(output_path_cmp) / 1024:.1f} KB')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Full Diagnostic Report\n",
    "\n",
    "The residuals report template includes:\n",
    "- Model summary\n",
    "- All residual diagnostic charts (Q-Q, Residuals vs. Fitted, ACF/PACF, etc.)\n",
    "- Interpretation guide per chart\n",
    "\n",
    "We use the **heteroskedastic** dataset to demonstrate a report that flags issues.\n",
    "\n",
    "The `generate_residual_report()` convenience method expects a `residual_data` dict\n",
    "with the chart HTML already embedded. We build it manually by:\n",
    "1. Generating diagnostic charts → Plotly figures\n",
    "2. Converting figures to HTML strings → `fig.to_html(full_html=False, include_plotlyjs='cdn')`\n",
    "3. Passing chart HTML in the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Heteroskedastic panel dataset ---\n",
    "\n",
    "rng_h = np.random.default_rng(99)\n",
    "\n",
    "n_ent_h, n_per_h = 50, 10\n",
    "entities_h = np.repeat(np.arange(1, n_ent_h + 1), n_per_h)\n",
    "periods_h  = np.tile(np.arange(1, n_per_h + 1), n_ent_h)\n",
    "alpha_h    = np.repeat(rng_h.normal(0, 0.5, n_ent_h), n_per_h)\n",
    "x1_h       = rng_h.normal(2, 1, n_ent_h * n_per_h)\n",
    "\n",
    "# Heteroskedastic errors: variance proportional to |x1|\n",
    "sigma_h    = 0.5 * np.abs(x1_h)\n",
    "eps_h      = rng_h.normal(0, 1, n_ent_h * n_per_h) * sigma_h\n",
    "y_h        = alpha_h + 1.5 * x1_h + eps_h\n",
    "\n",
    "df_h = pd.DataFrame({'entity': entities_h, 'time': periods_h, 'x1': x1_h, 'y': y_h})\n",
    "\n",
    "results_h = FixedEffects(\n",
    "    formula='y ~ x1', data=df_h,\n",
    "    entity_col='entity', time_col='time', entity_effects=True,\n",
    ").fit()\n",
    "\n",
    "print('Heteroskedastic model estimated.')\n",
    "print(f'Coefficient x1: {results_h.params[\"x1\"]:.4f}  (true: 1.500)')\n",
    "print(f'R²: {results_h.rsquared:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# --- Create residual diagnostic charts for the heteroskedastic model ---\n\ndiag_h = create_residual_diagnostics(results_h, theme='academic')\n\nprint('Diagnostic charts available:', list(diag_h.keys()))\n\n# Chart objects expose .figure (a Plotly Figure) for display\ndiag_h['residual_vs_fitted'].figure.show()\ndiag_h['scale_location'].figure.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "# --- Build residual_data and generate diagnostic HTML report ---\n\n# Convert chart objects to HTML strings for embedding\ncharts_html = {\n    name: chart.figure.to_html(full_html=False, include_plotlyjs='cdn')\n    for name, chart in diag_h.items()\n}\n\nresidual_data = {\n    'model_info': {\n        'model_type': 'Fixed Effects',\n        'formula': 'y ~ x1',\n        'nobs': results_h.nobs,\n        'n_entities': results_h.n_entities,\n        'n_periods': results_h.n_periods,\n        'r_squared': results_h.rsquared,\n    },\n    'residual_charts': charts_html,\n    'chart_names': list(diag_h.keys()),\n}\n\ntry:\n    html_diag = report_mgr.generate_residual_report(\n        residual_data=residual_data,\n        title='Residual Diagnostics — Heteroskedastic Panel',\n        subtitle='Heteroskedastic dataset: variance proportional to |x1|',\n        interactive=True,\n    )\n    output_path_diag = '../outputs/reports/html/04_diagnostic_report.html'\n    report_mgr.save_report(html_diag, output_path_diag, overwrite=True)\n    print(f'Diagnostic report saved: {output_path_diag}')\n    print(f'File size: {os.path.getsize(output_path_diag) / 1024:.1f} KB')\nexcept Exception as e:\n    print(f'Residual report: {e}')\n    print('Saving diagnostic charts as standalone HTML instead.')\n    # Fallback: export each chart individually\n    for name, chart in diag_h.items():\n        path = f'../outputs/reports/html/04_diag_{name}.html'\n        chart.figure.write_html(path, include_plotlyjs='cdn')\n        print(f'  Saved: {path}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 5. Template Customization (Jinja2)\n",
    "\n",
    "PanelBox reports use **Jinja2** templates stored in `panelbox/templates/`.\n",
    "You can customize reports by:\n",
    "\n",
    "1. **Override context variables** — pass different titles, dates, metadata\n",
    "2. **Inject custom CSS** — pass CSS string via `custom_css` parameter of `generate_report()`\n",
    "3. **Inspect template source** — copy to a local folder and adapt\n",
    "\n",
    "> **Important:** Do not edit the original template files inside the installed library.\n",
    "> Instead, copy the desired template to a local folder and load it with a custom template directory.\n",
    "\n",
    "Below we demonstrate **custom CSS injection** to apply organization branding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect template directory structure ---\n",
    "\n",
    "import panelbox\n",
    "templates_dir = os.path.join(os.path.dirname(panelbox.__file__), 'templates')\n",
    "\n",
    "print(f'Templates directory: {templates_dir}')\n",
    "print()\n",
    "print('Template files:')\n",
    "for root, dirs, files in os.walk(templates_dir):\n",
    "    for fname in sorted(files):\n",
    "        rel = os.path.relpath(os.path.join(root, fname), templates_dir)\n",
    "        print(f'  • {rel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": "# --- Custom CSS injection for branded report ---\n\n# Define organization CSS overrides\ncustom_css = \"\"\"\n:root {\n    --primary-color: #1A3A5C;   /* Dark blue brand color */\n    --accent-color:  #F4A261;   /* Orange accent */\n}\nh1, h2, h3 { color: #1A3A5C; }\n.report-header { background-color: #1A3A5C; color: white; }\n\"\"\"\n\n# Re-use the val_data from Section 2 (FE model on clean data)\nhtml_branded = report_mgr.generate_report(\n    report_type='validation',\n    template='validation/interactive/index.html',\n    context={\n        **val_data,\n        'report_title': 'Branded Report — My Research Institute',\n        'report_subtitle': 'Fixed Effects Model on Simulated Panel Data',\n    },\n    embed_assets=True,\n    include_plotly=True,\n    custom_css=[custom_css],\n)\n\noutput_path_branded = '../outputs/reports/html/04_branded_report.html'\nreport_mgr.save_report(html_branded, output_path_branded, overwrite=True)\nprint(f'Branded report saved: {output_path_branded}')\nprint(f'File size: {os.path.getsize(output_path_branded) / 1024:.1f} KB')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 6. LaTeX and Markdown Export\n",
    "\n",
    "For **academic publications**, PanelBox can export results to:\n",
    "- **`.tex` file** — LaTeX source with `booktabs` regression tables\n",
    "- **`.md` file** — Markdown with pipe tables (for GitHub, Quarto, etc.)\n",
    "\n",
    "Both exporters use the same data format:\n",
    "```python\n",
    "coefficients = [\n",
    "    {'variable': 'x1', 'coefficient': 1.42, 'std_error': 0.05,\n",
    "     't_statistic': 28.4, 'p_value': 0.000, 'stars': '***'},\n",
    "    ...\n",
    "]\n",
    "model_info = {'model_type': 'Fixed Effects', 'n_obs': 600, 'r_squared': 0.75}\n",
    "```\n",
    "\n",
    "> **Note:** PDF compilation requires `pdflatex` installed:\n",
    "> ```bash\n",
    "> sudo apt install texlive-latex-recommended\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# --- Build coefficient data from results_fe ---\n\ndef build_coefficient_table(results):\n    \"\"\"Convert PanelResults to the list-of-dicts format for exporters.\"\"\"\n    rows = []\n    for var in results.params.index:\n        coef  = results.params[var]\n        se    = results.std_errors[var]\n        tstat = results.tvalues[var]\n        pval  = results.pvalues[var]\n        if pval < 0.01:\n            stars = '***'\n        elif pval < 0.05:\n            stars = '**'\n        elif pval < 0.10:\n            stars = '*'\n        else:\n            stars = ''\n        rows.append({\n            'variable':    var,\n            'coefficient': coef,\n            'std_error':   se,\n            't_statistic': tstat,\n            'pvalue':      pval,\n            'stars':       stars,\n        })\n    return rows\n\ncoef_data = build_coefficient_table(results_fe)\nmodel_meta = {\n    'model_type': 'Fixed Effects',\n    'nobs':       results_fe.nobs,\n    'r_squared':  results_fe.rsquared,\n    'r_squared_within': results_fe.rsquared_within,\n    'r_squared_between': results_fe.rsquared_between,\n}\n\nprint(f'Coefficient rows prepared: {len(coef_data)}')\nfor row in coef_data:\n    print(f\"  {row['variable']:15s} {row['coefficient']:+.4f}  ({row['stars']})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export to LaTeX ---\n",
    "\n",
    "latex_exporter = LaTeXExporter()\n",
    "\n",
    "latex_content = latex_exporter.export_regression_table(\n",
    "    coefficients=coef_data,\n",
    "    model_info=model_meta,\n",
    "    caption='Fixed Effects Regression Results — Simulated Panel',\n",
    "    label='tab:fe_main',\n",
    ")\n",
    "\n",
    "tex_path = '../outputs/reports/latex/04_regression_table.tex'\n",
    "latex_exporter.save(\n",
    "    latex_content=latex_content,\n",
    "    output_path=tex_path,\n",
    "    overwrite=True,\n",
    "    add_preamble=True,   # wrap table in full LaTeX document\n",
    ")\n",
    "\n",
    "print(f'LaTeX file saved: {tex_path}')\n",
    "print(f'File size: {os.path.getsize(tex_path) / 1024:.1f} KB')\n",
    "print()\n",
    "print('LaTeX content preview:')\n",
    "print(latex_content[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compile LaTeX to PDF (optional — requires pdflatex) ---\n",
    "\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        ['pdflatex', '-interaction=nonstopmode',\n",
    "         '-output-directory', '../outputs/reports/latex/', tex_path],\n",
    "        capture_output=True, text=True, timeout=60\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        pdf_path = tex_path.replace('.tex', '.pdf')\n",
    "        print(f'PDF compiled successfully: {pdf_path}')\n",
    "    else:\n",
    "        print('LaTeX compilation encountered errors. Last 500 chars of log:')\n",
    "        print(result.stdout[-500:])\n",
    "except FileNotFoundError:\n",
    "    print('pdflatex not found. To compile PDF, install:')\n",
    "    print('  sudo apt install texlive-latex-recommended')\n",
    "except subprocess.TimeoutExpired:\n",
    "    print('LaTeX compilation timed out (> 60 s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export to Markdown ---\n",
    "\n",
    "markdown_exporter = MarkdownExporter()\n",
    "\n",
    "md_content = markdown_exporter.export_regression_table(\n",
    "    coefficients=coef_data,\n",
    "    model_info=model_meta,\n",
    "    title='Fixed Effects Regression Results',\n",
    ")\n",
    "\n",
    "md_path = '../outputs/reports/latex/04_regression_table.md'\n",
    "markdown_exporter.save(md_content, md_path, overwrite=True)\n",
    "\n",
    "print(f'Markdown report saved: {md_path}')\n",
    "print()\n",
    "print('Markdown content:')\n",
    "print(md_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 7. Controlling Report File Size\n",
    "\n",
    "A self-contained HTML report with Plotly.js **embedded** can be **3–5 MB**.\n",
    "For sharing via email or a slow server, use the CDN option:\n",
    "\n",
    "| Option | Size | Trade-off |\n",
    "|---|---|---|\n",
    "| `include_plotly=True` | ~3–5 MB | Self-contained, works offline |\n",
    "| `include_plotly=False` | ~50–100 KB | Requires Plotly.js from CDN |\n",
    "| Charts as PNG (static) | ~100–300 KB | No interactivity |\n",
    "\n",
    "The `save_report()` method also writes an existing file only if `overwrite=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": "# --- Compare file sizes: embedded vs. CDN Plotly.js ---\n\n# 1. Inline Plotly.js (already saved above)\ninline_path = '../outputs/reports/html/04_single_model_report.html'\ninline_size_kb = os.path.getsize(inline_path) / 1024\n\n# 2. No inline Plotly (CDN)\nhtml_cdn = report_mgr.generate_report(\n    report_type='validation',\n    template='validation/interactive/index.html',\n    context={\n        **val_data,\n        'report_title': 'CDN Plotly Report',\n    },\n    embed_assets=True,\n    include_plotly=False,   # Plotly NOT embedded; loaded from CDN\n)\ncdn_path = '../outputs/reports/html/04_cdn_report.html'\nreport_mgr.save_report(html_cdn, cdn_path, overwrite=True)\ncdn_size_kb = os.path.getsize(cdn_path) / 1024\n\nprint(f'Inline Plotly.js:  {inline_size_kb:.0f} KB')\nprint(f'CDN Plotly.js:     {cdn_size_kb:.0f} KB')\nreduction = (1 - cdn_size_kb / inline_size_kb) * 100\nprint(f'Size reduction:    {reduction:.0f}%')\nprint()\nprint('Tip: CDN reports require an internet connection to display charts.')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 8. Complete Automated Pipeline\n",
    "\n",
    "The final section encapsulates the full workflow in a reusable function.\n",
    "In practice, you would call this from a cron job, a GitHub Action, or a scheduled script:\n",
    "\n",
    "```bash\n",
    "python generate_monthly_report.py --data monthly_sales.csv --output reports/\n",
    "```\n",
    "\n",
    "**Pipeline steps:**\n",
    "1. Load data\n",
    "2. Estimate Pooled OLS, Fixed Effects, Random Effects\n",
    "3. Build validation data\n",
    "4. Create visualization charts\n",
    "5. Generate HTML validation + comparison reports\n",
    "6. Export LaTeX regression table\n",
    "7. Save all outputs to structured directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": "def run_panel_analysis_pipeline(\n    data: pd.DataFrame,\n    entity_col: str,\n    time_col: str,\n    dependent: str,\n    regressors: list,\n    output_dir: str,\n    report_title: str = 'Panel Data Analysis Report',\n    theme: str = 'academic',\n) -> dict:\n    \"\"\"\n    Full automated panel analysis pipeline.\n\n    Parameters\n    ----------\n    data        : DataFrame with panel data (entity, time, variables)\n    entity_col  : name of entity column\n    time_col    : name of time column\n    dependent   : name of dependent variable\n    regressors  : list of regressor column names\n    output_dir  : root output directory (reports/html and reports/latex created inside)\n    report_title: title for all generated reports\n    theme       : visualization theme ('academic', 'professional', etc.)\n\n    Returns\n    -------\n    dict with paths of all generated files\n    \"\"\"\n    os.makedirs(f'{output_dir}/reports/html',  exist_ok=True)\n    os.makedirs(f'{output_dir}/reports/latex', exist_ok=True)\n    os.makedirs(f'{output_dir}/charts/png',    exist_ok=True)\n\n    formula = f\"{dependent} ~ {' + '.join(regressors)}\"\n\n    # --- 1. Estimate models ---\n    print('[1/5] Estimating models...')\n    res_ols = PooledOLS(\n        formula=formula, data=data,\n        entity_col=entity_col, time_col=time_col\n    ).fit()\n    res_fe = FixedEffects(\n        formula=formula, data=data,\n        entity_col=entity_col, time_col=time_col, entity_effects=True\n    ).fit()\n    res_re = RandomEffects(\n        formula=formula, data=data,\n        entity_col=entity_col, time_col=time_col\n    ).fit()\n\n    # --- 2. Run validation tests ---\n    print('[2/5] Running validation tests...')\n    val_rpt = res_fe.validate(tests='all')\n    n_tests = (len(val_rpt.specification_tests) + len(val_rpt.serial_tests)\n               + len(val_rpt.het_tests) + len(val_rpt.cd_tests))\n    n_failed = len(val_rpt.get_failed_tests())\n    print(f'       Tests run: {n_tests}, failed: {n_failed}')\n    val_data_pipe = ValidationTransformer(val_rpt).transform(include_charts=True)\n\n    # --- 3. Create charts ---\n    print('[3/5] Creating charts...')\n    diag_charts = create_residual_diagnostics(res_fe, theme=theme)\n    comp_charts = create_comparison_charts(\n        results_list=[res_ols, res_fe, res_re],\n        names=['Pooled OLS', 'Fixed Effects', 'Random Effects'],\n        theme=theme,\n    )\n    # Export chart PNGs (skip silently if kaleido missing)\n    for name, chart in diag_charts.items():\n        try:\n            chart.figure.write_image(f'{output_dir}/charts/png/{name}.png',\n                                     width=900, height=600)\n        except Exception:\n            pass\n\n    # --- 4. Generate HTML reports ---\n    print('[4/5] Generating HTML reports...')\n    mgr = ReportManager()\n    date_str = pd.Timestamp.now().strftime('%Y-%m-%d')\n\n    html_v = mgr.generate_validation_report(\n        validation_data=val_data_pipe,\n        title=f'{report_title} — Validation',\n        subtitle=f'Generated {date_str}',\n    )\n    path_html_v = f'{output_dir}/reports/html/validation_report.html'\n    mgr.save_report(html_v, path_html_v, overwrite=True)\n\n    comp_data_pipe = {\n        'comparison_charts': comp_charts,\n        'models_info': [\n            {'name': 'Pooled OLS', 'estimator': 'PooledOLS',\n             'nobs': res_ols.nobs, 'r_squared': res_ols.rsquared},\n            {'name': 'Fixed Effects', 'estimator': 'FixedEffects',\n             'nobs': res_fe.nobs, 'r_squared': res_fe.rsquared},\n            {'name': 'Random Effects', 'estimator': 'RandomEffects',\n             'nobs': res_re.nobs, 'r_squared': res_re.rsquared},\n        ],\n        'best_model_aic': 'Fixed Effects',\n        'best_model_bic': 'Fixed Effects',\n    }\n    html_c = mgr.generate_comparison_report(\n        comparison_data=comp_data_pipe,\n        title=f'{report_title} — Comparison',\n        subtitle=f'Generated {date_str}',\n    )\n    path_html_c = f'{output_dir}/reports/html/comparison_report.html'\n    mgr.save_report(html_c, path_html_c, overwrite=True)\n\n    # --- 5. Export LaTeX ---\n    print('[5/5] Generating LaTeX table...')\n    coefs_pipe = [\n        {\n            'variable':    var,\n            'coefficient': res_fe.params[var],\n            'std_error':   res_fe.std_errors[var],\n            't_statistic': res_fe.tvalues[var],\n            'pvalue':      res_fe.pvalues[var],\n        }\n        for var in res_fe.params.index\n    ]\n    meta_pipe = {\n        'model_type': 'Fixed Effects',\n        'nobs': res_fe.nobs,\n        'r_squared': res_fe.rsquared,\n    }\n    latex_exp = LaTeXExporter()\n    latex_src = latex_exp.export_regression_table(\n        coefficients=coefs_pipe,\n        model_info=meta_pipe,\n        caption=report_title,\n        label='tab:results',\n    )\n    path_tex = f'{output_dir}/reports/latex/regression_table.tex'\n    latex_exp.save(latex_src, path_tex, overwrite=True, add_preamble=True)\n\n    # --- Summary ---\n    output_files = {\n        'html_validation': path_html_v,\n        'html_comparison': path_html_c,\n        'latex': path_tex,\n    }\n    print()\n    print('Pipeline complete. Generated files:')\n    for label, path in output_files.items():\n        size_kb = os.path.getsize(path) / 1024\n        print(f'  [{label}] {path} ({size_kb:.0f} KB)')\n\n    return output_files"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run the pipeline on a fresh dataset ---\n",
    "\n",
    "# Simulated monthly sales panel (35 entities × 12 periods)\n",
    "df_pipeline = generate_panel_data(n_individuals=35, n_periods=12, n_covariates=2, seed=123)\n",
    "# generate_panel_data returns a MultiIndex df; reset index for flat columns\n",
    "df_pipeline = df_pipeline.reset_index()\n",
    "\n",
    "generated = run_panel_analysis_pipeline(\n",
    "    data=df_pipeline,\n",
    "    entity_col='entity',\n",
    "    time_col='time',\n",
    "    dependent='y',\n",
    "    regressors=['x1', 'x2'],\n",
    "    output_dir='../outputs',\n",
    "    report_title='Monthly Panel Analysis — February 2026',\n",
    "    theme='professional',\n",
    ")\n",
    "\n",
    "print('\\nAll reports generated successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Display the final validation report in the notebook ---\n",
    "\n",
    "from IPython.display import IFrame, display, HTML\n",
    "\n",
    "display(HTML('<h3>Pipeline output — Validation Report:</h3>'))\n",
    "try:\n",
    "    display(IFrame(src=generated['html_validation'], width='100%', height=550))\n",
    "except Exception:\n",
    "    display(HTML(f'<a href=\"{generated[\"html_validation\"]}\" target=\"_blank\">'\n",
    "                 f'Open validation report</a>'))\n",
    "\n",
    "display(HTML('<h3>Pipeline output — Comparison Report:</h3>'))\n",
    "try:\n",
    "    display(IFrame(src=generated['html_comparison'], width='100%', height=550))\n",
    "except Exception:\n",
    "    display(HTML(f'<a href=\"{generated[\"html_comparison\"]}\" target=\"_blank\">'\n",
    "                 f'Open comparison report</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Capability | Method | Output format |\n",
    "|---|---|---|\n",
    "| Single-model report | `ReportManager.generate_validation_report(val_data, title)` | HTML |\n",
    "| Multi-model comparison | `ReportManager.generate_comparison_report(comp_data, title)` | HTML |\n",
    "| Full diagnostics | `ReportManager.generate_residual_report(residual_data, title)` | HTML |\n",
    "| Custom branding | `generate_report(..., custom_css=[css_str])` | HTML |\n",
    "| LaTeX regression table | `LaTeXExporter().export_regression_table(coefs, model_info)` | `.tex` |\n",
    "| PDF compilation | `pdflatex` via `subprocess` | `.pdf` |\n",
    "| Markdown table | `MarkdownExporter().export_regression_table(coefs, model_info)` | `.md` |\n",
    "| Automated pipeline | `run_panel_analysis_pipeline(...)` | HTML + LaTeX |\n",
    "\n",
    "**File size guide:**\n",
    "- `include_plotly=True`: 3–5 MB (offline, self-contained)\n",
    "- `include_plotly=False`: ~50 KB (CDN — requires internet)\n",
    "\n",
    "**Data preparation:**\n",
    "- `ValidationTransformer(val_report).transform()` → dict for `generate_validation_report()`\n",
    "- `create_comparison_charts(results_list, names, theme)` → dict for `generate_comparison_report()`\n",
    "\n",
    "**Congratulations!** You have completed the PanelBox Visualization Series (Notebooks 01–04).  \n",
    "You can now create, diagnose, visualize, compare, and report panel data analyses\n",
    "using PanelBox's complete visualization and report generation stack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
