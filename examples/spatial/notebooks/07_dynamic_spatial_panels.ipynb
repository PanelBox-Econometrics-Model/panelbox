{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Spatial Panel Models\n",
    "\n",
    "**Level**: Advanced  \n",
    "**Duration**: 180-210 minutes  \n",
    "**Prerequisites**: Notebooks 01-06, GMM for dynamic panels\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Estimate** dynamic spatial panel models via GMM\n",
    "2. **Understand** double endogeneity (Nickell bias + spatial endogeneity)\n",
    "3. **Construct** valid instruments for both sources of endogeneity\n",
    "4. **Compute** short-run vs long-run effects and dynamic multipliers\n",
    "5. **Generate** impulse-response functions across space and time\n",
    "6. **Test** instrument validity with Hansen J-test\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Motivation: Time + Space](#1.-Motivation:-Time-+-Space)\n",
    "2. [Valid Instruments for Dynamic Spatial Panels](#2.-Valid-Instruments-for-Dynamic-Spatial-Panels)\n",
    "3. [GMM Estimation](#3.-GMM-Estimation)\n",
    "4. [Short-Run vs Long-Run Effects](#4.-Short-Run-vs-Long-Run-Effects)\n",
    "5. [Hansen J-Test (Over-Identification)](#5.-Hansen-J-Test-(Over-Identification))\n",
    "6. [Impulse-Response Functions](#6.-Impulse-Response-Functions)\n",
    "7. [Difference-in-Sargan Test](#7.-Difference-in-Sargan-Test)\n",
    "8. [Case Study: Regional Economic Growth](#8.-Case-Study:-Regional-Economic-Growth)\n",
    "9. [Diagnostic Tests](#9.-Diagnostic-Tests)\n",
    "10. [Summary](#10.-Summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add panelbox to path\n",
    "panelbox_path = Path(\"/home/guhaase/projetos/panelbox\")\n",
    "sys.path.insert(0, str(panelbox_path))\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Packages loaded successfully\")\n",
    "print(f\"‚úì Panelbox path: {panelbox_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Motivation: Time + Space\n",
    "\n",
    "### The Dynamic Spatial Panel Model\n",
    "\n",
    "$$\n",
    "y_{it} = \\gamma y_{i,t-1} + \\rho W y_{it} + X_{it}\\beta + \\alpha_i + \\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\gamma$: **Temporal persistence** (AR coefficient)\n",
    "- $\\rho$: **Spatial spillover** parameter\n",
    "- $y_{i,t-1}$: Own past value (lagged dependent variable)\n",
    "- $Wy_{it}$: Contemporaneous spatial lag\n",
    "\n",
    "### Why Both Dynamics?\n",
    "\n",
    "**Temporal dynamics** ($\\gamma$):\n",
    "- Path dependence and adjustment costs\n",
    "- Habit formation and persistence\n",
    "- Economic convergence ($\\gamma < 1$ ‚Üí shocks dissipate)\n",
    "\n",
    "**Spatial dynamics** ($\\rho$):\n",
    "- Spillovers and externalities\n",
    "- Diffusion processes\n",
    "- Spatial contagion\n",
    "\n",
    "### Double Endogeneity Problem\n",
    "\n",
    "1. **Nickell bias**: $y_{i,t-1}$ correlated with $\\alpha_i$ (fixed effects)\n",
    "2. **Spatial endogeneity**: $Wy_{it}$ correlated with $\\varepsilon_{it}$ (simultaneity)\n",
    "3. **Solution**: GMM with valid instruments for BOTH sources\n",
    "\n",
    "### Applications\n",
    "\n",
    "| Application | $\\gamma$ (persistence) | $\\rho$ (spillover) |\n",
    "|-------------|----------------------|-------------------|\n",
    "| Economic growth | Convergence | Knowledge diffusion |\n",
    "| Crime | Recidivism | Spatial contagion |\n",
    "| Innovation | Learning by doing | Technology spillovers |\n",
    "| Unemployment | Hysteresis | Labor market linkages |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulated regional growth data (long panel: N=50 regions, T=15 years)\n",
    "print(\"Creating simulated regional growth dataset...\\n\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Panel dimensions\n",
    "N = 50  # regions\n",
    "T = 15  # years (need T >= 10 for dynamic panel)\n",
    "\n",
    "# Create spatial weight matrix (rook contiguity for 10√ó5 grid)\n",
    "from libpysal.weights import lat2W\n",
    "W = lat2W(10, 5)  # 10 rows √ó 5 columns = 50 regions\n",
    "W.transform = 'r'  # Row-standardize\n",
    "W_dense = W.full()[0]\n",
    "\n",
    "# True parameters\n",
    "gamma_true = 0.6    # Temporal persistence\n",
    "rho_true = 0.25     # Spatial spillover\n",
    "beta_invest = 0.15  # Investment effect\n",
    "beta_educ = 0.20    # Education effect\n",
    "\n",
    "# Generate data\n",
    "regions = np.arange(N)\n",
    "years = np.arange(2005, 2005 + T)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "# Fixed effects\n",
    "alpha = np.random.normal(2.0, 0.5, N)\n",
    "\n",
    "# Exogenous variables (with region-specific trends)\n",
    "investment = np.random.uniform(15, 30, (N, T))\n",
    "education = np.random.uniform(8, 14, (N, T))\n",
    "\n",
    "# Initialize\n",
    "y = np.zeros((N, T))\n",
    "y[:, 0] = alpha + 0.1 * np.random.randn(N)  # Initial condition\n",
    "\n",
    "# Generate dynamic spatial process\n",
    "I = np.eye(N)\n",
    "A_inv = np.linalg.inv(I - rho_true * W_dense)\n",
    "\n",
    "for t in range(1, T):\n",
    "    # DGP: y_t = (I - œÅW)^{-1}(Œ≥y_{t-1} + XŒ≤ + Œ± + Œµ)\n",
    "    mu = gamma_true * y[:, t-1] + beta_invest * investment[:, t] + beta_educ * education[:, t] + alpha\n",
    "    epsilon = np.random.normal(0, 0.3, N)\n",
    "    y[:, t] = A_inv @ (mu + epsilon)\n",
    "\n",
    "# Create panel dataframe\n",
    "for i in range(N):\n",
    "    for t in range(T):\n",
    "        data_list.append({\n",
    "            'region_id': i,\n",
    "            'year': years[t],\n",
    "            'gdp_growth': y[i, t],\n",
    "            'investment': investment[i, t],\n",
    "            'education': education[i, t]\n",
    "        })\n",
    "\n",
    "data = pd.DataFrame(data_list)\n",
    "\n",
    "print(f\"Panel dimensions:\")\n",
    "print(f\"  N = {data['region_id'].nunique()} regions\")\n",
    "print(f\"  T = {data['year'].nunique()} years\")\n",
    "print(f\"  Total obs = {len(data)}\")\n",
    "print(f\"\\nTrue parameters:\")\n",
    "print(f\"  Œ≥ (persistence) = {gamma_true}\")\n",
    "print(f\"  œÅ (spillover)   = {rho_true}\")\n",
    "print(f\"  Œ≤_investment    = {beta_invest}\")\n",
    "print(f\"  Œ≤_education     = {beta_educ}\")\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Valid Instruments for Dynamic Spatial Panels\n",
    "\n",
    "### Instrument Requirements\n",
    "\n",
    "For valid instruments $Z$:\n",
    "\n",
    "1. **Exogeneity**: $E(Z'\\varepsilon) = 0$\n",
    "2. **Relevance**: $\\text{Corr}(Z, \\text{endogenous vars}) \\neq 0$\n",
    "\n",
    "### Instrument Sets\n",
    "\n",
    "**For $y_{i,t-1}$ (Nickell bias)**:\n",
    "- Temporal lags: $y_{i,t-2}, y_{i,t-3}, \\ldots$ (Arellano-Bond)\n",
    "- Valid if $\\varepsilon_{it}$ is serially uncorrelated\n",
    "\n",
    "**For $Wy_{it}$ (spatial endogeneity)**:\n",
    "- Spatial lags of exogenous $X$: $WX_{it}, W^2X_{it}, \\ldots$\n",
    "- Temporal-spatial lags: $Wy_{i,t-1}, Wy_{i,t-2}, \\ldots$\n",
    "\n",
    "**Combined Instrument Matrix**:\n",
    "\n",
    "$$\n",
    "Z = [y_{i,t-2}, y_{i,t-3}, WX_{it}, W^2X_{it}, Wy_{i,t-1}, Wy_{i,t-2}]\n",
    "$$\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "- More instruments ‚â† better (over-fitting risk)\n",
    "- Hansen J-test checks over-identification restrictions\n",
    "- AR(2) test checks if instruments are valid (should be insignificant)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct lagged and spatial lag variables\n",
    "print(\"Constructing instruments...\\n\")\n",
    "\n",
    "# Add entity_id and time columns\n",
    "data['entity_id'] = data['region_id']\n",
    "data['time'] = data['year']\n",
    "\n",
    "# Sort by region and year\n",
    "data_sorted = data.sort_values(['entity_id', 'time']).reset_index(drop=True)\n",
    "\n",
    "# Create temporal lags of y\n",
    "data_sorted['y_lag1'] = data_sorted.groupby('entity_id')['gdp_growth'].shift(1)\n",
    "data_sorted['y_lag2'] = data_sorted.groupby('entity_id')['gdp_growth'].shift(2)\n",
    "data_sorted['y_lag3'] = data_sorted.groupby('entity_id')['gdp_growth'].shift(3)\n",
    "\n",
    "# Create spatial lags\n",
    "from libpysal.weights import lag_spatial\n",
    "\n",
    "# For each year, compute spatial lag\n",
    "Wy_list = []\n",
    "W_invest_list = []\n",
    "W_educ_list = []\n",
    "\n",
    "for year in data_sorted['year'].unique():\n",
    "    year_data = data_sorted[data_sorted['year'] == year].sort_values('region_id')\n",
    "    \n",
    "    # Spatial lag of y\n",
    "    Wy = lag_spatial(W, year_data['gdp_growth'].values)\n",
    "    Wy_list.extend(Wy)\n",
    "    \n",
    "    # Spatial lag of X (instruments)\n",
    "    W_invest = lag_spatial(W, year_data['investment'].values)\n",
    "    W_invest_list.extend(W_invest)\n",
    "    \n",
    "    W_educ = lag_spatial(W, year_data['education'].values)\n",
    "    W_educ_list.extend(W_educ)\n",
    "\n",
    "data_sorted['Wy'] = Wy_list\n",
    "data_sorted['W_invest'] = W_invest_list\n",
    "data_sorted['W_educ'] = W_educ_list\n",
    "\n",
    "# Create temporal lag of Wy (spatial-temporal instrument)\n",
    "data_sorted['Wy_lag1'] = data_sorted.groupby('entity_id')['Wy'].shift(1)\n",
    "\n",
    "print(\"Instrument variables created:\")\n",
    "print(\"  Temporal instruments: y_lag2, y_lag3 (for y_lag1)\")\n",
    "print(\"  Spatial instruments:  W_invest, W_educ (for Wy)\")\n",
    "print(\"  Combined:             Wy_lag1 (for Wy)\")\n",
    "\n",
    "print(\"\\nSample of constructed variables:\")\n",
    "data_sorted[['region_id', 'year', 'gdp_growth', 'y_lag1', 'y_lag2', 'Wy', 'W_invest']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GMM Estimation\n",
    "\n",
    "### Two-Step Efficient GMM\n",
    "\n",
    "**Moment conditions**:\n",
    "\n",
    "$$\n",
    "E[Z_i'(y_{it} - \\gamma y_{i,t-1} - \\rho Wy_{it} - X_{it}\\beta)] = 0\n",
    "$$\n",
    "\n",
    "**GMM estimator**:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{GMM} = \\arg\\min_{\\theta} \\, g(\\theta)' W^{-1} g(\\theta)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $g(\\theta) = \\frac{1}{N}\\sum_{i=1}^N Z_i'\\hat{\\varepsilon}_i$\n",
    "- $W$ = efficient weight matrix\n",
    "\n",
    "### Two-Step Procedure\n",
    "\n",
    "1. **First step**: 2SLS with $W = I$ (identity matrix)\n",
    "2. **Second step**: Efficient GMM with $W = \\hat{\\Omega}^{-1}$ (optimal weights)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, we'll use standard panel GMM with spatial lag as additional regressor\n",
    "# Note: This is a simplified approach. Full implementation would require specialized GMM estimator.\n",
    "\n",
    "print(\"Estimating Dynamic Spatial Panel via GMM...\\n\")\n",
    "\n",
    "# Remove missing values from lags\n",
    "data_gmm = data_sorted.dropna(subset=['y_lag1', 'y_lag2', 'y_lag3', 'Wy', 'W_invest', 'W_educ']).copy()\n",
    "\n",
    "print(f\"Estimation sample: {len(data_gmm)} observations\\n\")\n",
    "\n",
    "# Manual 2SLS estimation (simplified GMM)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.linalg import inv\n",
    "\n",
    "# Endogenous variables: y_lag1, Wy\n",
    "endog = data_gmm[['y_lag1', 'Wy']].values\n",
    "\n",
    "# Exogenous variables (include in both stages)\n",
    "exog = data_gmm[['investment', 'education']].values\n",
    "\n",
    "# Instruments: y_lag2, y_lag3, W_invest, W_educ, Wy_lag1\n",
    "instruments = data_gmm[['y_lag2', 'y_lag3', 'W_invest', 'W_educ']].values\n",
    "\n",
    "# Add constant\n",
    "const = np.ones((len(data_gmm), 1))\n",
    "\n",
    "# First stage: Regress endogenous on [instruments, exog, const]\n",
    "Z = np.hstack([instruments, exog, const])\n",
    "X_endog = endog\n",
    "\n",
    "# Fitted values\n",
    "Pi = inv(Z.T @ Z) @ Z.T @ X_endog\n",
    "X_endog_hat = Z @ Pi\n",
    "\n",
    "# Second stage: Regress y on [X_endog_hat, exog, const]\n",
    "y = data_gmm['gdp_growth'].values\n",
    "X = np.hstack([X_endog_hat, exog, const])\n",
    "\n",
    "beta_2sls = inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "# Extract coefficients\n",
    "gamma_hat = beta_2sls[0]\n",
    "rho_hat = beta_2sls[1]\n",
    "beta_invest_hat = beta_2sls[2]\n",
    "beta_educ_hat = beta_2sls[3]\n",
    "intercept = beta_2sls[4]\n",
    "\n",
    "# Compute standard errors (robust)\n",
    "residuals = y - X @ beta_2sls\n",
    "n = len(y)\n",
    "k = X.shape[1]\n",
    "\n",
    "# Robust variance-covariance matrix\n",
    "meat = Z.T @ np.diag(residuals**2) @ Z\n",
    "bread = inv(X.T @ Z @ inv(Z.T @ Z) @ Z.T @ X)\n",
    "V_robust = (n / (n - k)) * bread @ (X.T @ Z @ inv(Z.T @ Z) @ meat @ inv(Z.T @ Z) @ Z.T @ X) @ bread\n",
    "se_robust = np.sqrt(np.diag(V_robust))\n",
    "\n",
    "# t-statistics\n",
    "t_stats = beta_2sls / se_robust\n",
    "p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), n - k))\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*70)\n",
    "print(\"DYNAMIC SPATIAL PANEL GMM RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nSample size: N√óT = {data_gmm['entity_id'].nunique()}√ó{data_gmm['time'].nunique()} = {n}\")\n",
    "print(f\"Instruments: {Z.shape[1]} total\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"{'Variable':<20} {'Coef':>10} {'Std Err':>10} {'t':>8} {'P>|t|':>10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "var_names = ['y_lag1 (Œ≥)', 'Wy (œÅ)', 'investment', 'education', 'const']\n",
    "for i, name in enumerate(var_names):\n",
    "    print(f\"{name:<20} {beta_2sls[i]:>10.4f} {se_robust[i]:>10.4f} {t_stats[i]:>8.2f} {p_values[i]:>10.4f}\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(f\"\\nTemporal persistence (Œ≥): {gamma_hat:.4f} (true: {gamma_true})\")\n",
    "if 0 < gamma_hat < 1 and p_values[0] < 0.05:\n",
    "    half_life = np.log(0.5) / np.log(gamma_hat)\n",
    "    print(f\"  ‚úì Convergence detected: shocks dissipate over time\")\n",
    "    print(f\"  ‚Üí Half-life: {half_life:.2f} years\")\n",
    "elif gamma_hat >= 1:\n",
    "    print(f\"  ‚ö† No convergence: unit root or explosive process\")\n",
    "\n",
    "print(f\"\\nSpatial spillover (œÅ): {rho_hat:.4f} (true: {rho_true})\")\n",
    "if rho_hat > 0 and p_values[1] < 0.05:\n",
    "    print(f\"  ‚úì Positive spatial spillovers detected\")\n",
    "    print(f\"  ‚Üí Growth in neighbors increases own growth\")\n",
    "\n",
    "print(f\"\\nInvestment effect: {beta_invest_hat:.4f} (true: {beta_invest})\")\n",
    "print(f\"Education effect:  {beta_educ_hat:.4f} (true: {beta_educ})\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store for later use\n",
    "results_dict = {\n",
    "    'gamma': gamma_hat,\n",
    "    'rho': rho_hat,\n",
    "    'beta_invest': beta_invest_hat,\n",
    "    'beta_educ': beta_educ_hat,\n",
    "    'se': se_robust,\n",
    "    'pvalues': p_values,\n",
    "    'residuals': residuals,\n",
    "    'n': n,\n",
    "    'k': k,\n",
    "    'Z': Z,\n",
    "    'X': X\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Short-Run vs Long-Run Effects\n",
    "\n",
    "### Conceptual Difference\n",
    "\n",
    "**Short-run effect**: Immediate impact in same period (coefficient $\\beta$)\n",
    "\n",
    "**Long-run effect**: Cumulative effect after full adjustment\n",
    "\n",
    "### Long-Run Multiplier\n",
    "\n",
    "From the model:\n",
    "\n",
    "$$\n",
    "y_{it} = \\gamma y_{i,t-1} + \\rho Wy_{it} + X_{it}\\beta + \\alpha_i + \\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "At steady state ($y_{it} = y_{i,t-1} = y^*$):\n",
    "\n",
    "$$\n",
    "(I - \\rho W)y^* = \\frac{1}{1-\\gamma} X\\beta + \\text{const}\n",
    "$$\n",
    "\n",
    "**Long-run spatial multiplier**:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y^*}{\\partial X} = \\frac{1}{1-\\gamma} (I - \\rho W)^{-1} \\beta\n",
    "$$\n",
    "\n",
    "### Approximation\n",
    "\n",
    "Average long-run effect:\n",
    "\n",
    "$$\n",
    "LR = \\frac{\\beta}{1 - \\gamma - \\rho \\lambda_{max}}\n",
    "$$\n",
    "\n",
    "Where $\\lambda_{max}$ is the maximum eigenvalue of $W$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute short-run vs long-run effects\n",
    "print(\"=\"*70)\n",
    "print(\"SHORT-RUN vs LONG-RUN EFFECTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "gamma_hat = results_dict['gamma']\n",
    "rho_hat = results_dict['rho']\n",
    "beta_invest_hat = results_dict['beta_invest']\n",
    "beta_educ_hat = results_dict['beta_educ']\n",
    "\n",
    "# Compute max eigenvalue of W\n",
    "eigenvalues = np.linalg.eigvals(W_dense).real\n",
    "lambda_max = eigenvalues.max()\n",
    "\n",
    "print(f\"\\nMaximum eigenvalue of W: {lambda_max:.4f}\")\n",
    "\n",
    "# Temporal multiplier (ignoring spatial)\n",
    "temporal_multiplier = 1 / (1 - gamma_hat)\n",
    "\n",
    "# Combined dynamic-spatial multiplier (approximation)\n",
    "dyn_spatial_multiplier = 1 / (1 - gamma_hat - rho_hat * lambda_max)\n",
    "\n",
    "print(f\"\\nMultipliers:\")\n",
    "print(f\"  Temporal only:     {temporal_multiplier:.4f}x\")\n",
    "print(f\"  Dynamic + Spatial: {dyn_spatial_multiplier:.4f}x\")\n",
    "\n",
    "# Long-run effects\n",
    "lr_invest = beta_invest_hat * dyn_spatial_multiplier\n",
    "lr_educ = beta_educ_hat * dyn_spatial_multiplier\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"{'Variable':<15} {'Short-Run':>12} {'Long-Run':>12} {'LR/SR':>10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"{'Investment':<15} {beta_invest_hat:>12.4f} {lr_invest:>12.4f} {lr_invest/beta_invest_hat:>10.2f}x\")\n",
    "print(f\"{'Education':<15} {beta_educ_hat:>12.4f} {lr_educ:>12.4f} {lr_educ/beta_educ_hat:>10.2f}x\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\nINTERPRETATION (Investment):\")\n",
    "print(f\"\\n  ‚Üí 1 percentage point increase in investment rate:\")\n",
    "print(f\"    ‚Ä¢ Short-run: {beta_invest_hat:.3f} pp increase in GDP growth\")\n",
    "print(f\"    ‚Ä¢ Long-run:  {lr_invest:.3f} pp increase in GDP growth\")\n",
    "print(f\"    ‚Ä¢ Multiplier: {dyn_spatial_multiplier:.2f}x\")\n",
    "\n",
    "print(\"\\n  The long-run effect is larger because:\")\n",
    "print(f\"    1. Temporal persistence (Œ≥={gamma_hat:.2f}): past growth feeds into future growth\")\n",
    "print(f\"    2. Spatial spillovers (œÅ={rho_hat:.2f}): neighbors' growth boosts own growth\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "variables = ['Investment', 'Education']\n",
    "sr_effects = [beta_invest_hat, beta_educ_hat]\n",
    "lr_effects = [lr_invest, lr_educ]\n",
    "\n",
    "x = np.arange(len(variables))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, sr_effects, width, label='Short-Run', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, lr_effects, width, label='Long-Run', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Variable', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Effect on GDP Growth', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Short-Run vs Long-Run Effects', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(variables)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/nb07_sr_vs_lr.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Figure saved: ../outputs/figures/nb07_sr_vs_lr.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hansen J-Test (Over-Identification)\n",
    "\n",
    "### Testing Instrument Validity\n",
    "\n",
    "When # instruments > # parameters (over-identified), we can test validity.\n",
    "\n",
    "**Hansen J-statistic**:\n",
    "\n",
    "$$\n",
    "J = n \\cdot g(\\hat{\\theta})' \\hat{W}^{-1} g(\\hat{\\theta}) \\sim \\chi^2(df)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $df = $ # instruments - # parameters\n",
    "- $g(\\hat{\\theta}) = \\frac{1}{n}Z'\\hat{\\varepsilon}$\n",
    "\n",
    "**Hypotheses**:\n",
    "- $H_0$: Instruments are valid (uncorrelated with errors)\n",
    "- $H_A$: At least one instrument is invalid\n",
    "\n",
    "**Decision rule**:\n",
    "- p > 0.05: Fail to reject $H_0$ ‚Üí Instruments valid ‚úì\n",
    "- p < 0.05: Reject $H_0$ ‚Üí Instruments invalid ‚ö†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hansen J-test for over-identification\n",
    "print(\"=\"*70)\n",
    "print(\"HANSEN J-TEST FOR OVER-IDENTIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "n = results_dict['n']\n",
    "k = results_dict['k']\n",
    "Z = results_dict['Z']\n",
    "residuals = results_dict['residuals']\n",
    "\n",
    "# Number of instruments vs parameters\n",
    "num_instruments = Z.shape[1]\n",
    "num_params = k\n",
    "df_hansen = num_instruments - num_params\n",
    "\n",
    "print(f\"\\nNumber of instruments: {num_instruments}\")\n",
    "print(f\"Number of parameters:  {num_params}\")\n",
    "print(f\"Degrees of freedom:    {df_hansen}\")\n",
    "\n",
    "# Compute J-statistic\n",
    "# J = n * (Z'Œµ)' [Z'Z]^{-1} (Z'Œµ) / œÉ^2\n",
    "Ze = Z.T @ residuals / n\n",
    "sigma2 = np.sum(residuals**2) / (n - k)\n",
    "\n",
    "J_stat = n * Ze.T @ inv(Z.T @ Z / n) @ Ze / sigma2\n",
    "p_hansen = 1 - chi2.cdf(J_stat, df_hansen)\n",
    "\n",
    "print(f\"\\nJ-statistic: {J_stat:.4f}\")\n",
    "print(f\"p-value:     {p_hansen:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "if p_hansen > 0.05:\n",
    "    print(\"‚úì Fail to reject H‚ÇÄ ‚Üí Instruments are valid\")\n",
    "    print(\"  ‚Üí Over-identifying restrictions are satisfied\")\n",
    "else:\n",
    "    print(\"‚ö† Reject H‚ÇÄ ‚Üí Instruments may be invalid\")\n",
    "    print(\"  ‚Üí Check for:\")\n",
    "    print(\"    ‚Ä¢ Weak instruments (first-stage F-stat)\")\n",
    "    print(\"    ‚Ä¢ Serial correlation in errors (AR tests)\")\n",
    "    print(\"    ‚Ä¢ Invalid exclusion restrictions\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\nRECOMMENDATIONS:\")\n",
    "print(\"  ‚Ä¢ J-test alone is not sufficient for instrument validity\")\n",
    "print(\"  ‚Ä¢ Also check: AR(2) test, weak instrument diagnostics\")\n",
    "print(\"  ‚Ä¢ Consider difference-in-Sargan for subsets of instruments\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store\n",
    "results_dict['hansen_j'] = J_stat\n",
    "results_dict['hansen_pvalue'] = p_hansen\n",
    "results_dict['hansen_df'] = df_hansen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Impulse-Response Functions\n",
    "\n",
    "### Tracing Shock Propagation\n",
    "\n",
    "An **impulse-response function (IRF)** shows how a one-time shock in region $i$ at time $t$ propagates:\n",
    "- **Over time**: Through temporal persistence ($\\gamma$)\n",
    "- **Across space**: Through spatial spillovers ($\\rho$)\n",
    "\n",
    "### Dynamic Equation\n",
    "\n",
    "Simplified (ignoring $X$):\n",
    "\n",
    "$$\n",
    "y_t = (I - \\rho W)^{-1} \\gamma y_{t-1} + \\text{shock}\n",
    "$$\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Period 0**: Shock hits region $i$\n",
    "- **Period 1**: \n",
    "  - Region $i$: $\\gamma \\times$ shock (persistence)\n",
    "  - Neighbors: $\\rho \\times$ (region $i$'s shock)\n",
    "- **Period 2+**: Continues to decay and diffuse\n",
    "\n",
    "If $0 < \\gamma < 1$ and $|\\rho| < 1/\\lambda_{max}$, the system is stable (shocks dissipate).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and visualize Impulse-Response Function\n",
    "print(\"Computing Impulse-Response Function...\\n\")\n",
    "\n",
    "gamma_hat = results_dict['gamma']\n",
    "rho_hat = results_dict['rho']\n",
    "\n",
    "n_regions = W.n\n",
    "n_periods = 12\n",
    "\n",
    "# Initialize\n",
    "y_irf = np.zeros((n_periods, n_regions))\n",
    "\n",
    "# Unit shock in region 0 at t=0\n",
    "shock_region = 0\n",
    "y_irf[0, shock_region] = 1.0\n",
    "\n",
    "# Propagate shock over time and space\n",
    "I = np.eye(n_regions)\n",
    "A_inv = inv(I - rho_hat * W_dense)\n",
    "\n",
    "for t in range(1, n_periods):\n",
    "    # y_t = (I - œÅW)^{-1} Œ≥ y_{t-1}\n",
    "    y_irf[t, :] = A_inv @ (gamma_hat * y_irf[t-1, :])\n",
    "\n",
    "print(f\"Shock: Unit shock in region {shock_region} at t=0\")\n",
    "print(f\"Propagation: {n_periods} periods\\n\")\n",
    "\n",
    "# Identify neighbors of shocked region\n",
    "neighbor_idx = list(W.neighbors[shock_region])\n",
    "distant_idx = [i for i in range(n_regions) if i not in neighbor_idx and i != shock_region]\n",
    "\n",
    "print(f\"Shocked region:  {shock_region}\")\n",
    "print(f\"Neighbors:       {len(neighbor_idx)} regions\")\n",
    "print(f\"Distant regions: {len(distant_idx)} regions\")\n",
    "\n",
    "# Plot IRF\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "time_periods = np.arange(n_periods)\n",
    "\n",
    "# Shocked region\n",
    "ax.plot(time_periods, y_irf[:, shock_region], marker='o', label=f'Shocked region ({shock_region})',\n",
    "        linewidth=2.5, markersize=8, color='darkred')\n",
    "\n",
    "# Average response in neighbors\n",
    "neighbor_response = y_irf[:, neighbor_idx].mean(axis=1)\n",
    "ax.plot(time_periods, neighbor_response, marker='s',\n",
    "        label=f'Neighbors (avg of {len(neighbor_idx)})', linewidth=2.5, markersize=7, color='darkblue')\n",
    "\n",
    "# Average response in distant regions\n",
    "if len(distant_idx) > 0:\n",
    "    distant_response = y_irf[:, distant_idx].mean(axis=1)\n",
    "    ax.plot(time_periods, distant_response, marker='^',\n",
    "            label=f'Distant regions (avg of {len(distant_idx)})', linewidth=2.5, markersize=7, color='darkgreen')\n",
    "\n",
    "ax.set_xlabel('Time Period', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Response', fontsize=13, fontweight='bold')\n",
    "ax.set_title(f'Impulse-Response Function (Œ≥={gamma_hat:.2f}, œÅ={rho_hat:.2f})',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/nb07_irf.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì IRF plot saved: ../outputs/figures/nb07_irf.png\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(f\"  ‚Üí Shock decays over time (Œ≥ = {gamma_hat:.2f} < 1)\")\n",
    "print(f\"  ‚Üí Shock diffuses to neighbors (œÅ = {rho_hat:.2f} > 0)\")\n",
    "print(f\"  ‚Üí Distant regions affected with delay (multi-step spillovers)\")\n",
    "print(f\"  ‚Üí After {n_periods} periods, response in shocked region: {y_irf[-1, shock_region]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: Time √ó Space\n",
    "print(\"Creating IRF heatmap...\\n\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "im = ax.imshow(y_irf.T, cmap='RdBu_r', aspect='auto', interpolation='nearest',\n",
    "               vmin=-np.abs(y_irf).max(), vmax=np.abs(y_irf).max())\n",
    "\n",
    "ax.set_xlabel('Time Period', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Region Index', fontsize=13, fontweight='bold')\n",
    "ax.set_title(f'Impulse-Response Heatmap: Shock in Region {shock_region}',\n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# Highlight shocked region\n",
    "ax.axhline(shock_region, color='yellow', linestyle='--', linewidth=2, alpha=0.7)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Response Magnitude', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/nb07_irf_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì IRF heatmap saved: ../outputs/figures/nb07_irf_heatmap.png\")\n",
    "\n",
    "print(\"\\nHeatmap shows:\")\n",
    "print(\"  ‚Ä¢ Horizontal axis: Time progression\")\n",
    "print(\"  ‚Ä¢ Vertical axis: All regions (shocked region highlighted)\")\n",
    "print(\"  ‚Ä¢ Color intensity: Response magnitude\")\n",
    "print(\"  ‚Ä¢ Pattern: Shock diffuses spatially and decays temporally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Difference-in-Sargan Test\n",
    "\n",
    "### Testing Subsets of Instruments\n",
    "\n",
    "The **difference-in-Sargan test** compares:\n",
    "- **Full model**: Uses all instruments\n",
    "- **Restricted model**: Excludes subset of instruments\n",
    "\n",
    "**Test statistic**:\n",
    "\n",
    "$$\n",
    "\\Delta J = J_{full} - J_{restricted} \\sim \\chi^2(df)\n",
    "$$\n",
    "\n",
    "Where $df = $ # excluded instruments\n",
    "\n",
    "**Hypotheses**:\n",
    "- $H_0$: Excluded instruments are valid\n",
    "- $H_A$: At least one excluded instrument is invalid\n",
    "\n",
    "**Use case**: Test whether adding more lags improves or harms estimation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference-in-Sargan test\n",
    "print(\"=\"*70)\n",
    "print(\"DIFFERENCE-IN-SARGAN TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nComparing instrument sets:\")\n",
    "print(\"  Full:       y_lag2, y_lag3, W_invest, W_educ\")\n",
    "print(\"  Restricted: y_lag2, W_invest, W_educ (exclude y_lag3)\")\n",
    "\n",
    "# Re-estimate with restricted instrument set (exclude y_lag3)\n",
    "instruments_restricted = data_gmm[['y_lag2', 'W_invest', 'W_educ']].values\n",
    "Z_restricted = np.hstack([instruments_restricted, exog, const])\n",
    "\n",
    "# First stage\n",
    "Pi_r = inv(Z_restricted.T @ Z_restricted) @ Z_restricted.T @ endog\n",
    "X_endog_hat_r = Z_restricted @ Pi_r\n",
    "\n",
    "# Second stage\n",
    "X_r = np.hstack([X_endog_hat_r, exog, const])\n",
    "beta_r = inv(X_r.T @ X_r) @ X_r.T @ y\n",
    "\n",
    "# Residuals\n",
    "residuals_r = y - X_r @ beta_r\n",
    "\n",
    "# J-statistic for restricted model\n",
    "Ze_r = Z_restricted.T @ residuals_r / n\n",
    "sigma2_r = np.sum(residuals_r**2) / (n - k)\n",
    "J_restricted = n * Ze_r.T @ inv(Z_restricted.T @ Z_restricted / n) @ Ze_r / sigma2_r\n",
    "\n",
    "df_restricted = Z_restricted.shape[1] - k\n",
    "\n",
    "# Difference-in-Sargan\n",
    "J_full = results_dict['hansen_j']\n",
    "diff_sargan = J_full - J_restricted\n",
    "diff_df = results_dict['hansen_df'] - df_restricted\n",
    "\n",
    "p_diff = 1 - chi2.cdf(diff_sargan, diff_df)\n",
    "\n",
    "print(f\"\\nJ-statistic (full):       {J_full:.4f}\")\n",
    "print(f\"J-statistic (restricted): {J_restricted:.4f}\")\n",
    "print(f\"\\nDifference:               {diff_sargan:.4f}\")\n",
    "print(f\"df (# excluded):          {diff_df}\")\n",
    "print(f\"p-value:                  {p_diff:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "if p_diff > 0.05:\n",
    "    print(\"‚úì Fail to reject H‚ÇÄ ‚Üí Excluded instruments (y_lag3) are valid\")\n",
    "    print(\"  ‚Üí Using additional lags improves efficiency\")\n",
    "else:\n",
    "    print(\"‚ö† Reject H‚ÇÄ ‚Üí Excluded instruments may be invalid\")\n",
    "    print(\"  ‚Üí Additional lags may not satisfy exclusion restriction\")\n",
    "    print(\"  ‚Üí Possible serial correlation in errors\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Case Study: Regional Economic Growth\n",
    "\n",
    "### Research Questions\n",
    "\n",
    "1. **Do regions converge over time?** ($\\gamma < 1$?)\n",
    "2. **Are there spatial growth spillovers?** ($\\rho > 0$?)\n",
    "3. **What is the long-run impact of investment?** (LR multiplier)\n",
    "\n",
    "### Policy Implications\n",
    "\n",
    "- **Convergence** ($\\gamma < 1$): Poor regions catch up to rich regions\n",
    "- **Spillovers** ($\\rho > 0$): Regional policies have cross-border effects\n",
    "- **LR multipliers**: Short-run evaluations underestimate true impact\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CASE STUDY: REGIONAL ECONOMIC CONVERGENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nResearch Context:\")\n",
    "print(\"  Panel of {} regions over {} years\".format(\n",
    "    data_gmm['entity_id'].nunique(), data_gmm['time'].nunique()))\n",
    "print(\"  Dependent variable: GDP growth rate\")\n",
    "print(\"  Key regressors: Investment rate, education level\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"RESEARCH QUESTIONS & FINDINGS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "gamma_hat = results_dict['gamma']\n",
    "rho_hat = results_dict['rho']\n",
    "beta_invest_hat = results_dict['beta_invest']\n",
    "p_gamma = results_dict['pvalues'][0]\n",
    "p_rho = results_dict['pvalues'][1]\n",
    "\n",
    "# Q1: Convergence?\n",
    "print(\"\\n1. DO REGIONS CONVERGE OVER TIME?\")\n",
    "print(f\"   Œ≥ (persistence) = {gamma_hat:.4f} (p = {p_gamma:.4f})\")\n",
    "\n",
    "if gamma_hat < 1 and p_gamma < 0.05:\n",
    "    convergence_rate = (1 - gamma_hat) * 100\n",
    "    half_life = np.log(0.5) / np.log(gamma_hat)\n",
    "    print(f\"\\n   ‚úì YES - Evidence of convergence\")\n",
    "    print(f\"     ‚Ä¢ Convergence rate: {convergence_rate:.1f}% per year\")\n",
    "    print(f\"     ‚Ä¢ Half-life of shocks: {half_life:.1f} years\")\n",
    "    print(f\"     ‚Ä¢ Implication: Regional disparities diminish over time\")\n",
    "else:\n",
    "    print(f\"\\n   ‚úó NO - No evidence of convergence\")\n",
    "    print(f\"     ‚Ä¢ Shocks may have permanent effects\")\n",
    "\n",
    "# Q2: Spillovers?\n",
    "print(\"\\n2. ARE THERE SPATIAL GROWTH SPILLOVERS?\")\n",
    "print(f\"   œÅ (spatial lag) = {rho_hat:.4f} (p = {p_rho:.4f})\")\n",
    "\n",
    "if rho_hat > 0 and p_rho < 0.05:\n",
    "    print(f\"\\n   ‚úì YES - Positive spatial spillovers detected\")\n",
    "    print(f\"     ‚Ä¢ 1% increase in neighbors' growth ‚Üí {rho_hat:.2f}% own growth\")\n",
    "    print(f\"     ‚Ä¢ Mechanisms: Knowledge diffusion, trade linkages, migration\")\n",
    "    print(f\"     ‚Ä¢ Implication: Coordinated regional policies more effective\")\n",
    "else:\n",
    "    print(f\"\\n   ‚úó NO - No significant spatial spillovers\")\n",
    "\n",
    "# Q3: LR impact\n",
    "print(\"\\n3. WHAT IS THE LONG-RUN IMPACT OF INVESTMENT?\")\n",
    "print(f\"   Short-run effect: {beta_invest_hat:.4f}\")\n",
    "print(f\"   Long-run effect:  {lr_invest:.4f}\")\n",
    "print(f\"   LR multiplier:    {dyn_spatial_multiplier:.2f}x\")\n",
    "\n",
    "print(f\"\\n   ‚Üí 1 pp increase in investment rate:\")\n",
    "print(f\"     ‚Ä¢ Immediate:  +{beta_invest_hat:.3f} pp GDP growth\")\n",
    "print(f\"     ‚Ä¢ Long-run:   +{lr_invest:.3f} pp GDP growth\")\n",
    "print(f\"     ‚Ä¢ Multiplier effect: {dyn_spatial_multiplier:.2f}x\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"POLICY IMPLICATIONS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\n1. DYNAMIC EFFECTS\")\n",
    "print(f\"   ‚Ä¢ Regional investments have long-lasting effects (Œ≥ = {gamma_hat:.2f})\")\n",
    "print(f\"   ‚Ä¢ Short-run evaluations underestimate true impact by {(lr_invest/beta_invest_hat - 1)*100:.0f}%\")\n",
    "\n",
    "print(\"\\n2. SPATIAL COORDINATION\")\n",
    "print(f\"   ‚Ä¢ Spillovers magnify policy effects (œÅ = {rho_hat:.2f})\")\n",
    "print(f\"   ‚Ä¢ Unilateral policies ignore {(dyn_spatial_multiplier - temporal_multiplier)/dyn_spatial_multiplier*100:.0f}% of total effect\")\n",
    "print(f\"   ‚Ä¢ Coordinated regional strategies enhance effectiveness\")\n",
    "\n",
    "print(\"\\n3. TARGETING\")\n",
    "print(f\"   ‚Ä¢ High-spillover regions (central locations) have larger impact\")\n",
    "print(f\"   ‚Ä¢ Network position matters for policy effectiveness\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Diagnostic Tests\n",
    "\n",
    "### Arellano-Bond Serial Correlation Tests\n",
    "\n",
    "For dynamic panels, we test for serial correlation in **first-differenced errors**:\n",
    "\n",
    "- **AR(1) test**: Expected to be significant (differencing induces MA(1))\n",
    "- **AR(2) test**: Should be **insignificant** for valid instruments\n",
    "\n",
    "**Why AR(2) matters**:\n",
    "- If AR(2) is significant ‚Üí $\\varepsilon_{it}$ is serially correlated\n",
    "- Then $y_{i,t-2}$ is **not valid** as instrument for $y_{i,t-1}$\n",
    "- Need deeper lags: $y_{i,t-3}, y_{i,t-4}, \\ldots$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arellano-Bond AR tests (simplified)\n",
    "print(\"=\"*70)\n",
    "print(\"DIAGNOSTIC TESTS: SERIAL CORRELATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compute first-differenced residuals\n",
    "data_gmm_test = data_gmm.copy()\n",
    "data_gmm_test['resid'] = results_dict['residuals']\n",
    "data_gmm_test['resid_lag1'] = data_gmm_test.groupby('entity_id')['resid'].shift(1)\n",
    "data_gmm_test['resid_lag2'] = data_gmm_test.groupby('entity_id')['resid'].shift(2)\n",
    "\n",
    "# AR(1) test: correlation between ŒîŒµ_t and ŒîŒµ_{t-1}\n",
    "data_test1 = data_gmm_test.dropna(subset=['resid', 'resid_lag1'])\n",
    "corr_ar1 = np.corrcoef(data_test1['resid'], data_test1['resid_lag1'])[0, 1]\n",
    "n_ar1 = len(data_test1)\n",
    "z_ar1 = np.sqrt(n_ar1) * corr_ar1\n",
    "p_ar1 = 2 * (1 - stats.norm.cdf(np.abs(z_ar1)))\n",
    "\n",
    "# AR(2) test\n",
    "data_test2 = data_gmm_test.dropna(subset=['resid', 'resid_lag2'])\n",
    "corr_ar2 = np.corrcoef(data_test2['resid'], data_test2['resid_lag2'])[0, 1]\n",
    "n_ar2 = len(data_test2)\n",
    "z_ar2 = np.sqrt(n_ar2) * corr_ar2\n",
    "p_ar2 = 2 * (1 - stats.norm.cdf(np.abs(z_ar2)))\n",
    "\n",
    "print(\"\\nArellano-Bond Tests for Serial Correlation:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Test':<10} {'Correlation':>12} {'z-stat':>10} {'p-value':>10} {'Result'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"{'AR(1)':<10} {corr_ar1:>12.4f} {z_ar1:>10.2f} {p_ar1:>10.4f}\", end=\" \")\n",
    "if p_ar1 < 0.05:\n",
    "    print(\"(Expected)\")\n",
    "else:\n",
    "    print(\"\")\n",
    "\n",
    "print(f\"{'AR(2)':<10} {corr_ar2:>12.4f} {z_ar2:>10.2f} {p_ar2:>10.4f}\", end=\" \")\n",
    "if p_ar2 > 0.05:\n",
    "    print(\"‚úì Valid\")\n",
    "else:\n",
    "    print(\"‚ö† Invalid\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(\"  AR(1): Significant (expected due to differencing)\")\n",
    "\n",
    "if p_ar2 > 0.05:\n",
    "    print(\"  AR(2): ‚úì Insignificant ‚Üí Instruments likely valid\")\n",
    "    print(\"         ‚Üí No second-order serial correlation\")\n",
    "    print(\"         ‚Üí y_{t-2} is valid instrument for Œîy_{t-1}\")\n",
    "else:\n",
    "    print(\"  AR(2): ‚ö† Significant ‚Üí Instrument validity questionable\")\n",
    "    print(\"         ‚Üí Serial correlation detected\")\n",
    "    print(\"         ‚Üí Need deeper lags (y_{t-3}, y_{t-4}, ...)\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Dynamic spatial panels** combine:\n",
    "   - Temporal dynamics: $\\gamma y_{i,t-1}$ (persistence/convergence)\n",
    "   - Spatial dynamics: $\\rho Wy_{it}$ (spillovers/diffusion)\n",
    "\n",
    "2. **Double endogeneity** requires GMM:\n",
    "   - Nickell bias: $y_{i,t-1}$ correlated with $\\alpha_i$\n",
    "   - Spatial endogeneity: $Wy_{it}$ correlated with $\\varepsilon_{it}$\n",
    "\n",
    "3. **Valid instruments**:\n",
    "   - For $y_{i,t-1}$: Temporal lags $y_{i,t-2}, y_{i,t-3}, \\ldots$\n",
    "   - For $Wy_{it}$: Spatial lags of $X$ (WX, W¬≤X) and temporal-spatial lags\n",
    "\n",
    "4. **Short-run ‚â† Long-run**:\n",
    "   - LR multiplier = $\\frac{1}{1 - \\gamma - \\rho\\lambda_{max}}$\n",
    "   - Typical LR/SR ratio: 2-5x\n",
    "\n",
    "5. **Impulse-response functions**:\n",
    "   - Trace shock propagation across space and time\n",
    "   - Visualize decay (temporal) and diffusion (spatial)\n",
    "\n",
    "6. **Diagnostic tests**:\n",
    "   - Hansen J-test: Over-identification\n",
    "   - AR(2) test: Instrument validity\n",
    "   - Difference-in-Sargan: Subset validity\n",
    "\n",
    "---\n",
    "\n",
    "### Applications\n",
    "\n",
    "| Field | Temporal ($\\gamma$) | Spatial ($\\rho$) |\n",
    "|-------|-------------------|------------------|\n",
    "| **Economic growth** | Convergence dynamics | Knowledge spillovers |\n",
    "| **Crime** | Recidivism, persistence | Contagion effects |\n",
    "| **Innovation** | Learning by doing | Technology diffusion |\n",
    "| **Unemployment** | Hysteresis | Labor market linkages |\n",
    "| **Public health** | Disease progression | Spatial transmission |\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Notebook 08**: Comprehensive specification testing\n",
    "- Spatial autocorrelation tests (Moran's I, LM tests)\n",
    "- Model selection (SAR vs SEM vs SDM vs SDEM)\n",
    "- Robustness checks (alternative W matrices)\n",
    "\n",
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "1. **Arellano & Bond (1991)**: \"Some Tests of Specification for Panel Data\"\n",
    "2. **Blundell & Bond (1998)**: \"Initial Conditions and Moment Restrictions\"\n",
    "3. **Elhorst (2014)**: *Spatial Econometrics*\n",
    "4. **Yu et al. (2008)**: \"Quasi-maximum likelihood estimators for spatial dynamic panel data\"\n",
    "5. **Lee & Yu (2010)**: \"Estimation of spatial autoregressive panel data models with fixed effects\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary table\n",
    "print(\"=\"*70)\n",
    "print(\"NOTEBOOK COMPLETION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úì TASKS COMPLETED:\")\n",
    "tasks = [\n",
    "    \"Estimated dynamic spatial panel via GMM\",\n",
    "    \"Constructed valid instruments for double endogeneity\",\n",
    "    \"Computed short-run vs long-run effects\",\n",
    "    \"Performed Hansen J-test for over-identification\",\n",
    "    \"Generated impulse-response functions (line plot + heatmap)\",\n",
    "    \"Conducted difference-in-Sargan test\",\n",
    "    \"Analyzed regional growth convergence case study\",\n",
    "    \"Tested serial correlation (AR tests)\"\n",
    "]\n",
    "\n",
    "for i, task in enumerate(tasks, 1):\n",
    "    print(f\"  {i}. {task}\")\n",
    "\n",
    "print(\"\\nüìä OUTPUTS GENERATED:\")\n",
    "outputs = [\n",
    "    \"../outputs/figures/nb07_sr_vs_lr.png\",\n",
    "    \"../outputs/figures/nb07_irf.png\",\n",
    "    \"../outputs/figures/nb07_irf_heatmap.png\"\n",
    "]\n",
    "\n",
    "for output in outputs:\n",
    "    print(f\"  ‚Ä¢ {output}\")\n",
    "\n",
    "print(\"\\nüéì LEARNING OUTCOMES ACHIEVED:\")\n",
    "outcomes = [\n",
    "    \"Understanding of double endogeneity (Nickell + spatial)\",\n",
    "    \"GMM estimation with valid instruments\",\n",
    "    \"Distinction between short-run and long-run effects\",\n",
    "    \"Interpretation of temporal persistence (Œ≥) and spatial spillovers (œÅ)\",\n",
    "    \"Impulse-response analysis for shock propagation\",\n",
    "    \"Instrument validity testing (Hansen J, Sargan, AR tests)\"\n",
    "]\n",
    "\n",
    "for outcome in outcomes:\n",
    "    print(f\"  ‚úì {outcome}\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è  ESTIMATED COMPLETION TIME: 180-210 minutes\")\n",
    "print(\"\\nüìö NEXT: Notebook 08 - Comprehensive Specification Testing\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
