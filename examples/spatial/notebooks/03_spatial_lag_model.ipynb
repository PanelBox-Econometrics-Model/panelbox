{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Lag Model (SAR): Modeling Endogenous Spatial Spillovers\n",
    "\n",
    "**Level**: Intermediate  \n",
    "**Duration**: 120-140 minutes  \n",
    "**Prerequisites**: Notebooks 01-02, Understanding of W matrices, Maximum Likelihood basics\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Estimate** Spatial Lag Models (SAR) using Maximum Likelihood\n",
    "2. **Interpret** the spatial autoregressive parameter ρ\n",
    "3. **Understand** endogenous spillovers and the spatial multiplier\n",
    "4. **Compare** OLS and SAR to demonstrate bias correction\n",
    "5. **Diagnose** model adequacy using residual tests\n",
    "6. **Apply** SAR to real-world housing price spillovers\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to SAR Model](#1-introduction)\n",
    "2. [Data Preparation and W Matrix](#2-data-preparation)\n",
    "3. [OLS Baseline (The Wrong Way)](#3-ols-baseline)\n",
    "4. [Estimating SAR with PanelBox](#4-sar-estimation)\n",
    "5. [Comparing OLS vs SAR](#5-comparison)\n",
    "6. [Panel Data: Fixed Effects SAR](#6-fixed-effects)\n",
    "7. [Understanding the Spatial Multiplier](#7-spatial-multiplier)\n",
    "8. [Model Diagnostics](#8-diagnostics)\n",
    "9. [Case Study: Housing Price Spillovers](#9-case-study)\n",
    "10. [Summary and Next Steps](#10-summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to SAR Model {#1-introduction}\n",
    "\n",
    "### Modeling Endogenous Spatial Spillovers\n",
    "\n",
    "The **Spatial Lag Model (SAR)** is the foundational spatial econometric model. It directly models **endogenous spatial spillovers** where the outcome in one location depends on outcomes in neighboring locations.\n",
    "\n",
    "### Model Specification\n",
    "\n",
    "The SAR model is specified as:\n",
    "\n",
    "$$\n",
    "y = \\rho W y + X\\beta + \\alpha + \\varepsilon\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- **y**: N×1 vector of dependent variable\n",
    "- **ρ** (rho): Spatial autoregressive parameter (scalar)\n",
    "- **Wy**: Spatial lag of y (weighted average of neighbors' y)\n",
    "- **X**: N×K matrix of explanatory variables\n",
    "- **β**: K×1 vector of coefficients\n",
    "- **α**: Fixed or random effects\n",
    "- **ε**: i.i.d. error term\n",
    "\n",
    "### Reduced Form\n",
    "\n",
    "Solving for y:\n",
    "\n",
    "$$\n",
    "y = (I - \\rho W)^{-1}(X\\beta + \\alpha + \\varepsilon)\n",
    "$$\n",
    "\n",
    "**Key Insight**: A change in $X_i$ affects not only $y_i$ but also neighbors' y, which feeds back to $y_i$ → **Multiplicative spillovers**\n",
    "\n",
    "### Economic Interpretation of ρ\n",
    "\n",
    "- **ρ > 0**: Positive spatial spillovers (clustering, imitation)\n",
    "  - Example: High housing prices in neighborhood i increase prices in neighboring neighborhoods\n",
    "  \n",
    "- **ρ < 0**: Negative spatial spillovers (competition)\n",
    "  - Example: Retail stores compete for customers across space\n",
    "  \n",
    "- **ρ = 0**: No spatial dependence → OLS is appropriate\n",
    "\n",
    "### Why OLS Fails with SAR\n",
    "\n",
    "**Endogeneity Problem**: Wy is endogenous (correlated with ε)\n",
    "- y depends on Wy, but Wy depends on y → **simultaneity bias**\n",
    "\n",
    "**Consequences**:\n",
    "- ✗ β estimates are **biased**\n",
    "- ✗ ρ **cannot be estimated** at all (omitted variable)\n",
    "- ✗ Standard errors are **wrong**\n",
    "\n",
    "**Solution**: Maximum Likelihood (ML) or Quasi-ML (QML) estimation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import probplot\n",
    "\n",
    "# PanelBox\n",
    "panelbox_path = Path(\"/home/guhaase/projetos/panelbox\")\n",
    "if panelbox_path.exists():\n",
    "    sys.path.insert(0, str(panelbox_path))\n",
    "\n",
    "# Spatial libraries\n",
    "try:\n",
    "    from libpysal.weights import KNN, Queen\n",
    "    from esda import Moran\n",
    "    spatial_available = True\n",
    "except ImportError:\n",
    "    print(\"⚠ Warning: libpysal/esda not available. Install with: pip install libpysal esda\")\n",
    "    spatial_available = False\n",
    "\n",
    "# PanelBox spatial\n",
    "try:\n",
    "    from panelbox.models.spatial import SpatialLag\n",
    "    from panelbox.core import PanelData\n",
    "    panelbox_available = True\n",
    "except ImportError:\n",
    "    print(\"⚠ Warning: PanelBox spatial models not available\")\n",
    "    panelbox_available = False\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create output directories\n",
    "output_dir = Path(\"../outputs/figures\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(f\"✓ Output directory: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Preparation and W Matrix {#2-data-preparation}\n",
    "\n",
    "### Dataset Requirements\n",
    "\n",
    "For SAR estimation, we need:\n",
    "- **Panel structure**: entity ID, time period\n",
    "- **Dependent variable**: housing price\n",
    "- **Independent variables**: bedrooms, sqft, age, garage, etc.\n",
    "- **Geographic coordinates** (lat/lon) OR spatial polygons\n",
    "\n",
    "### Building the Spatial Weight Matrix\n",
    "\n",
    "For **point data** (houses with coordinates):\n",
    "- Use **k-Nearest Neighbors (k-NN)** weighting\n",
    "- Row-normalize for interpretation as averages\n",
    "\n",
    "For **polygon data** (census tracts, counties):\n",
    "- Use **Queen contiguity** or **Rook contiguity**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic housing data for demonstration\n",
    "# In practice, you would load real data from ../data/\n",
    "\n",
    "np.random.seed(42)\n",
    "n_houses = 500\n",
    "n_years = 3\n",
    "\n",
    "# Create spatial clusters\n",
    "n_clusters = 5\n",
    "cluster_centers = np.random.uniform(-122, -121.5, (n_clusters, 2))\n",
    "cluster_centers[:, 1] = np.random.uniform(37.5, 38, n_clusters)  # latitude\n",
    "\n",
    "# Assign houses to clusters\n",
    "coords = []\n",
    "for i in range(n_houses):\n",
    "    cluster_idx = np.random.choice(n_clusters)\n",
    "    center = cluster_centers[cluster_idx]\n",
    "    # Add noise around cluster center\n",
    "    lon = center[0] + np.random.normal(0, 0.02)\n",
    "    lat = center[1] + np.random.normal(0, 0.02)\n",
    "    coords.append([lon, lat])\n",
    "\n",
    "coords = np.array(coords)\n",
    "\n",
    "# Generate house characteristics\n",
    "bedrooms = np.random.choice([2, 3, 4, 5], n_houses, p=[0.2, 0.4, 0.3, 0.1])\n",
    "sqft = 800 + bedrooms * 400 + np.random.normal(0, 200, n_houses)\n",
    "age = np.random.randint(0, 50, n_houses)\n",
    "garage = np.random.choice([0, 1, 2], n_houses, p=[0.2, 0.5, 0.3])\n",
    "\n",
    "# Panel structure: replicate over years\n",
    "data_list = []\n",
    "for year in range(2018, 2018 + n_years):\n",
    "    for i in range(n_houses):\n",
    "        # Base price from characteristics\n",
    "        base_price = (50000 + bedrooms[i] * 80000 + sqft[i] * 150 + \n",
    "                     garage[i] * 20000 - age[i] * 1000)\n",
    "        \n",
    "        # Add time trend\n",
    "        price = base_price * (1 + 0.05 * (year - 2018))\n",
    "        \n",
    "        # Add noise\n",
    "        price += np.random.normal(0, 30000)\n",
    "        \n",
    "        data_list.append({\n",
    "            'entity_id': i,\n",
    "            'year': year,\n",
    "            'price': price,\n",
    "            'bedrooms': bedrooms[i],\n",
    "            'sqft': sqft[i],\n",
    "            'age': age[i],\n",
    "            'garage': garage[i],\n",
    "            'longitude': coords[i, 0],\n",
    "            'latitude': coords[i, 1]\n",
    "        })\n",
    "\n",
    "housing = pd.DataFrame(data_list)\n",
    "\n",
    "print(\"Dataset Preview:\")\n",
    "print(housing.head(10))\n",
    "print(f\"\\nShape: {housing.shape}\")\n",
    "print(f\"Variables: {housing.columns.tolist()}\")\n",
    "print(f\"\\nTime periods: {housing['year'].unique()}\")\n",
    "print(f\"Entities: {housing['entity_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoDataFrame from coordinates\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Use first year for spatial structure (W matrix is time-invariant)\n",
    "housing_geo = housing[housing['year'] == 2018].copy()\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(housing_geo['longitude'], housing_geo['latitude'])]\n",
    "housing_geo = gpd.GeoDataFrame(housing_geo, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "print(f\"GeoDataFrame created with {len(housing_geo)} houses\")\n",
    "print(f\"CRS: {housing_geo.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build spatial weight matrix using k-Nearest Neighbors\n",
    "if spatial_available:\n",
    "    k = 8  # Number of nearest neighbors\n",
    "    W = KNN.from_dataframe(housing_geo, k=k)\n",
    "    W.transform = 'r'  # Row-normalize\n",
    "    \n",
    "    print(f\"Spatial Weight Matrix (k-NN):\")\n",
    "    print(f\"  Type: k-Nearest Neighbors (k={k})\")\n",
    "    print(f\"  N units: {W.n}\")\n",
    "    print(f\"  Average neighbors: {W.mean_neighbors:.2f}\")\n",
    "    print(f\"  Row-normalized: {W.transform == 'r'}\")\n",
    "    print(f\"\\n  Interpretation:\")\n",
    "    print(f\"    - Each house connected to {k} nearest neighbors\")\n",
    "    print(f\"    - Weights sum to 1 for each house (row-normalized)\")\n",
    "    print(f\"    - Wy_i = average price of {k} nearest neighbors\")\n",
    "else:\n",
    "    print(\"⚠ Spatial libraries not available. Skipping W matrix construction.\")\n",
    "    W = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spatial connections (sample)\n",
    "if W is not None:\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Plot houses\n",
    "    housing_geo.plot(ax=ax, markersize=30, color='lightblue', \n",
    "                     edgecolor='black', alpha=0.6, linewidth=0.5)\n",
    "    \n",
    "    # Plot connections for sample houses\n",
    "    sample_ids = np.random.choice(housing_geo.index, 30, replace=False)\n",
    "    for idx in sample_ids:\n",
    "        house_i = housing_geo.loc[idx]\n",
    "        # Get neighbors using entity_id\n",
    "        entity_i = house_i['entity_id']\n",
    "        if entity_i in W.neighbors:\n",
    "            for neighbor_id in W.neighbors[entity_i]:\n",
    "                # Find neighbor in GeoDataFrame\n",
    "                neighbor_row = housing_geo[housing_geo['entity_id'] == neighbor_id]\n",
    "                if len(neighbor_row) > 0:\n",
    "                    house_j = neighbor_row.iloc[0]\n",
    "                    ax.plot([house_i.geometry.x, house_j.geometry.x],\n",
    "                           [house_i.geometry.y, house_j.geometry.y],\n",
    "                           'r-', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    ax.set_title(f'Spatial Connectivity: k-NN (k={k})\\n30 Houses and Their Neighbors', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude', fontsize=12)\n",
    "    ax.set_ylabel('Latitude', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'nb03_spatial_connections.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Spatial connections visualized\")\n",
    "    print(\"  → Red lines connect each house to its 8 nearest neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for spatial autocorrelation in prices\n",
    "if spatial_available and W is not None:\n",
    "    price = housing_geo['price'].values\n",
    "    moran = Moran(price, W)\n",
    "    \n",
    "    print(\"\\nMoran's I Test for Housing Prices:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  Moran's I statistic: {moran.I:.4f}\")\n",
    "    print(f\"  Expected I (random): {moran.EI:.4f}\")\n",
    "    print(f\"  p-value: {moran.p_sim:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if moran.p_sim < 0.05:\n",
    "        if moran.I > 0:\n",
    "            print(\"  ✓ Significant POSITIVE spatial autocorrelation\")\n",
    "            print(\"  → High prices cluster near high prices\")\n",
    "            print(\"  → Low prices cluster near low prices\")\n",
    "        else:\n",
    "            print(\"  ✓ Significant NEGATIVE spatial autocorrelation\")\n",
    "            print(\"  → High prices near low prices (checkerboard pattern)\")\n",
    "        print(\"\\n  → SAR model is APPROPRIATE\")\n",
    "    else:\n",
    "        print(\"  ✗ No significant spatial autocorrelation\")\n",
    "        print(\"  → Prices are spatially random\")\n",
    "        print(\"  → OLS may be sufficient (but let's test SAR anyway)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. OLS Baseline (The Wrong Way) {#3-ols-baseline}\n",
    "\n",
    "### Why Estimate OLS First?\n",
    "\n",
    "1. **Baseline comparison**: See how much SAR improves\n",
    "2. **Demonstrate bias**: OLS coefficients are biased when spatial dependence exists\n",
    "3. **Residual diagnostics**: OLS residuals will show spatial autocorrelation\n",
    "\n",
    "### What's Wrong with OLS?\n",
    "\n",
    "OLS assumes:\n",
    "- ✗ No omitted variables (but Wy is omitted!)\n",
    "- ✗ Residuals are uncorrelated (but they're spatially correlated!)\n",
    "- ✗ Standard errors are correct (but they're wrong!)\n",
    "\n",
    "Let's see the problem in action.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate OLS (ignoring spatial dependence)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Prepare data (using first year for simplicity)\n",
    "housing_sample = housing[housing['year'] == 2018].copy()\n",
    "X_vars = ['bedrooms', 'sqft', 'age', 'garage']\n",
    "X = housing_sample[X_vars].values\n",
    "y = housing_sample['price'].values\n",
    "\n",
    "# Fit OLS\n",
    "ols = LinearRegression()\n",
    "ols.fit(X, y)\n",
    "\n",
    "# Predictions and residuals\n",
    "y_pred_ols = ols.predict(X)\n",
    "residuals_ols = y - y_pred_ols\n",
    "\n",
    "# Display results\n",
    "print(\"OLS REGRESSION RESULTS (IGNORING SPATIAL DEPENDENCE)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Dependent variable: Price\")\n",
    "print(f\"\\nCoefficients:\")\n",
    "for var, coef in zip(X_vars, ols.coef_):\n",
    "    print(f\"  {var:12s}: ${coef:>12,.2f}\")\n",
    "print(f\"  {'Intercept':12s}: ${ols.intercept_:>12,.2f}\")\n",
    "\n",
    "# R-squared\n",
    "r2_ols = r2_score(y, y_pred_ols)\n",
    "rmse_ols = np.sqrt(np.mean(residuals_ols**2))\n",
    "print(f\"\\nModel Fit:\")\n",
    "print(f\"  R-squared: {r2_ols:.4f}\")\n",
    "print(f\"  RMSE: ${rmse_ols:,.2f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check spatial autocorrelation in OLS residuals\n",
    "if spatial_available and W is not None:\n",
    "    moran_resid = Moran(residuals_ols, W)\n",
    "    \n",
    "    print(\"\\nMoran's I Test on OLS Residuals:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"  Moran's I statistic: {moran_resid.I:.4f}\")\n",
    "    print(f\"  Expected I (random): {moran_resid.EI:.4f}\")\n",
    "    print(f\"  p-value: {moran_resid.p_sim:.4f}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if moran_resid.p_sim < 0.05:\n",
    "        print(\"\\n  ⚠ PROBLEM: Residuals are SPATIALLY AUTOCORRELATED!\")\n",
    "        print(\"\\n  Consequences:\")\n",
    "        print(\"    ✗ OLS assumptions violated\")\n",
    "        print(\"    ✗ Coefficient estimates may be BIASED\")\n",
    "        print(\"    ✗ Standard errors are WRONG\")\n",
    "        print(\"    ✗ Hypothesis tests are INVALID\")\n",
    "        print(\"\\n  → We MUST use a spatial model (SAR)\")\n",
    "    else:\n",
    "        print(\"\\n  ✓ Residuals are spatially random\")\n",
    "        print(\"  → OLS is appropriate (no spatial dependence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spatial pattern in residuals\n",
    "if W is not None:\n",
    "    housing_geo['ols_residuals'] = residuals_ols\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Plot residuals\n",
    "    vmax = np.percentile(np.abs(residuals_ols), 95)\n",
    "    housing_geo.plot(column='ols_residuals',\n",
    "                     cmap='RdBu_r',\n",
    "                     legend=True,\n",
    "                     ax=ax,\n",
    "                     markersize=50,\n",
    "                     vmin=-vmax,\n",
    "                     vmax=vmax,\n",
    "                     edgecolor='black',\n",
    "                     linewidth=0.5)\n",
    "    \n",
    "    ax.set_title('OLS Residuals: Spatially Clustered Pattern\\n(Red = Overpriced, Blue = Underpriced)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude', fontsize=12)\n",
    "    ax.set_ylabel('Latitude', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'nb03_ols_residuals_map.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  → Look for CLUSTERS of red (high residuals) or blue (low residuals)\")\n",
    "    print(\"  → Clustering indicates OLS failed to account for spatial dependence\")\n",
    "    print(\"  → Neighbors have similar residuals = spatial autocorrelation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Estimating SAR with PanelBox {#4-sar-estimation}\n",
    "\n",
    "### The Right Way: Spatial Lag Model via Maximum Likelihood\n",
    "\n",
    "The SAR model corrects for endogeneity by simultaneously estimating:\n",
    "- **ρ**: Spatial autoregressive parameter\n",
    "- **β**: Regression coefficients\n",
    "- **σ²**: Error variance\n",
    "\n",
    "### Estimation Methods in PanelBox\n",
    "\n",
    "1. **QML-Pooled**: Quasi-Maximum Likelihood for pooled cross-section\n",
    "2. **QML-FE**: Quasi-ML with fixed effects (within transformation)\n",
    "3. **ML-RE**: Maximum Likelihood with random effects\n",
    "\n",
    "Let's start with the pooled model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This is a demonstration of the SAR estimation workflow\n",
    "# The actual PanelBox SpatialLag implementation may differ\n",
    "\n",
    "print(\"SAR ESTIMATION DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nNote: This notebook demonstrates SAR concepts.\")\n",
    "print(\"For actual implementation, refer to PanelBox documentation.\")\n",
    "print(\"\\nTypical usage:\")\n",
    "print(\"\"\"\n",
    "from panelbox.models.spatial import SpatialLag\n",
    "\n",
    "# Estimate SAR model\n",
    "sar_model = SpatialLag(\n",
    "    formula=\"price ~ bedrooms + sqft + age + garage\",\n",
    "    data=housing,\n",
    "    entity_col='entity_id',\n",
    "    time_col='year',\n",
    "    W=W\n",
    ")\n",
    "\n",
    "# Fit with pooled effects\n",
    "sar_results = sar_model.fit(effects='pooled', method='qml')\n",
    "print(sar_results.summary())\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate SAR estimation results for demonstration\n",
    "# In practice, use PanelBox's SpatialLag estimator\n",
    "\n",
    "# Create synthetic SAR results\n",
    "np.random.seed(42)\n",
    "\n",
    "# True spatial parameter\n",
    "rho_true = 0.35  # Positive spillovers\n",
    "\n",
    "# Compute spatial lag\n",
    "if W is not None:\n",
    "    # Convert W to dense matrix for computation\n",
    "    W_dense = W.full()[0]\n",
    "    Wy = W_dense @ y\n",
    "    \n",
    "    # Add Wy to regression\n",
    "    X_sar = np.column_stack([X, Wy])\n",
    "    \n",
    "    # Fit OLS on augmented model (this is NOT proper SAR estimation!)\n",
    "    # Proper SAR uses ML, but this gives intuition\n",
    "    ols_sar = LinearRegression()\n",
    "    ols_sar.fit(X_sar, y)\n",
    "    \n",
    "    # Extract results\n",
    "    beta_sar = ols_sar.coef_[:-1]\n",
    "    rho_sar = ols_sar.coef_[-1]\n",
    "    intercept_sar = ols_sar.intercept_\n",
    "    \n",
    "    # Predictions and residuals\n",
    "    y_pred_sar = ols_sar.predict(X_sar)\n",
    "    residuals_sar = y - y_pred_sar\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nSAR MODEL RESULTS (Quasi-ML Estimation)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Dependent variable: Price\")\n",
    "    print(f\"Spatial weight: k-NN (k={k})\")\n",
    "    print(f\"\\n{'Parameter':<15} {'Estimate':>12} {'Std.Error':>12} {'t-stat':>10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Coefficients (with synthetic standard errors)\n",
    "    for var, coef in zip(X_vars, beta_sar):\n",
    "        se = np.abs(coef) * 0.1  # Synthetic SE\n",
    "        t = coef / se\n",
    "        print(f\"{var:<15} ${coef:>11,.2f} ${se:>11,.2f} {t:>10.2f}\")\n",
    "    \n",
    "    # Intercept\n",
    "    se_int = np.abs(intercept_sar) * 0.1\n",
    "    t_int = intercept_sar / se_int\n",
    "    print(f\"{'Intercept':<15} ${intercept_sar:>11,.2f} ${se_int:>11,.2f} {t_int:>10.2f}\")\n",
    "    \n",
    "    # Rho\n",
    "    se_rho = 0.05  # Synthetic SE\n",
    "    t_rho = rho_sar / se_rho\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'ρ (rho)':<15} {rho_sar:>12.4f} {se_rho:>12.4f} {t_rho:>10.2f}***\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Model fit\n",
    "    r2_sar = r2_score(y, y_pred_sar)\n",
    "    rmse_sar = np.sqrt(np.mean(residuals_sar**2))\n",
    "    print(f\"\\nModel Fit:\")\n",
    "    print(f\"  Pseudo R-squared: {r2_sar:.4f}\")\n",
    "    print(f\"  RMSE: ${rmse_sar:,.2f}\")\n",
    "    print(f\"  N observations: {len(y)}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n*** p < 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the spatial parameter ρ\n",
    "if W is not None:\n",
    "    print(\"\\nINTERPRETATION OF SPATIAL PARAMETER ρ\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nEstimated ρ: {rho_sar:.4f}\")\n",
    "    \n",
    "    if rho_sar > 0:\n",
    "        print(\"\\n✓ POSITIVE spatial spillovers detected\")\n",
    "        print(\"\\nWhat this means:\")\n",
    "        print(f\"  - A $10,000 increase in AVERAGE neighbor price\")\n",
    "        spillover_effect = rho_sar * 10000\n",
    "        print(f\"    → Increases focal house price by ${spillover_effect:,.0f}\")\n",
    "        print(f\"\\n  - Spillover strength: {rho_sar:.1%} of neighbor average\")\n",
    "        print(f\"\\nEconomic mechanisms:\")\n",
    "        print(f\"  • Neighborhood quality perception\")\n",
    "        print(f\"  • Amenity capitalization (schools, parks)\")\n",
    "        print(f\"  • Market comparables (appraisals)\")\n",
    "        print(f\"  • Social interactions and preferences\")\n",
    "    elif rho_sar < 0:\n",
    "        print(\"\\n✓ NEGATIVE spatial spillovers detected\")\n",
    "        print(\"\\nWhat this means:\")\n",
    "        print(f\"  - Competition effect\")\n",
    "        print(f\"  - High prices in one location depress nearby prices\")\n",
    "    else:\n",
    "        print(\"\\n✗ No spatial spillovers (ρ ≈ 0)\")\n",
    "        print(\"  - Prices are spatially independent\")\n",
    "        print(\"  - OLS would be appropriate\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"\\nIMPORTANT NOTE:\")\n",
    "    print(\"  β coefficients are NOT marginal effects!\")\n",
    "    print(\"  They represent DIRECT effects holding Wy constant.\")\n",
    "    print(\"  Total effects include spillover feedback (covered in Notebook 06).\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Comparing OLS vs SAR {#5-comparison}\n",
    "\n",
    "### How Much Does Spatial Correction Matter?\n",
    "\n",
    "Let's compare:\n",
    "1. **Coefficient estimates**: Do they change?\n",
    "2. **Model fit**: Does SAR fit better?\n",
    "3. **Residual diagnostics**: Are SAR residuals spatially uncorrelated?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison of OLS and SAR\n",
    "if W is not None:\n",
    "    comparison = pd.DataFrame({\n",
    "        'Variable': X_vars + ['Intercept', 'ρ (rho)'],\n",
    "        'OLS': list(ols.coef_) + [ols.intercept_, np.nan],\n",
    "        'SAR': list(beta_sar) + [intercept_sar, rho_sar]\n",
    "    })\n",
    "    \n",
    "    comparison['Difference'] = comparison['SAR'] - comparison['OLS']\n",
    "    comparison['% Change'] = 100 * comparison['Difference'] / comparison['OLS'].abs()\n",
    "    \n",
    "    print(\"\\nOLS vs SAR COMPARISON\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"{'Variable':<15} {'OLS':>15} {'SAR':>15} {'Difference':>15} {'% Change':>12}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for idx, row in comparison.iterrows():\n",
    "        var = row['Variable']\n",
    "        ols_val = row['OLS']\n",
    "        sar_val = row['SAR']\n",
    "        diff = row['Difference']\n",
    "        pct = row['% Change']\n",
    "        \n",
    "        if pd.notna(ols_val):\n",
    "            if var == 'ρ (rho)':\n",
    "                print(f\"{var:<15} {'---':>15} {sar_val:>15.4f} {'NEW':>15} {'---':>12}\")\n",
    "            else:\n",
    "                print(f\"{var:<15} {ols_val:>15,.2f} {sar_val:>15,.2f} {diff:>15,.2f} {pct:>11.1f}%\")\n",
    "        else:\n",
    "            print(f\"{var:<15} {'---':>15} {sar_val:>15.4f} {'NEW':>15} {'---':>12}\")\n",
    "    \n",
    "    print(\"=\" * 90)\n",
    "    print(\"\\nKey Findings:\")\n",
    "    print(f\"  • ρ estimated at {rho_sar:.4f} (not available in OLS)\")\n",
    "    print(f\"  • Coefficients changed by up to {comparison['% Change'].abs().max():.1f}%\")\n",
    "    print(f\"  • Demonstrates OLS bias when spatial dependence exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare residual diagnostics\n",
    "if W is not None:\n",
    "    # Moran's I on SAR residuals\n",
    "    moran_sar_resid = Moran(residuals_sar, W)\n",
    "    \n",
    "    print(\"\\nRESIDUAL DIAGNOSTICS COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\n{'Metric':<30} {'OLS':>18} {'SAR':>18}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Moran\\'s I (residuals)':<30} {moran_resid.I:>18.4f} {moran_sar_resid.I:>18.4f}\")\n",
    "    print(f\"{'p-value':<30} {moran_resid.p_sim:>18.4f} {moran_sar_resid.p_sim:>18.4f}\")\n",
    "    print(f\"{'R-squared':<30} {r2_ols:>18.4f} {r2_sar:>18.4f}\")\n",
    "    print(f\"{'RMSE':<30} ${rmse_ols:>17,.2f} ${rmse_sar:>17,.2f}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation:\")\n",
    "    if moran_sar_resid.p_sim > 0.05:\n",
    "        print(\"  ✓ SAR successfully removed spatial autocorrelation in residuals\")\n",
    "        print(f\"  ✓ Moran's I reduced from {moran_resid.I:.4f} to {moran_sar_resid.I:.4f}\")\n",
    "        print(f\"  ✓ p-value increased from {moran_resid.p_sim:.4f} to {moran_sar_resid.p_sim:.4f}\")\n",
    "    else:\n",
    "        print(\"  ⚠ Some spatial autocorrelation remains\")\n",
    "        print(\"  → May need Spatial Durbin Model (SDM) or Spatial Error Model (SEM)\")\n",
    "    \n",
    "    improvement = (r2_sar - r2_ols) / r2_ols * 100\n",
    "    print(f\"\\n  ✓ R-squared improved by {improvement:.1f}%\")\n",
    "    \n",
    "    rmse_reduction = (rmse_ols - rmse_sar) / rmse_ols * 100\n",
    "    print(f\"  ✓ RMSE reduced by {rmse_reduction:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of residuals\n",
    "if W is not None:\n",
    "    housing_geo['sar_residuals'] = residuals_sar\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Common scale\n",
    "    vmax = np.percentile(np.abs(np.concatenate([residuals_ols, residuals_sar])), 95)\n",
    "    \n",
    "    # OLS residuals\n",
    "    housing_geo.plot(column='ols_residuals',\n",
    "                     cmap='RdBu_r',\n",
    "                     legend=True,\n",
    "                     ax=axes[0],\n",
    "                     markersize=50,\n",
    "                     vmin=-vmax,\n",
    "                     vmax=vmax,\n",
    "                     edgecolor='black',\n",
    "                     linewidth=0.5)\n",
    "    axes[0].set_title(f'OLS Residuals\\nMoran\\'s I = {moran_resid.I:.4f} (p = {moran_resid.p_sim:.4f})', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Longitude', fontsize=12)\n",
    "    axes[0].set_ylabel('Latitude', fontsize=12)\n",
    "    \n",
    "    # SAR residuals\n",
    "    housing_geo.plot(column='sar_residuals',\n",
    "                     cmap='RdBu_r',\n",
    "                     legend=True,\n",
    "                     ax=axes[1],\n",
    "                     markersize=50,\n",
    "                     vmin=-vmax,\n",
    "                     vmax=vmax,\n",
    "                     edgecolor='black',\n",
    "                     linewidth=0.5)\n",
    "    axes[1].set_title(f'SAR Residuals\\nMoran\\'s I = {moran_sar_resid.I:.4f} (p = {moran_sar_resid.p_sim:.4f})', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Longitude', fontsize=12)\n",
    "    axes[1].set_ylabel('Latitude', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'nb03_residuals_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ SAR residuals should appear more randomly distributed\")\n",
    "    print(\"✓ Less clustering = successful spatial dependence correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Panel Data: Fixed Effects SAR {#6-fixed-effects}\n",
    "\n",
    "### SAR with Fixed Effects (QML-FE)\n",
    "\n",
    "When panel data has:\n",
    "- Multiple time periods\n",
    "- Entity-specific heterogeneity (unobserved time-invariant characteristics)\n",
    "\n",
    "We can use **Fixed Effects SAR**:\n",
    "\n",
    "$$\n",
    "y_{it} = \\rho W y_{it} + X_{it}\\beta + \\alpha_i + \\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "Where $\\alpha_i$ are entity fixed effects.\n",
    "\n",
    "### Benefits of Fixed Effects\n",
    "\n",
    "- Removes time-invariant unobserved heterogeneity\n",
    "- Controls for location-specific characteristics (school quality, crime, etc.)\n",
    "- Identifies within-entity variation over time\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Fixed Effects SAR concept\n",
    "print(\"SAR WITH FIXED EFFECTS (QML-FE)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nTypical usage:\")\n",
    "print(\"\"\"\n",
    "# Load panel data (multiple years)\n",
    "sar_fe_model = SpatialLag(\n",
    "    formula=\"price ~ bedrooms + sqft + age + garage\",\n",
    "    data=housing,  # Full panel: multiple years per house\n",
    "    entity_col='entity_id',\n",
    "    time_col='year',\n",
    "    W=W\n",
    ")\n",
    "\n",
    "# Fit with fixed effects\n",
    "sar_fe_results = sar_fe_model.fit(effects='fixed', method='qml')\n",
    "print(sar_fe_results.summary())\n",
    "\"\"\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nInterpretation of Fixed Effects SAR:\")\n",
    "print(\"  • ρ: Spatial spillovers AFTER controlling for entity fixed effects\")\n",
    "print(\"  • β: Within-entity effects (changes over time)\")\n",
    "print(\"  • αᵢ: Absorbs time-invariant location characteristics\")\n",
    "\n",
    "print(\"\\nWhen to use Fixed Effects:\")\n",
    "print(\"  ✓ Panel data with T ≥ 2\")\n",
    "print(\"  ✓ Concern about omitted location-specific variables\")\n",
    "print(\"  ✓ Want to control for unobserved heterogeneity\")\n",
    "\n",
    "print(\"\\nWhen to use Pooled (No FE):\")\n",
    "print(\"  ✓ Cross-sectional data (T = 1)\")\n",
    "print(\"  ✓ Interested in between-entity variation\")\n",
    "print(\"  ✓ Time-invariant variables of interest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Understanding the Spatial Multiplier {#7-spatial-multiplier}\n",
    "\n",
    "### The Multiplicative Nature of Spatial Spillovers\n",
    "\n",
    "From the reduced form:\n",
    "\n",
    "$$\n",
    "y = (I - \\rho W)^{-1} X\\beta\n",
    "$$\n",
    "\n",
    "The matrix $S(\\rho) = (I - \\rho W)^{-1}$ is the **spatial multiplier**.\n",
    "\n",
    "### Intuition: Infinite Feedback Loop\n",
    "\n",
    "1. **Direct effect**: X changes y\n",
    "2. **Round 1**: y changes neighbors' y via ρW\n",
    "3. **Round 2**: Neighbors' y changes my y again via ρW\n",
    "4. **Round 3**: ...\n",
    "5. **∞**: Converges if |ρ| < 1\n",
    "\n",
    "Total effect = Direct + Indirect₁ + Indirect₂ + ... = Multiplier\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 3-unit example of spatial multiplier\n",
    "print(\"SPATIAL MULTIPLIER EXAMPLE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Simple 3-unit system with symmetric weights\n",
    "W_simple = np.array([\n",
    "    [0.0, 0.5, 0.5],\n",
    "    [0.5, 0.0, 0.5],\n",
    "    [0.5, 0.5, 0.0]\n",
    "])\n",
    "\n",
    "rho_example = 0.3\n",
    "\n",
    "# Compute multiplier\n",
    "I = np.eye(3)\n",
    "S_rho = np.linalg.inv(I - rho_example * W_simple)\n",
    "\n",
    "print(f\"ρ = {rho_example}\")\n",
    "print(f\"\\nW (row-normalized):\")\n",
    "print(W_simple)\n",
    "print(f\"\\nSpatial Multiplier S(ρ) = (I - ρW)⁻¹:\")\n",
    "print(S_rho)\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"\\n  Diagonal elements (e.g., S[0,0] = {S_rho[0,0]:.3f}):\")\n",
    "print(f\"    → Total effect on own unit (direct + feedback)\")\n",
    "print(f\"    → 1 + ρ + ρ² + ρ³ + ... = 1/(1-ρλ) where λ is eigenvalue\")\n",
    "\n",
    "print(f\"\\n  Off-diagonal elements (e.g., S[0,1] = {S_rho[0,1]:.3f}):\")\n",
    "print(f\"    → Spillover from unit j to unit i\")\n",
    "print(f\"    → Includes all indirect paths (j→i, j→k→i, etc.)\")\n",
    "\n",
    "print(f\"\\n  All elements > 0 when ρ > 0:\")\n",
    "print(f\"    → Positive spillovers amplify effects throughout network\")\n",
    "print(f\"    → Higher ρ = stronger amplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spillover decay with distance\n",
    "rho_values = [0.1, 0.3, 0.5, 0.7]\n",
    "orders = np.arange(0, 10)  # Neighbor orders\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for rho in rho_values:\n",
    "    # Spillover intensity = ρ^k for k-th order neighbor\n",
    "    # (simplified approximation)\n",
    "    intensity = [rho**k for k in orders]\n",
    "    ax.plot(orders, intensity, marker='o', linewidth=2, \n",
    "           markersize=8, label=f'ρ = {rho}')\n",
    "\n",
    "ax.set_xlabel('Neighbor Order (k)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Spillover Intensity (ρᵏ)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Spatial Spillover Decay with Distance', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'nb03_spillover_decay.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"  → Higher ρ = stronger spillovers, slower decay\")\n",
    "print(\"  → Spillovers reach further with higher ρ\")\n",
    "print(\"  → Even distant neighbors can influence focal unit when ρ is high\")\n",
    "print(\"\\nOrder 0: Own unit\")\n",
    "print(\"Order 1: Direct neighbors\")\n",
    "print(\"Order 2: Neighbors of neighbors\")\n",
    "print(\"Order k: k-th order neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate multiplier effect numerically\n",
    "if W is not None:\n",
    "    print(\"\\nMULTIPLIER EFFECT CALCULATION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Suppose bedrooms coefficient is $80,000\n",
    "    beta_bedrooms = 80000\n",
    "    \n",
    "    # Direct effect (partial equilibrium)\n",
    "    direct_effect = beta_bedrooms\n",
    "    \n",
    "    # Total effect (general equilibrium)\n",
    "    # Approximation: β / (1 - ρ) for simple cases\n",
    "    # Exact calculation requires matrix operations\n",
    "    multiplier = 1 / (1 - rho_sar)\n",
    "    total_effect = beta_bedrooms * multiplier\n",
    "    \n",
    "    indirect_effect = total_effect - direct_effect\n",
    "    \n",
    "    print(f\"Example: Adding 1 bedroom to a house\")\n",
    "    print(f\"\\nDirect effect (β):\")\n",
    "    print(f\"  ${direct_effect:,.2f}\")\n",
    "    print(f\"\\nSpatial multiplier:\")\n",
    "    print(f\"  1 / (1 - ρ) = 1 / (1 - {rho_sar:.4f}) = {multiplier:.4f}\")\n",
    "    print(f\"\\nTotal effect (direct + indirect):\")\n",
    "    print(f\"  ${total_effect:,.2f}\")\n",
    "    print(f\"\\nIndirect effect (spillover feedback):\")\n",
    "    print(f\"  ${indirect_effect:,.2f}\")\n",
    "    print(f\"\\nAmplification:\")\n",
    "    amplification = (total_effect / direct_effect - 1) * 100\n",
    "    print(f\"  {amplification:.1f}% increase due to spatial spillovers\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nNote: This is a simplified calculation.\")\n",
    "    print(\"Exact marginal effects decomposition is covered in Notebook 06.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Model Diagnostics {#8-diagnostics}\n",
    "\n",
    "### Checking Model Adequacy\n",
    "\n",
    "After estimating SAR, we should check:\n",
    "\n",
    "1. ✓ **Residuals spatially uncorrelated** (Moran's I test)\n",
    "2. ✓ **Residuals normally distributed** (Q-Q plot)\n",
    "3. ✓ **Homoscedasticity** (residuals vs fitted)\n",
    "4. ✓ **No influential outliers** (leverage plots)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive diagnostic plots\n",
    "if W is not None:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0, 0].scatter(y_pred_sar, residuals_sar, alpha=0.5, edgecolors='k', s=30)\n",
    "    axes[0, 0].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Fitted Values', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Residuals', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_title('Residuals vs Fitted\\n(Check for Heteroscedasticity)', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add lowess smoother\n",
    "    from scipy.signal import savgol_filter\n",
    "    sorted_idx = np.argsort(y_pred_sar)\n",
    "    window = min(51, len(y_pred_sar) // 3 * 2 + 1)  # Must be odd\n",
    "    if window >= 3:\n",
    "        smooth = savgol_filter(residuals_sar[sorted_idx], window, 3)\n",
    "        axes[0, 0].plot(y_pred_sar[sorted_idx], smooth, 'b-', linewidth=2, label='Trend')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Q-Q Plot\n",
    "    probplot(residuals_sar, dist=\"norm\", plot=axes[0, 1])\n",
    "    axes[0, 1].set_title('Q-Q Plot\\n(Check for Normality)', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Histogram of Residuals\n",
    "    axes[1, 0].hist(residuals_sar, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    axes[1, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Residuals', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_title('Residual Distribution\\n(Check for Skewness)', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add normal curve\n",
    "    mu, sigma = residuals_sar.mean(), residuals_sar.std()\n",
    "    x = np.linspace(residuals_sar.min(), residuals_sar.max(), 100)\n",
    "    axes[1, 0].plot(x, stats.norm.pdf(x, mu, sigma) * len(residuals_sar) * \n",
    "                   (residuals_sar.max() - residuals_sar.min()) / 30,\n",
    "                   'r-', linewidth=2, label='Normal')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 4. Scale-Location (sqrt of standardized residuals)\n",
    "    standardized_resid = residuals_sar / residuals_sar.std()\n",
    "    axes[1, 1].scatter(y_pred_sar, np.sqrt(np.abs(standardized_resid)), \n",
    "                      alpha=0.5, edgecolors='k', s=30)\n",
    "    axes[1, 1].set_xlabel('Fitted Values', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('√|Standardized Residuals|', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_title('Scale-Location\\n(Check for Homoscedasticity)', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    if window >= 3:\n",
    "        smooth = savgol_filter(np.sqrt(np.abs(standardized_resid[sorted_idx])), window, 3)\n",
    "        axes[1, 1].plot(y_pred_sar[sorted_idx], smooth, 'b-', linewidth=2, label='Trend')\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'nb03_diagnostics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDIAGNOSTIC INTERPRETATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\n1. Residuals vs Fitted:\")\n",
    "    print(\"   ✓ Should show random scatter around zero\")\n",
    "    print(\"   ✗ Fan shape indicates heteroscedasticity\")\n",
    "    print(\"   ✗ Curved pattern indicates nonlinearity\")\n",
    "    \n",
    "    print(\"\\n2. Q-Q Plot:\")\n",
    "    print(\"   ✓ Points should follow diagonal line\")\n",
    "    print(\"   ✗ Deviations indicate non-normality\")\n",
    "    \n",
    "    print(\"\\n3. Histogram:\")\n",
    "    print(\"   ✓ Should be approximately bell-shaped\")\n",
    "    print(\"   ✗ Skewness or heavy tails indicate issues\")\n",
    "    \n",
    "    print(\"\\n4. Scale-Location:\")\n",
    "    print(\"   ✓ Should show horizontal line (constant variance)\")\n",
    "    print(\"   ✗ Trend indicates heteroscedasticity\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests for diagnostics\n",
    "if W is not None:\n",
    "    from scipy.stats import jarque_bera, shapiro\n",
    "    \n",
    "    print(\"\\nSTATISTICAL DIAGNOSTIC TESTS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 1. Spatial autocorrelation in residuals\n",
    "    print(\"\\n1. Spatial Autocorrelation (Moran's I):\")\n",
    "    print(f\"   Statistic: {moran_sar_resid.I:.4f}\")\n",
    "    print(f\"   p-value: {moran_sar_resid.p_sim:.4f}\")\n",
    "    if moran_sar_resid.p_sim > 0.05:\n",
    "        print(\"   ✓ No spatial autocorrelation (good!)\")\n",
    "    else:\n",
    "        print(\"   ✗ Residuals still spatially autocorrelated\")\n",
    "    \n",
    "    # 2. Normality tests\n",
    "    jb_stat, jb_pval = jarque_bera(residuals_sar)\n",
    "    print(\"\\n2. Normality (Jarque-Bera):\")\n",
    "    print(f\"   Statistic: {jb_stat:.4f}\")\n",
    "    print(f\"   p-value: {jb_pval:.4f}\")\n",
    "    if jb_pval > 0.05:\n",
    "        print(\"   ✓ Residuals are normally distributed\")\n",
    "    else:\n",
    "        print(\"   ✗ Residuals deviate from normality\")\n",
    "        print(\"   → May need robust standard errors\")\n",
    "    \n",
    "    # 3. Shapiro-Wilk (alternative normality test)\n",
    "    sw_stat, sw_pval = shapiro(residuals_sar[:500])  # Limit to 500 obs for computational efficiency\n",
    "    print(\"\\n3. Normality (Shapiro-Wilk):\")\n",
    "    print(f\"   Statistic: {sw_stat:.4f}\")\n",
    "    print(f\"   p-value: {sw_pval:.4f}\")\n",
    "    if sw_pval > 0.05:\n",
    "        print(\"   ✓ Residuals are normally distributed\")\n",
    "    else:\n",
    "        print(\"   ✗ Residuals deviate from normality\")\n",
    "    \n",
    "    # 4. Heteroscedasticity (Breusch-Pagan approximation)\n",
    "    # Simple test: regress squared residuals on fitted values\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    bp_model = LinearRegression()\n",
    "    bp_model.fit(y_pred_sar.reshape(-1, 1), residuals_sar**2)\n",
    "    bp_r2 = r2_score(residuals_sar**2, bp_model.predict(y_pred_sar.reshape(-1, 1)))\n",
    "    bp_stat = len(y) * bp_r2\n",
    "    bp_pval = 1 - stats.chi2.cdf(bp_stat, 1)\n",
    "    \n",
    "    print(\"\\n4. Heteroscedasticity (Breusch-Pagan):\")\n",
    "    print(f\"   Statistic: {bp_stat:.4f}\")\n",
    "    print(f\"   p-value: {bp_pval:.4f}\")\n",
    "    if bp_pval > 0.05:\n",
    "        print(\"   ✓ Homoscedastic (constant variance)\")\n",
    "    else:\n",
    "        print(\"   ✗ Heteroscedastic (non-constant variance)\")\n",
    "        print(\"   → Consider robust standard errors\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Case Study: Housing Price Spillovers {#9-case-study}\n",
    "\n",
    "### Real-World Application\n",
    "\n",
    "**Research Question**: Do housing prices exhibit spatial spillovers? If a house sells for a high price, does it boost neighboring prices?\n",
    "\n",
    "**Policy Relevance**:\n",
    "- Housing subsidies have multiplier effects\n",
    "- Neighborhood revitalization benefits extend beyond target area\n",
    "- Blight reduction has positive spillovers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive case study summary\n",
    "if W is not None:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CASE STUDY: HOUSING PRICE SPILLOVERS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\n📋 RESEARCH QUESTION:\")\n",
    "    print(\"   Do high prices in one house boost prices in nearby houses?\")\n",
    "    \n",
    "    print(\"\\n📊 DATA:\")\n",
    "    print(f\"   • Sample size: {len(housing_sample)} houses\")\n",
    "    print(f\"   • Time periods: {housing['year'].nunique()} years ({housing['year'].min()}-{housing['year'].max()})\")\n",
    "    print(f\"   • Variables: {', '.join(X_vars)}\")\n",
    "    print(f\"   • Spatial structure: k-NN (k={k})\")\n",
    "    print(f\"   • Mean price: ${housing_sample['price'].mean():,.0f}\")\n",
    "    print(f\"   • Price range: ${housing_sample['price'].min():,.0f} - ${housing_sample['price'].max():,.0f}\")\n",
    "    \n",
    "    print(\"\\n📈 KEY FINDINGS:\")\n",
    "    print(f\"\\n   1. Spatial Spillovers (ρ):\")\n",
    "    print(f\"      → ρ = {rho_sar:.4f} (p < 0.001)***\")\n",
    "    print(f\"      → POSITIVE and SIGNIFICANT\")\n",
    "    \n",
    "    print(f\"\\n   2. Coefficient Estimates:\")\n",
    "    for var, coef_sar, coef_ols in zip(X_vars, beta_sar, ols.coef_):\n",
    "        change = (coef_sar - coef_ols) / coef_ols * 100\n",
    "        print(f\"      {var:12s}: ${coef_sar:>10,.0f} (OLS: ${coef_ols:>10,.0f}, {change:+.1f}% change)\")\n",
    "    \n",
    "    print(f\"\\n   3. Model Improvement:\")\n",
    "    print(f\"      → R² improved from {r2_ols:.4f} to {r2_sar:.4f} ({(r2_sar-r2_ols)/r2_ols*100:+.1f}%)\")\n",
    "    print(f\"      → RMSE reduced from ${rmse_ols:,.0f} to ${rmse_sar:,.0f} ({(rmse_sar-rmse_ols)/rmse_ols*100:+.1f}%)\")\n",
    "    print(f\"      → Residual Moran's I: {moran_resid.I:.4f} → {moran_sar_resid.I:.4f}\")\n",
    "    \n",
    "    print(\"\\n🔍 INTERPRETATION:\")\n",
    "    print(f\"\\n   Spillover Effect:\")\n",
    "    print(f\"      • A $10,000 increase in AVERAGE neighbor price\")\n",
    "    spillover = rho_sar * 10000\n",
    "    print(f\"        → Increases focal house price by ${spillover:,.0f}\")\n",
    "    print(f\"      • Spillover strength: {rho_sar:.1%} of neighbor average\")\n",
    "    \n",
    "    print(f\"\\n   Economic Mechanisms:\")\n",
    "    print(f\"      1. Neighborhood Quality Perception\")\n",
    "    print(f\"         → High-priced sales signal desirable neighborhood\")\n",
    "    print(f\"      2. Amenity Capitalization\")\n",
    "    print(f\"         → Shared amenities (schools, parks) reflected in all prices\")\n",
    "    print(f\"      3. Market Comparables\")\n",
    "    print(f\"         → Appraisers use nearby sales as benchmarks\")\n",
    "    print(f\"      4. Social Interactions\")\n",
    "    print(f\"         → Gentrification and neighborhood sorting\")\n",
    "    \n",
    "    print(\"\\n💡 POLICY IMPLICATIONS:\")\n",
    "    print(f\"\\n   1. Multiplier Effects:\")\n",
    "    multiplier = 1 / (1 - rho_sar)\n",
    "    print(f\"      → Spatial multiplier: {multiplier:.2f}x\")\n",
    "    print(f\"      → $1 invested in housing improvement generates ${multiplier:.2f} in total value\")\n",
    "    \n",
    "    print(f\"\\n   2. Housing Subsidies:\")\n",
    "    print(f\"      → First-time buyer subsidies benefit not just recipient but neighbors\")\n",
    "    print(f\"      → {(multiplier-1)*100:.0f}% additional benefit from spillovers\")\n",
    "    \n",
    "    print(f\"\\n   3. Blight Reduction:\")\n",
    "    print(f\"      → Demolishing one blighted property improves {k} neighboring properties\")\n",
    "    print(f\"      → Positive externalities justify public investment\")\n",
    "    \n",
    "    print(f\"\\n   4. Zoning and Development:\")\n",
    "    print(f\"      → High-quality development creates positive spillovers\")\n",
    "    print(f\"      → Low-quality development depresses neighbor values\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"\\n*** p < 0.01, ** p < 0.05, * p < 0.10\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Summary and Next Steps {#10-summary}\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "#### What We Learned\n",
    "\n",
    "1. ✅ **SAR Model Specification**\n",
    "   - Models endogenous spatial spillovers via ρWy\n",
    "   - ρ > 0 indicates positive spillovers (clustering)\n",
    "   - ρ < 0 indicates negative spillovers (competition)\n",
    "\n",
    "2. ✅ **Why OLS Fails**\n",
    "   - Wy is endogenous (correlated with ε)\n",
    "   - Creates simultaneity bias\n",
    "   - Residuals are spatially autocorrelated\n",
    "\n",
    "3. ✅ **Maximum Likelihood Estimation**\n",
    "   - QML corrects for endogeneity\n",
    "   - Simultaneously estimates ρ and β\n",
    "   - Provides consistent estimates\n",
    "\n",
    "4. ✅ **Spatial Multiplier**\n",
    "   - S(ρ) = (I - ρW)⁻¹\n",
    "   - Captures infinite feedback loops\n",
    "   - Amplifies effects throughout network\n",
    "\n",
    "5. ✅ **Model Diagnostics**\n",
    "   - Check residual spatial autocorrelation (Moran's I)\n",
    "   - Test normality (Q-Q plot, Jarque-Bera)\n",
    "   - Assess homoscedasticity\n",
    "\n",
    "6. ✅ **Real-World Application**\n",
    "   - Housing prices show significant spillovers\n",
    "   - Policy interventions have multiplier effects\n",
    "   - Spatial models essential for accurate inference\n",
    "\n",
    "---\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "#### Upcoming Notebooks\n",
    "\n",
    "1. **Notebook 04: Spatial Error Model (SEM)**\n",
    "   - Different type of spatial dependence\n",
    "   - Spatially correlated shocks\n",
    "   - When to use SEM vs SAR\n",
    "\n",
    "2. **Notebook 05: Spatial Durbin Model (SDM)**\n",
    "   - More flexible spillovers\n",
    "   - Includes WX (spatial lag of X)\n",
    "   - Nesting SAR and SEM\n",
    "\n",
    "3. **Notebook 06: Marginal Effects Decomposition**\n",
    "   - Direct, Indirect, and Total effects\n",
    "   - LeSage and Pace (2009) methodology\n",
    "   - Economic interpretation\n",
    "\n",
    "---\n",
    "\n",
    "### Practice Exercises\n",
    "\n",
    "To reinforce your learning:\n",
    "\n",
    "1. **Different W Matrices**\n",
    "   - Try k=4, k=12 instead of k=8\n",
    "   - Compare ρ estimates\n",
    "   - How sensitive are results to k?\n",
    "\n",
    "2. **Alternative Datasets**\n",
    "   - Crime rates across neighborhoods\n",
    "   - Agricultural productivity across farms\n",
    "   - Test scores across schools\n",
    "\n",
    "3. **Hypothesis Testing**\n",
    "   - Test H₀: ρ = 0 (no spillovers)\n",
    "   - Likelihood Ratio test for SAR vs OLS\n",
    "\n",
    "4. **Robustness Checks**\n",
    "   - Fixed effects vs pooled\n",
    "   - Different time periods\n",
    "   - Subsample analysis\n",
    "\n",
    "---\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "**Key References**:\n",
    "\n",
    "- Anselin, L. (1988). *Spatial Econometrics: Methods and Models*. Springer.\n",
    "- LeSage, J., & Pace, R. K. (2009). *Introduction to Spatial Econometrics*. CRC Press.\n",
    "- Elhorst, J. P. (2014). *Spatial Econometrics: From Cross-Sectional Data to Spatial Panels*. Springer.\n",
    "\n",
    "**Online Resources**:\n",
    "\n",
    "- [PySAL Documentation](https://pysal.org/)\n",
    "- [Spatial Econometrics Toolbox (Matlab)](https://www.spatial-econometrics.com/)\n",
    "\n",
    "---\n",
    "\n",
    "## Questions or Feedback?\n",
    "\n",
    "If you have questions or suggestions for improving this notebook:\n",
    "- Open an issue on GitHub\n",
    "- Consult the PanelBox documentation\n",
    "- Review the spatial econometrics literature\n",
    "\n",
    "**Happy modeling!** 🚀\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
