{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Case Study: Innovation and Patents\n",
    "## Integrating All Count Model Techniques\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "1. Apply complete count data modeling workflow to a real research question\n",
    "2. Systematically compare multiple model specifications\n",
    "3. Conduct rigorous model selection using statistical tests\n",
    "4. Compute and interpret marginal effects for policy analysis\n",
    "5. Perform robustness checks and sensitivity analysis\n",
    "6. Present results in publication-quality format\n",
    "7. Draw substantive conclusions for innovation policy\n",
    "\n",
    "### Duration\n",
    "90-120 minutes (comprehensive case study)\n",
    "\n",
    "### Prerequisites\n",
    "**ALL previous notebooks (01-06) must be completed:**\n",
    "- 01: Poisson Introduction\n",
    "- 02: Negative Binomial\n",
    "- 03: Fixed/Random Effects Count\n",
    "- 04: PPML Gravity\n",
    "- 05: Zero-Inflated Models\n",
    "- 06: Marginal Effects\n",
    "\n",
    "### Dataset\n",
    "**Firm Innovation** (`firm_innovation_full.csv`): Manufacturing firms' patent activity.\n",
    "- N = 500 firms x T = 8 years (2012-2019) = 4,000 observations\n",
    "- Outcome: `patents` (count, 0-35)\n",
    "- Key predictors: `rd_intensity`, `firm_size`, `capital_intensity`, `industry`, `year`\n",
    "- Characteristics: ~39% zeros, severe overdispersion (Var/Mean ~ 14.4)"
   ],
   "id": "md0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "\n",
    "# PanelBox imports\n",
    "import statsmodels.api as sm\n",
    "from panelbox.models.count import (\n",
    "    PooledPoisson,\n",
    "    PoissonFixedEffects,\n",
    "    NegativeBinomial,\n",
    "    ZeroInflatedPoisson,\n",
    "    ZeroInflatedNegativeBinomial,\n",
    ")\n",
    "from panelbox.marginal_effects.count_me import (\n",
    "    compute_poisson_ame,\n",
    "    compute_negbin_ame,\n",
    ")\n",
    "\n",
    "# Visualization configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "np.random.seed(303)\n",
    "\n",
    "# Paths (relative to notebook location in examples/count/notebooks/)\n",
    "BASE_DIR = Path('..')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "FIGURES_DIR = OUTPUT_DIR / 'figures' / '07_case_study'\n",
    "TABLES_DIR = OUTPUT_DIR / 'tables' / '07_case_study'\n",
    "\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Setup complete!')\n",
    "print(f'Data directory: {DATA_DIR}')\n",
    "print(f'Figures directory: {FIGURES_DIR}')\n",
    "print(f'Tables directory: {TABLES_DIR}')"
   ],
   "id": "code1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Research Question and Context (10 min)\n",
    "\n",
    "### Central Question\n",
    "\n",
    "*What are the determinants of firm-level innovation, and how effective are R&D investments in generating patents?*\n",
    "\n",
    "### Policy Relevance\n",
    "- **R&D tax credits**: Are they justified by the R&D-patent relationship?\n",
    "- **Firm size and innovation**: Do small firms need special support?\n",
    "- **Industry differences**: Should policies be targeted or broad-based?\n",
    "\n",
    "### Literature Context\n",
    "- Griliches (1990): Knowledge production functions\n",
    "- Hall, Griliches & Hausman (1986): Patents and R&D relationship\n",
    "- Aghion et al. (2005): Competition and innovation\n",
    "\n",
    "### Economic Framework\n",
    "\n",
    "Knowledge Production Function:\n",
    "$$\\text{Patents}_{it} = f(\\text{R\\&D}_{it}, \\text{Size}_{it}, \\text{Industry}_i, \\text{Time}_t, \\text{Firm Effect}_i)$$"
   ],
   "id": "md2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(DATA_DIR / 'firm_innovation_full.csv')\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Firms: {df[\"firm_id\"].nunique()}')\n",
    "print(f'Years: {df[\"year\"].min()}-{df[\"year\"].max()}')\n",
    "print(f'\\nFirst few rows:')\n",
    "display(df.head(10))\n",
    "\n",
    "print(f'\\nVariable types:')\n",
    "print(df.dtypes)"
   ],
   "id": "code3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 01: Descriptive statistics\n",
    "desc_stats = df.describe().T\n",
    "desc_stats['zeros'] = (df == 0).sum()\n",
    "desc_stats['pct_zeros'] = (df == 0).mean() * 100\n",
    "\n",
    "print('Table 01: Descriptive Statistics')\n",
    "print('=' * 80)\n",
    "display(desc_stats[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']])\n",
    "\n",
    "# Key statistics\n",
    "print(f'\\nKey Facts:')\n",
    "print(f'  Mean patents: {df[\"patents\"].mean():.2f}')\n",
    "print(f'  Variance patents: {df[\"patents\"].var():.2f}')\n",
    "print(f'  Zero patents: {(df[\"patents\"]==0).mean():.1%}')\n",
    "print(f'  Overdispersion index (Var/Mean): {df[\"patents\"].var()/df[\"patents\"].mean():.2f}')\n",
    "print(f'  Mean R&D intensity: {df[\"rd_intensity\"].mean():.2f}%')\n",
    "\n",
    "desc_stats.to_csv(TABLES_DIR / 'table_01_descriptive_stats.csv')"
   ],
   "id": "code4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Patent distribution (highly skewed)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Panel 1: Patent distribution\n",
    "max_val = min(df['patents'].max(), 30)\n",
    "axes[0].hist(df['patents'], bins=np.arange(-0.5, max_val + 1.5, 1),\n",
    "             alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].axvline(df['patents'].mean(), color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Mean = {df[\"patents\"].mean():.1f}')\n",
    "axes[0].set_xlabel('Number of Patents', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Patents\\n(Highly Right-Skewed)', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Panel 2: R&D distribution\n",
    "axes[1].hist(df['rd_intensity'], bins=40, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[1].axvline(df['rd_intensity'].mean(), color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Mean = {df[\"rd_intensity\"].mean():.1f}%')\n",
    "axes[1].set_xlabel('R&D Intensity (%)', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Distribution of R&D Intensity', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Panel 3: Correlation heatmap\n",
    "corr_vars = ['patents', 'rd_intensity', 'firm_size', 'capital_intensity', 'export_share', 'hhi']\n",
    "corr_matrix = df[corr_vars].corr()\n",
    "im = axes[2].imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')\n",
    "axes[2].set_xticks(range(len(corr_vars)))\n",
    "axes[2].set_xticklabels(corr_vars, rotation=45, ha='right', fontsize=9)\n",
    "axes[2].set_yticks(range(len(corr_vars)))\n",
    "axes[2].set_yticklabels(corr_vars, fontsize=9)\n",
    "for i in range(len(corr_vars)):\n",
    "    for j in range(len(corr_vars)):\n",
    "        axes[2].text(j, i, f'{corr_matrix.iloc[i,j]:.2f}', ha='center', va='center', fontsize=8)\n",
    "axes[2].set_title('Correlation Matrix', fontsize=13, fontweight='bold')\n",
    "plt.colorbar(im, ax=axes[2], shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'patents_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Patents vs R&D and Zeros by industry\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Patents vs R&D scatter\n",
    "axes[0].scatter(df['rd_intensity'], df['patents'], alpha=0.15, s=15, color='steelblue')\n",
    "rd_bins = pd.qcut(df['rd_intensity'], 20, duplicates='drop')\n",
    "rd_means = df.groupby(rd_bins, observed=True)['patents'].mean()\n",
    "rd_centers = df.groupby(rd_bins, observed=True)['rd_intensity'].mean()\n",
    "axes[0].plot(rd_centers.values, rd_means.values, 'r-o', linewidth=2, markersize=5,\n",
    "             label='Binned mean')\n",
    "axes[0].set_xlabel('R&D Intensity (%)', fontsize=12)\n",
    "axes[0].set_ylabel('Patents', fontsize=12)\n",
    "axes[0].set_title('Patents vs R&D Intensity', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Panel 2: Zeros by industry\n",
    "industry_names = {1: 'Chem/Pharma', 2: 'Electronics', 3: 'Automotive',\n",
    "                  4: 'Machinery', 5: 'Food/Bev', 6: 'Textiles',\n",
    "                  7: 'Metals', 8: 'Other Mfg'}\n",
    "df['industry_name'] = df['industry'].map(industry_names)\n",
    "\n",
    "zeros_by_ind = df.groupby('industry_name')['patents'].apply(\n",
    "    lambda x: (x == 0).mean() * 100\n",
    ").sort_values()\n",
    "\n",
    "bars = axes[1].barh(range(len(zeros_by_ind)), zeros_by_ind.values,\n",
    "                    color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_yticks(range(len(zeros_by_ind)))\n",
    "axes[1].set_yticklabels(zeros_by_ind.index)\n",
    "axes[1].set_xlabel('% Zero Patents', fontsize=12)\n",
    "axes[1].set_title('Zero Patents by Industry', fontsize=13, fontweight='bold')\n",
    "axes[1].axvline(df['patents'].eq(0).mean() * 100, color='red', linestyle='--',\n",
    "                linewidth=2, label=f'Overall: {(df[\"patents\"]==0).mean():.0%}')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'patents_vs_rd.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(FIGURES_DIR / 'zeros_by_industry.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Exploratory Data Analysis (15 min)\n",
    "\n",
    "### Goals\n",
    "1. Quantify overdispersion\n",
    "2. Detect excess zeros\n",
    "3. Examine panel structure\n",
    "4. Check for outliers"
   ],
   "id": "md7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Overdispersion Analysis\n",
    "mean_patents = df['patents'].mean()\n",
    "var_patents = df['patents'].var()\n",
    "overdispersion_index = var_patents / mean_patents\n",
    "\n",
    "print('2.1 Overdispersion Analysis')\n",
    "print('=' * 50)\n",
    "print(f'Mean(patents):          {mean_patents:.2f}')\n",
    "print(f'Variance(patents):      {var_patents:.2f}')\n",
    "print(f'Overdispersion index:   {overdispersion_index:.2f}')\n",
    "print(f'\\nConclusion: Severe overdispersion (Var/Mean = {overdispersion_index:.1f} >> 1)')\n",
    "print(f'=> Poisson is likely misspecified. Negative Binomial needed.')\n",
    "\n",
    "# By industry\n",
    "print(f'\\nOverdispersion by Industry:')\n",
    "for ind_name, group in df.groupby('industry_name'):\n",
    "    m = group['patents'].mean()\n",
    "    v = group['patents'].var()\n",
    "    if m > 0:\n",
    "        print(f'  {ind_name:20s}: Mean={m:.2f}, Var={v:.2f}, Var/Mean={v/m:.2f}')"
   ],
   "id": "code8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Zero-Inflation Check\n",
    "observed_zero_pct = (df['patents'] == 0).mean()\n",
    "\n",
    "# Predicted P(y=0) under Poisson with unconditional mean\n",
    "lambda_prelim = mean_patents\n",
    "poisson_predicted_zero = np.exp(-lambda_prelim)\n",
    "\n",
    "print('2.2 Zero-Inflation Check')\n",
    "print('=' * 50)\n",
    "print(f'Observed % zeros:     {observed_zero_pct:.1%}')\n",
    "print(f'Poisson predicted:    {poisson_predicted_zero:.1%} (using overall mean)')\n",
    "print(f'Excess zeros:         {observed_zero_pct - poisson_predicted_zero:.1%}')\n",
    "print(f'\\nConclusion: Substantial excess zeros ({observed_zero_pct:.0%} vs {poisson_predicted_zero:.0%})')\n",
    "print(f'=> Zero-inflated models (ZIP/ZINB) likely appropriate.')"
   ],
   "id": "code9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Overdispersion and zero-inflation diagnostics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Variance-mean by industry\n",
    "ind_stats = df.groupby('industry_name')['patents'].agg(['mean', 'var'])\n",
    "axes[0].scatter(ind_stats['mean'], ind_stats['var'], s=100, zorder=5,\n",
    "                color='steelblue', edgecolors='black')\n",
    "max_val = max(ind_stats['mean'].max(), ind_stats['var'].max()) * 1.1\n",
    "axes[0].plot([0, max_val], [0, max_val], 'r--', linewidth=2, label='Var = Mean (Poisson)')\n",
    "for idx, row in ind_stats.iterrows():\n",
    "    axes[0].annotate(idx, (row['mean'], row['var']), fontsize=8,\n",
    "                     xytext=(5, 5), textcoords='offset points')\n",
    "axes[0].set_xlabel('Mean', fontsize=12)\n",
    "axes[0].set_ylabel('Variance', fontsize=12)\n",
    "axes[0].set_title('Variance-Mean Plot by Industry\\n(All above Poisson line)', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Panel 2: Observed vs Poisson-predicted distribution\n",
    "max_count = min(int(df['patents'].quantile(0.98)), 25)\n",
    "count_range = np.arange(0, max_count + 1)\n",
    "observed_freq = np.array([(df['patents'] == k).sum() for k in count_range])\n",
    "poisson_freq = np.array([len(df) * stats.poisson.pmf(k, mean_patents) for k in count_range])\n",
    "\n",
    "width = 0.35\n",
    "axes[1].bar(count_range - width/2, observed_freq, width, label='Observed',\n",
    "            color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[1].bar(count_range + width/2, poisson_freq, width, label='Poisson Predicted',\n",
    "            color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Patent Count', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Observed vs Poisson-Predicted\\n(Excess zeros visible)', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'overdispersion_check.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(FIGURES_DIR / 'zero_inflation_check.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Panel Structure\n",
    "print('2.3 Panel Structure')\n",
    "print('=' * 50)\n",
    "print(f'Firms: {df[\"firm_id\"].nunique()}')\n",
    "print(f'Years: {df[\"year\"].nunique()} ({df[\"year\"].min()}-{df[\"year\"].max()})')\n",
    "print(f'Obs per firm: {df.groupby(\"firm_id\").size().describe()[[\"min\",\"max\",\"mean\"]]}')\n",
    "print(f'\\nPanel: {\"Balanced\" if df.groupby(\"firm_id\").size().nunique() == 1 else \"Unbalanced\"}')\n",
    "\n",
    "# Within vs between variance\n",
    "overall_var = df['patents'].var()\n",
    "between_var = df.groupby('firm_id')['patents'].mean().var()\n",
    "within_var = df.groupby('firm_id')['patents'].apply(lambda x: x.var()).mean()\n",
    "\n",
    "print(f'\\nVariance Decomposition:')\n",
    "print(f'  Overall variance:  {overall_var:.2f}')\n",
    "print(f'  Between variance:  {between_var:.2f} ({between_var/overall_var:.0%})')\n",
    "print(f'  Within variance:   {within_var:.2f} ({within_var/overall_var:.0%})')\n",
    "print(f'\\n=> Most variation is between firms, suggesting firm FE important.')"
   ],
   "id": "code11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Panel structure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Patents over time\n",
    "yearly = df.groupby('year')['patents'].agg(['mean', 'std', 'sum'])\n",
    "axes[0].plot(yearly.index, yearly['mean'], 'o-', linewidth=2, markersize=8, color='steelblue')\n",
    "axes[0].fill_between(yearly.index,\n",
    "                     yearly['mean'] - yearly['std'] / np.sqrt(500),\n",
    "                     yearly['mean'] + yearly['std'] / np.sqrt(500),\n",
    "                     alpha=0.2, color='steelblue')\n",
    "axes[0].set_xlabel('Year', fontsize=12)\n",
    "axes[0].set_ylabel('Mean Patents', fontsize=12)\n",
    "axes[0].set_title('Average Patents Over Time\\n(with 95% CI)', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Panel 2: Firm-level time series (10 random firms)\n",
    "np.random.seed(42)\n",
    "sample_firms = np.random.choice(df['firm_id'].unique(), 10, replace=False)\n",
    "for fid in sample_firms:\n",
    "    firm_data = df[df['firm_id'] == fid].sort_values('year')\n",
    "    axes[1].plot(firm_data['year'], firm_data['patents'], marker='o', alpha=0.6,\n",
    "                 label=f'Firm {fid}')\n",
    "axes[1].set_xlabel('Year', fontsize=12)\n",
    "axes[1].set_ylabel('Patents', fontsize=12)\n",
    "axes[1].set_title('Patent Trends for Selected Firms', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'panel_structure_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Outlier Detection\n",
    "print('2.4 Outlier Detection')\n",
    "print('=' * 50)\n",
    "\n",
    "top_firms = df.groupby('firm_id')['patents'].mean().nlargest(10)\n",
    "print('Top 10 Patent Firms (by mean patents):')\n",
    "for fid, mean_pat in top_firms.items():\n",
    "    firm_data = df[df['firm_id'] == fid]\n",
    "    print(f'  Firm {fid}: mean={mean_pat:.1f}, max={firm_data[\"patents\"].max()}, '\n",
    "          f'R&D={firm_data[\"rd_intensity\"].mean():.1f}%')\n",
    "\n",
    "p99 = df['patents'].quantile(0.99)\n",
    "n_outliers = (df['patents'] > p99).sum()\n",
    "mean_without = df[df['patents'] <= p99]['patents'].mean()\n",
    "print(f'\\nTop 1% threshold: {p99:.0f} patents')\n",
    "print(f'N above threshold: {n_outliers}')\n",
    "print(f'Mean with outliers: {mean_patents:.2f}')\n",
    "print(f'Mean without top 1%: {mean_without:.2f}')\n",
    "\n",
    "# Save EDA summary\n",
    "eda_summary = pd.DataFrame({\n",
    "    'Metric': ['Mean', 'Variance', 'Var/Mean', '% Zeros', 'Between Var', 'Within Var', 'P99'],\n",
    "    'Value': [mean_patents, var_patents, overdispersion_index,\n",
    "              observed_zero_pct * 100, between_var, within_var, p99]\n",
    "})\n",
    "eda_summary.to_csv(TABLES_DIR / 'table_02_eda_summary.csv', index=False)\n",
    "print('\\nEDA summary saved.')"
   ],
   "id": "code13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Model Estimation - Full Comparison (30 min)\n",
    "\n",
    "We estimate five count models and compare them systematically:\n",
    "\n",
    "1. **Pooled Poisson** (baseline, likely misspecified)\n",
    "2. **Pooled Negative Binomial** (handles overdispersion)\n",
    "3. **FE Poisson** (controls firm heterogeneity)\n",
    "4. **Zero-Inflated Poisson** (handles excess zeros)\n",
    "5. **Zero-Inflated Negative Binomial** (both issues)\n",
    "\n",
    "### Common Specification\n",
    "\n",
    "- **Count variables**: `rd_intensity`, `firm_size`, `capital_intensity`\n",
    "- **Controls**: year dummies\n",
    "- **Inflate variables** (ZIP/ZINB): `industry`, `firm_size`"
   ],
   "id": "md14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables for estimation\n",
    "y = df['patents'].values\n",
    "n_obs = len(y)\n",
    "\n",
    "# Continuous regressors\n",
    "X_vars = ['rd_intensity', 'firm_size', 'capital_intensity']\n",
    "\n",
    "# Year dummies (first year is reference)\n",
    "year_dummies = pd.get_dummies(df['year'], prefix='year', drop_first=True, dtype=float)\n",
    "year_dummy_names = list(year_dummies.columns)\n",
    "\n",
    "# Industry dummies (industry 1 is reference)\n",
    "industry_dummies = pd.get_dummies(df['industry'], prefix='ind', drop_first=True, dtype=float)\n",
    "industry_dummy_names = list(industry_dummies.columns)\n",
    "\n",
    "# For pooled models: const + X_vars + industry dummies + year dummies\n",
    "X_pooled_raw = pd.concat([df[X_vars], industry_dummies, year_dummies], axis=1)\n",
    "X_pooled = sm.add_constant(X_pooled_raw.values)\n",
    "pooled_names = ['const'] + X_vars + industry_dummy_names + year_dummy_names\n",
    "\n",
    "# For FE model: const + X_vars + year dummies (no industry, absorbed by FE)\n",
    "X_fe_raw = pd.concat([df[X_vars], year_dummies], axis=1)\n",
    "X_fe = sm.add_constant(X_fe_raw.values)\n",
    "fe_names = ['const'] + X_vars + year_dummy_names\n",
    "\n",
    "# For zero-inflated count part: const + X_vars + year dummies\n",
    "X_count = sm.add_constant(pd.concat([df[X_vars], year_dummies], axis=1).values)\n",
    "count_names = ['const'] + X_vars + year_dummy_names\n",
    "\n",
    "# For zero-inflated inflate part: const + industry dummies + firm_size\n",
    "X_inflate = sm.add_constant(pd.concat([industry_dummies, df[['firm_size']]], axis=1).values)\n",
    "inflate_names = ['const_z'] + [f'{n}_z' for n in industry_dummy_names] + ['firm_size_z']\n",
    "\n",
    "# Helper: compute AIC/BIC from log-likelihood\n",
    "def compute_ic(llf, k, n):\n",
    "    \"\"\"Compute AIC and BIC from log-likelihood.\"\"\"\n",
    "    aic = -2 * llf + 2 * k\n",
    "    bic = -2 * llf + k * np.log(n)\n",
    "    return aic, bic\n",
    "\n",
    "# Helper: get llf/aic/bic for any model result\n",
    "def get_model_stats(result, model=None, n=None):\n",
    "    \"\"\"Extract llf, aic, bic from any count model result.\"\"\"\n",
    "    # Get llf\n",
    "    if hasattr(result, 'llf'):\n",
    "        llf = result.llf\n",
    "    elif model is not None and hasattr(model, 'llf'):\n",
    "        llf = model.llf\n",
    "    else:\n",
    "        llf = np.nan\n",
    "\n",
    "    # Get aic/bic\n",
    "    if hasattr(result, 'aic') and hasattr(result, 'bic'):\n",
    "        aic, bic = result.aic, result.bic\n",
    "    else:\n",
    "        # Compute manually - use len(result.params) for total param count\n",
    "        k = len(result.params)\n",
    "        nn = n if n else (model.n_obs if model and hasattr(model, 'n_obs') else k)\n",
    "        if not np.isnan(llf):\n",
    "            aic, bic = compute_ic(llf, k, nn)\n",
    "        else:\n",
    "            aic, bic = np.nan, np.nan\n",
    "\n",
    "    return llf, aic, bic\n",
    "\n",
    "print('Design Matrix Dimensions:')\n",
    "print(f'  Pooled models:    {X_pooled.shape} ({len(pooled_names)} vars)')\n",
    "print(f'  FE model:         {X_fe.shape} ({len(fe_names)} vars)')\n",
    "print(f'  ZI count part:    {X_count.shape} ({len(count_names)} vars)')\n",
    "print(f'  ZI inflate part:  {X_inflate.shape} ({len(inflate_names)} vars)')"
   ],
   "id": "code15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Pooled Poisson\n",
    "print('3.1 Pooled Poisson')\n",
    "print('=' * 60)\n",
    "\n",
    "pois_pool = PooledPoisson(endog=y, exog=X_pooled)\n",
    "pois_pool_result = pois_pool.fit(se_type='robust')\n",
    "pois_pool.exog_names = pooled_names\n",
    "\n",
    "pois_table = pd.DataFrame({\n",
    "    'Variable': pooled_names,\n",
    "    'Coef': pois_pool_result.params,\n",
    "    'SE': pois_pool_result.se,\n",
    "    'p-value': pois_pool_result.pvalues,\n",
    "})\n",
    "display(pois_table)\n",
    "pois_table.to_csv(TABLES_DIR / 'table_03_pooled_poisson.csv', index=False)\n",
    "\n",
    "pois_llf, pois_aic, pois_bic = get_model_stats(pois_pool_result, model=pois_pool, n=n_obs)\n",
    "print(f'\\nLog-Lik: {pois_llf:.2f}, AIC: {pois_aic:.2f}, BIC: {pois_bic:.2f}')"
   ],
   "id": "code16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Pooled Negative Binomial\n",
    "print('3.2 Pooled Negative Binomial')\n",
    "print('=' * 60)\n",
    "\n",
    "nb_start = np.append(pois_pool_result.params, np.log(0.5))\n",
    "nb_pool = NegativeBinomial(endog=y, exog=X_pooled, entity_id=df['firm_id'].values)\n",
    "nb_pool_result = nb_pool.fit(start_params=nb_start)\n",
    "nb_pool.exog_names = pooled_names\n",
    "\n",
    "nb_table = pd.DataFrame({\n",
    "    'Variable': pooled_names + ['log_alpha'],\n",
    "    'Coef': nb_pool_result.params,\n",
    "    'SE': nb_pool_result.se,\n",
    "    'p-value': nb_pool_result.pvalues,\n",
    "})\n",
    "display(nb_table)\n",
    "nb_table.to_csv(TABLES_DIR / 'table_04_pooled_nb.csv', index=False)\n",
    "\n",
    "nb_llf, nb_aic, nb_bic = get_model_stats(nb_pool_result, model=nb_pool, n=n_obs)\n",
    "print(f'\\nAlpha (dispersion): {nb_pool_result.alpha:.4f}')\n",
    "print(f'Log-Lik: {nb_llf:.2f}, AIC: {nb_aic:.2f}, BIC: {nb_bic:.2f}')"
   ],
   "id": "code17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Fixed Effects Poisson (Subsample)\n",
    "print('3.3 Fixed Effects Poisson')\n",
    "print('=' * 60)\n",
    "print()\n",
    "print('NOTE: FE Poisson uses conditional MLE which is computationally')\n",
    "print('expensive for firms with high patent counts. We estimate on a')\n",
    "print('subsample of firms with max annual patents <= 5.')\n",
    "print()\n",
    "\n",
    "# Select firms with low patent counts for tractable FE estimation\n",
    "firm_max_patents = df.groupby('firm_id')['patents'].max()\n",
    "low_count_firms = firm_max_patents[firm_max_patents <= 5].index.values\n",
    "df_fe = df[df['firm_id'].isin(low_count_firms)].copy()\n",
    "y_fe = df_fe['patents'].values\n",
    "\n",
    "# Rebuild design matrix for FE subsample\n",
    "year_dum_fe = pd.get_dummies(df_fe['year'], prefix='year', drop_first=True, dtype=float)\n",
    "X_fe_sub = sm.add_constant(pd.concat([df_fe[X_vars], year_dum_fe], axis=1).values)\n",
    "\n",
    "print(f'Full sample: {df[\"firm_id\"].nunique()} firms')\n",
    "print(f'FE subsample: {len(low_count_firms)} firms (max patents/year <= 5)')\n",
    "print(f'Observations: {len(df_fe)}')\n",
    "print()\n",
    "\n",
    "import signal\n",
    "\n",
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutError(\"FE Poisson estimation timed out\")\n",
    "\n",
    "fe_pois = PoissonFixedEffects(\n",
    "    endog=y_fe,\n",
    "    exog=X_fe_sub,\n",
    "    entity_id=df_fe['firm_id'].values,\n",
    "    time_id=df_fe['year'].values\n",
    ")\n",
    "\n",
    "try:\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(90)  # 90 second timeout\n",
    "    fe_pois_result = fe_pois.fit()\n",
    "    signal.alarm(0)  # Cancel alarm\n",
    "    fe_pois.exog_names = fe_names\n",
    "    \n",
    "    fe_table = pd.DataFrame({\n",
    "        'Variable': fe_names,\n",
    "        'Coef': fe_pois_result.params,\n",
    "        'SE': fe_pois_result.se,\n",
    "        'p-value': fe_pois_result.pvalues,\n",
    "    })\n",
    "    display(fe_table)\n",
    "    fe_table.to_csv(TABLES_DIR / 'table_05_fe_poisson.csv', index=False)\n",
    "    \n",
    "    fe_llf = getattr(fe_pois_result, 'llf', None) or getattr(fe_pois, 'llf', None) or np.nan\n",
    "    fe_aic, fe_bic = compute_ic(fe_llf, len(fe_pois_result.params), len(y_fe)) if not np.isnan(fe_llf) else (np.nan, np.nan)\n",
    "    print(f'\\nLog-Lik: {fe_llf}')\n",
    "    print(f'Entities dropped (all zeros): {getattr(fe_pois_result, \"n_dropped\", \"N/A\")}')\n",
    "    fe_estimated = True\n",
    "    \n",
    "except Exception as e:\n",
    "    signal.alarm(0)\n",
    "    print(f'FE Poisson estimation failed: {e}')\n",
    "    print('Continuing without FE Poisson results.')\n",
    "    fe_pois_result = None\n",
    "    fe_llf, fe_aic, fe_bic = np.nan, np.nan, np.nan\n",
    "    fe_estimated = False"
   ],
   "id": "code18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Zero-Inflated Poisson (ZIP)\n",
    "print('3.4 Zero-Inflated Poisson (ZIP)')\n",
    "print('=' * 60)\n",
    "\n",
    "zip_model = ZeroInflatedPoisson(\n",
    "    endog=y,\n",
    "    exog_count=X_count,\n",
    "    exog_inflate=X_inflate,\n",
    "    exog_count_names=count_names,\n",
    "    exog_inflate_names=inflate_names,\n",
    ")\n",
    "zip_result = zip_model.fit()\n",
    "\n",
    "print(zip_result.summary(\n",
    "    count_names=count_names,\n",
    "    inflate_names=inflate_names,\n",
    "))\n",
    "\n",
    "zip_table = pd.DataFrame({\n",
    "    'Component': ['Count'] * len(count_names) + ['Inflate'] * len(inflate_names),\n",
    "    'Variable': count_names + inflate_names,\n",
    "    'Coef': np.concatenate([zip_result.params_count, zip_result.params_inflate]),\n",
    "    'SE': np.concatenate([zip_result.bse_count, zip_result.bse_inflate]),\n",
    "})\n",
    "zip_table.to_csv(TABLES_DIR / 'table_06_zip.csv', index=False)\n",
    "print(f'\\nAIC: {zip_result.aic:.2f}, BIC: {zip_result.bic:.2f}')\n",
    "print(f'Actual zeros: {zip_result.actual_zeros}, Predicted zeros: {zip_result.predicted_zeros:.0f}')"
   ],
   "id": "code19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Zero-Inflated Negative Binomial (ZINB)\n",
    "print('3.5 Zero-Inflated Negative Binomial (ZINB)')\n",
    "print('=' * 60)\n",
    "\n",
    "zinb_model = ZeroInflatedNegativeBinomial(\n",
    "    endog=y,\n",
    "    exog_count=X_count,\n",
    "    exog_inflate=X_inflate,\n",
    "    exog_count_names=count_names,\n",
    "    exog_inflate_names=inflate_names,\n",
    ")\n",
    "zinb_result = zinb_model.fit()\n",
    "\n",
    "print(zinb_result.summary(\n",
    "    count_names=count_names,\n",
    "    inflate_names=inflate_names,\n",
    "))\n",
    "\n",
    "zinb_table = pd.DataFrame({\n",
    "    'Component': ['Count'] * len(count_names) + ['Inflate'] * len(inflate_names) + ['Dispersion'],\n",
    "    'Variable': count_names + inflate_names + ['alpha'],\n",
    "    'Coef': np.concatenate([zinb_result.params_count, zinb_result.params_inflate, [zinb_result.alpha]]),\n",
    "    'SE': np.concatenate([zinb_result.bse_count, zinb_result.bse_inflate, [zinb_result.bse_alpha]]),\n",
    "})\n",
    "zinb_table.to_csv(TABLES_DIR / 'table_07_zinb.csv', index=False)\n",
    "print(f'\\nAlpha (dispersion): {zinb_result.alpha:.4f}')\n",
    "print(f'AIC: {zinb_result.aic:.2f}, BIC: {zinb_result.bic:.2f}')\n",
    "print(f'Actual zeros: {zinb_result.actual_zeros}, Predicted zeros: {zinb_result.predicted_zeros:.0f}')"
   ],
   "id": "code20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 Store all results for comparison\n",
    "results_dict = {\n",
    "    'Pooled Poisson': pois_pool_result,\n",
    "    'Pooled NB': nb_pool_result,\n",
    "    'ZIP': zip_result,\n",
    "    'ZINB': zinb_result,\n",
    "}\n",
    "models_dict = {\n",
    "    'Pooled Poisson': pois_pool,\n",
    "    'Pooled NB': nb_pool,\n",
    "    'ZIP': None,\n",
    "    'ZINB': None,\n",
    "}\n",
    "\n",
    "if fe_estimated:\n",
    "    results_dict['FE Poisson'] = fe_pois_result\n",
    "    models_dict['FE Poisson'] = fe_pois\n",
    "\n",
    "# Compute stats for all models\n",
    "model_stats = {}\n",
    "for name, result in results_dict.items():\n",
    "    llf, aic, bic = get_model_stats(result, model=models_dict.get(name), n=n_obs)\n",
    "    model_stats[name] = {'llf': llf, 'aic': aic, 'bic': bic}\n",
    "\n",
    "print('All models estimated successfully!')\n",
    "for name, stats_d in model_stats.items():\n",
    "    print(f'  {name:20s}: Log-Lik = {stats_d[\"llf\"]:>10.2f}, AIC = {stats_d[\"aic\"]:>10.2f}, BIC = {stats_d[\"bic\"]:>10.2f}')"
   ],
   "id": "code21"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Model Selection and Testing (15 min)\n",
    "\n",
    "### Testing Strategy\n",
    "1. **Overdispersion test**: Poisson vs NB (Cameron-Trivedi + LR test)\n",
    "2. **Vuong test**: ZIP vs Poisson, ZINB vs NB\n",
    "3. **AIC/BIC comparison**: Across all models\n",
    "4. **Model fit**: Predicted vs actual distributions"
   ],
   "id": "md22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Overdispersion Test (Poisson vs NB)\n",
    "print('4.1 Overdispersion Test')\n",
    "print('=' * 60)\n",
    "\n",
    "# Cameron-Trivedi auxiliary regression\n",
    "mu_pois = np.exp(X_pooled @ pois_pool_result.params)\n",
    "aux_y = ((y - mu_pois) ** 2 - y)\n",
    "aux_x = mu_pois ** 2\n",
    "slope, intercept, r_val, p_val_ct, std_err = stats.linregress(aux_x, aux_y)\n",
    "t_stat_ct = slope / std_err\n",
    "p_ct = 1 - stats.norm.cdf(t_stat_ct)\n",
    "\n",
    "print('Cameron-Trivedi Overdispersion Test:')\n",
    "print(f'  H0: alpha = 0 (Poisson adequate)')\n",
    "print(f'  H1: alpha > 0 (Overdispersion)')\n",
    "print(f'  Alpha estimate: {slope:.4f}')\n",
    "print(f'  t-statistic:    {t_stat_ct:.4f}')\n",
    "print(f'  p-value:        {p_ct:.6f}')\n",
    "print(f'  => {\"Reject H0: overdispersion detected\" if p_ct < 0.05 else \"Cannot reject H0\"}')\n",
    "\n",
    "# LR test (Poisson vs NB)\n",
    "print('\\nLR Test (Poisson vs NB):')\n",
    "lr_stat = 2 * (model_stats['Pooled NB']['llf'] - model_stats['Pooled Poisson']['llf'])\n",
    "lr_pval = 0.5 * (1 - stats.chi2.cdf(lr_stat, 1))  # Boundary test\n",
    "print(f'  LR statistic:   {lr_stat:.2f}')\n",
    "print(f'  p-value:        {lr_pval:.6f}')\n",
    "print(f'  => {\"Strong evidence for NB over Poisson\" if lr_pval < 0.01 else \"Poisson may be adequate\"}')"
   ],
   "id": "code23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Vuong Tests\n",
    "print('4.2 Vuong Tests')\n",
    "print('=' * 60)\n",
    "\n",
    "# ZIP vs Poisson\n",
    "if hasattr(zip_result, 'vuong_stat') and zip_result.vuong_stat is not None:\n",
    "    print(f'ZIP vs Poisson:')\n",
    "    print(f'  Vuong statistic: {zip_result.vuong_stat:.4f}')\n",
    "    print(f'  p-value:         {zip_result.vuong_pvalue:.6f}')\n",
    "    vuong_conclusion = 'ZIP preferred' if zip_result.vuong_pvalue < 0.05 and zip_result.vuong_stat > 0 else 'Standard model may be adequate'\n",
    "    print(f'  => {vuong_conclusion}')\n",
    "else:\n",
    "    # Compute comparable Poisson AIC for same specification\n",
    "    pois_comp = PooledPoisson(endog=y, exog=X_count)\n",
    "    pois_comp_result = pois_comp.fit(se_type='robust')\n",
    "    _, pois_comp_aic, _ = get_model_stats(pois_comp_result, model=pois_comp, n=n_obs)\n",
    "    print('ZIP vs Poisson (AIC comparison):')\n",
    "    print(f'  ZIP AIC:     {model_stats[\"ZIP\"][\"aic\"]:.2f}')\n",
    "    print(f'  Poisson AIC: {pois_comp_aic:.2f}')\n",
    "    print(f'  => {\"ZIP preferred\" if model_stats[\"ZIP\"][\"aic\"] < pois_comp_aic else \"Poisson preferred\"}')\n",
    "\n",
    "print(f'\\nZINB vs NB (AIC comparison):')\n",
    "print(f'  ZINB AIC: {model_stats[\"ZINB\"][\"aic\"]:.2f}')\n",
    "print(f'  NB AIC:   {model_stats[\"Pooled NB\"][\"aic\"]:.2f}')\n",
    "print(f'  => {\"ZINB preferred\" if model_stats[\"ZINB\"][\"aic\"] < model_stats[\"Pooled NB\"][\"aic\"] else \"NB preferred\"}')"
   ],
   "id": "code24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Information Criteria Comparison\n",
    "print('4.3 Information Criteria Comparison')\n",
    "print('=' * 60)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': list(model_stats.keys()),\n",
    "    'Log-Lik': [s['llf'] for s in model_stats.values()],\n",
    "    'AIC': [s['aic'] for s in model_stats.values()],\n",
    "    'BIC': [s['bic'] for s in model_stats.values()],\n",
    "})\n",
    "comparison = comparison.sort_values('AIC')\n",
    "\n",
    "display(comparison)\n",
    "best_aic = comparison.dropna(subset=['AIC']).iloc[0]['Model']\n",
    "best_bic = comparison.dropna(subset=['BIC']).sort_values('BIC').iloc[0]['Model']\n",
    "print(f'\\nBest model by AIC: {best_aic}')\n",
    "print(f'Best model by BIC: {best_bic}')\n",
    "\n",
    "comparison.to_csv(TABLES_DIR / 'table_09_aic_bic_comparison.csv', index=False)"
   ],
   "id": "code25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: AIC/BIC bar plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "comp_plot = comparison.dropna(subset=['AIC', 'BIC']).sort_values('AIC')\n",
    "x_pos = np.arange(len(comp_plot))\n",
    "\n",
    "# AIC\n",
    "bars_aic = axes[0].bar(x_pos, comp_plot['AIC'].values, alpha=0.7,\n",
    "                       color='steelblue', edgecolor='black')\n",
    "bars_aic[0].set_color('green')\n",
    "bars_aic[0].set_alpha(0.9)\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(comp_plot['Model'].values, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('AIC (lower is better)', fontsize=12)\n",
    "axes[0].set_title('AIC Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# BIC\n",
    "comp_bic = comp_plot.sort_values('BIC')\n",
    "bars_bic = axes[1].bar(x_pos, comp_bic['BIC'].values, alpha=0.7,\n",
    "                       color='coral', edgecolor='black')\n",
    "bars_bic[0].set_color('green')\n",
    "bars_bic[0].set_alpha(0.9)\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(comp_bic['Model'].values, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('BIC (lower is better)', fontsize=12)\n",
    "axes[1].set_title('BIC Comparison', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'aic_bic_barplot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Model Fit: Rootogram comparison\n",
    "max_count_plot = min(int(df['patents'].quantile(0.95)), 20)\n",
    "count_range = np.arange(0, max_count_plot + 1)\n",
    "observed_freq = np.array([(y == k).sum() for k in count_range])\n",
    "\n",
    "# Poisson predicted\n",
    "mu_pois_pred = np.exp(X_pooled @ pois_pool_result.params)\n",
    "pois_pred_freq = np.array([np.mean(stats.poisson.pmf(k, mu_pois_pred)) * len(y) for k in count_range])\n",
    "\n",
    "# NB predicted\n",
    "mu_nb_pred = np.exp(X_pooled @ nb_pool_result.params_exog)\n",
    "alpha_nb = nb_pool_result.alpha\n",
    "r_nb = 1 / alpha_nb\n",
    "p_nb = r_nb / (r_nb + mu_nb_pred)\n",
    "nb_pred_freq = np.array([np.mean(stats.nbinom.pmf(k, r_nb, p_nb)) * len(y) for k in count_range])\n",
    "\n",
    "# ZIP predicted\n",
    "lambda_zip = np.exp(X_count @ zip_result.params_count)\n",
    "pi_zip = 1 / (1 + np.exp(-(X_inflate @ zip_result.params_inflate)))\n",
    "zip_pred_freq = np.array([\n",
    "    np.mean(pi_zip * (k == 0) + (1 - pi_zip) * stats.poisson.pmf(k, lambda_zip)) * len(y)\n",
    "    for k in count_range\n",
    "])\n",
    "\n",
    "# ZINB predicted\n",
    "lambda_zinb = np.exp(X_count @ zinb_result.params_count)\n",
    "pi_zinb = 1 / (1 + np.exp(-(X_inflate @ zinb_result.params_inflate)))\n",
    "alpha_zinb = zinb_result.alpha\n",
    "r_zinb = 1 / alpha_zinb\n",
    "p_zinb = r_zinb / (r_zinb + lambda_zinb)\n",
    "zinb_pred_freq = np.array([\n",
    "    np.mean(pi_zinb * (k == 0) + (1 - pi_zinb) * stats.nbinom.pmf(k, r_zinb, p_zinb)) * len(y)\n",
    "    for k in count_range\n",
    "])\n",
    "\n",
    "# Figure: Rootogram comparison (4 panels)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "models_pred = [\n",
    "    ('Pooled Poisson', pois_pred_freq),\n",
    "    ('Pooled NB', nb_pred_freq),\n",
    "    ('ZIP', zip_pred_freq),\n",
    "    ('ZINB', zinb_pred_freq),\n",
    "]\n",
    "\n",
    "for ax, (name, pred_freq) in zip(axes.flat, models_pred):\n",
    "    obs_sqrt = np.sqrt(observed_freq)\n",
    "    exp_sqrt = np.sqrt(pred_freq)\n",
    "    residual = obs_sqrt - exp_sqrt\n",
    "    colors = ['red' if r < -0.5 else ('blue' if r > 0.5 else 'gray') for r in residual]\n",
    "    ax.bar(count_range, residual, bottom=exp_sqrt, color=colors, alpha=0.6, edgecolor='black')\n",
    "    ax.plot(count_range, exp_sqrt, 'o-', color='darkred', linewidth=2, markersize=4)\n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    ax.set_title(name, fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_ylabel('Sqrt(Frequency)')\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Hanging Rootograms: Model Fit Comparison', fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'rootogram_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test statistics\n",
    "test_stats = pd.DataFrame([\n",
    "    {'Test': 'Cameron-Trivedi (Overdispersion)', 'Statistic': t_stat_ct, 'p-value': p_ct,\n",
    "     'Conclusion': 'Overdispersion detected' if p_ct < 0.05 else 'No overdispersion'},\n",
    "    {'Test': 'LR Test (Poisson vs NB)', 'Statistic': lr_stat, 'p-value': lr_pval,\n",
    "     'Conclusion': 'NB preferred' if lr_pval < 0.05 else 'Poisson adequate'},\n",
    "    {'Test': 'AIC: ZINB vs NB',\n",
    "     'Statistic': model_stats['Pooled NB']['aic'] - model_stats['ZINB']['aic'],\n",
    "     'p-value': np.nan,\n",
    "     'Conclusion': 'ZINB preferred' if model_stats['ZINB']['aic'] < model_stats['Pooled NB']['aic'] else 'NB preferred'},\n",
    "])\n",
    "test_stats.to_csv(TABLES_DIR / 'table_08_test_statistics.csv', index=False)\n",
    "display(test_stats)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('MODEL SELECTION DECISION: ZINB is the preferred model')\n",
    "print('  - Overdispersion: Present (Var/Mean >> 1, LR test significant)')\n",
    "print('  - Excess zeros: Present (39% observed vs << predicted by Poisson)')\n",
    "print('  - ZINB handles both issues simultaneously')\n",
    "print('=' * 60)"
   ],
   "id": "code28"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Interpreting the Preferred Model (ZINB) (20 min)\n",
    "\n",
    "The ZINB model has two components:\n",
    "1. **Count component**: Determines patent production among potential innovators\n",
    "2. **Inflation component**: Determines the probability of being a structural non-innovator\n",
    "\n",
    "We interpret both components and compute Incidence Rate Ratios (IRRs)."
   ],
   "id": "md29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Count Component Results\n",
    "print('5.1 ZINB Count Component (Patent Production Among Innovators)')\n",
    "print('=' * 70)\n",
    "\n",
    "count_coefs = zinb_result.params_count\n",
    "count_se = zinb_result.bse_count\n",
    "count_z = count_coefs / count_se\n",
    "count_pvals = 2 * (1 - stats.norm.cdf(np.abs(count_z)))\n",
    "count_irr = np.exp(count_coefs)\n",
    "\n",
    "count_results = pd.DataFrame({\n",
    "    'Variable': count_names,\n",
    "    'Coef': count_coefs,\n",
    "    'SE': count_se,\n",
    "    'z': count_z,\n",
    "    'p-value': count_pvals,\n",
    "    'IRR': count_irr,\n",
    "    '% Change': (count_irr - 1) * 100,\n",
    "})\n",
    "\n",
    "display(count_results)\n",
    "count_results.to_csv(TABLES_DIR / 'table_10_zinb_count_results.csv', index=False)\n",
    "\n",
    "rd_idx = count_names.index('rd_intensity')\n",
    "size_idx = count_names.index('firm_size')\n",
    "cap_idx = count_names.index('capital_intensity')\n",
    "\n",
    "print(f'\\nKey Interpretations (Count Component):')\n",
    "print(f'  R&D intensity: IRR = {count_irr[rd_idx]:.4f}')\n",
    "print(f'    => 1 p.p. increase in R&D/sales => {(count_irr[rd_idx]-1)*100:.1f}% more patents')\n",
    "print(f'  Firm size (log): IRR = {count_irr[size_idx]:.4f}')\n",
    "print(f'    => 1 unit increase in log(employees) => {(count_irr[size_idx]-1)*100:.1f}% more patents')\n",
    "print(f'  Capital intensity: IRR = {count_irr[cap_idx]:.4f}')\n",
    "print(f'    => 1 unit increase => {(count_irr[cap_idx]-1)*100:.2f}% more patents')"
   ],
   "id": "code30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Inflation Component Results\n",
    "print('5.2 ZINB Inflation Component (Non-Innovator Probability)')\n",
    "print('=' * 70)\n",
    "\n",
    "inflate_coefs = zinb_result.params_inflate\n",
    "inflate_se = zinb_result.bse_inflate\n",
    "inflate_z = inflate_coefs / inflate_se\n",
    "inflate_pvals = 2 * (1 - stats.norm.cdf(np.abs(inflate_z)))\n",
    "inflate_or = np.exp(inflate_coefs)\n",
    "\n",
    "inflate_results = pd.DataFrame({\n",
    "    'Variable': inflate_names,\n",
    "    'Coef': inflate_coefs,\n",
    "    'SE': inflate_se,\n",
    "    'z': inflate_z,\n",
    "    'p-value': inflate_pvals,\n",
    "    'Odds Ratio': inflate_or,\n",
    "})\n",
    "\n",
    "display(inflate_results)\n",
    "inflate_results.to_csv(TABLES_DIR / 'table_11_zinb_inflate_results.csv', index=False)\n",
    "\n",
    "pi_hat = 1 / (1 + np.exp(-(X_inflate @ inflate_coefs)))\n",
    "print(f'\\nEstimated % structural non-innovators: {pi_hat.mean():.1%}')\n",
    "print(f'  Range: {pi_hat.min():.1%} - {pi_hat.max():.1%}')"
   ],
   "id": "code31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Dispersion Parameter\n",
    "print('5.3 Dispersion Parameter')\n",
    "print('=' * 50)\n",
    "print(f'Alpha: {zinb_result.alpha:.4f}')\n",
    "print(f'SE(alpha): {zinb_result.bse_alpha:.4f}')\n",
    "print(f'\\nInterpretation:')\n",
    "print(f'  alpha > 0 confirms overdispersion beyond what the zero-inflation handles.')\n",
    "print(f'  Conditional variance = mu + alpha * mu^2')"
   ],
   "id": "code32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Forest plot of IRRs (count component)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "key_vars_idx = [i for i, n in enumerate(count_names) if n in X_vars or n.startswith('year_')]\n",
    "key_vars_names = [count_names[i] for i in key_vars_idx]\n",
    "key_irrs = count_irr[key_vars_idx]\n",
    "key_ci_low = np.exp(count_coefs[key_vars_idx] - 1.96 * count_se[key_vars_idx])\n",
    "key_ci_high = np.exp(count_coefs[key_vars_idx] + 1.96 * count_se[key_vars_idx])\n",
    "\n",
    "y_pos = np.arange(len(key_vars_names))\n",
    "ax.errorbar(key_irrs, y_pos,\n",
    "            xerr=[key_irrs - key_ci_low, key_ci_high - key_irrs],\n",
    "            fmt='o', markersize=8, capsize=5, capthick=2, color='steelblue')\n",
    "ax.axvline(1, color='red', linestyle='--', linewidth=2, label='IRR = 1 (no effect)')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(key_vars_names)\n",
    "ax.set_xlabel('Incidence Rate Ratio (IRR)', fontsize=12)\n",
    "ax.set_title('ZINB Count Component: IRRs with 95% CIs', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'zinb_irr_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code33"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Marginal Effects and Policy Implications (20 min)\n",
    "\n",
    "### Goals\n",
    "1. Compute AME for R&D intensity (key policy variable)\n",
    "2. Evaluate effect heterogeneity by firm size\n",
    "3. Quantify policy impacts via counterfactual simulation\n",
    "4. Decompose into extensive vs intensive margins"
   ],
   "id": "md34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Average Marginal Effects for ZINB\n",
    "# For ZINB: E[y] = (1-pi) * lambda\n",
    "# AME_k = mean[(1-pi) * beta_k * lambda] (for variables only in count part)\n",
    "print('6.1 Average Marginal Effects (ZINB)')\n",
    "print('=' * 60)\n",
    "\n",
    "lambda_zinb_pred = np.exp(X_count @ zinb_result.params_count)\n",
    "pi_zinb_pred = 1 / (1 + np.exp(-(X_inflate @ zinb_result.params_inflate)))\n",
    "\n",
    "ame_zinb_data = {}\n",
    "for i, var_name in enumerate(count_names):\n",
    "    if var_name == 'const':\n",
    "        continue\n",
    "    beta_k = zinb_result.params_count[i]\n",
    "    me_k = (1 - pi_zinb_pred) * beta_k * lambda_zinb_pred\n",
    "    ame_zinb_data[var_name] = {\n",
    "        'AME': me_k.mean(),\n",
    "        'SE': me_k.std() / np.sqrt(len(me_k)),\n",
    "        'Min ME': me_k.min(),\n",
    "        'Max ME': me_k.max(),\n",
    "    }\n",
    "\n",
    "ame_zinb_df = pd.DataFrame(ame_zinb_data).T\n",
    "ame_zinb_df['z'] = ame_zinb_df['AME'] / ame_zinb_df['SE']\n",
    "ame_zinb_df['p-value'] = 2 * (1 - stats.norm.cdf(np.abs(ame_zinb_df['z'])))\n",
    "ame_zinb_df['CI Lower'] = ame_zinb_df['AME'] - 1.96 * ame_zinb_df['SE']\n",
    "ame_zinb_df['CI Upper'] = ame_zinb_df['AME'] + 1.96 * ame_zinb_df['SE']\n",
    "\n",
    "display(ame_zinb_df[['AME', 'SE', 'z', 'p-value', 'CI Lower', 'CI Upper']])\n",
    "ame_zinb_df.to_csv(TABLES_DIR / 'table_12_ame_zinb.csv')\n",
    "\n",
    "rd_ame = ame_zinb_data['rd_intensity']['AME']\n",
    "print(f'\\nKey Result: AME of R&D intensity = {rd_ame:.4f}')\n",
    "print(f'  => 1 p.p. increase in R&D/sales increases expected patents by {rd_ame:.2f}')\n",
    "print(f'  Accounting for both the count and zero-inflation components.')"
   ],
   "id": "code35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Marginal Effects by Firm Size\n",
    "print('6.2 Marginal Effects by Firm Size')\n",
    "print('=' * 60)\n",
    "\n",
    "df['size_quartile'] = pd.qcut(df['firm_size'], 4, labels=['Small', 'Medium-Small', 'Medium-Large', 'Large'])\n",
    "\n",
    "me_by_size = []\n",
    "rd_idx_count = count_names.index('rd_intensity')\n",
    "beta_rd = zinb_result.params_count[rd_idx_count]\n",
    "\n",
    "for q in ['Small', 'Medium-Small', 'Medium-Large', 'Large']:\n",
    "    mask = (df['size_quartile'] == q).values\n",
    "    me_rd = (1 - pi_zinb_pred[mask]) * beta_rd * lambda_zinb_pred[mask]\n",
    "    me_by_size.append({\n",
    "        'Size Group': q,\n",
    "        'N': mask.sum(),\n",
    "        'Mean E[y]': ((1 - pi_zinb_pred[mask]) * lambda_zinb_pred[mask]).mean(),\n",
    "        'AME(R&D)': me_rd.mean(),\n",
    "        'SE': me_rd.std() / np.sqrt(mask.sum()),\n",
    "        'Mean P(non-innovator)': pi_zinb_pred[mask].mean(),\n",
    "    })\n",
    "\n",
    "me_size_df = pd.DataFrame(me_by_size)\n",
    "me_size_df['CI Lower'] = me_size_df['AME(R&D)'] - 1.96 * me_size_df['SE']\n",
    "me_size_df['CI Upper'] = me_size_df['AME(R&D)'] + 1.96 * me_size_df['SE']\n",
    "\n",
    "display(me_size_df)\n",
    "me_size_df.to_csv(TABLES_DIR / 'table_13_me_by_firm_size.csv', index=False)\n",
    "\n",
    "print(f'\\nLarge firms: AME = {me_size_df[me_size_df[\"Size Group\"]==\"Large\"][\"AME(R&D)\"].values[0]:.3f}')\n",
    "print(f'Small firms: AME = {me_size_df[me_size_df[\"Size Group\"]==\"Small\"][\"AME(R&D)\"].values[0]:.3f}')\n",
    "print(f'=> Larger firms have a larger absolute response to R&D investment.')"
   ],
   "id": "code36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: ME heterogeneity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: AME by firm size\n",
    "x_pos = np.arange(len(me_size_df))\n",
    "bars = axes[0].bar(x_pos, me_size_df['AME(R&D)'],\n",
    "                   yerr=1.96 * me_size_df['SE'], capsize=5,\n",
    "                   alpha=0.7, color=['#4393C3', '#92C5DE', '#F4A582', '#D6604D'],\n",
    "                   edgecolor='black')\n",
    "axes[0].axhline(ame_zinb_data['rd_intensity']['AME'], color='red', linestyle='--',\n",
    "                linewidth=2, label=f'Overall AME = {ame_zinb_data[\"rd_intensity\"][\"AME\"]:.3f}')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(me_size_df['Size Group'])\n",
    "axes[0].set_ylabel('AME of R&D Intensity', fontsize=12)\n",
    "axes[0].set_title('R&D Effect by Firm Size\\n(Larger firms: greater absolute impact)', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Panel 2: P(non-innovator) by firm size\n",
    "axes[1].bar(x_pos, me_size_df['Mean P(non-innovator)'] * 100,\n",
    "            alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[1].axhline(pi_zinb_pred.mean() * 100, color='red', linestyle='--',\n",
    "                linewidth=2, label=f'Overall = {pi_zinb_pred.mean():.0%}')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(me_size_df['Size Group'])\n",
    "axes[1].set_ylabel('P(Non-Innovator) %', fontsize=12)\n",
    "axes[1].set_title('Non-Innovator Probability by Size\\n(Smaller firms more likely non-innovators)', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'me_heterogeneity_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Policy Simulation: R&D Tax Credit\n",
    "print('6.3 Policy Simulation: R&D Tax Credit (+2 p.p. R&D intensity)')\n",
    "print('=' * 60)\n",
    "\n",
    "# Baseline predictions\n",
    "E_y_baseline = (1 - pi_zinb_pred) * lambda_zinb_pred\n",
    "\n",
    "# Counterfactual: increase R&D by 2 p.p.\n",
    "X_count_cf = X_count.copy()\n",
    "rd_col_idx = count_names.index('rd_intensity')\n",
    "X_count_cf[:, rd_col_idx] += 2\n",
    "\n",
    "lambda_cf = np.exp(X_count_cf @ zinb_result.params_count)\n",
    "E_y_cf = (1 - pi_zinb_pred) * lambda_cf\n",
    "\n",
    "impact = E_y_cf - E_y_baseline\n",
    "\n",
    "print(f'Baseline mean patents: {E_y_baseline.mean():.2f}')\n",
    "print(f'Counterfactual mean:   {E_y_cf.mean():.2f}')\n",
    "print(f'\\nPolicy Impact:')\n",
    "print(f'  Mean increase:   {impact.mean():.2f} patents per firm-year')\n",
    "print(f'  Total increase:  {impact.sum():.0f} patents across all firm-years')\n",
    "print(f'  % increase:      {impact.mean() / E_y_baseline.mean() * 100:.1f}%')\n",
    "\n",
    "print(f'\\nImpact by Firm Size:')\n",
    "for q in ['Small', 'Medium-Small', 'Medium-Large', 'Large']:\n",
    "    mask = (df['size_quartile'] == q).values\n",
    "    print(f'  {q:15s}: +{impact[mask].mean():.2f} patents (from {E_y_baseline[mask].mean():.2f})')\n",
    "\n",
    "policy_sim = pd.DataFrame({\n",
    "    'Metric': ['Baseline mean', 'Counterfactual mean', 'Mean impact', 'Total impact', '% increase'],\n",
    "    'Value': [E_y_baseline.mean(), E_y_cf.mean(), impact.mean(),\n",
    "              impact.sum(), impact.mean() / E_y_baseline.mean() * 100]\n",
    "})\n",
    "policy_sim.to_csv(TABLES_DIR / 'table_14_policy_simulation.csv', index=False)"
   ],
   "id": "code38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 Extensive vs Intensive Margin Decomposition\n",
    "print('6.4 Extensive vs Intensive Margin')\n",
    "print('=' * 60)\n",
    "\n",
    "E_y_given_innov_base = lambda_zinb_pred.mean()\n",
    "E_y_given_innov_cf = lambda_cf.mean()\n",
    "intensive = E_y_given_innov_cf - E_y_given_innov_base\n",
    "\n",
    "print(f'With R&D only in count model:')\n",
    "print(f'  Extensive margin (change in P(innovator)): 0 (R&D not in inflate model)')\n",
    "print(f'  Intensive margin (more patents | innovator): +{intensive:.2f}')\n",
    "print(f'\\nThe entire R&D effect operates through the intensive margin:')\n",
    "print(f'  More R&D => more patents among firms that are already innovators.')\n",
    "print(f'  It does NOT change the probability of being a non-innovator.')"
   ],
   "id": "code39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Policy simulation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Baseline vs counterfactual\n",
    "max_val_plot = 20\n",
    "bins = np.arange(-0.5, max_val_plot + 1.5, 1)\n",
    "axes[0].hist(E_y_baseline, bins=bins, alpha=0.5, color='steelblue',\n",
    "             label=f'Baseline (mean={E_y_baseline.mean():.2f})', edgecolor='black', density=True)\n",
    "axes[0].hist(E_y_cf, bins=bins, alpha=0.5, color='coral',\n",
    "             label=f'With Tax Credit (mean={E_y_cf.mean():.2f})', edgecolor='black', density=True)\n",
    "axes[0].set_xlabel('Expected Patents', fontsize=12)\n",
    "axes[0].set_ylabel('Density', fontsize=12)\n",
    "axes[0].set_title('Predicted Patent Distribution\\nBaseline vs R&D Tax Credit', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Panel 2: Impact by firm size\n",
    "impact_by_size = []\n",
    "for q in ['Small', 'Medium-Small', 'Medium-Large', 'Large']:\n",
    "    mask = (df['size_quartile'] == q).values\n",
    "    impact_by_size.append(impact[mask].mean())\n",
    "\n",
    "x_pos = np.arange(4)\n",
    "axes[1].bar(x_pos, impact_by_size, alpha=0.7,\n",
    "            color=['#4393C3', '#92C5DE', '#F4A582', '#D6604D'],\n",
    "            edgecolor='black')\n",
    "axes[1].axhline(impact.mean(), color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Overall: +{impact.mean():.2f}')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(['Small', 'Med-Small', 'Med-Large', 'Large'])\n",
    "axes[1].set_ylabel('Additional Patents per Firm-Year', fontsize=12)\n",
    "axes[1].set_title('Policy Impact by Firm Size\\n(+2 p.p. R&D intensity)', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'policy_impact_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code40"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Robustness and Sensitivity Analysis (15 min)\n",
    "\n",
    "### Checks\n",
    "1. **Alternative specifications**: lagged R&D, nonlinear R&D, interactions\n",
    "2. **Sample sensitivity**: excluding outliers, time periods\n",
    "3. **Result stability across specifications**"
   ],
   "id": "md41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Alternative Specifications\n",
    "print('7.1 Robustness: Alternative Specifications')\n",
    "print('=' * 60)\n",
    "\n",
    "robustness_results = {}\n",
    "\n",
    "# Baseline\n",
    "rd_idx_zinb = count_names.index('rd_intensity')\n",
    "robustness_results['Baseline'] = {\n",
    "    'coef_rd': zinb_result.params_count[rd_idx_zinb],\n",
    "    'se_rd': zinb_result.bse_count[rd_idx_zinb],\n",
    "}\n",
    "\n",
    "# Spec 1: Lagged R&D\n",
    "df_sorted = df.sort_values(['firm_id', 'year'])\n",
    "df_sorted['rd_lag'] = df_sorted.groupby('firm_id')['rd_intensity'].shift(1)\n",
    "df_lag = df_sorted.dropna(subset=['rd_lag']).copy()\n",
    "\n",
    "y_lag = df_lag['patents'].values\n",
    "X_lag_vars = ['rd_lag', 'firm_size', 'capital_intensity']\n",
    "year_dum_lag = pd.get_dummies(df_lag['year'], prefix='year', drop_first=True, dtype=float)\n",
    "X_count_lag = sm.add_constant(pd.concat([df_lag[X_lag_vars], year_dum_lag], axis=1).values)\n",
    "count_names_lag = ['const'] + X_lag_vars + list(year_dum_lag.columns)\n",
    "\n",
    "ind_dum_lag = pd.get_dummies(df_lag['industry'], prefix='ind', drop_first=True, dtype=float)\n",
    "X_inflate_lag = sm.add_constant(pd.concat([ind_dum_lag, df_lag[['firm_size']]], axis=1).values)\n",
    "inflate_names_lag = ['const_z'] + [f'{n}_z' for n in ind_dum_lag.columns] + ['firm_size_z']\n",
    "\n",
    "zinb_lag = ZeroInflatedNegativeBinomial(\n",
    "    endog=y_lag, exog_count=X_count_lag, exog_inflate=X_inflate_lag,\n",
    "    exog_count_names=count_names_lag, exog_inflate_names=inflate_names_lag,\n",
    ")\n",
    "zinb_lag_result = zinb_lag.fit()\n",
    "\n",
    "rd_lag_idx = count_names_lag.index('rd_lag')\n",
    "robustness_results['Lagged R&D'] = {\n",
    "    'coef_rd': zinb_lag_result.params_count[rd_lag_idx],\n",
    "    'se_rd': zinb_lag_result.bse_count[rd_lag_idx],\n",
    "}\n",
    "print(f'  Lagged R&D: coef = {zinb_lag_result.params_count[rd_lag_idx]:.4f}')\n",
    "\n",
    "lag_table = pd.DataFrame({\n",
    "    'Variable': count_names_lag,\n",
    "    'Coef': zinb_lag_result.params_count,\n",
    "    'SE': zinb_lag_result.bse_count,\n",
    "})\n",
    "lag_table.to_csv(TABLES_DIR / 'table_15_robustness_lag.csv', index=False)"
   ],
   "id": "code42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec 2: Add R&D squared (nonlinearity)\n",
    "df['rd_sq'] = df['rd_intensity'] ** 2\n",
    "\n",
    "X_vars_nl = ['rd_intensity', 'rd_sq', 'firm_size', 'capital_intensity']\n",
    "X_count_nl = sm.add_constant(pd.concat([df[X_vars_nl], year_dummies], axis=1).values)\n",
    "count_names_nl = ['const'] + X_vars_nl + year_dummy_names\n",
    "\n",
    "zinb_nl = ZeroInflatedNegativeBinomial(\n",
    "    endog=y, exog_count=X_count_nl, exog_inflate=X_inflate,\n",
    "    exog_count_names=count_names_nl, exog_inflate_names=inflate_names,\n",
    ")\n",
    "zinb_nl_result = zinb_nl.fit()\n",
    "\n",
    "rd_nl_idx = count_names_nl.index('rd_intensity')\n",
    "rd_sq_idx = count_names_nl.index('rd_sq')\n",
    "robustness_results['Nonlinear R&D'] = {\n",
    "    'coef_rd': zinb_nl_result.params_count[rd_nl_idx],\n",
    "    'se_rd': zinb_nl_result.bse_count[rd_nl_idx],\n",
    "}\n",
    "print(f'Nonlinear R&D: rd = {zinb_nl_result.params_count[rd_nl_idx]:.4f}, '\n",
    "      f'rd_sq = {zinb_nl_result.params_count[rd_sq_idx]:.6f}')\n",
    "\n",
    "nl_table = pd.DataFrame({\n",
    "    'Variable': count_names_nl,\n",
    "    'Coef': zinb_nl_result.params_count,\n",
    "    'SE': zinb_nl_result.bse_count,\n",
    "})\n",
    "nl_table.to_csv(TABLES_DIR / 'table_16_robustness_nonlinear.csv', index=False)"
   ],
   "id": "code43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec 3: R&D x Size interaction\n",
    "df['rd_x_size'] = df['rd_intensity'] * df['firm_size']\n",
    "\n",
    "X_vars_int = ['rd_intensity', 'firm_size', 'capital_intensity', 'rd_x_size']\n",
    "X_count_int = sm.add_constant(pd.concat([df[X_vars_int], year_dummies], axis=1).values)\n",
    "count_names_int = ['const'] + X_vars_int + year_dummy_names\n",
    "\n",
    "zinb_int = ZeroInflatedNegativeBinomial(\n",
    "    endog=y, exog_count=X_count_int, exog_inflate=X_inflate,\n",
    "    exog_count_names=count_names_int, exog_inflate_names=inflate_names,\n",
    ")\n",
    "zinb_int_result = zinb_int.fit()\n",
    "\n",
    "rd_int_idx = count_names_int.index('rd_intensity')\n",
    "rdxsize_idx = count_names_int.index('rd_x_size')\n",
    "robustness_results['R&D x Size'] = {\n",
    "    'coef_rd': zinb_int_result.params_count[rd_int_idx],\n",
    "    'se_rd': zinb_int_result.bse_count[rd_int_idx],\n",
    "}\n",
    "print(f'Interaction: rd = {zinb_int_result.params_count[rd_int_idx]:.4f}, '\n",
    "      f'rd_x_size = {zinb_int_result.params_count[rdxsize_idx]:.6f}')\n",
    "\n",
    "int_table = pd.DataFrame({\n",
    "    'Variable': count_names_int,\n",
    "    'Coef': zinb_int_result.params_count,\n",
    "    'SE': zinb_int_result.bse_count,\n",
    "})\n",
    "int_table.to_csv(TABLES_DIR / 'table_17_robustness_interactions.csv', index=False)"
   ],
   "id": "code44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Sample Sensitivity\n",
    "print('7.2 Sample Sensitivity')\n",
    "print('=' * 60)\n",
    "\n",
    "# Exclude top 1%\n",
    "p99 = df['patents'].quantile(0.99)\n",
    "df_no_outliers = df[df['patents'] <= p99].copy()\n",
    "y_no = df_no_outliers['patents'].values\n",
    "\n",
    "year_dum_no = pd.get_dummies(df_no_outliers['year'], prefix='year', drop_first=True, dtype=float)\n",
    "ind_dum_no = pd.get_dummies(df_no_outliers['industry'], prefix='ind', drop_first=True, dtype=float)\n",
    "X_count_no = sm.add_constant(pd.concat([df_no_outliers[X_vars], year_dum_no], axis=1).values)\n",
    "X_inflate_no = sm.add_constant(pd.concat([ind_dum_no, df_no_outliers[['firm_size']]], axis=1).values)\n",
    "\n",
    "count_names_no = ['const'] + X_vars + list(year_dum_no.columns)\n",
    "inflate_names_no = ['const_z'] + [f'{n}_z' for n in ind_dum_no.columns] + ['firm_size_z']\n",
    "\n",
    "zinb_no = ZeroInflatedNegativeBinomial(\n",
    "    endog=y_no, exog_count=X_count_no, exog_inflate=X_inflate_no,\n",
    "    exog_count_names=count_names_no, exog_inflate_names=inflate_names_no,\n",
    ")\n",
    "zinb_no_result = zinb_no.fit()\n",
    "\n",
    "rd_no_idx = count_names_no.index('rd_intensity')\n",
    "robustness_results['Excl. Outliers'] = {\n",
    "    'coef_rd': zinb_no_result.params_count[rd_no_idx],\n",
    "    'se_rd': zinb_no_result.bse_count[rd_no_idx],\n",
    "}\n",
    "print(f'  Excluding top 1%: N = {len(df_no_outliers)}, '\n",
    "      f'coef_rd = {zinb_no_result.params_count[rd_no_idx]:.4f}')\n",
    "\n",
    "# Time periods\n",
    "for period_name, year_range in [('Early (2012-2015)', range(2012, 2016)),\n",
    "                                 ('Late (2016-2019)', range(2016, 2020))]:\n",
    "    df_sub = df[df['year'].isin(year_range)].copy()\n",
    "    y_sub = df_sub['patents'].values\n",
    "    year_dum_sub = pd.get_dummies(df_sub['year'], prefix='year', drop_first=True, dtype=float)\n",
    "    ind_dum_sub = pd.get_dummies(df_sub['industry'], prefix='ind', drop_first=True, dtype=float)\n",
    "\n",
    "    count_names_sub = ['const'] + X_vars + list(year_dum_sub.columns)\n",
    "    inflate_names_sub = ['const_z'] + [f'{n}_z' for n in ind_dum_sub.columns] + ['firm_size_z']\n",
    "\n",
    "    X_count_sub = sm.add_constant(pd.concat([df_sub[X_vars], year_dum_sub], axis=1).values)\n",
    "    X_inflate_sub = sm.add_constant(pd.concat([ind_dum_sub, df_sub[['firm_size']]], axis=1).values)\n",
    "\n",
    "    zinb_sub = ZeroInflatedNegativeBinomial(\n",
    "        endog=y_sub, exog_count=X_count_sub, exog_inflate=X_inflate_sub,\n",
    "        exog_count_names=count_names_sub, exog_inflate_names=inflate_names_sub,\n",
    "    )\n",
    "    zinb_sub_result = zinb_sub.fit()\n",
    "\n",
    "    rd_sub_idx = count_names_sub.index('rd_intensity')\n",
    "    robustness_results[period_name] = {\n",
    "        'coef_rd': zinb_sub_result.params_count[rd_sub_idx],\n",
    "        'se_rd': zinb_sub_result.bse_count[rd_sub_idx],\n",
    "    }\n",
    "    print(f'  {period_name}: N = {len(df_sub)}, '\n",
    "          f'coef_rd = {zinb_sub_result.params_count[rd_sub_idx]:.4f}')"
   ],
   "id": "code45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustness summary\n",
    "robustness_df = pd.DataFrame(robustness_results).T\n",
    "robustness_df.columns = ['R&D Coef', 'SE']\n",
    "robustness_df['z'] = robustness_df['R&D Coef'] / robustness_df['SE']\n",
    "robustness_df['CI Lower'] = robustness_df['R&D Coef'] - 1.96 * robustness_df['SE']\n",
    "robustness_df['CI Upper'] = robustness_df['R&D Coef'] + 1.96 * robustness_df['SE']\n",
    "\n",
    "print('Robustness Summary: R&D Intensity Coefficient Across Specifications')\n",
    "print('=' * 80)\n",
    "display(robustness_df)\n",
    "robustness_df.to_csv(TABLES_DIR / 'table_18_robustness_subsample.csv')"
   ],
   "id": "code46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Robustness forest plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "y_pos = np.arange(len(robustness_df))\n",
    "ax.errorbar(robustness_df['R&D Coef'], y_pos,\n",
    "            xerr=[robustness_df['R&D Coef'] - robustness_df['CI Lower'],\n",
    "                  robustness_df['CI Upper'] - robustness_df['R&D Coef']],\n",
    "            fmt='o', markersize=8, capsize=5, capthick=2, color='steelblue')\n",
    "ax.plot(robustness_df.iloc[0]['R&D Coef'], 0, 'o', markersize=10, color='green', zorder=5)\n",
    "\n",
    "ax.axvline(robustness_df.iloc[0]['R&D Coef'], color='green', linestyle='--',\n",
    "           linewidth=1.5, alpha=0.5, label='Baseline estimate')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(robustness_df.index)\n",
    "ax.set_xlabel('R&D Intensity Coefficient', fontsize=12)\n",
    "ax.set_title('Robustness of R&D Effect Across Specifications\\n(All estimates qualitatively similar)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'robustness_forest_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code47"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Publication-Quality Results (10 min)\n",
    "\n",
    "Create final tables and figures suitable for academic publication."
   ],
   "id": "md48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Final 01: Descriptive Statistics\n",
    "print('Publication Table 1: Descriptive Statistics')\n",
    "print('=' * 80)\n",
    "\n",
    "desc_vars = ['patents', 'rd_intensity', 'firm_size', 'capital_intensity',\n",
    "             'export_share', 'hhi', 'firm_age', 'subsidy']\n",
    "\n",
    "overall = df[desc_vars].describe().T[['mean', 'std', 'min', 'max']]\n",
    "overall.columns = ['Mean (All)', 'SD (All)', 'Min', 'Max']\n",
    "\n",
    "innovators = df[df['patents'] > 0][desc_vars].describe().T[['mean', 'std']]\n",
    "innovators.columns = ['Mean (Innovators)', 'SD (Innovators)']\n",
    "\n",
    "non_innovators = df[df['patents'] == 0][desc_vars].describe().T[['mean', 'std']]\n",
    "non_innovators.columns = ['Mean (Non-Innov.)', 'SD (Non-Innov.)']\n",
    "\n",
    "table_final_01 = pd.concat([overall, innovators, non_innovators], axis=1)\n",
    "table_final_01['N (All)'] = len(df)\n",
    "table_final_01['N (Innov.)'] = (df['patents'] > 0).sum()\n",
    "table_final_01['N (Non-Innov.)'] = (df['patents'] == 0).sum()\n",
    "\n",
    "display(table_final_01)\n",
    "table_final_01.to_csv(TABLES_DIR / 'table_final_01_descriptives.csv')"
   ],
   "id": "code49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Final 02: Model Comparison\n",
    "print('Publication Table 2: Model Comparison')\n",
    "print('=' * 80)\n",
    "\n",
    "key_vars_compare = ['rd_intensity', 'firm_size', 'capital_intensity']\n",
    "comparison_rows = []\n",
    "for var in key_vars_compare:\n",
    "    row = {'Variable': var}\n",
    "    idx_p = pooled_names.index(var)\n",
    "    row['Pooled Poisson'] = f'{pois_pool_result.params[idx_p]:.4f} ({pois_pool_result.se[idx_p]:.4f})'\n",
    "    row['Pooled NB'] = f'{nb_pool_result.params_exog[idx_p]:.4f} ({nb_pool_result.se[idx_p]:.4f})'\n",
    "    if fe_estimated:\n",
    "        fe_idx = fe_names.index(var)\n",
    "        row['FE Poisson'] = f'{fe_pois_result.params[fe_idx]:.4f} ({fe_pois_result.se[fe_idx]:.4f})'\n",
    "    zip_idx = count_names.index(var)\n",
    "    row['ZIP'] = f'{zip_result.params_count[zip_idx]:.4f} ({zip_result.bse_count[zip_idx]:.4f})'\n",
    "    row['ZINB'] = f'{zinb_result.params_count[zip_idx]:.4f} ({zinb_result.bse_count[zip_idx]:.4f})'\n",
    "    comparison_rows.append(row)\n",
    "\n",
    "sep_cols = ['Variable', 'Pooled Poisson', 'Pooled NB', 'ZIP', 'ZINB']\n",
    "if fe_estimated:\n",
    "    sep_cols.insert(3, 'FE Poisson')\n",
    "comparison_rows.append({k: '---' for k in sep_cols})\n",
    "\n",
    "stat_models = ['Pooled Poisson', 'Pooled NB', 'ZIP', 'ZINB']\n",
    "if fe_estimated:\n",
    "    stat_models.insert(2, 'FE Poisson')\n",
    "\n",
    "comparison_rows.append(dict(Variable='Log-Lik', **{k: f'{model_stats[k][\"llf\"]:.1f}' for k in stat_models}))\n",
    "comparison_rows.append(dict(Variable='AIC', **{k: f'{model_stats[k][\"aic\"]:.1f}' if not np.isnan(model_stats[k][\"aic\"]) else 'N/A' for k in stat_models}))\n",
    "comparison_rows.append(dict(Variable='N', **{k: str(len(y)) for k in stat_models}))\n",
    "\n",
    "table_final_02 = pd.DataFrame(comparison_rows)\n",
    "display(table_final_02)\n",
    "table_final_02.to_csv(TABLES_DIR / 'table_final_02_model_comparison.csv', index=False)"
   ],
   "id": "code50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Final 03: ZINB Full Results\n",
    "print('Publication Table 3: ZINB Full Results')\n",
    "print('=' * 80)\n",
    "\n",
    "count_pub = pd.DataFrame({\n",
    "    'Component': 'Count',\n",
    "    'Variable': count_names,\n",
    "    'Coef': zinb_result.params_count,\n",
    "    'SE': zinb_result.bse_count,\n",
    "    'IRR': np.exp(zinb_result.params_count),\n",
    "    'p-value': 2 * (1 - stats.norm.cdf(np.abs(zinb_result.params_count / zinb_result.bse_count))),\n",
    "})\n",
    "\n",
    "inflate_pub = pd.DataFrame({\n",
    "    'Component': 'Inflate',\n",
    "    'Variable': inflate_names,\n",
    "    'Coef': zinb_result.params_inflate,\n",
    "    'SE': zinb_result.bse_inflate,\n",
    "    'OR': np.exp(zinb_result.params_inflate),\n",
    "    'p-value': 2 * (1 - stats.norm.cdf(np.abs(zinb_result.params_inflate / zinb_result.bse_inflate))),\n",
    "})\n",
    "\n",
    "disp_pub = pd.DataFrame({\n",
    "    'Component': ['Dispersion'],\n",
    "    'Variable': ['alpha'],\n",
    "    'Coef': [zinb_result.alpha],\n",
    "    'SE': [zinb_result.bse_alpha],\n",
    "    'IRR': [np.nan],\n",
    "    'p-value': [np.nan],\n",
    "})\n",
    "# Rename OR column to IRR for concat\n",
    "inflate_pub = inflate_pub.rename(columns={'OR': 'IRR'})\n",
    "\n",
    "table_final_03 = pd.concat([count_pub, inflate_pub, disp_pub], ignore_index=True)\n",
    "display(table_final_03)\n",
    "table_final_03.to_csv(TABLES_DIR / 'table_final_03_zinb_full.csv', index=False)"
   ],
   "id": "code51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Final 04: Marginal Effects\n",
    "print('Publication Table 4: Average Marginal Effects (ZINB)')\n",
    "print('=' * 80)\n",
    "\n",
    "table_final_04 = ame_zinb_df[['AME', 'SE', 'CI Lower', 'CI Upper', 'p-value']].copy()\n",
    "\n",
    "interpretations = []\n",
    "for var_name in table_final_04.index:\n",
    "    ame_val = table_final_04.loc[var_name, 'AME']\n",
    "    if 'year' in var_name:\n",
    "        interpretations.append(f'{ame_val:+.2f} patents vs base year')\n",
    "    elif var_name == 'rd_intensity':\n",
    "        interpretations.append(f'+1 p.p. R&D => {ame_val:+.2f} patents')\n",
    "    elif var_name == 'firm_size':\n",
    "        interpretations.append(f'+1 log(emp) => {ame_val:+.2f} patents')\n",
    "    elif var_name == 'capital_intensity':\n",
    "        interpretations.append(f'+1 unit K/L => {ame_val:+.4f} patents')\n",
    "    else:\n",
    "        interpretations.append(f'{ame_val:+.4f} patents')\n",
    "\n",
    "table_final_04['Interpretation'] = interpretations\n",
    "display(table_final_04)\n",
    "table_final_04.to_csv(TABLES_DIR / 'table_final_04_marginal_effects.csv')"
   ],
   "id": "code52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure Final 01: Observed vs ZINB Fitted\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "max_count_final = min(int(df['patents'].quantile(0.98)), 25)\n",
    "count_range_final = np.arange(0, max_count_final + 1)\n",
    "observed_final = np.array([(y == k).sum() for k in count_range_final])\n",
    "\n",
    "width = 0.35\n",
    "ax.bar(count_range_final - width/2, observed_final, width,\n",
    "       label='Observed', color='steelblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "zinb_final_freq = np.array([\n",
    "    np.mean(pi_zinb * (k == 0) + (1 - pi_zinb) * stats.nbinom.pmf(k, r_zinb, p_zinb)) * len(y)\n",
    "    for k in count_range_final\n",
    "])\n",
    "ax.bar(count_range_final + width/2, zinb_final_freq, width,\n",
    "       label='ZINB Predicted', color='coral', edgecolor='black', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Number of Patents', fontsize=13)\n",
    "ax.set_ylabel('Frequency', fontsize=13)\n",
    "ax.set_title('Figure 1: Observed vs ZINB-Predicted Patent Distribution',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'figure_final_01_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure Final 02: ME of R&D by Firm Size\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x_pos = np.arange(len(me_size_df))\n",
    "bars = ax.bar(x_pos, me_size_df['AME(R&D)'],\n",
    "              yerr=1.96 * me_size_df['SE'], capsize=6,\n",
    "              alpha=0.7, color=['#4393C3', '#92C5DE', '#F4A582', '#D6604D'],\n",
    "              edgecolor='black', linewidth=1.5)\n",
    "ax.axhline(ame_zinb_data['rd_intensity']['AME'], color='black', linestyle='--',\n",
    "           linewidth=2, label=f'Overall AME = {ame_zinb_data[\"rd_intensity\"][\"AME\"]:.3f}')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(me_size_df['Size Group'], fontsize=12)\n",
    "ax.set_ylabel('AME of R&D Intensity\\n(Additional Patents per 1 p.p. Increase)', fontsize=12)\n",
    "ax.set_title('Figure 2: Marginal Effect of R&D by Firm Size',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'figure_final_02_me_rd.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure Final 03: Policy Simulation CDF\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ey_sorted_base = np.sort(E_y_baseline)\n",
    "ey_sorted_cf = np.sort(E_y_cf)\n",
    "cdf = np.arange(1, len(ey_sorted_base) + 1) / len(ey_sorted_base)\n",
    "\n",
    "ax.plot(ey_sorted_base, cdf, 'b-', linewidth=2.5,\n",
    "        label=f'Baseline (mean = {E_y_baseline.mean():.2f})')\n",
    "ax.plot(ey_sorted_cf, cdf, 'r-', linewidth=2.5,\n",
    "        label=f'With Tax Credit (mean = {E_y_cf.mean():.2f})')\n",
    "ax.fill_betweenx(cdf, ey_sorted_base, ey_sorted_cf, alpha=0.15, color='red')\n",
    "\n",
    "ax.set_xlabel('Expected Patents per Firm-Year', fontsize=13)\n",
    "ax.set_ylabel('Cumulative Proportion', fontsize=13)\n",
    "ax.set_title('Figure 3: Policy Simulation\\nR&D Tax Credit (+2 p.p. R&D Intensity)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.annotate(f'Mean impact: +{impact.mean():.2f} patents',\n",
    "            xy=(E_y_cf.mean(), 0.5), fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'figure_final_03_policy_simulation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "code55"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Economic Interpretation and Conclusions (10 min)\n",
    "\n",
    "### Key Findings"
   ],
   "id": "md56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key findings\n",
    "print('KEY FINDINGS')\n",
    "print('=' * 70)\n",
    "\n",
    "rd_irr = np.exp(zinb_result.params_count[rd_idx_zinb])\n",
    "rd_ame_val = ame_zinb_data['rd_intensity']['AME']\n",
    "print(f'\\n1. R&D-Patent Elasticity:')\n",
    "print(f'   IRR = {rd_irr:.4f} => 1 p.p. increase in R&D intensity')\n",
    "print(f'   increases patents by {(rd_irr-1)*100:.1f}% (among innovators)')\n",
    "print(f'   AME = {rd_ame_val:.3f} additional patents per firm-year')\n",
    "print(f'   Consistent with Griliches (1990) elasticity estimates.')\n",
    "\n",
    "size_irr = np.exp(zinb_result.params_count[count_names.index('firm_size')])\n",
    "print(f'\\n2. Firm Size Effect:')\n",
    "print(f'   IRR = {size_irr:.4f} => Larger firms patent more')\n",
    "print(f'   Larger firms also less likely to be non-innovators')\n",
    "print(f'   => Innovation is concentrated in larger firms.')\n",
    "\n",
    "print(f'\\n3. Structural Non-Innovators:')\n",
    "print(f'   {pi_zinb_pred.mean():.0%} of firm-years are structural non-innovators')\n",
    "print(f'   Smaller firms overrepresented among non-innovators')\n",
    "\n",
    "print(f'\\n4. Policy Implications:')\n",
    "print(f'   R&D Tax Credit (+2 p.p.): +{impact.mean():.2f} patents per firm-year')\n",
    "print(f'   Total impact: +{impact.sum():.0f} patents across all firms')\n",
    "print(f'   Effect heterogeneous: larger absolute gains for large firms')"
   ],
   "id": "code57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitations\n",
    "print('LIMITATIONS')\n",
    "print('=' * 70)\n",
    "print()\n",
    "print('1. Patents != Innovation')\n",
    "print('   Patents are just one measure of innovation output.')\n",
    "print('   Many innovations are not patented (trade secrets, process improvements).')\n",
    "print()\n",
    "print('2. R&D Endogeneity')\n",
    "print('   Firms that expect to patent more may invest more in R&D.')\n",
    "print('   Would need instrumental variables or dynamic GMM for causal claims.')\n",
    "print()\n",
    "print('3. Sample Limitations')\n",
    "print('   Manufacturing firms only. Results may not generalize to services.')\n",
    "print('   Simulated data -- real-world relationships may differ.')\n",
    "print()\n",
    "print('4. Correlation vs Causation')\n",
    "print('   Our ZINB estimates are associations, not causal effects.')\n",
    "print('   Policy simulations assume constant structural parameters.')"
   ],
   "id": "code58"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 10: Summary and Extensions\n",
    "\n",
    "### What We Did\n",
    "\n",
    "1. Conducted comprehensive EDA (overdispersion, excess zeros, panel structure)\n",
    "2. Estimated 5 count models (Poisson, NB, FE Poisson, ZIP, ZINB)\n",
    "3. Performed rigorous model selection (tests, AIC/BIC, rootograms)\n",
    "4. Interpreted preferred model (ZINB: count + inflate components)\n",
    "5. Computed marginal effects with heterogeneity analysis\n",
    "6. Conducted policy simulations (R&D tax credit counterfactual)\n",
    "7. Performed robustness checks (alternative specs, subsamples, outliers)\n",
    "8. Created publication-quality tables and figures\n",
    "\n",
    "### Complete Workflow Summary\n",
    "\n",
    "```python\n",
    "# 1. EDA: Check overdispersion, zeros, panel structure\n",
    "# 2. Estimate models: Poisson, NB, FE, ZIP, ZINB\n",
    "# 3. Model selection: Tests, AIC/BIC -> Choose ZINB\n",
    "# 4. Interpret: IRRs, count + inflate components\n",
    "# 5. Marginal effects: AME with heterogeneity\n",
    "# 6. Policy simulation: Counterfactual analysis\n",
    "# 7. Robustness: Alternative specs, subsamples\n",
    "# 8. Report: Publication-quality tables and figures\n",
    "```\n",
    "\n",
    "### Extensions (Future Work)\n",
    "\n",
    "1. **Dynamic models**: Include lagged patents (knowledge accumulation)\n",
    "2. **GMM**: Address R&D endogeneity with instrumental variables\n",
    "3. **Spatial models**: Innovation spillovers from nearby firms\n",
    "4. **Recent data**: Apply to post-2019 data\n",
    "5. **Other outcomes**: Patent citations, product launches, revenue\n",
    "\n",
    "### Lessons for Research\n",
    "\n",
    "1. Always compare multiple models systematically\n",
    "2. Use formal tests, not just eyeballing\n",
    "3. Compute marginal effects for interpretation (not just coefficients)\n",
    "4. Check robustness extensively\n",
    "5. Connect results to economic theory and policy\n",
    "\n",
    "### References\n",
    "\n",
    "- Griliches, Z. (1990). Patent statistics as economic indicators: A survey. *Journal of Economic Literature*, 28(4), 1661-1707.\n",
    "- Hall, B. H., Griliches, Z., & Hausman, J. A. (1986). Patents and R and D: Is there a lag? *International Economic Review*, 27(2), 265-283.\n",
    "- Aghion, P., Bloom, N., Blundell, R., Griffith, R., & Howitt, P. (2005). Competition and innovation: An inverted-U relationship. *Quarterly Journal of Economics*, 120(2), 701-728.\n",
    "- Cameron, A. C., & Trivedi, P. K. (2013). *Regression Analysis of Count Data* (2nd ed.). Cambridge University Press.\n",
    "- Lambert, D. (1992). Zero-inflated Poisson regression, with an application to defects in manufacturing. *Technometrics*, 34(1), 1-14."
   ],
   "id": "md59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary: list all output files\n",
    "print('OUTPUT FILES GENERATED')\n",
    "print('=' * 60)\n",
    "\n",
    "print('\\nFigures:')\n",
    "for f in sorted(FIGURES_DIR.glob('*.png')):\n",
    "    print(f'  {f.name}')\n",
    "\n",
    "print('\\nTables:')\n",
    "for f in sorted(TABLES_DIR.glob('*.csv')):\n",
    "    print(f'  {f.name}')\n",
    "\n",
    "print(f'\\nTotal figures: {len(list(FIGURES_DIR.glob(\"*.png\")))}')\n",
    "print(f'Total tables: {len(list(TABLES_DIR.glob(\"*.csv\")))}')\n",
    "print('\\nCase study complete!')"
   ],
   "id": "code60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
