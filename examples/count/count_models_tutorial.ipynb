{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Panel Count Models with PanelBox\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates how to use PanelBox for estimating count models with panel data. We'll work through a practical example of patent applications, covering:\n",
    "\n",
    "1. **Pooled Poisson** regression\n",
    "2. **Overdispersion** testing and diagnostics\n",
    "3. **Negative Binomial** models for overdispersed data\n",
    "4. **Fixed Effects Poisson** (conditional MLE)\n",
    "5. **Random Effects** count models\n",
    "6. **Zero-inflated** and **Hurdle** models\n",
    "7. **Model selection** and interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Generation\n",
    "\n",
    "Let's start by importing libraries and generating synthetic data on firm patent applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Import PanelBox count models\n",
    "import panelbox as pb\n",
    "from panelbox.models.count import (\n",
    "    PooledPoisson,\n",
    "    PoissonFixedEffects,\n",
    "    RandomEffectsPoisson,\n",
    "    NegativeBinomial,\n",
    "    ZeroInflatedPoisson,\n",
    "    HurdlePoisson\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"PanelBox version: {pb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Panel Data for Patent Applications\n",
    "\n",
    "We'll simulate data on firm patent applications with:\n",
    "- **patents**: Number of patent applications (count outcome)\n",
    "- **rd_intensity**: R&D spending as % of revenue\n",
    "- **firm_size**: Log of firm employees\n",
    "- **industry**: Industry dummy variables\n",
    "- **year**: Time effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patent_data(n_firms=300, n_years=10, seed=42):\n",
    "    \"\"\"Generate synthetic panel data for patent applications.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Panel structure\n",
    "    firm_id = np.repeat(range(1, n_firms + 1), n_years)\n",
    "    year = np.tile(range(2010, 2010 + n_years), n_firms)\n",
    "    \n",
    "    # Firm-specific effects (unobserved innovation capability)\n",
    "    alpha_i = np.repeat(np.random.gamma(2, 0.5, n_firms), n_years)\n",
    "    \n",
    "    # Industry categories (time-invariant)\n",
    "    industries = ['Tech', 'Pharma', 'Manufacturing', 'Other']\n",
    "    industry_probs = [0.3, 0.2, 0.3, 0.2]\n",
    "    firm_industries = np.random.choice(industries, n_firms, p=industry_probs)\n",
    "    industry = np.repeat(firm_industries, n_years)\n",
    "    \n",
    "    # Create industry dummies\n",
    "    industry_tech = (industry == 'Tech').astype(int)\n",
    "    industry_pharma = (industry == 'Pharma').astype(int)\n",
    "    industry_manuf = (industry == 'Manufacturing').astype(int)\n",
    "    \n",
    "    # R&D intensity (% of revenue, time-varying)\n",
    "    rd_base = np.repeat(np.random.uniform(0, 10, n_firms), n_years)\n",
    "    rd_intensity = rd_base + np.random.normal(0, 1, len(firm_id))\n",
    "    rd_intensity = np.maximum(0, rd_intensity)  # Cannot be negative\n",
    "    \n",
    "    # Firm size (log employees, slowly changing)\n",
    "    size_base = np.repeat(np.random.normal(6, 1.5, n_firms), n_years)\n",
    "    size_trend = np.tile(np.arange(n_years) * 0.02, n_firms)\n",
    "    firm_size = size_base + size_trend + np.random.normal(0, 0.2, len(firm_id))\n",
    "    \n",
    "    # Market competition (time-varying, affects all firms)\n",
    "    competition = np.tile(np.random.uniform(0.3, 0.7, n_years), n_firms)\n",
    "    \n",
    "    # Generate patent counts (Negative Binomial for overdispersion)\n",
    "    # True parameters\n",
    "    beta_rd = 0.15\n",
    "    beta_size = 0.3\n",
    "    beta_competition = -0.5\n",
    "    beta_tech = 0.8\n",
    "    beta_pharma = 0.6\n",
    "    beta_manuf = 0.2\n",
    "    \n",
    "    # Linear predictor\n",
    "    lambda_log = (alpha_i + \n",
    "                  beta_rd * rd_intensity + \n",
    "                  beta_size * firm_size +\n",
    "                  beta_competition * competition +\n",
    "                  beta_tech * industry_tech +\n",
    "                  beta_pharma * industry_pharma +\n",
    "                  beta_manuf * industry_manuf)\n",
    "    \n",
    "    lambda_i = np.exp(lambda_log)\n",
    "    \n",
    "    # Add overdispersion using Negative Binomial\n",
    "    dispersion = 0.5  # Higher = more overdispersion\n",
    "    patents = np.random.negative_binomial(lambda_i / dispersion, 1 / (1 + dispersion))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'firm_id': firm_id,\n",
    "        'year': year,\n",
    "        'patents': patents,\n",
    "        'rd_intensity': rd_intensity,\n",
    "        'firm_size': firm_size,\n",
    "        'competition': competition,\n",
    "        'industry': industry,\n",
    "        'industry_tech': industry_tech,\n",
    "        'industry_pharma': industry_pharma,\n",
    "        'industry_manuf': industry_manuf\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate data\n",
    "data = generate_patent_data(n_firms=300, n_years=10)\n",
    "data = data.set_index(['firm_id', 'year'])\n",
    "\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"\\nFirst few observations:\")\n",
    "print(data.head(10))\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(data.describe())\n",
    "print(f\"\\nMean patents: {data['patents'].mean():.2f}\")\n",
    "print(f\"Variance of patents: {data['patents'].var():.2f}\")\n",
    "print(f\"Variance/Mean ratio: {data['patents'].var()/data['patents'].mean():.2f}\")\n",
    "print(\"(Ratio > 1 suggests overdispersion)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Let's explore the distribution of patents and check for overdispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Distribution of patents\n",
    "axes[0, 0].hist(data['patents'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Number of Patents')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Patent Applications')\n",
    "axes[0, 0].axvline(data['patents'].mean(), color='red', linestyle='--', label=f'Mean={data[\"patents\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Patents by R&D intensity\n",
    "rd_bins = pd.qcut(data['rd_intensity'], q=4)\n",
    "patents_by_rd = data.groupby(rd_bins)['patents'].mean()\n",
    "axes[0, 1].bar(range(len(patents_by_rd)), patents_by_rd.values)\n",
    "axes[0, 1].set_xticklabels([f'Q{i+1}' for i in range(4)])\n",
    "axes[0, 1].set_xlabel('R&D Intensity Quartile')\n",
    "axes[0, 1].set_ylabel('Mean Patents')\n",
    "axes[0, 1].set_title('Patents by R&D Intensity')\n",
    "\n",
    "# Patents by firm size\n",
    "size_bins = pd.qcut(data['firm_size'], q=4)\n",
    "patents_by_size = data.groupby(size_bins)['patents'].mean()\n",
    "axes[0, 2].bar(range(len(patents_by_size)), patents_by_size.values)\n",
    "axes[0, 2].set_xticklabels([f'Q{i+1}' for i in range(4)])\n",
    "axes[0, 2].set_xlabel('Firm Size Quartile')\n",
    "axes[0, 2].set_ylabel('Mean Patents')\n",
    "axes[0, 2].set_title('Patents by Firm Size')\n",
    "\n",
    "# Patents by industry\n",
    "patents_by_industry = data.groupby('industry')['patents'].mean().sort_values()\n",
    "axes[1, 0].bar(range(len(patents_by_industry)), patents_by_industry.values)\n",
    "axes[1, 0].set_xticklabels(patents_by_industry.index, rotation=45)\n",
    "axes[1, 0].set_xlabel('Industry')\n",
    "axes[1, 0].set_ylabel('Mean Patents')\n",
    "axes[1, 0].set_title('Patents by Industry')\n",
    "\n",
    "# Time trend\n",
    "patents_by_year = data.groupby(data.index.get_level_values('year'))['patents'].mean()\n",
    "axes[1, 1].plot(patents_by_year.index, patents_by_year.values, marker='o')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Mean Patents')\n",
    "axes[1, 1].set_title('Patents Over Time')\n",
    "\n",
    "# Variance-Mean relationship (check for overdispersion)\n",
    "# Group data and compute mean and variance\n",
    "grouped = data.groupby('firm_id')['patents'].agg(['mean', 'var'])\n",
    "axes[1, 2].scatter(grouped['mean'], grouped['var'], alpha=0.5)\n",
    "axes[1, 2].plot([0, grouped['mean'].max()], [0, grouped['mean'].max()], 'r--', label='Var=Mean (Poisson)')\n",
    "axes[1, 2].set_xlabel('Mean Patents per Firm')\n",
    "axes[1, 2].set_ylabel('Variance of Patents per Firm')\n",
    "axes[1, 2].set_title('Variance-Mean Relationship')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for excess zeros\n",
    "zero_prop = (data['patents'] == 0).mean()\n",
    "print(f\"\\nProportion of zeros: {zero_prop:.1%}\")\n",
    "if zero_prop > 0.3:\n",
    "    print(\"High proportion of zeros - consider zero-inflated models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pooled Poisson Model (Baseline)\n",
    "\n",
    "Start with the simplest count model - Pooled Poisson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Pooled Poisson\n",
    "poisson_model = PooledPoisson.from_formula(\n",
    "    'patents ~ rd_intensity + firm_size + competition + industry_tech + industry_pharma + industry_manuf',\n",
    "    data=data\n",
    ")\n",
    "poisson_result = poisson_model.fit()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"POOLED POISSON RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(poisson_result.summary())\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION (Multiplicative Effects)\")\n",
    "print(\"=\"*60)\n",
    "for var in ['rd_intensity', 'firm_size', 'competition']:\n",
    "    coef = poisson_result.params[var]\n",
    "    effect = (np.exp(coef) - 1) * 100\n",
    "    print(f\"{var}: 1-unit increase → {effect:.1f}% change in expected patents\")\n",
    "\n",
    "# Industry effects\n",
    "for var in ['industry_tech', 'industry_pharma', 'industry_manuf']:\n",
    "    coef = poisson_result.params[var]\n",
    "    effect = (np.exp(coef) - 1) * 100\n",
    "    industry_name = var.replace('industry_', '').title()\n",
    "    print(f\"{industry_name} vs Other: {effect:.1f}% more patents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing for Overdispersion\n",
    "\n",
    "Poisson assumes variance equals mean. Let's test this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overdispersion test\n",
    "od_test = poisson_result.overdispersion_test()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OVERDISPERSION TEST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dispersion parameter: {od_test['dispersion']:.3f}\")\n",
    "print(f\"Chi-squared statistic: {od_test['statistic']:.2f}\")\n",
    "print(f\"P-value: {od_test['p_value']:.4f}\")\n",
    "\n",
    "if od_test['p_value'] < 0.05:\n",
    "    print(\"\\n*** Significant overdispersion detected ***\")\n",
    "    print(\"Consider using Negative Binomial or Quasi-Poisson models\")\n",
    "else:\n",
    "    print(\"\\nNo significant overdispersion - Poisson is appropriate\")\n",
    "\n",
    "# Visual check: Residuals vs Fitted\n",
    "residuals = poisson_result.resid_pearson\n",
    "fitted = poisson_result.fittedvalues\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(fitted, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Pearson Residuals')\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "\n",
    "# Q-Q plot\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Negative Binomial Model\n",
    "\n",
    "If overdispersion is present, Negative Binomial is more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Negative Binomial\n",
    "nb_model = NegativeBinomial.from_formula(\n",
    "    'patents ~ rd_intensity + firm_size + competition + industry_tech + industry_pharma + industry_manuf',\n",
    "    data=data\n",
    ")\n",
    "nb_result = nb_model.fit()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NEGATIVE BINOMIAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(nb_result.summary())\n",
    "\n",
    "# Dispersion parameter\n",
    "print(f\"\\nDispersion parameter (alpha): {nb_result.alpha:.4f}\")\n",
    "print(\"(Smaller alpha = less overdispersion)\")\n",
    "\n",
    "# Compare with Poisson\n",
    "comparison = pd.DataFrame({\n",
    "    'Poisson Coef': poisson_result.params,\n",
    "    'NB Coef': nb_result.params[:-1],  # Exclude alpha\n",
    "    'Poisson SE': poisson_result.bse,\n",
    "    'NB SE': nb_result.bse[:-1]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: POISSON vs NEGATIVE BINOMIAL\")\n",
    "print(\"=\"*60)\n",
    "print(comparison)\n",
    "\n",
    "# Likelihood ratio test\n",
    "lr_stat = 2 * (nb_result.llf - poisson_result.llf)\n",
    "lr_pvalue = stats.chi2.sf(lr_stat, df=1)\n",
    "print(f\"\\nLikelihood Ratio Test (NB vs Poisson):\")\n",
    "print(f\"  LR statistic: {lr_stat:.2f}\")\n",
    "print(f\"  P-value: {lr_pvalue:.4f}\")\n",
    "if lr_pvalue < 0.05:\n",
    "    print(\"  → Negative Binomial is significantly better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fixed Effects Poisson\n",
    "\n",
    "Control for firm-specific unobserved heterogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Effects Poisson (industry dummies drop out as time-invariant)\n",
    "fe_poisson = PoissonFixedEffects.from_formula(\n",
    "    'patents ~ rd_intensity + firm_size + competition',\n",
    "    data=data\n",
    ")\n",
    "fe_result = fe_poisson.fit()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FIXED EFFECTS POISSON RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(fe_result.summary())\n",
    "\n",
    "print(f\"\\nNumber of firms: {fe_result.n_groups}\")\n",
    "print(f\"Firms dropped (all zeros): {fe_result.n_dropped_groups}\")\n",
    "print(f\"Observations used: {fe_result.nobs}\")\n",
    "\n",
    "# Compare time-varying coefficients\n",
    "time_varying_vars = ['rd_intensity', 'firm_size', 'competition']\n",
    "fe_comparison = pd.DataFrame({\n",
    "    'Pooled': [poisson_result.params[v] for v in time_varying_vars],\n",
    "    'Fixed Effects': [fe_result.params[v] for v in time_varying_vars]\n",
    "}, index=time_varying_vars)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: POOLED vs FIXED EFFECTS\")\n",
    "print(\"=\"*60)\n",
    "print(fe_comparison)\n",
    "print(\"\\nNote: Differences suggest correlation between firm effects and regressors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Random Effects Poisson\n",
    "\n",
    "Allow for both time-invariant variables and unobserved heterogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Effects Poisson\n",
    "re_poisson = RandomEffectsPoisson.from_formula(\n",
    "    'patents ~ rd_intensity + firm_size + competition + industry_tech + industry_pharma + industry_manuf',\n",
    "    data=data\n",
    ")\n",
    "re_result = re_poisson.fit()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM EFFECTS POISSON RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(re_result.summary())\n",
    "\n",
    "# Variance decomposition\n",
    "sigma_alpha = re_result.sigma_alpha\n",
    "print(f\"\\nSigma_alpha (RE std dev): {sigma_alpha:.4f}\")\n",
    "print(f\"Proportion of variance due to firm effects: {sigma_alpha**2 / (sigma_alpha**2 + 1):.1%}\")\n",
    "\n",
    "# Compare all models\n",
    "all_models_comparison = pd.DataFrame({\n",
    "    'Pooled': poisson_result.params,\n",
    "    'Negative Binomial': nb_result.params[:-1],\n",
    "    'Random Effects': re_result.params[:-1]  # Exclude sigma\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL MODELS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(all_models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Zero-Inflated and Hurdle Models\n",
    "\n",
    "For data with excess zeros, specialized models may be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we need zero-inflated models\n",
    "observed_zeros = (data['patents'] == 0).sum()\n",
    "expected_zeros_poisson = len(data) * np.exp(-poisson_result.fittedvalues.mean())\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ZERO INFLATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Observed zeros: {observed_zeros} ({observed_zeros/len(data):.1%})\")\n",
    "print(f\"Expected zeros (Poisson): {expected_zeros_poisson:.0f} ({expected_zeros_poisson/len(data):.1%})\")\n",
    "\n",
    "if observed_zeros > expected_zeros_poisson * 1.5:\n",
    "    print(\"\\n*** Excess zeros detected - Zero-inflated model recommended ***\")\n",
    "    \n",
    "    # Fit Zero-Inflated Poisson\n",
    "    zip_model = ZeroInflatedPoisson.from_formula(\n",
    "        'patents ~ rd_intensity + firm_size + competition',\n",
    "        inflate='rd_intensity + firm_size',  # Zero-inflation equation\n",
    "        data=data\n",
    "    )\n",
    "    zip_result = zip_model.fit()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ZERO-INFLATED POISSON RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(zip_result.summary())\n",
    "    \n",
    "    # Hurdle Model alternative\n",
    "    hurdle_model = HurdlePoisson.from_formula(\n",
    "        'patents ~ rd_intensity + firm_size + competition',\n",
    "        data=data\n",
    "    )\n",
    "    hurdle_result = hurdle_model.fit()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HURDLE POISSON RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(hurdle_result.summary())\n",
    "    \n",
    "    # Model comparison\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL COMPARISON - AIC\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Poisson AIC: {poisson_result.aic:.2f}\")\n",
    "    print(f\"Zero-Inflated Poisson AIC: {zip_result.aic:.2f}\")\n",
    "    print(f\"Hurdle Poisson AIC: {hurdle_result.aic:.2f}\")\n",
    "else:\n",
    "    print(\"\\nNo significant excess zeros - standard count models are appropriate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Marginal Effects and Interpretation\n",
    "\n",
    "For count models, we often want to know the marginal effect on the expected count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate marginal effects for Poisson model\n",
    "me_poisson = poisson_result.marginal_effects(kind='average')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MARGINAL EFFECTS - POOLED POISSON\")\n",
    "print(\"=\"*60)\n",
    "print(me_poisson.summary())\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ECONOMIC INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for var in ['rd_intensity', 'firm_size', 'competition']:\n",
    "    effect = me_poisson.effects[var]\n",
    "    print(f\"{var}: 1-unit increase → {effect:.3f} additional patents on average\")\n",
    "\n",
    "# Industry effects\n",
    "for var in ['industry_tech', 'industry_pharma', 'industry_manuf']:\n",
    "    effect = me_poisson.effects[var]\n",
    "    industry_name = var.replace('industry_', '').title()\n",
    "    print(f\"{industry_name} firms: {effect:.2f} more patents than Other industry\")\n",
    "\n",
    "# Calculate elasticities\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ELASTICITIES (% change in patents for 1% change in X)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for var in ['rd_intensity', 'firm_size']:\n",
    "    elasticity = poisson_result.params[var]  # For Poisson, elasticity = coefficient\n",
    "    print(f\"{var}: {elasticity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Predictions and Model Validation\n",
    "\n",
    "Evaluate model performance using predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from different models\n",
    "pred_poisson = poisson_result.predict(data)\n",
    "pred_nb = nb_result.predict(data)\n",
    "\n",
    "# Calculate prediction metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "models_predictions = {\n",
    "    'Poisson': pred_poisson,\n",
    "    'Negative Binomial': pred_nb\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREDICTION ACCURACY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, predictions in models_predictions.items():\n",
    "    mae = mean_absolute_error(data['patents'], predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(data['patents'], predictions))\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  MAE: {mae:.3f}\")\n",
    "    print(f\"  RMSE: {rmse:.3f}\")\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for idx, (name, predictions) in enumerate(models_predictions.items()):\n",
    "    axes[idx].scatter(data['patents'], predictions, alpha=0.5)\n",
    "    axes[idx].plot([0, data['patents'].max()], [0, data['patents'].max()], 'r--')\n",
    "    axes[idx].set_xlabel('Actual Patents')\n",
    "    axes[idx].set_ylabel('Predicted Patents')\n",
    "    axes[idx].set_title(f'{name} Model')\n",
    "    \n",
    "    # Add correlation\n",
    "    corr = np.corrcoef(data['patents'], predictions)[0, 1]\n",
    "    axes[idx].text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                   transform=axes[idx].transAxes, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(data['patents'], bins=30, alpha=0.5, label='Actual', density=True)\n",
    "plt.hist(pred_poisson, bins=30, alpha=0.5, label='Poisson Predicted', density=True)\n",
    "plt.hist(pred_nb, bins=30, alpha=0.5, label='NB Predicted', density=True)\n",
    "plt.xlabel('Number of Patents')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution: Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Best Practices and Common Pitfalls\n",
    "\n",
    "### Common Pitfalls:\n",
    "\n",
    "1. **Ignoring overdispersion**\n",
    "   - Always test variance-mean relationship\n",
    "   - Use Negative Binomial if overdispersed\n",
    "\n",
    "2. **Not checking for excess zeros**\n",
    "   - Compare observed vs expected zeros\n",
    "   - Consider ZIP or Hurdle models\n",
    "\n",
    "3. **Interpreting coefficients directly**\n",
    "   - Coefficients are on log scale\n",
    "   - Calculate marginal effects or IRRs\n",
    "\n",
    "4. **Ignoring panel structure**\n",
    "   - Use FE/RE models for panel data\n",
    "   - Account for within-unit correlation\n",
    "\n",
    "5. **Not checking model assumptions**\n",
    "   - Examine residual plots\n",
    "   - Test for autocorrelation in panels\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Start with Poisson, test assumptions**\n",
    "2. **Use robust standard errors**\n",
    "3. **Consider exposure/offset variables if needed**\n",
    "4. **Report Incidence Rate Ratios (IRR) for interpretability**\n",
    "5. **Validate with out-of-sample predictions**\n",
    "6. **Compare multiple model specifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Incidence Rate Ratios\n",
    "print(\"=\"*60)\n",
    "print(\"INCIDENCE RATE RATIOS (IRR)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "irr = np.exp(poisson_result.params)\n",
    "irr_ci_lower = np.exp(poisson_result.params - 1.96 * poisson_result.bse)\n",
    "irr_ci_upper = np.exp(poisson_result.params + 1.96 * poisson_result.bse)\n",
    "\n",
    "irr_table = pd.DataFrame({\n",
    "    'IRR': irr,\n",
    "    '95% CI Lower': irr_ci_lower,\n",
    "    '95% CI Upper': irr_ci_upper\n",
    "})\n",
    "\n",
    "print(irr_table)\n",
    "print(\"\\nInterpretation: IRR > 1 means factor increases count\")\n",
    "print(\"                IRR < 1 means factor decreases count\")\n",
    "print(\"                IRR = 1.5 means 50% increase in expected count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Model Selection Summary\n",
    "\n",
    "Let's create a final comparison to choose the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive model comparison\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Poisson', 'Negative Binomial', 'FE Poisson', 'RE Poisson'],\n",
    "    'Log-Likelihood': [\n",
    "        poisson_result.llf,\n",
    "        nb_result.llf,\n",
    "        fe_result.llf,\n",
    "        re_result.llf\n",
    "    ],\n",
    "    'AIC': [\n",
    "        poisson_result.aic,\n",
    "        nb_result.aic,\n",
    "        getattr(fe_result, 'aic', np.nan),\n",
    "        re_result.aic\n",
    "    ],\n",
    "    'BIC': [\n",
    "        poisson_result.bic,\n",
    "        nb_result.bic,\n",
    "        getattr(fe_result, 'bic', np.nan),\n",
    "        re_result.bic\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(model_comparison)\n",
    "print(\"\\nBest model by AIC:\", model_comparison.loc[model_comparison['AIC'].idxmin(), 'Model'])\n",
    "print(\"Best model by BIC:\", model_comparison.loc[model_comparison['BIC'].idxmin(), 'Model'])\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if od_test['p_value'] < 0.05:\n",
    "    print(\"✓ Overdispersion detected → Use Negative Binomial\")\n",
    "else:\n",
    "    print(\"✓ No overdispersion → Poisson is appropriate\")\n",
    "\n",
    "if zero_prop > 0.3:\n",
    "    print(\"✓ High zero proportion → Consider Zero-Inflated models\")\n",
    "\n",
    "print(\"✓ For causal inference → Use Fixed Effects\")\n",
    "print(\"✓ For prediction with time-invariant vars → Use Random Effects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Conclusion\n",
    "\n",
    "This tutorial covered the main count models in PanelBox:\n",
    "\n",
    "- **Poisson**: Baseline model, assumes variance = mean\n",
    "- **Negative Binomial**: Handles overdispersion\n",
    "- **Fixed Effects Poisson**: Controls for unobserved heterogeneity\n",
    "- **Random Effects Poisson**: Balances efficiency and bias\n",
    "- **Zero-Inflated/Hurdle**: For excess zeros\n",
    "\n",
    "Key takeaways:\n",
    "1. Always test for overdispersion and excess zeros\n",
    "2. Panel structure matters - use appropriate FE/RE models\n",
    "3. Interpret results using marginal effects or IRRs\n",
    "4. Validate models with predictions and diagnostics\n",
    "5. Choose models based on data characteristics and research goals\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Apply to your own count data\n",
    "- Explore Quasi-Poisson models for mild overdispersion\n",
    "- Try panel-specific extensions (dynamic count models)\n",
    "- Use bootstrap for robust inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tutorial complete! Ready for count data analysis with PanelBox.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
