{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Identification and Exclusion Restrictions \u2014 SOLUTION\n",
    "\n",
    "**This is the worked solution notebook.**\n",
    "It corresponds to `06_identification.ipynb` and provides complete solutions for all 4 exercises.\n",
    "\n",
    "> Instructors: do not distribute this file to students before they complete the tutorial notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises Overview\n",
    "\n",
    "| Exercise | Topic | Difficulty |\n",
    "|---|---|---|\n",
    "| 1 | Evaluate Candidate Instruments (Conceptual) | Introductory |\n",
    "| 2 | Implement and Compare Specifications (Hands-On) | Intermediate |\n",
    "| 3 | Collinearity Diagnostic (Intermediate) | Intermediate |\n",
    "| 4 | Monte Carlo Simulation (Advanced) | Advanced |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize as sp_minimize\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# PanelBox imports\n",
    "from panelbox.models.selection import PanelHeckman\n",
    "from panelbox.models.selection.inverse_mills import compute_imr, test_selection_effect\n",
    "\n",
    "# Visualization configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Paths (relative to solutions/ directory)\n",
    "BASE_DIR = Path('..')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "FIGURES_DIR = OUTPUT_DIR / 'figures'\n",
    "TABLES_DIR = OUTPUT_DIR / 'tables'\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "mroz = pd.read_csv(DATA_DIR / 'mroz_1987.csv')\n",
    "college = pd.read_csv(DATA_DIR / 'college_wage.csv')\n",
    "\n",
    "print(f'Mroz dataset: {len(mroz)} observations, columns: {list(mroz.columns)}')\n",
    "print(f'College dataset: {len(college)} observations, columns: {list(college.columns)}')\n",
    "\n",
    "# Prepare Mroz data\n",
    "mroz['log_wage'] = np.log(mroz['wage'])\n",
    "y_mroz = mroz['log_wage'].fillna(0).values\n",
    "selection_mroz = mroz['lfp'].values\n",
    "\n",
    "# Outcome equation variables (X) for Mroz\n",
    "X_mroz = sm.add_constant(mroz[['education', 'experience', 'experience_sq']].values)\n",
    "X_mroz_names = ['const', 'education', 'experience', 'experience_sq']\n",
    "\n",
    "# Prepare College data\n",
    "college['log_wage'] = np.log(college['wage'])\n",
    "y_college = college['log_wage'].fillna(0).values\n",
    "selection_college = college['college'].values\n",
    "\n",
    "# Outcome equation variables (X) for College\n",
    "X_college = sm.add_constant(\n",
    "    college[['ability', 'parent_education', 'family_income', 'urban', 'female']].values\n",
    ")\n",
    "X_college_names = ['const', 'ability', 'parent_education', 'family_income', 'urban', 'female']\n",
    "\n",
    "print(f'\\nMroz: {selection_mroz.sum()}/{len(selection_mroz)} selected ({selection_mroz.mean():.1%})')\n",
    "print(f'College: {selection_college.sum()}/{len(selection_college)} selected ({selection_college.mean():.1%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Evaluate Candidate Instruments (Conceptual)\n",
    "\n",
    "For each proposed exclusion restriction below, evaluate whether it satisfies:\n",
    "- **Relevance**: Does it plausibly affect selection?\n",
    "- **Validity**: Can we argue it does NOT directly affect the outcome?\n",
    "\n",
    "| Application | Selection | Outcome | Proposed Instrument |\n",
    "|---|---|---|---|\n",
    "| (a) Female labor supply | Work vs not work | Hourly wage | Husband's age |\n",
    "| (b) College wage premium | Attend college | Post-college wage | SAT score |\n",
    "| (c) Union wage gap | Union member | Log wage | State right-to-work law |\n",
    "| (d) Training program | Participate in training | Quarterly earnings | Distance to training site |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Solution: Exercise 1\n",
    "\n",
    "---\n",
    "\n",
    "#### (a) Husband's age as instrument for female labor supply\n",
    "\n",
    "**Relevance**: Moderate. Husband's age is correlated with husband's income and career stage,\n",
    "which affects the household's financial need for the wife to work. Older husbands may have\n",
    "higher incomes, reducing the wife's need to participate. However, the effect may be indirect\n",
    "and weak after controlling for husband's income directly.\n",
    "\n",
    "**Validity**: Questionable. Husband's age is likely correlated with the wife's own age\n",
    "(assortative mating), which in turn correlates with her experience and human capital\n",
    "accumulation. Since experience affects wages directly, husband's age could violate\n",
    "the exclusion restriction by proxying for the wife's own age/experience.\n",
    "\n",
    "**Assessment**: **Weak/problematic instrument.** While it has some relevance through the\n",
    "income channel, the strong correlation with wife's age creates a plausible direct channel\n",
    "to wages. Better alternatives exist (number of young children, husband's income).\n",
    "\n",
    "---\n",
    "\n",
    "#### (b) SAT score as instrument for college wage premium\n",
    "\n",
    "**Relevance**: Strong. SAT scores are highly predictive of college attendance. Higher SAT\n",
    "scores increase the probability of admission and enrollment.\n",
    "\n",
    "**Validity**: **FAILS.** SAT scores are a direct measure of academic ability and cognitive\n",
    "skill, which are rewarded in the labor market independently of college attendance. Employers\n",
    "value the skills that SAT scores reflect (analytical reasoning, quantitative ability), so\n",
    "SAT scores almost certainly affect wages directly. This is a classic example of an instrument\n",
    "that is relevant but invalid.\n",
    "\n",
    "**Assessment**: **Invalid instrument.** SAT scores directly affect wages through the ability\n",
    "channel. Using SAT as an exclusion restriction would conflate the selection correction with\n",
    "the ability premium, producing biased estimates of the college wage premium.\n",
    "\n",
    "---\n",
    "\n",
    "#### (c) State right-to-work law for union wage gap\n",
    "\n",
    "**Relevance**: Strong. Right-to-work laws prohibit mandatory union membership as a\n",
    "condition of employment. States with such laws have significantly lower unionization rates\n",
    "(about 5-7% vs. 12-15% in non-RTW states). This creates strong, policy-driven variation\n",
    "in union membership.\n",
    "\n",
    "**Validity**: Debatable. The key concern is whether right-to-work laws affect wages through\n",
    "channels other than individual union membership. If RTW laws reduce overall union density,\n",
    "they may weaken unions' ability to bargain for all workers (including non-members through\n",
    "spillover effects), which would violate the exclusion restriction. Also, RTW laws may\n",
    "correlate with other state-level policies (taxes, regulation) that affect wages.\n",
    "\n",
    "**Assessment**: **Reasonable but imperfect instrument.** The relevance condition is strongly\n",
    "satisfied. The validity concern depends on whether one conditions on state-level controls.\n",
    "With proper state fixed effects or controls for state economic conditions, RTW laws\n",
    "become a more credible instrument. Best used in combination with other instruments.\n",
    "\n",
    "---\n",
    "\n",
    "#### (d) Distance to training site for training program\n",
    "\n",
    "**Relevance**: Moderate to strong. Greater distance to the training site increases\n",
    "participation costs (travel time, transportation expenses), reducing the probability\n",
    "of participation. This follows the logic of Card (1995) who used distance to college\n",
    "as an instrument for college attendance.\n",
    "\n",
    "**Validity**: Generally plausible, but requires careful consideration. The main concern is\n",
    "that distance may correlate with local labor market conditions. Workers in rural areas\n",
    "(farther from training sites) may face different wage structures than urban workers.\n",
    "However, conditional on observable labor market characteristics (urban/rural, industry,\n",
    "local unemployment rate), the remaining variation in distance is plausibly exogenous\n",
    "to individual earnings potential.\n",
    "\n",
    "**Assessment**: **Good instrument.** This is one of the most credible types of exclusion\n",
    "restrictions in program evaluation. The economic argument is clear: distance shifts the\n",
    "cost of participation without directly affecting a worker's productivity. Recommended\n",
    "to include controls for local labor market conditions to strengthen the exclusion\n",
    "restriction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table for Exercise 1\n",
    "assessment_df = pd.DataFrame({\n",
    "    'Application': [\n",
    "        '(a) Female labor supply',\n",
    "        '(b) College wage premium',\n",
    "        '(c) Union wage gap',\n",
    "        '(d) Training program'\n",
    "    ],\n",
    "    'Instrument': [\n",
    "        \"Husband's age\",\n",
    "        'SAT score',\n",
    "        'Right-to-work law',\n",
    "        'Distance to site'\n",
    "    ],\n",
    "    'Relevance': [\n",
    "        'Moderate (indirect via income)',\n",
    "        'Strong (predicts enrollment)',\n",
    "        'Strong (policy-driven)',\n",
    "        'Moderate-Strong (cost channel)'\n",
    "    ],\n",
    "    'Validity': [\n",
    "        'Questionable (corr. with wife age)',\n",
    "        'FAILS (ability -> wages)',\n",
    "        'Debatable (spillover effects)',\n",
    "        'Plausible (with controls)'\n",
    "    ],\n",
    "    'Verdict': [\n",
    "        'Weak / Problematic',\n",
    "        'INVALID',\n",
    "        'Reasonable (with caveats)',\n",
    "        'GOOD'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print('=' * 90)\n",
    "print('  EXERCISE 1: ASSESSMENT OF CANDIDATE EXCLUSION RESTRICTIONS')\n",
    "print('=' * 90)\n",
    "print()\n",
    "print(assessment_df.to_string(index=False))\n",
    "\n",
    "print('\\n' + '=' * 90)\n",
    "print('Key Lesson: A valid exclusion restriction must satisfy BOTH conditions:')\n",
    "print('  1. RELEVANCE: It must significantly predict selection')\n",
    "print('  2. VALIDITY:  It must NOT directly affect the outcome')\n",
    "print('The SAT score example shows that strong relevance is not sufficient;')\n",
    "print('validity is equally (or more) important.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Implement and Compare Specifications (Hands-On)\n",
    "\n",
    "Using the Mroz dataset, implement the following three models and compare:\n",
    "\n",
    "1. **Model A**: Exclusion restrictions = `children_lt6` + `husband_income`\n",
    "2. **Model B**: Exclusion restrictions = `children_6_18` + `husband_income`\n",
    "3. **Model C**: Exclusion restrictions = `age` only\n",
    "\n",
    "**Tasks**:\n",
    "- Estimate all three models\n",
    "- Create a comparison table of outcome coefficients and selection parameters\n",
    "- Which specification produces the most stable results? Why?\n",
    "- Run the LR relevance test for each set of exclusion restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Solution: Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the selection equation variable matrices for each model\n",
    "\n",
    "# Model A: X + children_lt6 + husband_income\n",
    "Z_A = sm.add_constant(\n",
    "    mroz[['education', 'experience', 'experience_sq',\n",
    "          'children_lt6', 'husband_income']].values\n",
    ")\n",
    "Z_A_names = ['const', 'education', 'experience', 'experience_sq',\n",
    "             'children_lt6', 'husband_income']\n",
    "\n",
    "# Model B: X + children_6_18 + husband_income\n",
    "Z_B = sm.add_constant(\n",
    "    mroz[['education', 'experience', 'experience_sq',\n",
    "          'children_6_18', 'husband_income']].values\n",
    ")\n",
    "Z_B_names = ['const', 'education', 'experience', 'experience_sq',\n",
    "             'children_6_18', 'husband_income']\n",
    "\n",
    "# Model C: X + age (single exclusion restriction)\n",
    "Z_C = sm.add_constant(\n",
    "    mroz[['education', 'experience', 'experience_sq', 'age']].values\n",
    ")\n",
    "Z_C_names = ['const', 'education', 'experience', 'experience_sq', 'age']\n",
    "\n",
    "print('Model A exclusion restrictions: children_lt6, husband_income')\n",
    "print(f'  Z_A shape: {Z_A.shape}')\n",
    "print('Model B exclusion restrictions: children_6_18, husband_income')\n",
    "print(f'  Z_B shape: {Z_B.shape}')\n",
    "print('Model C exclusion restriction:  age only')\n",
    "print(f'  Z_C shape: {Z_C.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Estimate each model using PanelHeckman\n",
    "\n",
    "# Model A\n",
    "model_A = PanelHeckman(\n",
    "    endog=y_mroz,\n",
    "    exog=X_mroz,\n",
    "    selection=selection_mroz,\n",
    "    exog_selection=Z_A,\n",
    "    method='two_step'\n",
    ")\n",
    "result_A = model_A.fit()\n",
    "\n",
    "# Model B\n",
    "model_B = PanelHeckman(\n",
    "    endog=y_mroz,\n",
    "    exog=X_mroz,\n",
    "    selection=selection_mroz,\n",
    "    exog_selection=Z_B,\n",
    "    method='two_step'\n",
    ")\n",
    "result_B = model_B.fit()\n",
    "\n",
    "# Model C\n",
    "model_C = PanelHeckman(\n",
    "    endog=y_mroz,\n",
    "    exog=X_mroz,\n",
    "    selection=selection_mroz,\n",
    "    exog_selection=Z_C,\n",
    "    method='two_step'\n",
    ")\n",
    "result_C = model_C.fit()\n",
    "\n",
    "print('All three models estimated successfully.')\n",
    "print(f'\\nModel A - rho: {result_A.rho:.4f}, sigma: {result_A.sigma:.4f}')\n",
    "print(f'Model B - rho: {result_B.rho:.4f}, sigma: {result_B.sigma:.4f}')\n",
    "print(f'Model C - rho: {result_C.rho:.4f}, sigma: {result_C.sigma:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create comparison table of outcome coefficients and selection parameters\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Variable': X_mroz_names,\n",
    "    'Model A (children_lt6 + husb_inc)': result_A.outcome_params,\n",
    "    'Model B (children_6_18 + husb_inc)': result_B.outcome_params,\n",
    "    'Model C (age only)': result_C.outcome_params,\n",
    "}).set_index('Variable')\n",
    "\n",
    "# Add selection parameters\n",
    "sel_params = pd.DataFrame({\n",
    "    'Variable': ['sigma', 'rho', 'lambda (rho*sigma)'],\n",
    "    'Model A (children_lt6 + husb_inc)': [\n",
    "        result_A.sigma, result_A.rho, result_A.rho * result_A.sigma\n",
    "    ],\n",
    "    'Model B (children_6_18 + husb_inc)': [\n",
    "        result_B.sigma, result_B.rho, result_B.rho * result_B.sigma\n",
    "    ],\n",
    "    'Model C (age only)': [\n",
    "        result_C.sigma, result_C.rho, result_C.rho * result_C.sigma\n",
    "    ],\n",
    "}).set_index('Variable')\n",
    "\n",
    "full_comparison = pd.concat([comparison, sel_params])\n",
    "\n",
    "print('=' * 80)\n",
    "print('  EXERCISE 2: COMPARISON OF THREE EXCLUSION RESTRICTION SPECIFICATIONS')\n",
    "print('=' * 80)\n",
    "print()\n",
    "print(full_comparison.round(4).to_string())\n",
    "\n",
    "# Compute coefficient stability metrics\n",
    "print('\\n' + '-' * 80)\n",
    "print('Stability Metrics:')\n",
    "for var in X_mroz_names:\n",
    "    vals = full_comparison.loc[var].values.astype(float)\n",
    "    print(f'  {var:20s} - Range: {vals.max() - vals.min():.4f}, '\n",
    "          f'Std: {vals.std():.4f}')\n",
    "\n",
    "rho_vals = full_comparison.loc['rho'].values.astype(float)\n",
    "print(f'  {\"rho\":20s} - Range: {rho_vals.max() - rho_vals.min():.4f}, '\n",
    "      f'Std: {rho_vals.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 (continued): Visualization of coefficient comparison\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: Outcome equation coefficients (excluding constant for scale)\n",
    "vars_to_plot = ['education', 'experience', 'experience_sq']\n",
    "idx_plot = [X_mroz_names.index(v) for v in vars_to_plot]\n",
    "\n",
    "x_pos = np.arange(len(vars_to_plot))\n",
    "width = 0.25\n",
    "\n",
    "axes[0].bar(x_pos - width, [result_A.outcome_params[i] for i in idx_plot],\n",
    "            width, label='Model A (children_lt6 + husb_inc)', color='#27ae60', alpha=0.8)\n",
    "axes[0].bar(x_pos, [result_B.outcome_params[i] for i in idx_plot],\n",
    "            width, label='Model B (children_6_18 + husb_inc)', color='#2980b9', alpha=0.8)\n",
    "axes[0].bar(x_pos + width, [result_C.outcome_params[i] for i in idx_plot],\n",
    "            width, label='Model C (age only)', color='#e74c3c', alpha=0.8)\n",
    "\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(vars_to_plot, fontsize=11)\n",
    "axes[0].set_ylabel('Coefficient Value', fontsize=12)\n",
    "axes[0].set_title('Outcome Equation: Coefficients\\nAcross Three Specifications', fontsize=13)\n",
    "axes[0].legend(fontsize=8, loc='best')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].axhline(y=0, color='black', linewidth=0.8)\n",
    "\n",
    "# Right: Selection parameters (rho, sigma, lambda)\n",
    "sel_labels = [r'$\\sigma$', r'$\\rho$', r'$\\lambda = \\rho\\sigma$']\n",
    "sel_A = [result_A.sigma, result_A.rho, result_A.rho * result_A.sigma]\n",
    "sel_B = [result_B.sigma, result_B.rho, result_B.rho * result_B.sigma]\n",
    "sel_C = [result_C.sigma, result_C.rho, result_C.rho * result_C.sigma]\n",
    "\n",
    "x_pos2 = np.arange(len(sel_labels))\n",
    "axes[1].bar(x_pos2 - width, sel_A, width, label='Model A', color='#27ae60', alpha=0.8)\n",
    "axes[1].bar(x_pos2, sel_B, width, label='Model B', color='#2980b9', alpha=0.8)\n",
    "axes[1].bar(x_pos2 + width, sel_C, width, label='Model C', color='#e74c3c', alpha=0.8)\n",
    "\n",
    "axes[1].set_xticks(x_pos2)\n",
    "axes[1].set_xticklabels(sel_labels, fontsize=12)\n",
    "axes[1].set_ylabel('Parameter Value', fontsize=12)\n",
    "axes[1].set_title('Selection Parameters\\nAcross Three Specifications', fontsize=13)\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].axhline(y=0, color='black', linewidth=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'ex2_specification_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Likelihood Ratio relevance test for each specification\n",
    "\n",
    "def probit_log_likelihood(gamma, Z, selection):\n",
    "    \"\"\"Compute probit log-likelihood.\"\"\"\n",
    "    linear_pred = Z @ gamma\n",
    "    prob = stats.norm.cdf(linear_pred)\n",
    "    prob = np.clip(prob, 1e-10, 1 - 1e-10)\n",
    "    return np.sum(selection * np.log(prob) + (1 - selection) * np.log(1 - prob))\n",
    "\n",
    "def neg_probit_llf(gamma, Z, sel):\n",
    "    \"\"\"Negative probit log-likelihood for minimization.\"\"\"\n",
    "    return -probit_log_likelihood(gamma, Z, sel)\n",
    "\n",
    "# Restricted probit: selection equation with only X (no exclusion restrictions)\n",
    "res_restricted = sp_minimize(\n",
    "    neg_probit_llf, np.zeros(X_mroz.shape[1]),\n",
    "    args=(X_mroz, selection_mroz), method='BFGS'\n",
    ")\n",
    "ll_restricted = -res_restricted.fun\n",
    "\n",
    "print('=' * 80)\n",
    "print('  EXERCISE 2: LIKELIHOOD RATIO RELEVANCE TESTS')\n",
    "print('=' * 80)\n",
    "print(f'\\nRestricted log-likelihood (Z = X, no exclusions): {ll_restricted:.4f}')\n",
    "print()\n",
    "\n",
    "for name, result, Z_spec in [\n",
    "    ('Model A (children_lt6 + husb_inc)', result_A, Z_A),\n",
    "    ('Model B (children_6_18 + husb_inc)', result_B, Z_B),\n",
    "    ('Model C (age only)', result_C, Z_C),\n",
    "]:\n",
    "    # Unrestricted log-likelihood\n",
    "    ll_unrestricted = probit_log_likelihood(result.probit_params, Z_spec, selection_mroz)\n",
    "    \n",
    "    # Number of exclusion restrictions\n",
    "    n_excl = Z_spec.shape[1] - X_mroz.shape[1]\n",
    "    \n",
    "    # LR statistic\n",
    "    lr_stat = 2 * (ll_unrestricted - ll_restricted)\n",
    "    lr_pvalue = 1 - stats.chi2.cdf(lr_stat, df=n_excl)\n",
    "    \n",
    "    print(f'{name}:')\n",
    "    print(f'  Unrestricted LL:  {ll_unrestricted:.4f}')\n",
    "    print(f'  LR statistic:     {lr_stat:.4f}')\n",
    "    print(f'  df:               {n_excl}')\n",
    "    print(f'  p-value:          {lr_pvalue:.6f}')\n",
    "    print(f'  Verdict:          {\"RELEVANT (reject H0)\" if lr_pvalue < 0.05 else \"WEAK (fail to reject)\"}\"')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Discussion and conclusions\n",
    "\n",
    "print('=' * 80)\n",
    "print('  EXERCISE 2: DISCUSSION')\n",
    "print('=' * 80)\n",
    "print()\n",
    "print('Which specification produces the most stable results?')\n",
    "print('-' * 60)\n",
    "print()\n",
    "print('Model A (children_lt6 + husband_income) is likely the BEST specification:')\n",
    "print()\n",
    "print('  1. children_lt6 is the strongest exclusion restriction because young children')\n",
    "print('     have a large, well-documented effect on mothers\\' labor supply through the')\n",
    "print('     childcare cost channel. This effect is strong and robust.')\n",
    "print()\n",
    "print('  2. husband_income provides an additional source of identifying variation')\n",
    "print('     through the household income effect on the participation decision.')\n",
    "print()\n",
    "print('  3. Having TWO exclusion restrictions allows for over-identification checks')\n",
    "print('     and generally produces more stable estimates than a single instrument.')\n",
    "print()\n",
    "print('Model B (children_6_18 + husband_income) is similar but slightly weaker:')\n",
    "print('  - School-age children (6-18) have a weaker effect on labor supply than')\n",
    "print('    young children (< 6), because school provides free childcare.')\n",
    "print()\n",
    "print('Model C (age only) is the WEAKEST specification:')\n",
    "print('  - Only one exclusion restriction (less over-identification)')\n",
    "print('  - Age is correlated with experience and experience_sq, which are in the')\n",
    "print('    outcome equation. This creates a potential validity concern.')\n",
    "print('  - The exclusion restriction is that age affects selection through factors')\n",
    "print('    other than experience (e.g., social norms about working women by age),')\n",
    "print('    but this argument is weaker than the childcare cost argument.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Collinearity Diagnostic (Intermediate)\n",
    "\n",
    "For the College Wage dataset:\n",
    "\n",
    "1. Estimate the Heckman model with and without exclusion restrictions\n",
    "2. For each specification, compute the correlation matrix between the IMR and each X variable (for selected observations only)\n",
    "3. Create a heatmap visualization of both correlation matrices side by side\n",
    "4. Compute the condition number of the augmented design matrix $[X, \\lambda]$ for both cases\n",
    "5. Discuss: how does adding exclusion restrictions reduce the condition number?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Solution: Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Estimate Heckman model WITH exclusion restrictions\n",
    "\n",
    "Z_college_full = sm.add_constant(\n",
    "    college[['ability', 'parent_education', 'family_income',\n",
    "             'urban', 'female', 'distance_college', 'tuition']].values\n",
    ")\n",
    "Z_college_full_names = ['const', 'ability', 'parent_education', 'family_income',\n",
    "                        'urban', 'female', 'distance_college', 'tuition']\n",
    "\n",
    "model_with_excl = PanelHeckman(\n",
    "    endog=y_college,\n",
    "    exog=X_college,\n",
    "    selection=selection_college,\n",
    "    exog_selection=Z_college_full,\n",
    "    method='two_step'\n",
    ")\n",
    "result_with_excl = model_with_excl.fit()\n",
    "\n",
    "# Estimate Heckman model WITHOUT exclusion restrictions (Z = X)\n",
    "model_no_excl = PanelHeckman(\n",
    "    endog=y_college,\n",
    "    exog=X_college,\n",
    "    selection=selection_college,\n",
    "    exog_selection=X_college,  # Z = X: no exclusion restrictions!\n",
    "    method='two_step'\n",
    ")\n",
    "result_no_excl = model_no_excl.fit()\n",
    "\n",
    "print('Both models estimated.')\n",
    "print(f'\\nWith exclusion restrictions: rho = {result_with_excl.rho:.4f}')\n",
    "print(f'Without exclusion restrictions: rho = {result_no_excl.rho:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compute IMR for both specifications\n",
    "\n",
    "# With exclusion restrictions\n",
    "Zg_with = Z_college_full @ result_with_excl.probit_params\n",
    "Phi_with = stats.norm.cdf(Zg_with)\n",
    "imr_with = stats.norm.pdf(Zg_with) / np.clip(Phi_with, 1e-10, None)\n",
    "\n",
    "# Without exclusion restrictions\n",
    "Xg_no = X_college @ result_no_excl.probit_params\n",
    "Phi_no = stats.norm.cdf(Xg_no)\n",
    "imr_no = stats.norm.pdf(Xg_no) / np.clip(Phi_no, 1e-10, None)\n",
    "\n",
    "# Mask for selected observations\n",
    "sel_mask = selection_college == 1\n",
    "\n",
    "print(f'IMR with exclusion - Mean: {imr_with[sel_mask].mean():.4f}, Std: {imr_with[sel_mask].std():.4f}')\n",
    "print(f'IMR without exclusion - Mean: {imr_no[sel_mask].mean():.4f}, Std: {imr_no[sel_mask].std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute correlation matrices between IMR and X variables\n",
    "\n",
    "# Variable names (excluding constant for correlation analysis)\n",
    "var_names = ['ability', 'parent_education', 'family_income', 'urban', 'female']\n",
    "var_indices = list(range(1, X_college.shape[1]))  # skip constant (column 0)\n",
    "\n",
    "# Build correlation DataFrames\n",
    "# WITH exclusion restrictions\n",
    "data_with = pd.DataFrame(\n",
    "    X_college[sel_mask, 1:],  # exclude constant\n",
    "    columns=var_names\n",
    ")\n",
    "data_with['IMR'] = imr_with[sel_mask]\n",
    "corr_with = data_with.corr()\n",
    "\n",
    "# WITHOUT exclusion restrictions\n",
    "data_no = pd.DataFrame(\n",
    "    X_college[sel_mask, 1:],  # exclude constant\n",
    "    columns=var_names\n",
    ")\n",
    "data_no['IMR'] = imr_no[sel_mask]\n",
    "corr_no = data_no.corr()\n",
    "\n",
    "# Print IMR correlations\n",
    "print('=== Correlation of IMR with X Variables (Selected Sample) ===')\n",
    "print()\n",
    "print(f'{\"Variable\":25s} {\"With Exclusion\":>15s} {\"Without Exclusion\":>18s} {\"Difference\":>12s}')\n",
    "print('-' * 75)\n",
    "for var in var_names:\n",
    "    r_with = corr_with.loc[var, 'IMR']\n",
    "    r_no = corr_no.loc[var, 'IMR']\n",
    "    flag = ' *** HIGH' if abs(r_no) > 0.7 else ''\n",
    "    print(f'{var:25s} {r_with:15.4f} {r_no:18.4f} {abs(r_no) - abs(r_with):12.4f}{flag}')\n",
    "\n",
    "print()\n",
    "print('*** HIGH marks correlations above 0.7 in absolute value (without exclusion).')\n",
    "print('\\nConclusion: Without exclusion restrictions, the IMR is more')\n",
    "print('correlated with X variables, indicating worse multicollinearity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 (continued): Create side-by-side heatmaps\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Heatmap: WITH exclusion restrictions\n",
    "sns.heatmap(\n",
    "    corr_with, annot=True, fmt='.3f', cmap='RdBu_r',\n",
    "    center=0, vmin=-1, vmax=1, square=True,\n",
    "    ax=axes[0], linewidths=0.5,\n",
    "    cbar_kws={'shrink': 0.8}\n",
    ")\n",
    "axes[0].set_title('WITH Exclusion Restrictions\\n(distance_college, tuition)', fontsize=13)\n",
    "axes[0].tick_params(axis='both', labelsize=9)\n",
    "\n",
    "# Heatmap: WITHOUT exclusion restrictions\n",
    "sns.heatmap(\n",
    "    corr_no, annot=True, fmt='.3f', cmap='RdBu_r',\n",
    "    center=0, vmin=-1, vmax=1, square=True,\n",
    "    ax=axes[1], linewidths=0.5,\n",
    "    cbar_kws={'shrink': 0.8}\n",
    ")\n",
    "axes[1].set_title('WITHOUT Exclusion Restrictions\\n(Z = X)', fontsize=13)\n",
    "axes[1].tick_params(axis='both', labelsize=9)\n",
    "\n",
    "plt.suptitle('Correlation Matrices: X Variables and IMR\\n(College Wage Data, Selected Sample)',\n",
    "             fontsize=14, fontweight='bold', y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'ex3_collinearity_heatmaps.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('Notice the IMR row/column:')\n",
    "print('  - LEFT (with exclusion): IMR has moderate correlations with X variables')\n",
    "print('  - RIGHT (without exclusion): IMR has stronger correlations, indicating collinearity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compute condition numbers of the augmented design matrix [X, lambda]\n",
    "\n",
    "# Augmented matrix: [X, IMR] for selected observations\n",
    "X_sel = X_college[sel_mask]\n",
    "\n",
    "# With exclusion restrictions\n",
    "X_aug_with = np.column_stack([X_sel, imr_with[sel_mask]])\n",
    "cond_with = np.linalg.cond(X_aug_with)\n",
    "\n",
    "# Without exclusion restrictions\n",
    "X_aug_no = np.column_stack([X_sel, imr_no[sel_mask]])\n",
    "cond_no = np.linalg.cond(X_aug_no)\n",
    "\n",
    "# Also compute condition number of X alone (baseline)\n",
    "cond_X = np.linalg.cond(X_sel)\n",
    "\n",
    "print('=' * 70)\n",
    "print('  EXERCISE 3: CONDITION NUMBER ANALYSIS')\n",
    "print('=' * 70)\n",
    "print()\n",
    "print(f'{\"Matrix\":40s} {\"Condition Number\":>18s}')\n",
    "print('-' * 62)\n",
    "print(f'{\"X alone (baseline)\":40s} {cond_X:18.2f}')\n",
    "print(f'{\"[X, IMR] WITH exclusion restrictions\":40s} {cond_with:18.2f}')\n",
    "print(f'{\"[X, IMR] WITHOUT exclusion restrictions\":40s} {cond_no:18.2f}')\n",
    "\n",
    "print(f'\\nRatio (without / with): {cond_no / cond_with:.2f}x')\n",
    "\n",
    "print()\n",
    "print('Interpretation:')\n",
    "print('  - A condition number > 30 suggests moderate multicollinearity')\n",
    "print('  - A condition number > 100 suggests severe multicollinearity')\n",
    "print('  - Adding the IMR column increases the condition number in both cases,')\n",
    "print('    but the increase is MUCH LARGER without exclusion restrictions.')\n",
    "print('  - With exclusion restrictions, the IMR has independent variation from')\n",
    "print('    the excluded variables (distance, tuition), keeping collinearity in check.')\n",
    "print('  - Without exclusion restrictions, the IMR is nearly a linear function of X,')\n",
    "print('    causing the condition number to explode.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the collinearity problem with scatter plots\n",
    "\n",
    "# Compute X'beta for the selected sample\n",
    "Xb = X_sel @ result_with_excl.outcome_params\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# With exclusion restrictions\n",
    "corr_xb_with = np.corrcoef(Xb, imr_with[sel_mask])[0, 1]\n",
    "axes[0].scatter(Xb, imr_with[sel_mask], alpha=0.3, s=15, color='#27ae60')\n",
    "axes[0].set_xlabel(r\"$X'\\hat{\\beta}$ (outcome linear predictor)\", fontsize=12)\n",
    "axes[0].set_ylabel(r\"$\\lambda(Z'\\hat{\\gamma})$ (IMR)\", fontsize=12)\n",
    "axes[0].set_title(f'WITH Exclusion Restrictions\\n'\n",
    "                   f'Corr(X\\'b, IMR) = {corr_xb_with:.3f}', fontsize=13)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Without exclusion restrictions\n",
    "corr_xb_no = np.corrcoef(Xb, imr_no[sel_mask])[0, 1]\n",
    "axes[1].scatter(Xb, imr_no[sel_mask], alpha=0.3, s=15, color='#e74c3c')\n",
    "axes[1].set_xlabel(r\"$X'\\hat{\\beta}$ (outcome linear predictor)\", fontsize=12)\n",
    "axes[1].set_ylabel(r\"$\\lambda(X'\\hat{\\gamma})$ (IMR)\", fontsize=12)\n",
    "axes[1].set_title(f'WITHOUT Exclusion Restrictions\\n'\n",
    "                   f'Corr(X\\'b, IMR) = {corr_xb_no:.3f}', fontsize=13)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Collinearity Diagnostic: IMR vs Outcome Linear Predictor\\n(College Wage Data)',\n",
    "             fontsize=14, fontweight='bold', y=1.04)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'ex3_imr_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Correlation(X\\'b, IMR) with exclusion:    {corr_xb_with:.4f}')\n",
    "print(f'Correlation(X\\'b, IMR) without exclusion: {corr_xb_no:.4f}')\n",
    "print()\n",
    "print('The right panel shows a much tighter relationship between the IMR and')\n",
    "print('the linear predictor, confirming the collinearity problem.')\n",
    "print('The left panel shows more dispersion, indicating that the exclusion')\n",
    "print('restrictions provide independent variation in the IMR.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 (continued): Summary discussion\n",
    "\n",
    "print('=' * 80)\n",
    "print('  EXERCISE 3: SUMMARY DISCUSSION')\n",
    "print('=' * 80)\n",
    "print()\n",
    "print('How do exclusion restrictions reduce the condition number?')\n",
    "print('-' * 60)\n",
    "print()\n",
    "print('1. MATHEMATICAL MECHANISM:')\n",
    "print('   Without exclusion restrictions (Z = X), the IMR is computed as:')\n",
    "print('     lambda = phi(X\\'gamma) / Phi(X\\'gamma)')\n",
    "print('   Since lambda(.) is approximately linear over typical data ranges,')\n",
    "print('     lambda \\u2248 a + b * X\\'gamma = a + b * (X_1*g_1 + X_2*g_2 + ...)')\n",
    "print('   This makes the IMR column nearly a linear combination of the X columns,')\n",
    "print('   inflating the condition number.')\n",
    "print()\n",
    "print('2. WITH EXCLUSION RESTRICTIONS:')\n",
    "print('   The IMR is computed from a broader set of variables Z = [X, W]:')\n",
    "print('     lambda = phi(X\\'g_1 + W\\'g_2) / Phi(X\\'g_1 + W\\'g_2)')\n",
    "print('   The variation in W generates variation in lambda that is NOT a linear')\n",
    "print('   function of X alone. This \"breaks\" the collinearity.')\n",
    "print()\n",
    "print('3. PRACTICAL CONSEQUENCE:')\n",
    "print(f'   Condition number with exclusion:    {cond_with:.1f}')\n",
    "print(f'   Condition number without exclusion: {cond_no:.1f}')\n",
    "print(f'   Ratio: {cond_no/cond_with:.1f}x worse without exclusion')\n",
    "print()\n",
    "print('4. IMPLICATIONS FOR INFERENCE:')\n",
    "print('   Higher condition numbers lead to:')\n",
    "print('   - Larger standard errors for all coefficients')\n",
    "print('   - Numerical instability in OLS computation')\n",
    "print('   - Sensitivity of estimates to small changes in the data')\n",
    "print('   - Unreliable hypothesis tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Monte Carlo Simulation (Advanced)\n",
    "\n",
    "Design a Monte Carlo experiment to demonstrate the importance of exclusion restrictions:\n",
    "\n",
    "1. Generate data from a known DGP with:\n",
    "   - True $\\beta = [1.0, 0.5]$ (outcome equation)\n",
    "   - True $\\rho = 0.5$ (selection correlation)\n",
    "   - A valid exclusion restriction $W$ that affects selection but not the outcome\n",
    "\n",
    "2. For 200 replications, estimate the Heckman model:\n",
    "   - (a) With the exclusion restriction\n",
    "   - (b) Without the exclusion restriction\n",
    "\n",
    "3. Compare the sampling distributions of $\\hat{\\beta}_1$, $\\hat{\\rho}$, and $\\hat{\\sigma}$\n",
    "\n",
    "4. Create histograms showing the distributions and mark the true parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "### Solution: Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the Data Generating Process (DGP)\n",
    "\n",
    "def generate_heckman_data(n, beta, gamma_x, gamma_w, rho, sigma, seed=None):\n",
    "    \"\"\"\n",
    "    Generate data from a Heckman selection model DGP.\n",
    "    \n",
    "    Outcome equation:  y = beta[0] + beta[1] * x + epsilon\n",
    "    Selection equation: s* = gamma_x[0] + gamma_x[1] * x + gamma_w * w + u\n",
    "    s = 1 if s* > 0\n",
    "    y observed only if s = 1\n",
    "    \n",
    "    (u, epsilon) ~ Bivariate Normal with correlation rho\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Sample size\n",
    "    beta : array-like\n",
    "        [intercept, slope] for outcome equation\n",
    "    gamma_x : array-like\n",
    "        [intercept, slope_x] for selection equation (shared with outcome)\n",
    "    gamma_w : float\n",
    "        Coefficient on exclusion restriction W in selection equation\n",
    "    rho : float\n",
    "        Correlation between selection and outcome errors\n",
    "    sigma : float\n",
    "        Standard deviation of outcome error\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict with x, w, y, selection, y_latent\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        rng = np.random.RandomState(seed)\n",
    "    else:\n",
    "        rng = np.random.RandomState()\n",
    "    \n",
    "    # Generate covariates\n",
    "    x = rng.randn(n)  # observed in both equations\n",
    "    w = rng.randn(n)  # exclusion restriction: only in selection equation\n",
    "    \n",
    "    # Generate correlated errors (u, epsilon)\n",
    "    # u ~ N(0, 1) for probit, epsilon ~ N(0, sigma^2)\n",
    "    cov_matrix = np.array([\n",
    "        [1.0, rho * sigma],\n",
    "        [rho * sigma, sigma**2]\n",
    "    ])\n",
    "    errors = rng.multivariate_normal([0, 0], cov_matrix, size=n)\n",
    "    u = errors[:, 0]\n",
    "    epsilon = errors[:, 1]\n",
    "    \n",
    "    # Selection equation: s* = gamma_x[0] + gamma_x[1]*x + gamma_w*w + u\n",
    "    s_star = gamma_x[0] + gamma_x[1] * x + gamma_w * w + u\n",
    "    selection = (s_star > 0).astype(float)\n",
    "    \n",
    "    # Outcome equation: y = beta[0] + beta[1]*x + epsilon\n",
    "    y_latent = beta[0] + beta[1] * x + epsilon\n",
    "    \n",
    "    # Observed outcome (0 for non-selected, actual value for selected)\n",
    "    y_obs = np.where(selection == 1, y_latent, 0.0)\n",
    "    \n",
    "    return {\n",
    "        'x': x,\n",
    "        'w': w,\n",
    "        'y': y_obs,\n",
    "        'y_latent': y_latent,\n",
    "        'selection': selection,\n",
    "        'u': u,\n",
    "        'epsilon': epsilon,\n",
    "    }\n",
    "\n",
    "# Define true parameters\n",
    "TRUE_BETA = np.array([1.0, 0.5])       # outcome: intercept=1.0, slope=0.5\n",
    "TRUE_GAMMA_X = np.array([0.0, 0.3])    # selection: intercept=0, slope_x=0.3\n",
    "TRUE_GAMMA_W = 0.8                      # exclusion restriction coefficient\n",
    "TRUE_RHO = 0.5                          # selection correlation\n",
    "TRUE_SIGMA = 1.0                        # outcome error std dev\n",
    "\n",
    "# Test the DGP with a single draw\n",
    "test_data = generate_heckman_data(\n",
    "    n=1000, beta=TRUE_BETA, gamma_x=TRUE_GAMMA_X,\n",
    "    gamma_w=TRUE_GAMMA_W, rho=TRUE_RHO, sigma=TRUE_SIGMA, seed=42\n",
    ")\n",
    "\n",
    "print('DGP Test (single draw, n=1000):')\n",
    "print(f'  Selection rate: {test_data[\"selection\"].mean():.1%}')\n",
    "print(f'  Mean latent y: {test_data[\"y_latent\"].mean():.3f}')\n",
    "print(f'  Mean observed y (selected): {test_data[\"y\"][test_data[\"selection\"]==1].mean():.3f}')\n",
    "print(f'  Corr(u, epsilon): {np.corrcoef(test_data[\"u\"], test_data[\"epsilon\"])[0,1]:.3f}')\n",
    "print(f'  True rho: {TRUE_RHO}')\n",
    "print(f'\\nTrue parameters:')\n",
    "print(f'  beta = {TRUE_BETA}')\n",
    "print(f'  rho = {TRUE_RHO}, sigma = {TRUE_SIGMA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Monte Carlo simulation - 200 replications\n",
    "\n",
    "n_reps = 200\n",
    "n_obs = 500\n",
    "\n",
    "# Storage for results\n",
    "results_with_excl = {'beta0': [], 'beta1': [], 'rho': [], 'sigma': []}\n",
    "results_without_excl = {'beta0': [], 'beta1': [], 'rho': [], 'sigma': []}\n",
    "results_ols = {'beta0': [], 'beta1': []}  # OLS on selected sample (biased)\n",
    "\n",
    "n_failed_with = 0\n",
    "n_failed_without = 0\n",
    "\n",
    "print(f'Running Monte Carlo simulation: {n_reps} replications, n={n_obs} each...')\n",
    "print()\n",
    "\n",
    "for rep in range(n_reps):\n",
    "    if (rep + 1) % 50 == 0:\n",
    "        print(f'  Replication {rep + 1}/{n_reps}...')\n",
    "    \n",
    "    # Generate data\n",
    "    data = generate_heckman_data(\n",
    "        n=n_obs, beta=TRUE_BETA, gamma_x=TRUE_GAMMA_X,\n",
    "        gamma_w=TRUE_GAMMA_W, rho=TRUE_RHO, sigma=TRUE_SIGMA,\n",
    "        seed=1000 + rep\n",
    "    )\n",
    "    \n",
    "    x = data['x']\n",
    "    w = data['w']\n",
    "    y = data['y']\n",
    "    sel = data['selection']\n",
    "    \n",
    "    # Design matrices\n",
    "    X_mc = sm.add_constant(x)\n",
    "    Z_with = sm.add_constant(np.column_stack([x, w]))  # X + exclusion\n",
    "    Z_without = X_mc.copy()                            # X only (no exclusion)\n",
    "    \n",
    "    # --- OLS on selected sample (naive, biased) ---\n",
    "    sel_mask_mc = sel == 1\n",
    "    if sel_mask_mc.sum() > 5:  # need enough observations\n",
    "        try:\n",
    "            beta_ols = np.linalg.lstsq(X_mc[sel_mask_mc], y[sel_mask_mc], rcond=None)[0]\n",
    "            results_ols['beta0'].append(beta_ols[0])\n",
    "            results_ols['beta1'].append(beta_ols[1])\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # --- Heckman WITH exclusion restriction ---\n",
    "    try:\n",
    "        model_w = PanelHeckman(\n",
    "            endog=y, exog=X_mc, selection=sel,\n",
    "            exog_selection=Z_with, method='two_step'\n",
    "        )\n",
    "        res_w = model_w.fit()\n",
    "        results_with_excl['beta0'].append(res_w.outcome_params[0])\n",
    "        results_with_excl['beta1'].append(res_w.outcome_params[1])\n",
    "        results_with_excl['rho'].append(res_w.rho)\n",
    "        results_with_excl['sigma'].append(res_w.sigma)\n",
    "    except Exception:\n",
    "        n_failed_with += 1\n",
    "    \n",
    "    # --- Heckman WITHOUT exclusion restriction ---\n",
    "    try:\n",
    "        model_wo = PanelHeckman(\n",
    "            endog=y, exog=X_mc, selection=sel,\n",
    "            exog_selection=Z_without, method='two_step'\n",
    "        )\n",
    "        res_wo = model_wo.fit()\n",
    "        results_without_excl['beta0'].append(res_wo.outcome_params[0])\n",
    "        results_without_excl['beta1'].append(res_wo.outcome_params[1])\n",
    "        results_without_excl['rho'].append(res_wo.rho)\n",
    "        results_without_excl['sigma'].append(res_wo.sigma)\n",
    "    except Exception:\n",
    "        n_failed_without += 1\n",
    "\n",
    "print(f'\\nSimulation complete!')\n",
    "print(f'  Successful replications (with excl):    {len(results_with_excl[\"beta1\"])}/{n_reps}')\n",
    "print(f'  Successful replications (without excl): {len(results_without_excl[\"beta1\"])}/{n_reps}')\n",
    "print(f'  Failed (with excl):    {n_failed_with}')\n",
    "print(f'  Failed (without excl): {n_failed_without}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compare sampling distributions\n",
    "\n",
    "# Convert to arrays\n",
    "beta1_with = np.array(results_with_excl['beta1'])\n",
    "beta1_without = np.array(results_without_excl['beta1'])\n",
    "beta1_ols = np.array(results_ols['beta1'])\n",
    "\n",
    "rho_with = np.array(results_with_excl['rho'])\n",
    "rho_without = np.array(results_without_excl['rho'])\n",
    "\n",
    "sigma_with = np.array(results_with_excl['sigma'])\n",
    "sigma_without = np.array(results_without_excl['sigma'])\n",
    "\n",
    "# Summary statistics\n",
    "print('=' * 85)\n",
    "print('  EXERCISE 4: MONTE CARLO RESULTS')\n",
    "print('=' * 85)\n",
    "print(f'  True parameters: beta_1 = {TRUE_BETA[1]}, rho = {TRUE_RHO}, sigma = {TRUE_SIGMA}')\n",
    "print()\n",
    "\n",
    "print(f'{\"\":35s} {\"Mean\":>10s} {\"Bias\":>10s} {\"Std Dev\":>10s} {\"RMSE\":>10s}')\n",
    "print('-' * 80)\n",
    "\n",
    "# beta_1\n",
    "for label, arr, true_val in [\n",
    "    ('beta_1 (Heckman WITH excl)', beta1_with, TRUE_BETA[1]),\n",
    "    ('beta_1 (Heckman WITHOUT excl)', beta1_without, TRUE_BETA[1]),\n",
    "    ('beta_1 (OLS, biased)', beta1_ols, TRUE_BETA[1]),\n",
    "]:\n",
    "    mean_val = arr.mean()\n",
    "    bias = mean_val - true_val\n",
    "    std_val = arr.std()\n",
    "    rmse = np.sqrt(bias**2 + std_val**2)\n",
    "    print(f'{label:35s} {mean_val:10.4f} {bias:10.4f} {std_val:10.4f} {rmse:10.4f}')\n",
    "\n",
    "print()\n",
    "\n",
    "# rho\n",
    "for label, arr, true_val in [\n",
    "    ('rho (Heckman WITH excl)', rho_with, TRUE_RHO),\n",
    "    ('rho (Heckman WITHOUT excl)', rho_without, TRUE_RHO),\n",
    "]:\n",
    "    mean_val = arr.mean()\n",
    "    bias = mean_val - true_val\n",
    "    std_val = arr.std()\n",
    "    rmse = np.sqrt(bias**2 + std_val**2)\n",
    "    print(f'{label:35s} {mean_val:10.4f} {bias:10.4f} {std_val:10.4f} {rmse:10.4f}')\n",
    "\n",
    "print()\n",
    "\n",
    "# sigma\n",
    "for label, arr, true_val in [\n",
    "    ('sigma (Heckman WITH excl)', sigma_with, TRUE_SIGMA),\n",
    "    ('sigma (Heckman WITHOUT excl)', sigma_without, TRUE_SIGMA),\n",
    "]:\n",
    "    mean_val = arr.mean()\n",
    "    bias = mean_val - true_val\n",
    "    std_val = arr.std()\n",
    "    rmse = np.sqrt(bias**2 + std_val**2)\n",
    "    print(f'{label:35s} {mean_val:10.4f} {bias:10.4f} {std_val:10.4f} {rmse:10.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create histograms showing the sampling distributions\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# ---- Row 1: beta_1 distributions ----\n",
    "\n",
    "# (a) Heckman WITH exclusion\n",
    "axes[0, 0].hist(beta1_with, bins=25, alpha=0.7, color='#27ae60',\n",
    "                edgecolor='black', linewidth=0.5, density=True)\n",
    "axes[0, 0].axvline(TRUE_BETA[1], color='red', linewidth=2.5, linestyle='--',\n",
    "                    label=f'True $\\\\beta_1$ = {TRUE_BETA[1]}')\n",
    "axes[0, 0].axvline(beta1_with.mean(), color='blue', linewidth=2, linestyle=':',\n",
    "                    label=f'Mean = {beta1_with.mean():.3f}')\n",
    "axes[0, 0].set_title('$\\\\hat{\\\\beta}_1$: Heckman WITH Exclusion', fontsize=12)\n",
    "axes[0, 0].set_xlabel(r'$\\hat{\\beta}_1$', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Density', fontsize=11)\n",
    "axes[0, 0].legend(fontsize=9)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# (b) Heckman WITHOUT exclusion\n",
    "axes[0, 1].hist(beta1_without, bins=25, alpha=0.7, color='#e74c3c',\n",
    "                edgecolor='black', linewidth=0.5, density=True)\n",
    "axes[0, 1].axvline(TRUE_BETA[1], color='red', linewidth=2.5, linestyle='--',\n",
    "                    label=f'True $\\\\beta_1$ = {TRUE_BETA[1]}')\n",
    "axes[0, 1].axvline(beta1_without.mean(), color='blue', linewidth=2, linestyle=':',\n",
    "                    label=f'Mean = {beta1_without.mean():.3f}')\n",
    "axes[0, 1].set_title('$\\\\hat{\\\\beta}_1$: Heckman WITHOUT Exclusion', fontsize=12)\n",
    "axes[0, 1].set_xlabel(r'$\\hat{\\beta}_1$', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Density', fontsize=11)\n",
    "axes[0, 1].legend(fontsize=9)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# (c) OLS (biased)\n",
    "axes[0, 2].hist(beta1_ols, bins=25, alpha=0.7, color='#f39c12',\n",
    "                edgecolor='black', linewidth=0.5, density=True)\n",
    "axes[0, 2].axvline(TRUE_BETA[1], color='red', linewidth=2.5, linestyle='--',\n",
    "                    label=f'True $\\\\beta_1$ = {TRUE_BETA[1]}')\n",
    "axes[0, 2].axvline(beta1_ols.mean(), color='blue', linewidth=2, linestyle=':',\n",
    "                    label=f'Mean = {beta1_ols.mean():.3f}')\n",
    "axes[0, 2].set_title('$\\\\hat{\\\\beta}_1$: OLS (No Selection Correction)', fontsize=12)\n",
    "axes[0, 2].set_xlabel(r'$\\hat{\\beta}_1$', fontsize=11)\n",
    "axes[0, 2].set_ylabel('Density', fontsize=11)\n",
    "axes[0, 2].legend(fontsize=9)\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# ---- Row 2: rho and sigma distributions ----\n",
    "\n",
    "# (d) rho WITH exclusion\n",
    "axes[1, 0].hist(rho_with, bins=25, alpha=0.7, color='#27ae60',\n",
    "                edgecolor='black', linewidth=0.5, density=True)\n",
    "axes[1, 0].axvline(TRUE_RHO, color='red', linewidth=2.5, linestyle='--',\n",
    "                    label=f'True $\\\\rho$ = {TRUE_RHO}')\n",
    "axes[1, 0].axvline(rho_with.mean(), color='blue', linewidth=2, linestyle=':',\n",
    "                    label=f'Mean = {rho_with.mean():.3f}')\n",
    "axes[1, 0].set_title('$\\\\hat{\\\\rho}$: Heckman WITH Exclusion', fontsize=12)\n",
    "axes[1, 0].set_xlabel(r'$\\hat{\\rho}$', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Density', fontsize=11)\n",
    "axes[1, 0].legend(fontsize=9)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# (e) rho WITHOUT exclusion\n",
    "axes[1, 1].hist(rho_without, bins=25, alpha=0.7, color='#e74c3c',\n",
    "                edgecolor='black', linewidth=0.5, density=True)\n",
    "axes[1, 1].axvline(TRUE_RHO, color='red', linewidth=2.5, linestyle='--',\n",
    "                    label=f'True $\\\\rho$ = {TRUE_RHO}')\n",
    "axes[1, 1].axvline(rho_without.mean(), color='blue', linewidth=2, linestyle=':',\n",
    "                    label=f'Mean = {rho_without.mean():.3f}')\n",
    "axes[1, 1].set_title('$\\\\hat{\\\\rho}$: Heckman WITHOUT Exclusion', fontsize=12)\n",
    "axes[1, 1].set_xlabel(r'$\\hat{\\rho}$', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Density', fontsize=11)\n",
    "axes[1, 1].legend(fontsize=9)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# (f) sigma comparison (overlaid)\n",
    "axes[1, 2].hist(sigma_with, bins=25, alpha=0.5, color='#27ae60',\n",
    "                edgecolor='black', linewidth=0.5, density=True,\n",
    "                label=f'With excl. (mean={sigma_with.mean():.3f})')\n",
    "axes[1, 2].hist(sigma_without, bins=25, alpha=0.5, color='#e74c3c',\n",
    "                edgecolor='black', linewidth=0.5, density=True,\n",
    "                label=f'Without excl. (mean={sigma_without.mean():.3f})')\n",
    "axes[1, 2].axvline(TRUE_SIGMA, color='red', linewidth=2.5, linestyle='--',\n",
    "                    label=f'True $\\\\sigma$ = {TRUE_SIGMA}')\n",
    "axes[1, 2].set_title('$\\\\hat{\\\\sigma}$: Comparison', fontsize=12)\n",
    "axes[1, 2].set_xlabel(r'$\\hat{\\sigma}$', fontsize=11)\n",
    "axes[1, 2].set_ylabel('Density', fontsize=11)\n",
    "axes[1, 2].legend(fontsize=8)\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Monte Carlo Simulation: Sampling Distributions\\n'\n",
    "             f'({n_reps} replications, n={n_obs}, true $\\\\rho$={TRUE_RHO})',\n",
    "             fontsize=14, fontweight='bold', y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'ex4_monte_carlo_histograms.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 (continued): Box plots for a cleaner comparison\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# beta_1 box plot\n",
    "bp1 = axes[0].boxplot(\n",
    "    [beta1_with, beta1_without, beta1_ols],\n",
    "    labels=['Heckman\\n(with excl.)', 'Heckman\\n(no excl.)', 'OLS\\n(biased)'],\n",
    "    patch_artist=True,\n",
    "    medianprops=dict(color='black', linewidth=2),\n",
    "    boxprops=dict(linewidth=1.5),\n",
    ")\n",
    "colors = ['#27ae60', '#e74c3c', '#f39c12']\n",
    "for patch, color in zip(bp1['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "axes[0].axhline(TRUE_BETA[1], color='red', linewidth=2, linestyle='--',\n",
    "                label=f'True value = {TRUE_BETA[1]}')\n",
    "axes[0].set_ylabel(r'$\\hat{\\beta}_1$', fontsize=12)\n",
    "axes[0].set_title(r'Distribution of $\\hat{\\beta}_1$', fontsize=13)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# rho box plot\n",
    "bp2 = axes[1].boxplot(\n",
    "    [rho_with, rho_without],\n",
    "    labels=['Heckman\\n(with excl.)', 'Heckman\\n(no excl.)'],\n",
    "    patch_artist=True,\n",
    "    medianprops=dict(color='black', linewidth=2),\n",
    "    boxprops=dict(linewidth=1.5),\n",
    ")\n",
    "for patch, color in zip(bp2['boxes'], ['#27ae60', '#e74c3c']):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "axes[1].axhline(TRUE_RHO, color='red', linewidth=2, linestyle='--',\n",
    "                label=f'True value = {TRUE_RHO}')\n",
    "axes[1].set_ylabel(r'$\\hat{\\rho}$', fontsize=12)\n",
    "axes[1].set_title(r'Distribution of $\\hat{\\rho}$', fontsize=13)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# sigma box plot\n",
    "bp3 = axes[2].boxplot(\n",
    "    [sigma_with, sigma_without],\n",
    "    labels=['Heckman\\n(with excl.)', 'Heckman\\n(no excl.)'],\n",
    "    patch_artist=True,\n",
    "    medianprops=dict(color='black', linewidth=2),\n",
    "    boxprops=dict(linewidth=1.5),\n",
    ")\n",
    "for patch, color in zip(bp3['boxes'], ['#27ae60', '#e74c3c']):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "axes[2].axhline(TRUE_SIGMA, color='red', linewidth=2, linestyle='--',\n",
    "                label=f'True value = {TRUE_SIGMA}')\n",
    "axes[2].set_ylabel(r'$\\hat{\\sigma}$', fontsize=12)\n",
    "axes[2].set_title(r'Distribution of $\\hat{\\sigma}$', fontsize=13)\n",
    "axes[2].legend(fontsize=10)\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Monte Carlo: Box Plots of Estimator Distributions\\n'\n",
    "             f'({n_reps} replications, n={n_obs})',\n",
    "             fontsize=14, fontweight='bold', y=1.04)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'ex4_monte_carlo_boxplots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Detailed interpretation and conclusions\n",
    "\n",
    "print('=' * 85)\n",
    "print('  EXERCISE 4: MONTE CARLO CONCLUSIONS')\n",
    "print('=' * 85)\n",
    "print()\n",
    "print('1. BIAS COMPARISON (beta_1):')\n",
    "print(f'   True beta_1 = {TRUE_BETA[1]}')\n",
    "print(f'   Heckman with exclusion:    mean = {beta1_with.mean():.4f}, bias = {beta1_with.mean() - TRUE_BETA[1]:.4f}')\n",
    "print(f'   Heckman without exclusion: mean = {beta1_without.mean():.4f}, bias = {beta1_without.mean() - TRUE_BETA[1]:.4f}')\n",
    "print(f'   OLS (ignoring selection):  mean = {beta1_ols.mean():.4f}, bias = {beta1_ols.mean() - TRUE_BETA[1]:.4f}')\n",
    "print()\n",
    "print('2. VARIANCE COMPARISON (beta_1):')\n",
    "print(f'   Heckman with exclusion:    std = {beta1_with.std():.4f}')\n",
    "print(f'   Heckman without exclusion: std = {beta1_without.std():.4f}')\n",
    "print(f'   OLS (ignoring selection):  std = {beta1_ols.std():.4f}')\n",
    "print(f'   Variance ratio (without/with): {(beta1_without.std()/beta1_with.std())**2:.2f}x')\n",
    "print()\n",
    "print('3. RMSE COMPARISON (overall accuracy):')\n",
    "rmse_with = np.sqrt(np.mean((beta1_with - TRUE_BETA[1])**2))\n",
    "rmse_without = np.sqrt(np.mean((beta1_without - TRUE_BETA[1])**2))\n",
    "rmse_ols = np.sqrt(np.mean((beta1_ols - TRUE_BETA[1])**2))\n",
    "print(f'   Heckman with exclusion:    RMSE = {rmse_with:.4f}')\n",
    "print(f'   Heckman without exclusion: RMSE = {rmse_without:.4f}')\n",
    "print(f'   OLS (ignoring selection):  RMSE = {rmse_ols:.4f}')\n",
    "print()\n",
    "print('4. SELECTION PARAMETER RECOVERY:')\n",
    "print(f'   True rho = {TRUE_RHO}')\n",
    "print(f'   With exclusion:    mean = {rho_with.mean():.4f}, std = {rho_with.std():.4f}')\n",
    "print(f'   Without exclusion: mean = {rho_without.mean():.4f}, std = {rho_without.std():.4f}')\n",
    "print()\n",
    "print('5. KEY FINDINGS:')\n",
    "print('   - Heckman WITH exclusion restrictions produces the least biased estimates')\n",
    "print('     of both the outcome coefficient (beta_1) and the selection correlation (rho).')\n",
    "print('   - Heckman WITHOUT exclusion restrictions has higher variance (due to collinearity')\n",
    "print('     between the IMR and X variables) and may show more bias as well.')\n",
    "print('   - OLS ignoring selection is biased because it does not correct for the')\n",
    "print('     correlation between selection and outcome errors.')\n",
    "print('   - The exclusion restriction provides genuine identifying variation that')\n",
    "print('     stabilizes the Heckman estimator and improves both bias and precision.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What We Demonstrated in These Solutions\n",
    "\n",
    "| Exercise | Key Insight |\n",
    "|---|---|\n",
    "| 1 (Conceptual) | Evaluating instruments requires assessing BOTH relevance AND validity. Strong relevance alone (e.g., SAT scores) does not make a valid instrument. |\n",
    "| 2 (Hands-On) | Different exclusion restrictions yield different estimates. Strong instruments (children_lt6) produce more stable results than weak ones (age). Multiple instruments allow over-identification checks. |\n",
    "| 3 (Collinearity) | Without exclusion restrictions, the IMR is highly collinear with X, inflating condition numbers and destabilizing estimation. Exclusion restrictions provide independent variation that breaks this collinearity. |\n",
    "| 4 (Monte Carlo) | Simulation confirms that Heckman with exclusion restrictions has lower bias and variance than Heckman without exclusion restrictions or naive OLS. |\n",
    "\n",
    "### Practical Guidelines for Applied Research\n",
    "\n",
    "1. **Always use exclusion restrictions** when a credible instrument is available\n",
    "2. **Economic reasoning** for instrument validity is more important than any statistical test\n",
    "3. **Test instrument relevance** with a likelihood ratio test on the probit selection equation\n",
    "4. **Report sensitivity analyses** across different instrument sets\n",
    "5. **Use multiple instruments** when possible for over-identification checks\n",
    "6. **Be transparent** about the limitations of your identification strategy\n",
    "\n",
    "### References\n",
    "\n",
    "- Heckman, J.J. (1979). \"Sample Selection Bias as a Specification Error.\" *Econometrica*, 47(1), 153-161.\n",
    "- Card, D. (1995). \"Using Geographic Variation in College Proximity to Estimate the Return to Schooling.\"\n",
    "- Mroz, T.A. (1987). \"The Sensitivity of an Empirical Model of Married Women's Hours of Work.\" *Econometrica*, 55(4), 765-799.\n",
    "- Puhani, P.A. (2000). \"The Heckman Correction for Sample Selection and Its Critique.\" *Journal of Economic Surveys*, 14(1), 53-68."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat": 4,
   "nbformat_minor": 5,
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
