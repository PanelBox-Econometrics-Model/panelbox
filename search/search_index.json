{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"PanelBox <p>Python library for panel data econometrics</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>PanelBox is a comprehensive Python library for panel data econometrics, providing implementations of:</p> <ul> <li>Static panel models: Pooled OLS, Fixed Effects, Random Effects, Between, First Differences</li> <li>Dynamic panel GMM: Difference GMM (Arellano-Bond 1991), System GMM (Blundell-Bond 1998)</li> <li>HTML Report System (NEW in v0.8.0): Interactive validation, comparison, and residual diagnostic reports</li> <li>Test Runners (NEW in v0.8.0): ValidationTest and ComparisonTest with configurable presets</li> <li>Master Reports (NEW in v0.8.0): Comprehensive overview with navigation to all sub-reports</li> <li>Robust inference: 8+ types of standard errors (clustered, HAC, heteroskedasticity-robust)</li> <li>Diagnostic tests: Hansen J, Sargan, AR tests, Hausman, Wooldridge, Breusch-Pagan</li> <li>Validation: Cross-validated against Stata's <code>xtabond2</code> and R's <code>plm</code></li> </ul> <p>Design Philosophy:</p> <ul> <li>\ud83c\udfaf Ease of use: R-style formulas, pandas-friendly API</li> <li>\ud83d\udd2c Academic rigor: Implementations match published econometrics papers</li> <li>\u26a1 Performance: Numba-optimized critical paths (up to 348x speedup)</li> <li>\ud83d\udcca Publication-ready: LaTeX export, formatted output tables</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import panelbox as pb\n\n# Load example data\ndata = pb.load_grunfeld()\n\n# Create experiment and fit multiple models (NEW in v0.8.0!)\nexperiment = pb.PanelExperiment(\n    data=data,\n    formula=\"invest ~ value + capital\",\n    entity_col=\"firm\",\n    time_col=\"year\"\n)\n\n# Fit models\nexperiment.fit_model('pooled_ols', name='ols')\nexperiment.fit_model('fixed_effects', name='fe')\nexperiment.fit_model('random_effects', name='re')\n\n# Generate reports with one line each (NEW in v0.8.0!)\nvalidation = experiment.validate_model('fe')\nvalidation.save_html('validation.html', test_type='validation')\n\ncomparison = experiment.compare_models(['ols', 'fe', 're'])\ncomparison.save_html('comparison.html', test_type='comparison')\n\n# Generate master report (NEW in v0.8.0!)\nexperiment.save_master_report('master.html', reports=[\n    {'type': 'validation', 'title': 'Model Validation', 'file_path': 'validation.html'},\n    {'type': 'comparison', 'title': 'Model Comparison', 'file_path': 'comparison.html'}\n])\n</code></pre> <p>Output:</p> <p>Three interactive HTML reports are generated: - <code>validation.html</code>: Comprehensive diagnostic tests with pass/fail indicators - <code>comparison.html</code>: Side-by-side model comparison with coefficients and metrics - <code>master.html</code>: Overview dashboard with navigation to all reports</p> <p>Open <code>master.html</code> in your browser for an interactive analysis experience!</p>"},{"location":"#installation","title":"Installation","text":"<p>Install PanelBox via pip:</p> <pre><code>pip install panelbox\n</code></pre> <p>Requirements: - Python \u2265 3.9 - NumPy \u2265 1.24.0 - Pandas \u2265 2.0.0 - SciPy \u2265 1.10.0</p> <p>Optional dependencies: <pre><code>pip install panelbox[plots]        # Matplotlib for plotting\npip install panelbox[performance]  # Numba for speed\npip install panelbox[all]          # Everything\n</code></pre></p> <p>See Installation Guide for detailed instructions.</p>"},{"location":"#features","title":"Features","text":""},{"location":"#static-panel-models","title":"Static Panel Models","text":"<p>Estimators: - Pooled OLS: Baseline model ignoring panel structure - Fixed Effects (Within): Controls for time-invariant entity heterogeneity - Random Effects (GLS): Efficient if effects uncorrelated with regressors - Between: Cross-sectional regression of entity means - First Differences: Simple differencing to eliminate fixed effects</p> <p>Standard Errors (8 types): - Heteroskedasticity-robust: HC0, HC1, HC2, HC3 - Cluster-robust: One-way and two-way clustering - HAC: Driscoll-Kraay, Newey-West - Panel-corrected (PCSE)</p> <p>Specification Tests: - Hausman test (FE vs RE) - Breusch-Pagan LM test (random effects) - Wooldridge test (serial correlation) - F-test for fixed effects</p>"},{"location":"#dynamic-panel-gmm","title":"Dynamic Panel GMM","text":"<p>Estimators: - Difference GMM (Arellano-Bond 1991)   - First-difference transformation   - Lagged levels as instruments   - Handles short panels (small T, large N)</p> <ul> <li>System GMM (Blundell-Bond 1998)</li> <li>Combines difference and level equations</li> <li>More efficient for persistent series</li> <li>Additional moment conditions</li> </ul> <p>Features: - One-step and two-step estimation - Windmeijer finite-sample correction (2005) - Instrument collapse (Roodman 2009) to avoid proliferation - Robust to unbalanced panels</p> <p>Diagnostic Tests: - Hansen J test (overidentification) - Sargan test (alternative) - AR(1) and AR(2) tests (serial correlation) - Difference-in-Hansen test (System GMM levels)</p>"},{"location":"#html-report-system-new-in-v080","title":"HTML Report System (NEW in v0.8.0)","text":"<p>Report Types: - Validation Reports: Comprehensive diagnostic tests with interactive visualizations - Comparison Reports: Side-by-side model comparison with coefficients and fit metrics - Residual Reports: Diagnostic plots (QQ plots, residuals vs fitted, ACF/PACF) - Master Reports: Overview dashboard with navigation to all sub-reports</p> <p>Features: - Three Professional Themes: Professional (blue), Academic (gray), Presentation (purple) - Test Runners: ValidationTest and ComparisonTest with configurable presets (quick, basic, full) - Self-Contained: HTML files work offline, no external dependencies - Interactive: Plotly charts, sortable tables, responsive design - Export Options: JSON export for programmatic analysis</p> <p>Quick Start: <pre><code># Create experiment\nexperiment = pb.PanelExperiment(data, formula, entity_col, time_col)\n\n# Fit models\nexperiment.fit_model('fixed_effects', name='fe')\n\n# Generate reports\nvalidation = experiment.validate_model('fe')\nvalidation.save_html('report.html', test_type='validation', theme='professional')\n</code></pre></p>"},{"location":"#data-and-reporting","title":"Data and Reporting","text":"<p>Datasets: - Grunfeld investment data (10 firms, 20 years) - Arellano-Bond employment data (optional)</p> <p>Output Formats: - Interactive HTML reports (NEW in v0.8.0) - Console-friendly summary tables - LaTeX export for publications - Pandas DataFrames for further analysis - JSON export for programmatic analysis (NEW in v0.8.0)</p>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#getting-started","title":"\ud83d\udcd8 Getting Started","text":"<ul> <li>Installation: Install PanelBox on your system</li> <li>Quick Start Tutorial: Your first panel model in 15 minutes</li> <li>Choose a Model: Decision guide for selecting the right estimator</li> </ul>"},{"location":"#tutorials-learning-oriented","title":"\ud83d\udcda Tutorials (Learning-Oriented)","text":"<ol> <li>Getting Started: Load data, estimate Pooled OLS, interpret results</li> <li>Static Panel Models: Fixed Effects, Random Effects, Hausman test</li> <li>GMM Introduction: Difference GMM, System GMM, diagnostics</li> <li>HTML Report System: Generate professional reports (NEW in v0.8.0)</li> </ol>"},{"location":"#how-to-guides-task-oriented","title":"\ud83d\udee0\ufe0f How-To Guides (Task-Oriented)","text":"<ul> <li>Install PanelBox: Installation on Windows, macOS, Linux</li> <li>Load Your Data: Prepare panel data from various sources</li> <li>Choose a Model: Decision trees and workflows</li> <li>Interpret Tests: Understand diagnostic test output</li> </ul>"},{"location":"#explanation-guides-understanding-oriented","title":"\ud83d\udcd6 Explanation Guides (Understanding-Oriented)","text":"<ul> <li>Panel Data Introduction: What is panel data and when to use it</li> <li>Fixed vs Random Effects: Deep dive into FE and RE</li> <li>GMM Explained: Theory and mechanics of GMM estimation</li> </ul>"},{"location":"#api-reference","title":"\ud83d\udd0d API Reference","text":"<ul> <li>Static Models API: PooledOLS, FixedEffects, RandomEffects, Between, FirstDifferences</li> <li>GMM API: DifferenceGMM, SystemGMM</li> <li>Results API: PanelResults class</li> <li>Validation API: Diagnostic tests</li> <li>Datasets API: load_grunfeld, load_abdata</li> </ul>"},{"location":"#why-panelbox","title":"Why PanelBox?","text":""},{"location":"#designed-for-researchers","title":"\ud83c\udfaf Designed for Researchers","text":"<p>PanelBox brings Stata and R panel econometrics to Python:</p> Feature PanelBox Stata R (plm) linearmodels Difference GMM \u2705 \u2705 (xtabond2) \u2705 \u274c System GMM \u2705 \u2705 (xtabond2) \u2705 \u274c Instrument collapse \u2705 \u2705 \u2705 \u274c Windmeijer correction \u2705 \u2705 \u2705 \u274c Unbalanced panels \u2705 \u2705 \u2705 \u26a0\ufe0f (limited) Hansen J test \u2705 \u2705 \u2705 \u274c AR(1)/AR(2) tests \u2705 \u2705 \u2705 \u274c Hausman test \u2705 \u2705 \u2705 \u2705 <p>Validated against academic standards: - Stata <code>xtabond2</code> (Roodman 2009) for GMM - R <code>plm</code> package for static models - 600+ unit tests with 93% passing - Reproduction of published results from seminal papers</p>"},{"location":"#performance","title":"\u26a1 Performance","text":"<p>Numba-optimized critical paths:</p> Operation Pure Python Numba Speedup GMM weighting matrix 12.5s 0.036s 348x Within transformation 2.1s 0.15s 14x Instrument construction 5.3s 0.41s 13x <p>Benchmark: N=5000, T=10, 2 lags (typical dynamic panel)</p>"},{"location":"#publication-ready","title":"\ud83d\udcca Publication-Ready","text":"<p>Export to LaTeX: <pre><code>results.to_latex(\"table1.tex\", caption=\"Investment Regression Results\")\n</code></pre></p> <p>Formatted tables: - Coefficient estimates with stars (, *, ***) - Standard errors in parentheses - R-squared, diagnostics footer - Customizable formatting</p>"},{"location":"#examples","title":"Examples","text":""},{"location":"#fixed-effects","title":"Fixed Effects","text":"<pre><code>import panelbox as pb\n\ndata = pb.load_grunfeld()\n\n# Two-way fixed effects\nfe = pb.FixedEffects(\n    formula=\"invest ~ value + capital\",\n    data=data,\n    entity_col=\"firm\",\n    time_col=\"year\",\n    entity_effects=True,\n    time_effects=True\n)\n\nresults = fe.fit(cov_type='clustered')\nprint(results.summary())\n</code></pre>"},{"location":"#hausman-test-fe-vs-re","title":"Hausman Test (FE vs RE)","text":"<pre><code># Estimate both models\nfe = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\").fit()\nre = pb.RandomEffects(\"invest ~ value + capital\", data, \"firm\", \"year\").fit()\n\n# Test\nfrom panelbox.validation import HausmanTest\nhausman = HausmanTest(fe, re)\nprint(hausman)\n\n# Output: p-value = 0.3113 \u2192 Use Random Effects (more efficient)\n</code></pre>"},{"location":"#system-gmm-with-diagnostics","title":"System GMM with Diagnostics","text":"<pre><code>gmm = pb.SystemGMM(\n    data=data,\n    dep_var='invest',\n    lags=1,\n    exog_vars=['value', 'capital'],\n    id_var='firm',\n    time_var='year',\n    collapse=True,\n    robust=True\n)\n\nresults = gmm.fit()\n\n# Check validity\nassert results.hansen_j.pvalue &gt; 0.10, \"Hansen J test failed\"\nassert results.ar2_test.pvalue &gt; 0.10, \"AR(2) test failed\"\nassert results.instrument_ratio &lt; 2.0, \"Too many instruments\"\n\nprint(results.summary())\nresults.to_latex(\"gmm_results.tex\")\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<p>Completed (v1.0.0): - \u2705 Static panel models (Pooled, FE, RE, Between, FD) - \u2705 Dynamic GMM (Difference and System) - \u2705 Comprehensive diagnostic tests - \u2705 Robust standard errors (8 types) - \u2705 Validation against Stata and R - \u2705 Complete documentation</p> <p>Planned (v1.1.0+): - \ud83d\udd1c Panel cointegration tests (Pedroni, Kao, Westerlund) - \ud83d\udd1c Panel unit root tests (Im-Pesaran-Shin, Levin-Lin-Chu) - \ud83d\udd1c Panel VAR models - \ud83d\udd1c Quantile regression for panels - \ud83d\udd1c Spatial panel models</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use PanelBox in academic research, please cite:</p> <pre><code>@software{panelbox2024,\n  author = {Haase, Gustavo and Dourado, Paulo},\n  title = {PanelBox: Panel Data Econometrics for Python},\n  year = {2024},\n  version = {1.0.0},\n  url = {https://github.com/PanelBox-Econometrics-Model/panelbox}\n}\n</code></pre> <p>Key references implemented: - Arellano, M., &amp; Bond, S. (1991). \"Some Tests of Specification for Panel Data\", Review of Economic Studies, 58(2), 277-297. - Blundell, R., &amp; Bond, S. (1998). \"Initial Conditions and Moment Restrictions\", Journal of Econometrics, 87(1), 115-143. - Roodman, D. (2009). \"How to do xtabond2\", The Stata Journal, 9(1), 86-136. - Windmeijer, F. (2005). \"A Finite Sample Correction\", Journal of Econometrics, 126(1), 25-51.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! See CONTRIBUTING.md for guidelines.</p> <p>Ways to contribute: - \ud83d\udc1b Report bugs via GitHub Issues - \ud83d\udca1 Suggest features or enhancements - \ud83d\udcdd Improve documentation - \ud83e\uddea Add tests or examples - \ud83d\udd27 Submit pull requests</p>"},{"location":"#license","title":"License","text":"<p>PanelBox is released under the MIT License.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>Documentation: https://panelbox-econometrics-model.github.io/panelbox</li> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>PyPI: https://pypi.org/project/panelbox/</li> </ul> <p>Built with \u2764\ufe0f for econometricians and data scientists</p>"},{"location":"DOCUMENTATION_UPDATED_V08/","title":"Documentation Updated for v0.8.0","text":"<p>Date: 2026-02-08 Status: \u2705 COMPLETE</p>"},{"location":"DOCUMENTATION_UPDATED_V08/#summary","title":"Summary","text":"<p>All documentation has been updated to reflect the new features in PanelBox v0.8.0, including: - HTML Report System - Test Runners (ValidationTest, ComparisonTest) - Master Reports - Result Containers (ValidationResult, ComparisonResult, ResidualResult)</p>"},{"location":"DOCUMENTATION_UPDATED_V08/#files-updated","title":"Files Updated","text":""},{"location":"DOCUMENTATION_UPDATED_V08/#1-main-documentation-index-docsindexmd","title":"1. Main Documentation Index (<code>docs/index.md</code>)","text":"<p>Changes: - Updated Overview section with v0.8.0 features - Replaced Quick Example with PanelExperiment workflow - Added new \"HTML Report System\" section with features - Updated output formats to include HTML and JSON exports - Added link to new tutorial (04_html_reports.md)</p> <p>Highlights: <pre><code># NEW Quick Example\nexperiment = pb.PanelExperiment(data, formula, entity_col, time_col)\nexperiment.fit_model('fixed_effects', name='fe')\nvalidation = experiment.validate_model('fe')\nvalidation.save_html('validation.html', test_type='validation')\n</code></pre></p>"},{"location":"DOCUMENTATION_UPDATED_V08/#2-api-reference-index-docsapiindexmd","title":"2. API Reference Index (<code>docs/api/index.md</code>)","text":"<p>Changes: - Updated Report section with new APIs:   - PanelExperiment   - ValidationResult, ComparisonResult, ResidualResult   - ValidationTest, ComparisonTest   - save_html(), save_master_report() - Added new Quick Links for v0.8.0 features - Added \"Complete Workflow with Reports\" example (47 lines)</p> <p>New Quick Links: - Create Experiment \u2192 PanelExperiment - Validate Model \u2192 ValidationTest - Compare Models \u2192 ComparisonTest - Generate HTML Report \u2192 save_html - Master Report \u2192 save_master_report</p>"},{"location":"DOCUMENTATION_UPDATED_V08/#3-report-api-documentation-docsapireportmd","title":"3. Report API Documentation (<code>docs/api/report.md</code>)","text":"<p>Major Expansion: 273 lines \u2192 Comprehensive v0.8.0 documentation</p> <p>New Sections: 1. PanelExperiment (130 lines)    - Overview and usage    - Methods: fit_model, validate_model, compare_models, analyze_residuals, save_master_report    - Complete examples for each method</p> <ol> <li>ValidationTest (27 lines)</li> <li>Test runner with configurable presets</li> <li>quick, basic, full configurations</li> <li> <p>Usage examples</p> </li> <li> <p>ComparisonTest (20 lines)</p> </li> <li>Multi-model comparison runner</li> <li> <p>Usage example</p> </li> <li> <p>Result Containers (68 lines)</p> </li> <li>ValidationResult: Methods and examples</li> <li>ComparisonResult: Methods, best_model(), examples</li> <li> <p>ResidualResult: Methods and properties</p> </li> <li> <p>Themes (28 lines)</p> </li> <li>Professional (blue, default)</li> <li>Academic (gray, publications)</li> <li>Presentation (purple, slides)</li> <li>Examples for each theme</li> </ol> <p>Total: Comprehensive API reference for all v0.8.0 features</p>"},{"location":"DOCUMENTATION_UPDATED_V08/#4-new-tutorial-docstutorials04_html_reportsmd","title":"4. NEW Tutorial (<code>docs/tutorials/04_html_reports.md</code>)","text":"<p>Created: Complete tutorial (565 lines) for HTML Report System</p> <p>Sections: 1. Introduction (What You'll Learn, Prerequisites) 2. Step 1: Create PanelExperiment 3. Step 2: Fit Multiple Models 4. Step 3: Generate Validation Report    - Validation configs (quick, basic, full) 5. Step 4: Generate Comparison Report    - Identify best models 6. Step 5: Generate Residual Diagnostics 7. Step 6: Generate Master Report 8. Step 7: Try Different Themes 9. Step 8: Export to JSON 10. Complete Workflow (example script) 11. Best Practices (5 tips) 12. Tips and Tricks (batch processing, customization) 13. Next Steps</p> <p>Examples: - 15+ code examples - Complete workflow script - Best practices guide - Custom configurations</p>"},{"location":"DOCUMENTATION_UPDATED_V08/#documentation-structure","title":"Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                          \u2705 UPDATED (v0.8.0 features)\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 index.md                      \u2705 UPDATED (new APIs, workflow)\n\u2502   \u251c\u2500\u2500 report.md                     \u2705 MAJOR UPDATE (273 lines, comprehensive)\n\u2502   \u251c\u2500\u2500 models.md                     (existing)\n\u2502   \u251c\u2500\u2500 gmm.md                        (existing)\n\u2502   \u251c\u2500\u2500 results.md                    (existing)\n\u2502   \u251c\u2500\u2500 validation.md                 (existing)\n\u2502   \u2514\u2500\u2500 datasets.md                   (existing)\n\u251c\u2500\u2500 tutorials/\n\u2502   \u251c\u2500\u2500 01_getting_started.md         (existing)\n\u2502   \u251c\u2500\u2500 02_static_models.md           (existing)\n\u2502   \u251c\u2500\u2500 03_gmm_intro.md               (existing)\n\u2502   \u2514\u2500\u2500 04_html_reports.md            \u2705 NEW (565 lines, complete tutorial)\n\u251c\u2500\u2500 how-to/\n\u2502   \u2514\u2500\u2500 ...                           (existing)\n\u2514\u2500\u2500 guides/\n    \u2514\u2500\u2500 ...                           (existing)\n</code></pre>"},{"location":"DOCUMENTATION_UPDATED_V08/#key-features-documented","title":"Key Features Documented","text":""},{"location":"DOCUMENTATION_UPDATED_V08/#panelexperiment","title":"PanelExperiment","text":"<ul> <li>\u2705 Constructor and initialization</li> <li>\u2705 fit_model() with model types</li> <li>\u2705 validate_model() with configs</li> <li>\u2705 compare_models() with multiple models</li> <li>\u2705 analyze_residuals()</li> <li>\u2705 save_master_report() with navigation</li> <li>\u2705 Complete workflow examples</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#test-runners","title":"Test Runners","text":"<ul> <li>\u2705 ValidationTest with presets (quick, basic, full)</li> <li>\u2705 ComparisonTest for multi-model comparison</li> <li>\u2705 Custom test selection</li> <li>\u2705 Configuration options</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#result-containers","title":"Result Containers","text":"<ul> <li>\u2705 ValidationResult: save_html, save_json, summary</li> <li>\u2705 ComparisonResult: save_html, save_json, best_model</li> <li>\u2705 ResidualResult: save_html, save_json, diagnostic properties</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#report-system","title":"Report System","text":"<ul> <li>\u2705 HTML report generation</li> <li>\u2705 Three themes (professional, academic, presentation)</li> <li>\u2705 Master reports with navigation</li> <li>\u2705 JSON export for analysis</li> <li>\u2705 Self-contained, offline-capable reports</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#themes","title":"Themes","text":"<ul> <li>\u2705 Professional: Blue, corporate, default</li> <li>\u2705 Academic: Gray, publications, conservative</li> <li>\u2705 Presentation: Purple, slides, bold</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#examples-added","title":"Examples Added","text":""},{"location":"DOCUMENTATION_UPDATED_V08/#quick-examples-short","title":"Quick Examples (Short)","text":"<ol> <li>PanelExperiment creation (7 lines)</li> <li>Model fitting (3 lines)</li> <li>Validation report (3 lines)</li> <li>Comparison report (3 lines)</li> <li>Master report (5 lines)</li> </ol>"},{"location":"DOCUMENTATION_UPDATED_V08/#complete-workflows-long","title":"Complete Workflows (Long)","text":"<ol> <li>Basic workflow (API index, 15 lines)</li> <li>Complete workflow with reports (API index, 47 lines)</li> <li>Tutorial complete workflow (tutorial, 30 lines)</li> </ol>"},{"location":"DOCUMENTATION_UPDATED_V08/#specialized-examples","title":"Specialized Examples","text":"<ol> <li>Validation configs (quick, basic, full)</li> <li>Theme customization (3 themes)</li> <li>JSON export</li> <li>Batch processing</li> <li>Custom test selection</li> </ol> <p>Total: 15+ code examples across all documentation</p>"},{"location":"DOCUMENTATION_UPDATED_V08/#coverage","title":"Coverage","text":""},{"location":"DOCUMENTATION_UPDATED_V08/#topics-covered","title":"Topics Covered","text":"<ul> <li>\u2705 PanelExperiment API</li> <li>\u2705 Test runners</li> <li>\u2705 Result containers</li> <li>\u2705 HTML reports</li> <li>\u2705 Master reports</li> <li>\u2705 Themes</li> <li>\u2705 JSON export</li> <li>\u2705 Best practices</li> <li>\u2705 Complete workflows</li> <li>\u2705 Troubleshooting tips</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#audience","title":"Audience","text":"<ul> <li>\u2705 Beginners: Step-by-step tutorial</li> <li>\u2705 Intermediate: Complete workflows</li> <li>\u2705 Advanced: Custom configurations</li> <li>\u2705 Reference: Comprehensive API docs</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#quality-metrics","title":"Quality Metrics","text":""},{"location":"DOCUMENTATION_UPDATED_V08/#documentation-stats","title":"Documentation Stats","text":"<ul> <li>Files Updated: 3</li> <li>Files Created: 1</li> <li>Total Lines Added: 850+</li> <li>Code Examples: 15+</li> <li>Complete Workflows: 3</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#coverage_1","title":"Coverage","text":"<ul> <li>API Reference: 100% (all v0.8.0 features)</li> <li>Tutorial: Complete (565 lines)</li> <li>Examples: Comprehensive (15+ examples)</li> <li>Best Practices: Included</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#validation","title":"Validation","text":""},{"location":"DOCUMENTATION_UPDATED_V08/#links-verified","title":"Links Verified","text":"<ul> <li>\u2705 Internal links between docs</li> <li>\u2705 Links to API reference</li> <li>\u2705 Links to tutorials</li> <li>\u2705 Links to examples</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#examples-tested","title":"Examples Tested","text":"<ul> <li>\u2705 All code examples validated</li> <li>\u2705 Syntax checking passed</li> <li>\u2705 Workflow scripts tested in tutorial notebook</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#consistency","title":"Consistency","text":"<ul> <li>\u2705 Terminology consistent across docs</li> <li>\u2705 Code style consistent</li> <li>\u2705 Section structure consistent</li> </ul>"},{"location":"DOCUMENTATION_UPDATED_V08/#next-steps-optional","title":"Next Steps (Optional)","text":""},{"location":"DOCUMENTATION_UPDATED_V08/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Add screenshots of HTML reports to tutorial</li> <li>Create video walkthrough of report system</li> <li>Add troubleshooting section</li> <li>Expand best practices guide</li> <li>Add performance tips for large datasets</li> </ol>"},{"location":"DOCUMENTATION_UPDATED_V08/#documentation-site-deployment","title":"Documentation Site Deployment","text":"<ol> <li>Build docs with MkDocs</li> <li>Deploy to Read the Docs or GitHub Pages</li> <li>Set up automatic deployment on push</li> <li>Add version selector</li> </ol>"},{"location":"DOCUMENTATION_UPDATED_V08/#summary_1","title":"Summary","text":"<p>All documentation has been successfully updated for v0.8.0:</p> <p>\u2705 Main Index: Updated with v0.8.0 features \u2705 API Reference: Comprehensive coverage of new APIs \u2705 Report API: Major expansion (273 lines) \u2705 New Tutorial: Complete HTML Report System guide (565 lines) \u2705 Examples: 15+ code examples added \u2705 Workflows: 3 complete workflows documented \u2705 Themes: All three themes documented \u2705 Best Practices: Included in tutorial</p> <p>Status: Documentation is complete and production-ready for v0.8.0 release! \ud83d\udcda\u2728</p> <p>Documentation Update Complete \u2705 Ready for Deployment \ud83d\ude80</p>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for PanelBox.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>PanelBox provides a comprehensive API for panel data econometrics organized into the following modules:</p>"},{"location":"api/#static-models","title":"\ud83d\udcca Static Models","text":"<p>Panel models without dynamics:</p> <ul> <li>PooledOLS: Pooled Ordinary Least Squares</li> <li>FixedEffects: Fixed Effects (Within) estimator</li> <li>RandomEffects: Random Effects (GLS) estimator</li> <li>Between: Between estimator (entity means)</li> <li>FirstDifferences: First Differences estimator</li> </ul>"},{"location":"api/#gmm-models","title":"\ud83d\udd04 GMM Models","text":"<p>Dynamic panel GMM estimators:</p> <ul> <li>DifferenceGMM: Arellano-Bond Difference GMM (1991)</li> <li>SystemGMM: Blundell-Bond System GMM (1998)</li> </ul>"},{"location":"api/#results","title":"\ud83d\udcc8 Results","text":"<p>Results container class:</p> <ul> <li>PanelResults: Estimation results with summary, tests, export</li> </ul>"},{"location":"api/#validation","title":"\u2705 Validation","text":"<p>Diagnostic and specification tests:</p> <ul> <li>HausmanTest: Fixed Effects vs Random Effects</li> <li>BreuschPaganLM: Random effects test</li> <li>BreuschPaganTest: Heteroskedasticity test</li> <li>WooldridgeTest: Serial correlation test</li> <li>Hansen J, Sargan: GMM overidentification tests</li> <li>AR tests: GMM serial correlation tests</li> </ul>"},{"location":"api/#datasets","title":"\ud83d\udce6 Datasets","text":"<p>Example datasets for learning and testing:</p> <ul> <li>load_grunfeld(): Grunfeld investment data</li> <li>load_abdata(): Arellano-Bond employment data</li> <li>list_datasets(): List available datasets</li> <li>get_dataset_info(): Dataset information</li> </ul>"},{"location":"api/#report","title":"\ud83d\udccb Report","text":"<p>Reporting and export utilities:</p> <ul> <li>PanelExperiment: High-level API for panel data analysis (NEW in v0.8.0)</li> <li>ValidationResult: Container for validation test results with HTML export (NEW in v0.8.0)</li> <li>ComparisonResult: Container for model comparison with HTML export (NEW in v0.8.0)</li> <li>ResidualResult: Container for residual diagnostics with HTML export (NEW in v0.7.0)</li> <li>ValidationTest: Test runner with configurable presets (NEW in v0.8.0)</li> <li>ComparisonTest: Multi-model comparison runner (NEW in v0.8.0)</li> <li>to_latex(): Export to LaTeX tables</li> <li>summary(): Formatted summary tables</li> <li>save_html(): Generate interactive HTML reports (NEW in v0.8.0)</li> <li>save_master_report(): Generate master report with navigation (NEW in v0.8.0)</li> </ul>"},{"location":"api/#quick-links","title":"Quick Links","text":"Topic API Documentation Estimate Fixed Effects FixedEffects Estimate Random Effects RandomEffects Run Hausman Test HausmanTest Estimate Difference GMM DifferenceGMM Estimate System GMM SystemGMM Check Hansen J Test Results Load Example Data load_grunfeld Export to LaTeX to_latex Create Experiment PanelExperiment Validate Model ValidationTest Compare Models ComparisonTest Generate HTML Report save_html Master Report save_master_report"},{"location":"api/#usage-patterns","title":"Usage Patterns","text":""},{"location":"api/#basic-workflow","title":"Basic Workflow","text":"<pre><code>import panelbox as pb\n\n# 1. Load data\ndata = pb.load_grunfeld()\n\n# 2. Create model\nmodel = pb.FixedEffects(\n    formula=\"invest ~ value + capital\",\n    data=data,\n    entity_col=\"firm\",\n    time_col=\"year\"\n)\n\n# 3. Fit model\nresults = model.fit(cov_type='clustered')\n\n# 4. View results\nprint(results.summary())\n\n# 5. Export\nresults.to_latex(\"table1.tex\")\n</code></pre>"},{"location":"api/#advanced-workflow-gmm","title":"Advanced Workflow (GMM)","text":"<pre><code># 1. Load data\ndata = pb.load_grunfeld()\n\n# 2. Create GMM model\ngmm = pb.SystemGMM(\n    data=data,\n    dep_var='invest',\n    lags=1,\n    exog_vars=['value', 'capital'],\n    id_var='firm',\n    time_var='year',\n    collapse=True,\n    robust=True\n)\n\n# 3. Fit\nresults = gmm.fit()\n\n# 4. Check diagnostics\nprint(f\"Hansen J: {results.hansen_j.pvalue:.3f}\")\nprint(f\"AR(2): {results.ar2_test.pvalue:.3f}\")\n\n# 5. If tests pass, view results\nif results.hansen_j.pvalue &gt; 0.10 and results.ar2_test.pvalue &gt; 0.10:\n    print(results.summary())\n</code></pre>"},{"location":"api/#complete-workflow-with-reports-new-in-v080","title":"Complete Workflow with Reports (NEW in v0.8.0)","text":"<pre><code>import panelbox as pb\n\n# 1. Load data\ndata = pb.load_grunfeld()\n\n# 2. Create experiment\nexperiment = pb.PanelExperiment(\n    data=data,\n    formula=\"invest ~ value + capital\",\n    entity_col=\"firm\",\n    time_col=\"year\"\n)\n\n# 3. Fit multiple models\nexperiment.fit_model('pooled_ols', name='ols')\nexperiment.fit_model('fixed_effects', name='fe')\nexperiment.fit_model('random_effects', name='re')\n\n# 4. Generate validation report\nvalidation = experiment.validate_model('fe', config='full')\nvalidation.save_html('validation.html', test_type='validation', theme='professional')\n\n# 5. Generate comparison report\ncomparison = experiment.compare_models(['ols', 'fe', 're'])\ncomparison.save_html('comparison.html', test_type='comparison', theme='professional')\n\n# 6. Generate residual diagnostics\nresiduals = experiment.analyze_residuals('fe')\nresiduals.save_html('residuals.html', test_type='residuals', theme='professional')\n\n# 7. Generate master report\nexperiment.save_master_report('master.html', theme='professional', reports=[\n    {'type': 'validation', 'title': 'Model Validation',\n     'description': 'Specification tests', 'file_path': 'validation.html'},\n    {'type': 'comparison', 'title': 'Model Comparison',\n     'description': 'Compare OLS, FE, RE', 'file_path': 'comparison.html'},\n    {'type': 'residuals', 'title': 'Residual Diagnostics',\n     'description': 'Diagnostic plots', 'file_path': 'residuals.html'}\n])\n\n# Open master.html in your browser!\n</code></pre>"},{"location":"api/#module-organization","title":"Module Organization","text":"<pre><code>panelbox/\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 static/\n\u2502   \u2502   \u251c\u2500\u2500 pooled_ols.py      \u2192 PooledOLS\n\u2502   \u2502   \u251c\u2500\u2500 fixed_effects.py   \u2192 FixedEffects\n\u2502   \u2502   \u251c\u2500\u2500 random_effects.py  \u2192 RandomEffects\n\u2502   \u2502   \u251c\u2500\u2500 between.py         \u2192 Between\n\u2502   \u2502   \u2514\u2500\u2500 first_differences.py \u2192 FirstDifferences\n\u2502   \u2514\u2500\u2500 base.py                \u2192 PanelModel (base class)\n\u251c\u2500\u2500 gmm/\n\u2502   \u251c\u2500\u2500 difference_gmm.py      \u2192 DifferenceGMM\n\u2502   \u2514\u2500\u2500 system_gmm.py          \u2192 SystemGMM\n\u251c\u2500\u2500 core/\n\u2502   \u2514\u2500\u2500 results.py             \u2192 PanelResults\n\u251c\u2500\u2500 validation/\n\u2502   \u251c\u2500\u2500 specification/\n\u2502   \u2502   \u251c\u2500\u2500 hausman.py         \u2192 HausmanTest\n\u2502   \u2502   \u2514\u2500\u2500 breusch_pagan_lm.py \u2192 BreuschPaganLM\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 datasets/\n\u2502   \u2514\u2500\u2500 load.py                \u2192 load_grunfeld, etc.\n\u2514\u2500\u2500 report/\n    \u2514\u2500\u2500 latex.py               \u2192 LaTeX export\n</code></pre>"},{"location":"api/#next-steps","title":"Next Steps","text":"<ul> <li>Browse specific API documentation in the navigation</li> <li>See Tutorials for hands-on examples</li> <li>Check How-To Guides for task-oriented help</li> </ul>"},{"location":"api/datasets/","title":"Datasets API","text":"<p>API documentation for loading example panel datasets.</p>"},{"location":"api/datasets/#load_grunfeld","title":"load_grunfeld","text":""},{"location":"api/datasets/#panelbox.datasets.load.load_grunfeld","title":"panelbox.datasets.load.load_grunfeld","text":"<pre><code>load_grunfeld(return_panel_data: bool = False) -&gt; Union[pd.DataFrame, PanelData]\n</code></pre> <p>Load Grunfeld investment data.</p> <p>Classic panel dataset on investment behavior of large US corporations.</p> <p>Parameters:</p> Name Type Description Default <code>return_panel_data</code> <code>bool</code> <p>If True, returns a PanelData object instead of DataFrame</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame or PanelData</code> <p>Panel dataset with firm-year observations</p> Notes <p>Dataset Description:</p> <p>The Grunfeld data contains observations on 10 large US manufacturing firms over the period 1935-1954 (20 years). It has been widely used to illustrate panel data econometric methods.</p> <p>Variables: - <code>firm</code> : Firm identifier (1-10) - <code>year</code> : Year (1935-1954) - <code>invest</code> : Gross investment (millions of dollars) - <code>value</code> : Market value of the firm (millions of dollars) - <code>capital</code> : Stock of plant and equipment (millions of dollars)</p> <p>Sample Size: - Entities (N): 10 firms - Time periods (T): 20 years - Total observations: 200</p> <p>Panel Structure: - Balanced panel (all firms observed in all years)</p> <p>Common Uses: - Fixed effects estimation - Between vs. within variation - Dynamic panel models</p> <p>Citation: Grunfeld, Y. (1958). The determinants of corporate investment. Unpublished Ph.D. dissertation, University of Chicago.</p> <p>Source: Standard dataset in econometrics, available in Stata (<code>webuse grunfeld</code>) and R (<code>plm</code> package).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load data\n&gt;&gt;&gt; data = pb.load_grunfeld()\n&gt;&gt;&gt; print(data.head())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Panel structure\n&gt;&gt;&gt; print(f\"Firms: {data['firm'].nunique()}\")\n&gt;&gt;&gt; print(f\"Years: {data['year'].nunique()}\")\n&gt;&gt;&gt; print(f\"Total obs: {len(data)}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate fixed effects\n&gt;&gt;&gt; fe = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results = fe.fit()\n&gt;&gt;&gt; print(results.summary())\n</code></pre> See Also <p>FixedEffects : Fixed Effects estimator RandomEffects : Random Effects estimator DifferenceGMM : Difference GMM estimator SystemGMM : System GMM estimator</p>"},{"location":"api/datasets/#load_abdata","title":"load_abdata","text":""},{"location":"api/datasets/#panelbox.datasets.load.load_abdata","title":"panelbox.datasets.load.load_abdata","text":"<pre><code>load_abdata(return_panel_data: bool = False) -&gt; Optional[Union[pd.DataFrame, PanelData]]\n</code></pre> <p>Load Arellano-Bond employment data.</p> <p>Panel dataset on UK company employment used in Arellano &amp; Bond (1991).</p> <p>Parameters:</p> Name Type Description Default <code>return_panel_data</code> <code>bool</code> <p>If True, returns a PanelData object instead of DataFrame</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame or PanelData or None</code> <p>Panel dataset with firm-year observations, or None if not found</p> Notes <p>Dataset Description:</p> <p>This is the employment dataset used in the seminal Arellano-Bond (1991) paper on dynamic panel GMM estimation. It contains data on UK companies.</p> <p>Variables (typical): - <code>id</code> : Company identifier - <code>year</code> : Year - <code>n</code> or <code>emp</code> : Employment (number of employees) - <code>w</code> or <code>wage</code> : Real wage - <code>k</code> or <code>capital</code> : Gross capital stock - <code>ys</code> or <code>output</code> : Industry output</p> <p>Sample Size: - Entities (N): ~140 firms - Time periods (T): 7-9 years (1976-1984) - Total observations: ~1,000 (unbalanced)</p> <p>Panel Structure: - Unbalanced panel (not all firms observed in all years)</p> <p>Common Uses: - Dynamic panel GMM estimation - Arellano-Bond Difference GMM - Blundell-Bond System GMM - Testing for serial correlation in errors</p> <p>Citation: Arellano, M., &amp; Bond, S. (1991). Some tests of specification for panel data: Monte Carlo evidence and an application to employment equations. Review of Economic Studies, 58(2), 277-297.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load data\n&gt;&gt;&gt; data = pb.load_abdata()\n&gt;&gt;&gt; if data is not None:\n...     # Estimate Difference GMM\n...     gmm = pb.DifferenceGMM(\n...         data=data,\n...         dep_var='n',\n...         lags=1,\n...         exog_vars=['w', 'k'],\n...         id_var='id',\n...         time_var='year'\n...     )\n...     results = gmm.fit()\n</code></pre>"},{"location":"api/datasets/#list_datasets","title":"list_datasets","text":""},{"location":"api/datasets/#panelbox.datasets.load.list_datasets","title":"panelbox.datasets.load.list_datasets","text":"<pre><code>list_datasets() -&gt; List[str]\n</code></pre> <p>List all available datasets.</p> <p>Returns:</p> Type Description <code>list of str</code> <p>Names of available datasets</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; datasets = pb.list_datasets()\n&gt;&gt;&gt; print(\"Available datasets:\")\n&gt;&gt;&gt; for ds in datasets:\n...     print(f\"  - {ds}\")\n</code></pre>"},{"location":"api/datasets/#get_dataset_info","title":"get_dataset_info","text":""},{"location":"api/datasets/#panelbox.datasets.load.get_dataset_info","title":"panelbox.datasets.load.get_dataset_info","text":"<pre><code>get_dataset_info(dataset_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get information about a specific dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>Name of the dataset (e.g., 'grunfeld', 'abdata')</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing dataset information: - name: Dataset name - description: Brief description - n_entities: Number of entities (if loaded) - n_periods: Number of time periods (if loaded) - n_obs: Total observations (if loaded) - variables: List of variables (if loaded) - balanced: Whether panel is balanced (if loaded) - source: Data source/citation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; info = pb.get_dataset_info('grunfeld')\n&gt;&gt;&gt; print(f\"Dataset: {info['name']}\")\n&gt;&gt;&gt; print(f\"Description: {info['description']}\")\n&gt;&gt;&gt; print(f\"Variables: {', '.join(info['variables'])}\")\n</code></pre>"},{"location":"api/datasets/#load_dataset","title":"load_dataset","text":""},{"location":"api/datasets/#panelbox.datasets.load.load_dataset","title":"panelbox.datasets.load.load_dataset","text":"<pre><code>load_dataset(name: str, **kwargs) -&gt; Optional[pd.DataFrame]\n</code></pre> <p>Load a dataset by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the dataset</p> required <code>**kwargs</code> <p>Additional arguments passed to the specific load function</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame or None</code> <p>The requested dataset, or None if not found</p>"},{"location":"api/gmm/","title":"GMM Models API","text":"<p>API documentation for dynamic panel GMM estimators.</p>"},{"location":"api/gmm/#differencegmm","title":"DifferenceGMM","text":""},{"location":"api/gmm/#panelbox.gmm.difference_gmm.DifferenceGMM","title":"panelbox.gmm.difference_gmm.DifferenceGMM","text":"<pre><code>DifferenceGMM(data: DataFrame, dep_var: str, lags: Union[int, List[int]], id_var: str = 'id', time_var: str = 'year', exog_vars: Optional[List[str]] = None, endogenous_vars: Optional[List[str]] = None, predetermined_vars: Optional[List[str]] = None, time_dummies: bool = True, collapse: bool = False, two_step: bool = True, robust: bool = True, gmm_type: str = 'two_step')\n</code></pre> <p>Arellano-Bond (1991) Difference GMM estimator.</p> <p>Eliminates fixed effects through first-differencing and uses lagged levels as instruments for the differenced equation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Panel data in long format</p> required <code>dep_var</code> <code>str</code> <p>Name of dependent variable</p> required <code>lags</code> <code>Union[int, List[int]]</code> <p>Lags of dependent variable to include (e.g., 1 or [1, 2])</p> required <code>id_var</code> <code>str</code> <p>Name of cross-sectional identifier (default: 'id')</p> <code>'id'</code> <code>time_var</code> <code>str</code> <p>Name of time variable (default: 'year')</p> <code>'year'</code> <code>exog_vars</code> <code>List[str]</code> <p>List of strictly exogenous variables</p> <code>None</code> <code>endogenous_vars</code> <code>List[str]</code> <p>List of endogenous variables (excluding lagged dependent)</p> <code>None</code> <code>predetermined_vars</code> <code>List[str]</code> <p>List of predetermined variables</p> <code>None</code> <code>time_dummies</code> <code>bool</code> <p>Include time dummies (default: True)</p> <code>True</code> <code>collapse</code> <code>bool</code> <p>Collapse instruments to avoid proliferation (default: False)</p> <code>False</code> <code>two_step</code> <code>bool</code> <p>Use two-step GMM (default: True)</p> <code>True</code> <code>robust</code> <code>bool</code> <p>Use robust variance matrix with Windmeijer correction (default: True)</p> <code>True</code> <code>gmm_type</code> <code>str</code> <p>GMM estimation type: 'one_step', 'two_step', or 'iterative' (default: 'two_step')</p> <code>'two_step'</code> <p>Attributes:</p> Name Type Description <code>data</code> <code>DataFrame</code> <p>Panel data</p> <code>params</code> <code>Series</code> <p>Estimated coefficients (after fitting)</p> <code>results</code> <code>GMMResults</code> <p>Full results object (after fitting)</p> <p>Examples:</p> <p>Basic example with employment data:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from panelbox.gmm import DifferenceGMM\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load panel data (firms over time)\n&gt;&gt;&gt; data = pd.read_csv('panel_data.csv')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate Difference GMM\n&gt;&gt;&gt; model = DifferenceGMM(\n...     data=data,\n...     dep_var='employment',\n...     lags=1,                    # Include employment_{t-1}\n...     id_var='firm_id',\n...     time_var='year',\n...     exog_vars=['wages', 'capital'],\n...     time_dummies=True,\n...     collapse=True,             # Recommended to avoid instrument proliferation\n...     two_step=True,             # Two-step with Windmeijer correction\n...     robust=True                # Robust standard errors\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Fit and get results\n&gt;&gt;&gt; results = model.fit()\n&gt;&gt;&gt; print(results.summary())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access coefficients\n&gt;&gt;&gt; print(f\"Persistence: {results.params['L1.employment']:.3f}\")\n&gt;&gt;&gt; print(f\"Wage effect: {results.params['wages']:.3f}\")\n</code></pre> <p>Interpreting diagnostic tests:</p> <pre><code>&gt;&gt;&gt; # Check if estimation is valid\n&gt;&gt;&gt; if results.ar2_test.pvalue &gt; 0.10:\n...     print(\"\u2713 Moment conditions valid\")\n...\n&gt;&gt;&gt; if 0.10 &lt; results.hansen_j.pvalue &lt; 0.25:\n...     print(\"\u2713 Instruments appear valid\")\n...\n&gt;&gt;&gt; if results.instrument_ratio &lt; 1.0:\n...     print(\"\u2713 Instrument count appropriate\")\n</code></pre> <p>With predetermined and endogenous variables:</p> <pre><code>&gt;&gt;&gt; # Some variables may not be strictly exogenous\n&gt;&gt;&gt; model = DifferenceGMM(\n...     data=data,\n...     dep_var='output',\n...     lags=1,\n...     exog_vars=['policy_var'],        # Strictly exogenous\n...     predetermined_vars=['capital'],   # Instruments: t-1 and earlier\n...     endogenous_vars=['labor'],        # Instruments: t-2 and earlier\n...     collapse=True,\n...     two_step=True\n... )\n&gt;&gt;&gt; results = model.fit()\n</code></pre> <p>For unbalanced panels:</p> <pre><code>&gt;&gt;&gt; # Always use collapse=True and avoid many time dummies\n&gt;&gt;&gt; model = DifferenceGMM(\n...     data=unbalanced_data,\n...     dep_var='y',\n...     lags=1,\n...     exog_vars=['x1', 'x2'],\n...     time_dummies=False,  # Or use linear trend\n...     collapse=True,       # Essential for unbalanced panels\n...     two_step=True\n... )\n&gt;&gt;&gt; results = model.fit()\n&gt;&gt;&gt; print(f\"Retained {results.nobs}/{len(unbalanced_data)} observations\")\n</code></pre> Notes <p>Model and Transformation:</p> <p>The Difference GMM estimator addresses dynamic panel bias by:</p> <ol> <li> <p>First-differencing to eliminate fixed effects \u03b1_i:</p> <p>\u0394y_{it} = \u03b3 \u0394y_{i,t-1} + \u03b2' \u0394x_{it} + \u0394\u03b5_{it}</p> </li> <li> <p>Using lagged levels as instruments (valid under E[y_{i,t-s} \u0394\u03b5_{it}] = 0)</p> </li> </ol> <p>Instrument Strategy:</p> <p>For the differenced equation at time t, available instruments are:</p> <ul> <li>Strictly exogenous variables: All lags and leads (t-\u221e to t+\u221e)</li> <li>Predetermined variables: Lags t-2 and earlier</li> <li>Endogenous variables: Lags t-3 and earlier</li> <li>Lagged dependent: Levels y_{i,t-2}, y_{i,t-3}, ... for \u0394y_{i,t-1}</li> </ul> <p>Instrument Proliferation:</p> <p>Without collapse, instruments grow as O(T\u00b2). Always use collapse=True (Roodman 2009) to:</p> <ul> <li>Avoid overfitting</li> <li>Improve finite-sample properties</li> <li>Reduce computational burden</li> <li>Achieve better numerical stability</li> </ul> <p>Diagnostic Tests:</p> <ol> <li>Hansen J-test: Tests overidentifying restrictions</li> <li>p &gt; 0.25: Strong evidence instruments are valid</li> <li>0.10 &lt; p &lt; 0.25: Acceptable</li> <li> <p>p &lt; 0.10: Reject (instruments may be invalid)</p> </li> <li> <p>AR(2) test: Tests for second-order autocorrelation in differenced errors</p> </li> <li>p &gt; 0.10: Fail to reject (good)</li> <li> <p>p &lt; 0.10: Reject (moment conditions violated)</p> </li> <li> <p>Instrument ratio: Number of instruments / number of groups</p> </li> <li>Should be &lt; 1.0 (fewer instruments than groups)</li> <li>If &gt; 1.0, consider collapsing or reducing lags</li> </ol> <p>When to Use:</p> <p>Difference GMM is appropriate for:</p> <ul> <li>Dynamic panels: y_{it} depends on y_{i,t-1}</li> <li>Short panels: Small T (T &lt; 10-20), large N</li> <li>Fixed effects correlated with regressors</li> <li>Strict exogeneity fails (endogenous regressors)</li> </ul> <p>Limitations:</p> <ul> <li>Weak instruments when series are highly persistent (\u03c1 \u2192 1)</li> <li>Use System GMM instead for persistent series</li> <li>Requires T \u2265 3 for identification</li> <li>Inefficient for unbalanced panels (use collapse=True)</li> </ul> References <p>.. [1] Arellano, M., &amp; Bond, S. (1991). \"Some Tests of Specification        for Panel Data: Monte Carlo Evidence and an Application to        Employment Equations.\" Review of Economic Studies, 58(2), 277-297. .. [2] Roodman, D. (2009). \"How to do xtabond2: An Introduction to        Difference and System GMM in Stata.\" The Stata Journal, 9(1), 86-136. .. [3] Windmeijer, F. (2005). \"A Finite Sample Correction for the        Variance of Linear Efficient Two-step GMM Estimators.\"        Journal of Econometrics, 126(1), 25-51.</p> See Also <p>SystemGMM : System GMM (Blundell-Bond) for persistent series FixedEffects : Fixed Effects estimator (for static panels)</p> <p>Initialize Difference GMM model.</p>"},{"location":"api/gmm/#panelbox.gmm.difference_gmm.DifferenceGMM-functions","title":"Functions","text":""},{"location":"api/gmm/#panelbox.gmm.difference_gmm.DifferenceGMM.fit","title":"fit","text":"<pre><code>fit() -&gt; GMMResults\n</code></pre> <p>Estimate the Difference GMM model.</p> <p>Returns:</p> Type Description <code>GMMResults</code> <p>Estimation results including coefficients, tests, and diagnostics</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If model specification is invalid</p> <code>RuntimeError</code> <p>If estimation fails</p> Notes <p>Estimation procedure: 1. Transform data to first-differences 2. Generate instruments (lags of levels) 3. Estimate GMM (one-step, two-step, or iterative) 4. Compute specification tests 5. Return results object</p>"},{"location":"api/gmm/#panelbox.gmm.difference_gmm.DifferenceGMM.summary","title":"summary","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Print model summary.</p> <p>Returns:</p> Type Description <code>str</code> <p>Summary string</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If model has not been fit yet</p>"},{"location":"api/gmm/#panelbox.gmm.difference_gmm.DifferenceGMM.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Representation of the model.</p>"},{"location":"api/gmm/#systemgmm","title":"SystemGMM","text":""},{"location":"api/gmm/#panelbox.gmm.system_gmm.SystemGMM","title":"panelbox.gmm.system_gmm.SystemGMM","text":"<pre><code>SystemGMM(data: DataFrame, dep_var: str, lags: Union[int, List[int]], id_var: str = 'id', time_var: str = 'year', exog_vars: Optional[List[str]] = None, endogenous_vars: Optional[List[str]] = None, predetermined_vars: Optional[List[str]] = None, time_dummies: bool = True, collapse: bool = False, two_step: bool = True, robust: bool = True, gmm_type: str = 'two_step', level_instruments: Optional[Dict] = None)\n</code></pre> <p>               Bases: <code>DifferenceGMM</code></p> <p>Blundell-Bond (1998) System GMM estimator.</p> <p>Combines difference and level equations in a stacked system: - Difference equations (instruments: lags of levels) - Level equations (instruments: lags of differences)</p> <p>Advantages over Difference GMM: - More efficient when series are persistent - Better precision for coefficient estimates - Additional moment conditions</p> <p>Requires assumption: E[\u0394y_{i,t-1} \u00b7 \u03b7_i] = 0  (initial conditions)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Panel data in long format</p> required <code>dep_var</code> <code>str</code> <p>Name of dependent variable</p> required <code>lags</code> <code>Union[int, List[int]]</code> <p>Lags of dependent variable to include</p> required <code>id_var</code> <code>str</code> <p>Name of cross-sectional identifier (default: 'id')</p> <code>'id'</code> <code>time_var</code> <code>str</code> <p>Name of time variable (default: 'year')</p> <code>'year'</code> <code>exog_vars</code> <code>List[str]</code> <p>List of strictly exogenous variables</p> <code>None</code> <code>endogenous_vars</code> <code>List[str]</code> <p>List of endogenous variables</p> <code>None</code> <code>predetermined_vars</code> <code>List[str]</code> <p>List of predetermined variables</p> <code>None</code> <code>time_dummies</code> <code>bool</code> <p>Include time dummies (default: True)</p> <code>True</code> <code>collapse</code> <code>bool</code> <p>Collapse instruments (default: False)</p> <code>False</code> <code>two_step</code> <code>bool</code> <p>Use two-step GMM (default: True)</p> <code>True</code> <code>robust</code> <code>bool</code> <p>Use robust variance with Windmeijer correction (default: True)</p> <code>True</code> <code>gmm_type</code> <code>str</code> <p>GMM type: 'one_step', 'two_step', 'iterative' (default: 'two_step')</p> <code>'two_step'</code> <code>level_instruments</code> <code>Dict</code> <p>Configuration for level equation instruments Example: {'max_lags': 1} uses L.D.y as instrument</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>level_instruments</code> <code>Dict</code> <p>Configuration for level equation instruments</p> <p>Examples:</p> <p>When to use System GMM:</p> <p>System GMM is preferred over Difference GMM when: - Variables are highly persistent (AR coefficient near 1) - Lagged levels are weak instruments for differences - You want more efficient estimates (smaller standard errors)</p> <p>Basic System GMM with production function:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from panelbox.gmm import SystemGMM\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load production data\n&gt;&gt;&gt; data = pd.read_csv('production.csv')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate System GMM\n&gt;&gt;&gt; model = SystemGMM(\n...     data=data,\n...     dep_var='output',\n...     lags=1,                        # Include output_{t-1}\n...     id_var='firm_id',\n...     time_var='year',\n...     exog_vars=['capital', 'labor'],\n...     collapse=True,                 # Always recommended\n...     two_step=True,\n...     robust=True,\n...     level_instruments={'max_lags': 1}  # Use \u0394y_{t-1} for level equation\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; results = model.fit()\n&gt;&gt;&gt; print(results.summary())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check if more efficient than Difference GMM\n&gt;&gt;&gt; print(f\"Standard error: {results.std_errors['L1.output']:.4f}\")\n</code></pre> <p>Comparing Difference vs System GMM:</p> <pre><code>&gt;&gt;&gt; from panelbox.gmm import DifferenceGMM, SystemGMM\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate both\n&gt;&gt;&gt; diff_gmm = DifferenceGMM(\n...     data=data,\n...     dep_var='y',\n...     lags=1,\n...     exog_vars=['x1', 'x2'],\n...     collapse=True,\n...     two_step=True\n... )\n&gt;&gt;&gt; diff_results = diff_gmm.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; sys_gmm = SystemGMM(\n...     data=data,\n...     dep_var='y',\n...     lags=1,\n...     exog_vars=['x1', 'x2'],\n...     collapse=True,\n...     two_step=True,\n...     level_instruments={'max_lags': 1}\n... )\n&gt;&gt;&gt; sys_results = sys_gmm.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compare efficiency\n&gt;&gt;&gt; coef_name = 'L1.y'\n&gt;&gt;&gt; diff_se = diff_results.std_errors[coef_name]\n&gt;&gt;&gt; sys_se = sys_results.std_errors[coef_name]\n&gt;&gt;&gt; efficiency_gain = (diff_se - sys_se) / diff_se * 100\n&gt;&gt;&gt; print(f\"System GMM SE is {efficiency_gain:.1f}% smaller\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check if both are valid\n&gt;&gt;&gt; if sys_results.ar2_test.pvalue &gt; 0.10 and sys_results.hansen_j.pvalue &gt; 0.10:\n...     print(\"System GMM preferred (more efficient and valid)\")\n</code></pre> <p>With custom level instruments:</p> <pre><code>&gt;&gt;&gt; # Control instrument depth for level equation\n&gt;&gt;&gt; model = SystemGMM(\n...     data=data,\n...     dep_var='n',\n...     lags=1,\n...     exog_vars=['w', 'k'],\n...     collapse=True,\n...     level_instruments={'max_lags': 1}\n... )\n&gt;&gt;&gt; results = model.fit()\n</code></pre> Notes <p>Model and System:</p> <p>System GMM stacks two sets of equations:</p> <ol> <li> <p>Difference equations (Arellano-Bond):</p> <p>\u0394y_{it} = \u03b3 \u0394y_{i,t-1} + \u03b2' \u0394x_{it} + \u0394\u03b5_{it}</p> </li> </ol> <p>Instruments: Lags of levels (y_{i,t-2}, y_{i,t-3}, ...)</p> <ol> <li> <p>Level equations (additional moment conditions):</p> <p>y_{it} = \u03b3 y_{i,t-1} + \u03b2' x_{it} + \u03b7_i + \u03b5_{it}</p> </li> </ol> <p>Instruments: Lags of differences (\u0394y_{i,t-1}, \u0394y_{i,t-2}, ...)</p> <p>Critical Additional Assumption:</p> <pre><code>E[\u0394y_{i,1} \u00b7 \u03b7_i] = 0  (stationarity of initial conditions)\n</code></pre> <p>This requires: - The process generating y_i started long before the first observation - Initial deviations from long-run mean are uncorrelated with fixed effects - Violated if panel starts at firm entry, policy change, etc.</p> <p>When to Use System GMM:</p> <p>Prefer System over Difference GMM when:</p> <ul> <li>Persistent series: AR coefficient &gt; 0.8 (levels weak instruments)</li> <li>Small T: Few time periods (efficiency matters)</li> <li>Stationary process: Initial conditions assumption plausible</li> <li>Need precision: Want smaller standard errors</li> </ul> <p>Use Difference GMM when:</p> <ul> <li>Initial conditions suspect: Panel starts at event time</li> <li>Non-stationary: Unit root processes</li> <li>Conservative approach: Fewer assumptions</li> </ul> <p>Diagnostic Tests:</p> <p>Same as Difference GMM, plus:</p> <ul> <li>Difference-in-Hansen test: Tests validity of level instruments</li> <li>p &gt; 0.10: Fail to reject (level instruments valid)</li> <li>p &lt; 0.10: Reject (use Difference GMM instead)</li> </ul> <p>Efficiency Gains:</p> <p>System GMM typically reduces standard errors by 20-50% compared to Difference GMM when:</p> <ul> <li>Series are persistent (\u03c1 &gt; 0.8)</li> <li>Additional moment conditions are valid</li> <li>Sample size is moderate (N &gt; 50)</li> </ul> <p>Instrument Control:</p> <p>Use <code>level_instruments={'max_lags': k}</code> to control depth:</p> <ul> <li>max_lags=1: Use only \u0394y_{t-1} (most conservative, recommended)</li> <li>max_lags=2: Use \u0394y_{t-1}, \u0394y_{t-2}</li> <li>Deeper lags rarely improve efficiency</li> </ul> References <p>.. [1] Blundell, R., &amp; Bond, S. (1998). \"Initial Conditions and Moment        Restrictions in Dynamic Panel Data Models.\" Journal of Econometrics,        87(1), 115-143. .. [2] Roodman, D. (2009). \"How to do xtabond2: An Introduction to        Difference and System GMM in Stata.\" The Stata Journal, 9(1), 86-136. .. [3] Bond, S. R., Hoeffler, A., &amp; Temple, J. (2001). \"GMM Estimation of        Empirical Growth Models.\" Economics Papers 2001-W21, Economics Group,        Nuffield College, University of Oxford.</p> See Also <p>DifferenceGMM : Difference GMM (Arellano-Bond) estimator FixedEffects : Fixed Effects estimator (for static panels)</p> <p>Initialize System GMM model.</p>"},{"location":"api/gmm/#panelbox.gmm.system_gmm.SystemGMM-functions","title":"Functions","text":""},{"location":"api/gmm/#panelbox.gmm.system_gmm.SystemGMM.fit","title":"fit","text":"<pre><code>fit() -&gt; GMMResults\n</code></pre> <p>Estimate the System GMM model.</p> <p>Returns:</p> Type Description <code>GMMResults</code> <p>Estimation results</p> Notes <p>Estimation procedure: 1. Create difference equations (as in Difference GMM) 2. Create level equations 3. Stack equations and instruments 4. Estimate using stacked system 5. Compute specification tests including Diff-in-Hansen</p>"},{"location":"api/gmm/#panelbox.gmm.system_gmm.SystemGMM.summary","title":"summary","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Print model summary.</p> <p>Returns:</p> Type Description <code>str</code> <p>Summary string</p>"},{"location":"api/gmm/#panelbox.gmm.system_gmm.SystemGMM.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Representation of the model.</p>"},{"location":"api/models/","title":"Static Panel Models API","text":"<p>API documentation for static panel estimators (no lagged dependent variable).</p>"},{"location":"api/models/#pooledols","title":"PooledOLS","text":""},{"location":"api/models/#panelbox.models.static.pooled_ols.PooledOLS","title":"panelbox.models.static.pooled_ols.PooledOLS","text":"<pre><code>PooledOLS(formula: str, data: DataFrame, entity_col: str, time_col: str, weights: Optional[ndarray] = None)\n</code></pre> <p>               Bases: <code>PanelModel</code></p> <p>Pooled OLS estimator for panel data.</p> <p>This estimator ignores the panel structure and pools all observations together, estimating a standard OLS regression. This is often used as a baseline comparison for panel-specific estimators like Fixed Effects or Random Effects.</p> <p>The model estimated is:</p> <pre><code>y_it = X_it \u03b2 + \u03b5_it\n</code></pre> <p>where i indexes entities, t indexes time, and no entity-specific or time-specific effects are included.</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>Model formula in R-style syntax (e.g., \"y ~ x1 + x2\")</p> required <code>data</code> <code>DataFrame</code> <p>Panel data in long format (one row per entity-time observation)</p> required <code>entity_col</code> <code>str</code> <p>Name of the column identifying entities (e.g., 'firm', 'country')</p> required <code>time_col</code> <code>str</code> <p>Name of the column identifying time periods (e.g., 'year', 'quarter')</p> required <code>weights</code> <code>ndarray</code> <p>Observation weights for WLS estimation</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>formula_parser</code> <code>FormulaParser</code> <p>Parsed formula object</p> <code>data</code> <code>PanelData</code> <p>Panel data container</p> <code>entity_col</code> <code>str</code> <p>Entity identifier column name</p> <code>time_col</code> <code>str</code> <p>Time identifier column name</p> <code>weights</code> <code>ndarray or None</code> <p>Observation weights</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; from panelbox.datasets import load_grunfeld\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load example data\n&gt;&gt;&gt; data = load_grunfeld()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate Pooled OLS\n&gt;&gt;&gt; model = pb.PooledOLS(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results = model.fit(cov_type='robust')\n&gt;&gt;&gt; print(results.summary())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With clustered standard errors by entity\n&gt;&gt;&gt; results_cluster = model.fit(cov_type='clustered')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With Driscoll-Kraay standard errors\n&gt;&gt;&gt; results_dk = model.fit(cov_type='driscoll_kraay', max_lags=3)\n</code></pre> Notes <p>When to Use:</p> <p>Pooled OLS is appropriate when:</p> <ul> <li>No unobserved entity-specific heterogeneity exists</li> <li>The panel structure can be ignored</li> <li>You want a baseline for comparison with FE or RE models</li> </ul> <p>Limitations:</p> <ul> <li>Does not control for unobserved heterogeneity</li> <li>Standard errors may be biased if errors are correlated within entities</li> <li>Use clustered standard errors (<code>cov_type='clustered'</code>) to account   for within-entity correlation</li> </ul> <p>Standard Error Options:</p> <p>This implementation supports 9 types of standard errors:</p> <ol> <li>Classical OLS (<code>nonrobust</code>)</li> <li>Heteroskedasticity-robust: HC0, HC1, HC2, HC3</li> <li>Cluster-robust: one-way (<code>clustered</code>) and two-way (<code>twoway</code>)</li> <li>HAC: Driscoll-Kraay (<code>driscoll_kraay</code>), Newey-West (<code>newey_west</code>)</li> <li>Panel-corrected (<code>pcse</code>)</li> </ol> References <p>.. [1] Wooldridge, J. M. (2010). Econometric Analysis of Cross Section        and Panel Data (2<sup>nd</sup> ed.). MIT Press. .. [2] Baltagi, B. H. (2021). Econometric Analysis of Panel Data        (6<sup>th</sup> ed.). Springer.</p> See Also <p>FixedEffects : Fixed Effects (Within) estimator RandomEffects : Random Effects (GLS) estimator</p>"},{"location":"api/models/#panelbox.models.static.pooled_ols.PooledOLS-functions","title":"Functions","text":""},{"location":"api/models/#panelbox.models.static.pooled_ols.PooledOLS.fit","title":"fit","text":"<pre><code>fit(cov_type: str = 'nonrobust', **cov_kwds) -&gt; PanelResults\n</code></pre> <p>Fit the Pooled OLS model.</p> <p>Parameters:</p> Name Type Description Default <code>cov_type</code> <code>str</code> <p>Type of covariance estimator: - 'nonrobust': Classical OLS standard errors - 'robust' or 'hc1': Heteroskedasticity-robust (HC1) - 'hc0', 'hc2', 'hc3': Other HC variants - 'clustered': Cluster-robust (clustered by entity by default) - 'twoway': Two-way clustering (entity and time) - 'driscoll_kraay': Driscoll-Kraay for spatial/temporal dependence - 'newey_west': Newey-West HAC - 'pcse': Panel-corrected standard errors</p> <code>'nonrobust'</code> <code>**cov_kwds</code> <p>Additional arguments for covariance estimation: - max_lags : int, for driscoll_kraay and newey_west - kernel : str, for driscoll_kraay and newey_west</p> <code>{}</code> <p>Returns:</p> Type Description <code>PanelResults</code> <p>Fitted model results</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Classical standard errors\n&gt;&gt;&gt; results = model.fit(cov_type='nonrobust')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Heteroskedasticity-robust\n&gt;&gt;&gt; results = model.fit(cov_type='robust')\n&gt;&gt;&gt; results = model.fit(cov_type='hc3')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Cluster-robust\n&gt;&gt;&gt; results = model.fit(cov_type='clustered')\n&gt;&gt;&gt; results = model.fit(cov_type='twoway')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # HAC\n&gt;&gt;&gt; results = model.fit(cov_type='driscoll_kraay', max_lags=3)\n&gt;&gt;&gt; results = model.fit(cov_type='newey_west', max_lags=4, kernel='bartlett')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # PCSE\n&gt;&gt;&gt; results = model.fit(cov_type='pcse')\n</code></pre>"},{"location":"api/models/#fixedeffects","title":"FixedEffects","text":""},{"location":"api/models/#panelbox.models.static.fixed_effects.FixedEffects","title":"panelbox.models.static.fixed_effects.FixedEffects","text":"<pre><code>FixedEffects(formula: str, data: DataFrame, entity_col: str, time_col: str, entity_effects: bool = True, time_effects: bool = False, weights: Optional[ndarray] = None)\n</code></pre> <p>               Bases: <code>PanelModel</code></p> <p>Fixed Effects (Within) estimator for panel data.</p> <p>Removes unobserved entity-specific (and optionally time-specific) fixed effects through demeaning (within transformation). This is equivalent to including entity (and time) dummy variables, but more computationally efficient.</p> <p>The model estimated is:</p> <pre><code>y_it = \u03b1_i + \u03b3_t + X_it \u03b2 + \u03b5_it\n</code></pre> <p>where \u03b1_i are entity fixed effects and \u03b3_t are time fixed effects (if time_effects=True). The within transformation removes these effects by demeaning:</p> <pre><code>(y_it - \u0233_i) = (X_it - X\u0304_i) \u03b2 + (\u03b5_it - \u03b5\u0304_i)\n</code></pre> <p>Important: Time-invariant variables are automatically dropped from the model as they are absorbed by the fixed effects.</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>Model formula in R-style syntax (e.g., \"y ~ x1 + x2\")</p> required <code>data</code> <code>DataFrame</code> <p>Panel data in long format (one row per entity-time observation)</p> required <code>entity_col</code> <code>str</code> <p>Name of the column identifying entities (e.g., 'firm', 'country')</p> required <code>time_col</code> <code>str</code> <p>Name of the column identifying time periods (e.g., 'year', 'quarter')</p> required <code>entity_effects</code> <code>bool</code> <p>Include entity fixed effects (one-way FE if time_effects=False)</p> <code>True</code> <code>time_effects</code> <code>bool</code> <p>Include time fixed effects (two-way FE if entity_effects=True)</p> <code>False</code> <code>weights</code> <code>ndarray</code> <p>Observation weights for WLS estimation</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>entity_effects</code> <code>bool</code> <p>Whether entity fixed effects are included</p> <code>time_effects</code> <code>bool</code> <p>Whether time fixed effects are included</p> <code>entity_fe</code> <code>(Series, optional)</code> <p>Estimated entity fixed effects (populated after fit())</p> <code>time_fe</code> <code>(Series, optional)</code> <p>Estimated time fixed effects (populated after fit())</p> <code>formula_parser</code> <code>FormulaParser</code> <p>Parsed formula object</p> <code>data</code> <code>PanelData</code> <p>Panel data container</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; from panelbox.datasets import load_grunfeld\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load example data\n&gt;&gt;&gt; data = load_grunfeld()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # One-way fixed effects (entity only)\n&gt;&gt;&gt; model = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results = model.fit(cov_type='clustered')\n&gt;&gt;&gt; print(results.summary())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Two-way fixed effects (entity + time)\n&gt;&gt;&gt; model_twoway = pb.FixedEffects(\n...     \"invest ~ value + capital\",\n...     data,\n...     \"firm\",\n...     \"year\",\n...     entity_effects=True,\n...     time_effects=True\n... )\n&gt;&gt;&gt; results_twoway = model_twoway.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access estimated fixed effects\n&gt;&gt;&gt; print(f\"Entity FE: {model.entity_fe.head()}\")\n</code></pre> Notes <p>When to Use:</p> <p>Fixed Effects is appropriate when:</p> <ul> <li>Unobserved entity heterogeneity exists and is correlated with regressors</li> <li>You want to control for time-invariant confounders</li> <li>Strict exogeneity holds: E[\u03b5_it | X_i, \u03b1_i] = 0</li> </ul> <p>Advantages:</p> <ul> <li>Consistent under correlation between \u03b1_i and X_it</li> <li>Does not require assumptions about distribution of \u03b1_i</li> <li>Controls for all time-invariant unobserved factors</li> </ul> <p>Limitations:</p> <ul> <li>Cannot estimate coefficients on time-invariant variables</li> <li>Inefficient if Random Effects assumptions hold</li> <li>May amplify measurement error in differenced data</li> <li>Requires T \u2265 2 observations per entity</li> </ul> <p>R-squared Interpretation:</p> <ul> <li><code>rsquared_within</code>: R\u00b2 for demeaned (within) model</li> <li><code>rsquared_between</code>: R\u00b2 for entity means</li> <li><code>rsquared_overall</code>: Overall R\u00b2 including fixed effects</li> </ul> <p>The within R\u00b2 is the most relevant for FE models.</p> <p>Standard Error Options:</p> <p>Supports the same 9 types as PooledOLS. Clustered standard errors (<code>cov_type='clustered'</code>) are recommended to account for within-entity correlation remaining after fixed effects.</p> References <p>.. [1] Wooldridge, J. M. (2010). Econometric Analysis of Cross Section        and Panel Data (2<sup>nd</sup> ed.). MIT Press. Chapter 10. .. [2] Baltagi, B. H. (2021). Econometric Analysis of Panel Data        (6<sup>th</sup> ed.). Springer. Chapter 2. .. [3] Cameron, A. C., &amp; Trivedi, P. K. (2005). Microeconometrics:        Methods and Applications. Cambridge University Press. Chapter 21.</p> See Also <p>RandomEffects : Random Effects (GLS) estimator PooledOLS : Pooled OLS without fixed effects FirstDifferences : First differences estimator (alternative to FE) HausmanTest : Test for choosing between FE and RE</p>"},{"location":"api/models/#panelbox.models.static.fixed_effects.FixedEffects-functions","title":"Functions","text":""},{"location":"api/models/#panelbox.models.static.fixed_effects.FixedEffects.fit","title":"fit","text":"<pre><code>fit(cov_type: str = 'nonrobust', **cov_kwds) -&gt; PanelResults\n</code></pre> <p>Fit the Fixed Effects model.</p> <p>Parameters:</p> Name Type Description Default <code>cov_type</code> <code>str</code> <p>Type of covariance estimator: - 'nonrobust': Classical standard errors - 'robust' or 'hc1': Heteroskedasticity-robust (HC1) - 'hc0', 'hc2', 'hc3': Other HC variants - 'clustered': Cluster-robust (by entity by default) - 'twoway': Two-way clustered (entity and time) - 'driscoll_kraay': Driscoll-Kraay (spatial/temporal dependence) - 'newey_west': Newey-West HAC - 'pcse': Panel-Corrected Standard Errors (requires T &gt; N)</p> <code>'nonrobust'</code> <code>**cov_kwds</code> <p>Additional arguments for covariance estimation: - cluster_col: For custom clustering (default: entity) - max_lags: For Driscoll-Kraay and Newey-West - kernel: For HAC estimators ('bartlett', 'parzen', 'quadratic_spectral')</p> <code>{}</code> <p>Returns:</p> Type Description <code>PanelResults</code> <p>Fitted model results</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Classical standard errors\n&gt;&gt;&gt; results = model.fit(cov_type='nonrobust')\n</code></pre> <pre><code>&gt;&gt;&gt; # Heteroskedasticity-robust\n&gt;&gt;&gt; results = model.fit(cov_type='robust')\n&gt;&gt;&gt; results = model.fit(cov_type='hc3')\n</code></pre> <pre><code>&gt;&gt;&gt; # Cluster-robust by entity\n&gt;&gt;&gt; results = model.fit(cov_type='clustered')\n</code></pre> <pre><code>&gt;&gt;&gt; # Two-way clustering\n&gt;&gt;&gt; results = model.fit(cov_type='twoway')\n</code></pre> <pre><code>&gt;&gt;&gt; # Driscoll-Kraay (for spatial/temporal dependence)\n&gt;&gt;&gt; results = model.fit(cov_type='driscoll_kraay', max_lags=3)\n</code></pre> <pre><code>&gt;&gt;&gt; # Newey-West HAC\n&gt;&gt;&gt; results = model.fit(cov_type='newey_west', max_lags=4)\n</code></pre> <pre><code>&gt;&gt;&gt; # Panel-Corrected SE (requires T &gt; N)\n&gt;&gt;&gt; results = model.fit(cov_type='pcse')\n</code></pre>"},{"location":"api/models/#randomeffects","title":"RandomEffects","text":""},{"location":"api/models/#panelbox.models.static.random_effects.RandomEffects","title":"panelbox.models.static.random_effects.RandomEffects","text":"<pre><code>RandomEffects(formula: str, data: DataFrame, entity_col: str, time_col: str, variance_estimator: str = 'swamy-arora', weights: Optional[ndarray] = None)\n</code></pre> <p>               Bases: <code>PanelModel</code></p> <p>Random Effects (GLS) estimator for panel data.</p> <p>Assumes entity-specific effects are uncorrelated with regressors and uses Generalized Least Squares (GLS) to efficiently estimate the model accounting for the variance component structure.</p> <p>The model estimated is:</p> <pre><code>y_it = X_it \u03b2 + u_i + \u03b5_it\n</code></pre> <p>where u_i ~ i.i.d(0, \u03c3\u00b2_u) is the entity-specific random effect and \u03b5_it ~ i.i.d(0, \u03c3\u00b2_\u03b5) is the idiosyncratic error.</p> <p>Key Assumption: E[u_i | X_it] = 0 (random effects uncorrelated with X)</p> <p>The GLS transformation is:</p> <pre><code>y*_it = y_it - \u03b8 \u0233_i\nX*_it = X_it - \u03b8 X\u0304_i\n</code></pre> <p>where \u03b8 = 1 - \u221a(\u03c3\u00b2_\u03b5 / (\u03c3\u00b2_\u03b5 + T \u03c3\u00b2_u)) depends on the variance components.</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>Model formula in R-style syntax (e.g., \"y ~ x1 + x2\")</p> required <code>data</code> <code>DataFrame</code> <p>Panel data in long format (one row per entity-time observation)</p> required <code>entity_col</code> <code>str</code> <p>Name of the column identifying entities (e.g., 'firm', 'country')</p> required <code>time_col</code> <code>str</code> <p>Name of the column identifying time periods (e.g., 'year', 'quarter')</p> required <code>variance_estimator</code> <code>str</code> <p>Method for estimating variance components: - 'swamy-arora': Swamy-Arora estimator (most common, default) - 'walhus': Wallace-Hussain estimator - 'amemiya': Amemiya estimator - 'nerlove': Nerlove estimator</p> <code>'swamy-arora'</code> <code>weights</code> <code>ndarray</code> <p>Observation weights for WLS estimation</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>variance_estimator</code> <code>str</code> <p>Variance estimation method used</p> <code>sigma2_u</code> <code>float or None</code> <p>Estimated variance of entity-specific effects (populated after fit())</p> <code>sigma2_e</code> <code>float or None</code> <p>Estimated variance of idiosyncratic errors (populated after fit())</p> <code>theta</code> <code>float or None</code> <p>GLS transformation parameter (populated after fit())</p> <code>formula_parser</code> <code>FormulaParser</code> <p>Parsed formula object</p> <code>data</code> <code>PanelData</code> <p>Panel data container</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; from panelbox.datasets import load_grunfeld\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load example data\n&gt;&gt;&gt; data = load_grunfeld()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate Random Effects\n&gt;&gt;&gt; model = pb.RandomEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results = model.fit()\n&gt;&gt;&gt; print(results.summary())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Examine variance components\n&gt;&gt;&gt; print(f\"Entity variance (\u03c3\u00b2_u): {model.sigma2_u:.4f}\")\n&gt;&gt;&gt; print(f\"Idiosyncratic variance (\u03c3\u00b2_\u03b5): {model.sigma2_e:.4f}\")\n&gt;&gt;&gt; print(f\"Theta: {model.theta:.4f}\")\n&gt;&gt;&gt; print(f\"Proportion of variance due to u_i: \"\n...       f\"{model.sigma2_u/(model.sigma2_u + model.sigma2_e):.2%}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use different variance estimator\n&gt;&gt;&gt; model_amemiya = pb.RandomEffects(\n...     \"invest ~ value + capital\",\n...     data,\n...     \"firm\",\n...     \"year\",\n...     variance_estimator='amemiya'\n... )\n&gt;&gt;&gt; results_amemiya = model_amemiya.fit()\n</code></pre> Notes <p>When to Use:</p> <p>Random Effects is appropriate when:</p> <ul> <li>Entity-specific effects are uncorrelated with regressors: E[u_i | X_it] = 0</li> <li>You want to estimate effects of time-invariant variables</li> <li>The sample is a random draw from a large population</li> <li>Efficiency is important (RE is more efficient than FE under correct specification)</li> </ul> <p>Advantages over Fixed Effects:</p> <ul> <li>Can estimate coefficients on time-invariant variables</li> <li>More efficient (lower standard errors) when assumptions hold</li> <li>Better for small T (few time periods)</li> </ul> <p>Limitations:</p> <ul> <li>Inconsistent if E[u_i | X_it] \u2260 0 (correlation between effects and regressors)</li> <li>Requires stronger assumptions than Fixed Effects</li> <li>Use Hausman test to check if RE assumptions are valid</li> </ul> <p>Variance Estimators:</p> <p>Different methods for estimating \u03c3\u00b2_u and \u03c3\u00b2_\u03b5:</p> <ul> <li>swamy-arora (default): Most commonly used, performs well in practice</li> <li>walhus: Wallace-Hussain estimator</li> <li>amemiya: Amemiya's alternative estimator</li> <li>nerlove: Nerlove's estimator</li> </ul> <p>All produce consistent estimates; differences are typically small.</p> <p>Testing FE vs RE:</p> <p>Use the Hausman test to choose between Fixed and Random Effects:</p> <p>from panelbox import FixedEffects, RandomEffects, HausmanTest fe_results = FixedEffects(...).fit() re_results = RandomEffects(...).fit() hausman = HausmanTest(fe_results, re_results) print(hausman)  # p-value &lt; 0.05 suggests FE is preferred</p> References <p>.. [1] Baltagi, B. H. (2021). Econometric Analysis of Panel Data        (6<sup>th</sup> ed.). Springer. Chapter 2. .. [2] Wooldridge, J. M. (2010). Econometric Analysis of Cross Section        and Panel Data (2<sup>nd</sup> ed.). MIT Press. Chapter 10. .. [3] Swamy, P. A. V. B., &amp; Arora, S. S. (1972). The Exact Finite Sample        Properties of the Estimators of Coefficients in the Error Components        Regression Models. Econometrica, 40(2), 261-275.</p> See Also <p>FixedEffects : Fixed Effects (Within) estimator PooledOLS : Pooled OLS without random effects HausmanTest : Test for choosing between FE and RE</p>"},{"location":"api/models/#panelbox.models.static.random_effects.RandomEffects-functions","title":"Functions","text":""},{"location":"api/models/#panelbox.models.static.random_effects.RandomEffects.fit","title":"fit","text":"<pre><code>fit(cov_type: str = 'nonrobust', **cov_kwds) -&gt; PanelResults\n</code></pre> <p>Fit the Random Effects model.</p> <p>Parameters:</p> Name Type Description Default <code>cov_type</code> <code>str</code> <p>Type of covariance estimator: - 'nonrobust': Classical GLS standard errors - 'robust' or 'hc1': Heteroskedasticity-robust (HC1) - 'hc0', 'hc2', 'hc3': Other HC variants - 'clustered': Cluster-robust (by entity by default) - 'twoway': Two-way clustered (entity and time) - 'driscoll_kraay': Driscoll-Kraay (spatial/temporal dependence) - 'newey_west': Newey-West HAC</p> <code>'nonrobust'</code> <code>**cov_kwds</code> <p>Additional arguments for covariance estimation: - max_lags: For Driscoll-Kraay and Newey-West - kernel: For HAC estimators</p> <code>{}</code> <p>Returns:</p> Type Description <code>PanelResults</code> <p>Fitted model results</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; results = model.fit()\n&gt;&gt;&gt; results_robust = model.fit(cov_type='robust')\n</code></pre>"},{"location":"api/models/#betweenestimator","title":"BetweenEstimator","text":""},{"location":"api/models/#panelbox.models.static.between.BetweenEstimator","title":"panelbox.models.static.between.BetweenEstimator","text":"<pre><code>BetweenEstimator(formula: str, data: DataFrame, entity_col: str, time_col: str, weights: Optional[ndarray] = None)\n</code></pre> <p>               Bases: <code>PanelModel</code></p> <p>Between estimator for panel data.</p> <p>This estimator regresses on group (entity) means, capturing the variation between entities rather than within entities. It answers: \"Do entities with higher average X also have higher average Y?\"</p> <p>The between transformation computes group means:     \u0233_i = \u03b2 x\u0304_i + \u03b1 + \u016b_i</p> <p>where bars denote averages over time for each entity i.</p> <p>This estimator is useful when: - T (time periods) is small relative to N (entities) - Focus is on cross-sectional (between-entity) variation - Time-invariant characteristics are of interest</p> <p>Contrast with Fixed Effects (within estimator): - FE uses deviations from entity means (within variation) - BE uses entity means themselves (between variation)</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>Model formula in R-style syntax (e.g., \"y ~ x1 + x2\")</p> required <code>data</code> <code>DataFrame</code> <p>Panel data in long format</p> required <code>entity_col</code> <code>str</code> <p>Name of the column identifying entities</p> required <code>time_col</code> <code>str</code> <p>Name of the column identifying time periods</p> required <code>weights</code> <code>ndarray</code> <p>Observation weights (applied to entity means)</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>entity_means</code> <code>(DataFrame, optional)</code> <p>Entity-level means (after fitting)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load data\n&gt;&gt;&gt; data = pb.load_grunfeld()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Between estimator\n&gt;&gt;&gt; be = pb.BetweenEstimator(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results = be.fit(cov_type='robust')\n&gt;&gt;&gt; print(results.summary())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compare with Fixed Effects (within)\n&gt;&gt;&gt; fe = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results_fe = fe.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # BE captures between variation, FE captures within variation\n&gt;&gt;&gt; print(f\"Between R\u00b2: {results.rsquared:.4f}\")\n&gt;&gt;&gt; print(f\"Within R\u00b2: {results_fe.rsquared:.4f}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access entity means\n&gt;&gt;&gt; entity_means = be.entity_means\n&gt;&gt;&gt; print(entity_means.head())\n</code></pre> Notes <p>Mathematical Formulation:</p> <p>The Between estimator computes entity-level averages:</p> <pre><code>\u0233_i = (1/T_i) \u03a3_t y_it\nx\u0304_i = (1/T_i) \u03a3_t x_it\n</code></pre> <p>Then runs OLS on the cross-section of N entities:</p> <pre><code>\u0233_i = \u03b2\u2080 + \u03b2\u2081 x\u0304_i + \u016b_i\n</code></pre> <p>where \u016b_i is the average of residuals u_it for entity i.</p> <p>When to Use:</p> <p>The Between estimator is appropriate when:</p> <ul> <li>Focus on cross-sectional variation: Interest is in differences across   entities, not changes within entities over time</li> <li>Small T, large N: Many entities but few time periods per entity</li> <li>Time-invariant regressors: Variables that don't vary over time can be   included (unlike Fixed Effects)</li> <li>Exploratory analysis: Understanding which entities differ and why</li> </ul> <p>Comparison with Other Estimators:</p> Estimator Variation Used Sample Size Time-Invariant X Between Across entities N \u2705 Allowed Fixed Effects Within entities NT \u274c Dropped Random Effects Both (weighted) NT \u2705 Allowed Pooled OLS Both (unweighted) NT \u2705 Allowed <p>Properties:</p> <ul> <li>Efficiency: Less efficient than FE or RE when T is large (uses less data)</li> <li>Consistency: Consistent if E[\u016b_i | x\u0304_i] = 0 (between-entity exogeneity)</li> <li>R-squared: Measures between-entity variation only</li> <li>Degrees of Freedom: Based on N (not NT), so standard errors larger</li> </ul> <p>Interpretation:</p> <p>Between estimates answer: \"Do firms with higher average investment also have higher average capital?\" (cross-sectional question)</p> <p>Fixed Effects estimates answer: \"When a firm increases investment, does it also increase capital?\" (within-firm question)</p> <p>Estimation Steps:</p> <ol> <li>Compute entity-level means for all variables</li> <li>Run OLS on the N entity means (not NT observations)</li> <li>Report R\u00b2 as the between R\u00b2 (variation explained across entities)</li> </ol> <p>Degrees of Freedom:</p> <ul> <li>N observations (one per entity)</li> <li>k parameters (slopes + intercept)</li> <li>df_resid = N - k</li> </ul> <p>Standard Errors:</p> <p>All SE types are supported (robust, clustered, etc.) and are applied to the N entity-level observations. Clustering by time is possible if needed.</p> See Also <p>FixedEffects : Within estimator (uses within-entity variation) RandomEffects : GLS estimator (uses both within and between variation) PooledOLS : Ignores panel structure entirely</p> References <p>.. [1] Wooldridge, J. M. (2010). Econometric Analysis of Cross Section        and Panel Data (2<sup>nd</sup> ed.). MIT Press. Section 10.2.2. .. [2] Baltagi, B. H. (2021). Econometric Analysis of Panel Data        (6<sup>th</sup> ed.). Springer. Chapter 2. .. [3] Hsiao, C. (2014). Analysis of Panel Data (3<sup>rd</sup> ed.). Cambridge        University Press. Chapter 3.</p>"},{"location":"api/models/#panelbox.models.static.between.BetweenEstimator-functions","title":"Functions","text":""},{"location":"api/models/#panelbox.models.static.between.BetweenEstimator.fit","title":"fit","text":"<pre><code>fit(cov_type: str = 'nonrobust', **cov_kwds) -&gt; PanelResults\n</code></pre> <p>Fit the Between estimator.</p> <p>Parameters:</p> Name Type Description Default <code>cov_type</code> <code>str</code> <p>Type of covariance estimator: - 'nonrobust': Classical standard errors - 'robust' or 'hc1': Heteroskedasticity-robust (HC1) - 'hc0', 'hc2', 'hc3': Other HC variants - 'clustered': Cluster-robust (by entity by default, or custom) - 'twoway': Two-way clustered (entity and time at group level) - 'driscoll_kraay': Driscoll-Kraay (spatial/temporal dependence) - 'newey_west': Newey-West HAC - 'pcse': Panel-Corrected Standard Errors</p> <code>'nonrobust'</code> <code>**cov_kwds</code> <p>Additional arguments for covariance estimation: - cluster_col: For custom clustering - max_lags: For Driscoll-Kraay and Newey-West - kernel: For HAC estimators ('bartlett', 'parzen', 'quadratic_spectral')</p> <code>{}</code> <p>Returns:</p> Type Description <code>PanelResults</code> <p>Fitted model results</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Classical standard errors\n&gt;&gt;&gt; results = model.fit(cov_type='nonrobust')\n</code></pre> <pre><code>&gt;&gt;&gt; # Heteroskedasticity-robust\n&gt;&gt;&gt; results = model.fit(cov_type='robust')\n&gt;&gt;&gt; results = model.fit(cov_type='hc3')\n</code></pre> <pre><code>&gt;&gt;&gt; # Cluster-robust\n&gt;&gt;&gt; results = model.fit(cov_type='clustered')\n</code></pre> <pre><code>&gt;&gt;&gt; # Driscoll-Kraay\n&gt;&gt;&gt; results = model.fit(cov_type='driscoll_kraay', max_lags=3)\n</code></pre>"},{"location":"api/models/#firstdifferenceestimator","title":"FirstDifferenceEstimator","text":""},{"location":"api/models/#panelbox.models.static.first_difference.FirstDifferenceEstimator","title":"panelbox.models.static.first_difference.FirstDifferenceEstimator","text":"<pre><code>FirstDifferenceEstimator(formula: str, data: DataFrame, entity_col: str, time_col: str, weights: Optional[ndarray] = None)\n</code></pre> <p>               Bases: <code>PanelModel</code></p> <p>First Difference estimator for panel data.</p> <p>This estimator eliminates unobserved entity-specific fixed effects through first-differencing. Instead of demeaning (like Fixed Effects), it takes differences:     \u0394y_it = y_it - y_{i,t-1} = \u03b2 \u0394x_it + \u0394\u03b5_it</p> <p>where \u0394 denotes the first difference operator.</p> <p>The entity fixed effect (\u03b1_i) cancels out because it's time-invariant:     \u0394\u03b1_i = \u03b1_i - \u03b1_i = 0</p> <p>Advantages over Fixed Effects (within estimator): - More robust when T is small (few time periods) - Better suited for models with serially correlated errors - Handles unbalanced panels naturally - No dummy variable trap issues</p> <p>Disadvantages: - Loses one time period per entity (first period dropped) - Amplifies measurement error (differences magnify noise) - Less efficient than FE under homoskedastic errors - Loses time-invariant variables (like FE)</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>Model formula in R-style syntax (e.g., \"y ~ x1 + x2\")</p> required <code>data</code> <code>DataFrame</code> <p>Panel data in long format (must be sorted by entity and time)</p> required <code>entity_col</code> <code>str</code> <p>Name of the column identifying entities</p> required <code>time_col</code> <code>str</code> <p>Name of the column identifying time periods</p> required <code>weights</code> <code>ndarray</code> <p>Observation weights (applied to differenced data)</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>n_obs_original</code> <code>int</code> <p>Number of observations before differencing</p> <code>n_obs_differenced</code> <code>int</code> <p>Number of observations after differencing (loses first period per entity)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load data\n&gt;&gt;&gt; data = pb.load_grunfeld()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # First Difference estimator\n&gt;&gt;&gt; fd = pb.FirstDifferenceEstimator(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results = fd.fit(cov_type='robust')\n&gt;&gt;&gt; print(results.summary())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compare with Fixed Effects\n&gt;&gt;&gt; fe = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results_fe = fe.fit(cov_type='robust')\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(f\"First Diff coefs: {results.params.values}\")\n&gt;&gt;&gt; print(f\"Fixed Effects coefs: {results_fe.params.values}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Under homoskedasticity, should be similar\n&gt;&gt;&gt; # Under serial correlation, FD may be more consistent\n</code></pre> Notes <p>Data Requirements: - Data must be sorted by entity and time before estimation - Missing periods will be handled by taking differences only within consecutive observations - At least 2 time periods per entity required</p> <p>First Differencing: - For each entity i, compute: \u0394y_it = y_it - y_{i,t-1} - Drops the first observation for each entity - If N entities and T periods (balanced): N*T \u2192 N*(T-1) observations</p> <p>Inference: - Standard errors account for structure of differenced data - Cluster-robust SE recommended (clustering by entity) - Driscoll-Kraay useful for serial correlation and heteroskedasticity</p> <p>Comparison with Fixed Effects:</p> Aspect First Difference Fixed Effects Transformation y_it - y_{i,t-1} y_it - \u0233_i Observations lost First period (N) None Serial correlation More robust Problematic if MA(1) in \u0394\u03b5 Efficiency Less efficient More efficient Unit roots Handles well May be inconsistent <p>When FD is Preferred:</p> <ul> <li>Serial correlation: When errors follow AR(1) or random walk</li> <li>Small T: FE requires larger T for asymptotic properties</li> <li>Unit roots: When y_it has a unit root (non-stationary)</li> <li>Measurement error: When measurement error is not i.i.d.</li> </ul> <p>When FE is Preferred:</p> <ul> <li>Homoskedastic errors: FE is BLUE under classical assumptions</li> <li>Large T: Efficiency gains matter more</li> <li>No serial correlation: Classical assumptions hold</li> <li>Sample preservation: Don't want to lose observations</li> </ul> <p>Mathematical Equivalence:</p> <p>Under certain conditions, FD and FE are numerically equivalent:</p> <ul> <li>Balanced panel with T = 2: FD \u2261 FE</li> <li>No serial correlation in levels: Both consistent</li> <li>Different weights on time periods otherwise</li> </ul> <p>Standard Error Considerations:</p> <p>First-differencing induces MA(1) structure in errors even if original errors are i.i.d.:</p> <pre><code>\u0394\u03b5_it = \u03b5_it - \u03b5_{i,t-1}\n</code></pre> <p>Therefore: - Cov(\u0394\u03b5_it, \u0394\u03b5_{i,t-1}) = -\u03c3\u00b2_\u03b5 (negative correlation) - Cluster-robust or Driscoll-Kraay SEs recommended - Newey-West with lag=1 minimum</p> See Also <p>FixedEffects : Within estimator (demeaning transformation) BetweenEstimator : Between estimator (entity means) DifferenceGMM : GMM with first-differencing (for dynamics)</p> References <p>.. [1] Wooldridge, J. M. (2010). Econometric Analysis of Cross Section        and Panel Data (2<sup>nd</sup> ed.). MIT Press. Section 10.5. .. [2] Baltagi, B. H. (2021). Econometric Analysis of Panel Data        (6<sup>th</sup> ed.). Springer. Chapter 3. .. [3] Hsiao, C. (2014). Analysis of Panel Data (3<sup>rd</sup> ed.). Cambridge        University Press. Chapter 4. .. [4] Anderson, T. W., &amp; Hsiao, C. (1981). \"Estimation of Dynamic Models        with Error Components.\" Journal of the American Statistical Association,        76(375), 598-606.</p>"},{"location":"api/models/#panelbox.models.static.first_difference.FirstDifferenceEstimator-functions","title":"Functions","text":""},{"location":"api/models/#panelbox.models.static.first_difference.FirstDifferenceEstimator.fit","title":"fit","text":"<pre><code>fit(cov_type: str = 'nonrobust', **cov_kwds) -&gt; PanelResults\n</code></pre> <p>Fit the First Difference estimator.</p> <p>Parameters:</p> Name Type Description Default <code>cov_type</code> <code>str</code> <p>Type of covariance estimator: - 'nonrobust': Classical standard errors - 'robust' or 'hc1': Heteroskedasticity-robust (HC1) - 'hc0', 'hc2', 'hc3': Other HC variants - 'clustered': Cluster-robust (by entity, recommended for FD) - 'twoway': Two-way clustered (entity and time) - 'driscoll_kraay': Driscoll-Kraay (for serial correlation) - 'newey_west': Newey-West HAC - 'pcse': Panel-Corrected Standard Errors</p> <code>'nonrobust'</code> <code>**cov_kwds</code> <p>Additional arguments for covariance estimation: - cluster_col: For custom clustering (default: entity) - max_lags: For Driscoll-Kraay and Newey-West - kernel: For HAC estimators ('bartlett', 'parzen', 'quadratic_spectral')</p> <code>{}</code> <p>Returns:</p> Type Description <code>PanelResults</code> <p>Fitted model results</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Classical standard errors\n&gt;&gt;&gt; results = model.fit(cov_type='nonrobust')\n</code></pre> <pre><code>&gt;&gt;&gt; # Heteroskedasticity-robust (recommended)\n&gt;&gt;&gt; results = model.fit(cov_type='robust')\n</code></pre> <pre><code>&gt;&gt;&gt; # Cluster-robust by entity (recommended for FD)\n&gt;&gt;&gt; results = model.fit(cov_type='clustered')\n</code></pre> <pre><code>&gt;&gt;&gt; # Driscoll-Kraay (for serial correlation + heteroskedasticity)\n&gt;&gt;&gt; results = model.fit(cov_type='driscoll_kraay', max_lags=2)\n</code></pre> Notes <p>For First Difference models, clustered or Driscoll-Kraay standard errors are typically recommended because: - Differencing can induce serial correlation (MA(1) structure) - Cluster-robust SE account for within-entity correlation - Driscoll-Kraay handles both serial correlation and heteroskedasticity</p>"},{"location":"api/report/","title":"Report and Export API","text":"<p>API documentation for reporting and export utilities.</p> <p>NEW in v0.8.0: PanelExperiment, ValidationTest, ComparisonTest, HTML reports, Master reports</p>"},{"location":"api/report/#panelexperiment-new-in-v080","title":"PanelExperiment (NEW in v0.8.0)","text":"<p>High-level API for panel data analysis with integrated report generation.</p>"},{"location":"api/report/#overview","title":"Overview","text":"<p><code>PanelExperiment</code> provides a unified interface for: - Fitting multiple panel models - Running validation tests - Comparing models - Analyzing residuals - Generating HTML reports</p>"},{"location":"api/report/#usage","title":"Usage","text":"<pre><code>import panelbox as pb\n\n# Create experiment\nexperiment = pb.PanelExperiment(\n    data=data,\n    formula=\"y ~ x1 + x2\",\n    entity_col=\"entity\",\n    time_col=\"time\"\n)\n\n# Fit models\nexperiment.fit_model('pooled_ols', name='ols')\nexperiment.fit_model('fixed_effects', name='fe')\nexperiment.fit_model('random_effects', name='re')\n\n# List fitted models\nprint(experiment.list_models())  # ['ols', 'fe', 're']\n\n# Get model\nresults = experiment.get_model('fe')\n</code></pre>"},{"location":"api/report/#methods","title":"Methods","text":""},{"location":"api/report/#fit_modelmodel_type-name-kwargs","title":"fit_model(model_type, name, **kwargs)","text":"<p>Fit a panel model and store it in the experiment.</p> <p>Parameters: - <code>model_type</code> (str): Model type ('pooled_ols', 'fixed_effects', 'random_effects', 'between', 'first_differences') - <code>name</code> (str): Name for the fitted model - <code>**kwargs</code>: Additional arguments passed to model constructor</p> <p>Returns: PanelResults object</p>"},{"location":"api/report/#validate_modelname-configbasic-testsnone","title":"validate_model(name, config='basic', tests=None)","text":"<p>Run validation tests on a fitted model.</p> <p>Parameters: - <code>name</code> (str): Name of fitted model - <code>config</code> (str): Test configuration ('quick', 'basic', 'full') - <code>tests</code> (list, optional): Specific tests to run</p> <p>Returns: ValidationResult object</p> <p>Example: <pre><code># Quick validation (2 tests)\nval_quick = experiment.validate_model('fe', config='quick')\n\n# Full validation (all tests)\nval_full = experiment.validate_model('fe', config='full')\n\n# Custom tests\nval_custom = experiment.validate_model('fe', tests=['heteroskedasticity', 'normality'])\n</code></pre></p>"},{"location":"api/report/#compare_modelsmodel_names-include_coefficientstrue-include_statisticstrue","title":"compare_models(model_names, include_coefficients=True, include_statistics=True)","text":"<p>Compare multiple fitted models.</p> <p>Parameters: - <code>model_names</code> (list): List of model names to compare - <code>include_coefficients</code> (bool): Include coefficient comparison - <code>include_statistics</code> (bool): Include fit statistics</p> <p>Returns: ComparisonResult object</p> <p>Example: <pre><code>comparison = experiment.compare_models(['ols', 'fe', 're'])\nbest = comparison.best_model('rsquared_adj', prefer_lower=False)\nprint(f\"Best model: {best}\")\n</code></pre></p>"},{"location":"api/report/#analyze_residualsname","title":"analyze_residuals(name)","text":"<p>Analyze residuals from a fitted model.</p> <p>Parameters: - <code>name</code> (str): Name of fitted model</p> <p>Returns: ResidualResult object</p>"},{"location":"api/report/#save_master_reportfile_path-themeprofessional-titlenone-reportsnone","title":"save_master_report(file_path, theme='professional', title=None, reports=None)","text":"<p>Generate master HTML report with navigation to all sub-reports.</p> <p>Parameters: - <code>file_path</code> (str): Output file path - <code>theme</code> (str): Visual theme ('professional', 'academic', 'presentation') - <code>title</code> (str, optional): Custom report title - <code>reports</code> (list, optional): List of sub-report configurations</p> <p>Returns: str (file path)</p> <p>Example: <pre><code>experiment.save_master_report('master.html', theme='professional', reports=[\n    {'type': 'validation', 'title': 'Validation', 'description': 'Tests', 'file_path': 'val.html'},\n    {'type': 'comparison', 'title': 'Comparison', 'description': 'Models', 'file_path': 'comp.html'},\n    {'type': 'residuals', 'title': 'Residuals', 'description': 'Diagnostics', 'file_path': 'res.html'}\n])\n</code></pre></p>"},{"location":"api/report/#validationtest-new-in-v080","title":"ValidationTest (NEW in v0.8.0)","text":"<p>Test runner for model validation with configurable presets.</p>"},{"location":"api/report/#overview_1","title":"Overview","text":"<p><code>ValidationTest</code> provides three preset configurations: - quick: Fast validation (heteroskedasticity, autocorrelation) - basic: Standard validation (adds normality test) - full: Comprehensive validation (adds Hausman test)</p>"},{"location":"api/report/#usage_1","title":"Usage","text":"<pre><code>from panelbox.experiment.tests import ValidationTest\n\nrunner = ValidationTest()\n\n# Run with preset\nvalidation_result = runner.run(results, config='full')\n\n# Run with custom tests\nvalidation_result = runner.run(results, tests=['heteroskedasticity', 'normality'])\n</code></pre>"},{"location":"api/report/#available-configs","title":"Available Configs","text":"<pre><code>runner.CONFIGS = {\n    'quick': ['heteroskedasticity', 'autocorrelation'],\n    'basic': ['heteroskedasticity', 'autocorrelation', 'normality'],\n    'full': ['heteroskedasticity', 'autocorrelation', 'normality', 'hausman']\n}\n</code></pre>"},{"location":"api/report/#comparisontest-new-in-v080","title":"ComparisonTest (NEW in v0.8.0)","text":"<p>Test runner for comparing multiple models.</p>"},{"location":"api/report/#usage_2","title":"Usage","text":"<pre><code>from panelbox.experiment.tests import ComparisonTest\n\nrunner = ComparisonTest()\n\n# Compare models\nmodels = {\n    'ols': ols_results,\n    'fe': fe_results,\n    're': re_results\n}\n\ncomparison_result = runner.run(models)\n</code></pre>"},{"location":"api/report/#result-containers","title":"Result Containers","text":""},{"location":"api/report/#validationresult-new-in-v080","title":"ValidationResult (NEW in v0.8.0)","text":"<p>Container for validation test results.</p> <p>Methods: - <code>save_html(file_path, test_type='validation', theme='professional')</code>: Generate HTML report - <code>save_json(file_path)</code>: Export to JSON - <code>summary()</code>: Get text summary</p> <p>Example: <pre><code>validation = experiment.validate_model('fe')\nvalidation.save_html('validation.html', test_type='validation', theme='professional')\nprint(validation.summary())\n</code></pre></p>"},{"location":"api/report/#comparisonresult-new-in-v080","title":"ComparisonResult (NEW in v0.8.0)","text":"<p>Container for model comparison results.</p> <p>Methods: - <code>save_html(file_path, test_type='comparison', theme='professional')</code>: Generate HTML report - <code>save_json(file_path)</code>: Export to JSON - <code>summary()</code>: Get text summary - <code>best_model(metric, prefer_lower=True)</code>: Identify best model</p> <p>Example: <pre><code>comparison = experiment.compare_models(['ols', 'fe', 're'])\nbest = comparison.best_model('aic', prefer_lower=True)\ncomparison.save_html('comparison.html', test_type='comparison')\n</code></pre></p>"},{"location":"api/report/#residualresult-new-in-v070","title":"ResidualResult (NEW in v0.7.0)","text":"<p>Container for residual diagnostics.</p> <p>Methods: - <code>save_html(file_path, test_type='residuals', theme='professional')</code>: Generate HTML report - <code>save_json(file_path)</code>: Export to JSON - <code>summary()</code>: Get text summary</p> <p>Properties: - <code>shapiro_test</code>: Shapiro-Wilk normality test - <code>durbin_watson</code>: Durbin-Watson autocorrelation test - <code>jarque_bera</code>: Jarque-Bera normality test - <code>ljung_box</code>: Ljung-Box serial correlation test</p>"},{"location":"api/report/#themes","title":"Themes","text":"<p>PanelBox provides three professional themes for HTML reports:</p>"},{"location":"api/report/#professional-default","title":"Professional (Default)","text":"<ul> <li>Color: Blue (#2563eb)</li> <li>Use Case: Corporate reports, general analysis</li> <li>Style: Clean, modern, professional</li> </ul>"},{"location":"api/report/#academic","title":"Academic","text":"<ul> <li>Color: Gray (#4b5563)</li> <li>Use Case: Research papers, academic publications</li> <li>Style: Conservative, publication-ready</li> </ul>"},{"location":"api/report/#presentation","title":"Presentation","text":"<ul> <li>Color: Purple (#7c3aed)</li> <li>Use Case: Presentations, slides, demos</li> <li>Style: Bold, eye-catching</li> </ul> <p>Example: <pre><code># Try different themes\nvalidation.save_html('val_pro.html', theme='professional')\nvalidation.save_html('val_academic.html', theme='academic')\nvalidation.save_html('val_presentation.html', theme='presentation')\n</code></pre></p>"},{"location":"api/report/#summary-tables","title":"Summary Tables","text":""},{"location":"api/report/#summary-method","title":"summary Method","text":"<p>Generate formatted summary table of estimation results.</p> <p>Usage:</p> <pre><code>results = model.fit()\n\n# Print summary\nprint(results.summary())\n\n# Get as string\nsummary_str = str(results.summary())\n</code></pre> <p>Available via:</p>"},{"location":"api/report/#panelbox.core.results.PanelResults.summary","title":"panelbox.core.results.PanelResults.summary","text":"<pre><code>summary(title: Optional[str] = None) -&gt; str\n</code></pre> <p>Generate formatted summary table of estimation results.</p> <p>Produces a comprehensive summary table including model information, sample statistics, goodness-of-fit measures, coefficient estimates, standard errors, test statistics, and diagnostic tests.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Custom title for the summary table. If None, defaults to \"{model_type} Estimation Results\".</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted summary table as a multi-line string, suitable for printing to console or including in reports.</p> Notes <p>Summary Structure:</p> <p>The summary table includes the following sections:</p> <ol> <li>Header: Model type and title</li> <li>Model Information: Formula, estimation method</li> <li>Sample Statistics: Number of observations, entities, time periods</li> <li>Goodness-of-Fit: R-squared (within/between/overall), F-statistic</li> <li>Coefficients Table: Estimates, standard errors, t/z-statistics, p-values</li> <li>Confidence Intervals: 95% confidence intervals (default)</li> <li>Diagnostic Tests (if applicable): Hansen J, AR tests, Hausman test</li> </ol> <p>For GMM Models:</p> <p>Additional diagnostics included: - Hansen J test statistic and p-value - Sargan test statistic and p-value - AR(1) and AR(2) test statistics and p-values - Number of instruments and instrument ratio</p> <p>Output Format:</p> <p>The output is formatted for 78-character width terminals and includes: - Aligned columns for easy reading - Separators between sections - Significance stars (, *, ***) for p-values &lt; 0.10, 0.05, 0.01</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; data = pb.load_grunfeld()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Fixed Effects example\n&gt;&gt;&gt; fe = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results = fe.fit()\n&gt;&gt;&gt; print(results.summary())\n================================================================================\n                      Fixed Effects Estimation Results\n================================================================================\nFormula: invest ~ value + capital\nModel:   Fixed Effects\n...\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom title\n&gt;&gt;&gt; print(results.summary(title=\"Investment Regression Results\"))\n================================================================================\n                    Investment Regression Results\n================================================================================\n...\n</code></pre> <pre><code>&gt;&gt;&gt; # GMM example with diagnostics\n&gt;&gt;&gt; gmm = pb.SystemGMM(data, 'invest', lags=1, exog_vars=['value', 'capital'],\n...                    id_var='firm', time_var='year', collapse=True)\n&gt;&gt;&gt; gmm_results = gmm.fit()\n&gt;&gt;&gt; print(gmm_results.summary())\n================================================================================\n                       System GMM Estimation Results\n================================================================================\n...\nHansen J statistic:        12.45\nHansen J p-value:          0.189\nAR(2) p-value:             0.356\n...\n</code></pre> See Also <p>to_latex : Export results to LaTeX format params : Coefficient estimates std_errors : Standard errors pvalues : P-values for coefficients conf_int : Confidence intervals</p> References <p>.. [1] Wooldridge, J. M. (2010). Econometric Analysis of Cross Section        and Panel Data (2<sup>nd</sup> ed.). MIT Press.</p>"},{"location":"api/report/#model-comparison","title":"Model Comparison","text":""},{"location":"api/report/#compare-multiple-models","title":"Compare Multiple Models","text":"<p>Compare results from multiple models side-by-side.</p> <p>Usage:</p> <pre><code>import pandas as pd\n\n# Estimate models\npooled = pb.PooledOLS(...).fit()\nfe = pb.FixedEffects(...).fit()\nre = pb.RandomEffects(...).fit()\n\n# Compare coefficients\ncomparison = pd.DataFrame({\n    'Pooled OLS': pooled.params,\n    'Fixed Effects': fe.params,\n    'Random Effects': re.params\n})\n\nprint(comparison)\n\n# Compare standard errors\nse_comparison = pd.DataFrame({\n    'Pooled OLS': pooled.std_errors,\n    'Fixed Effects': fe.std_errors,\n    'Random Effects': re.std_errors\n})\n\nprint(se_comparison)\n</code></pre>"},{"location":"api/report/#export-examples","title":"Export Examples","text":""},{"location":"api/report/#example-side-by-side-model-comparison","title":"Example: Side-by-Side Model Comparison","text":"<pre><code># Estimate multiple models\nmodels = {\n    'Difference GMM': pb.DifferenceGMM(...).fit(),\n    'System GMM': pb.SystemGMM(...).fit()\n}\n\n# Create comparison table\ncomparison = pd.DataFrame({\n    name: res.params for name, res in models.items()\n})\n\n# Add standard errors row\nfor name, res in models.items():\n    comparison[f\"{name} (SE)\"] = res.std_errors\n\n# Export to LaTeX manually\nwith open(\"comparison.tex\", \"w\") as f:\n    f.write(comparison.to_latex(float_format=\"%.3f\"))\n</code></pre>"},{"location":"api/results/","title":"Results API","text":"<p>API documentation for the PanelResults class and related functionality.</p>"},{"location":"api/results/#panelresults","title":"PanelResults","text":""},{"location":"api/results/#panelbox.core.results.PanelResults","title":"panelbox.core.results.PanelResults","text":"<pre><code>PanelResults(params: Series, std_errors: Series, cov_params: DataFrame, resid: ndarray, fittedvalues: ndarray, model_info: Dict[str, Any], data_info: Dict[str, Any], rsquared_dict: Optional[Dict[str, float]] = None, model: Optional[Any] = None)\n</code></pre> <p>Container for panel model estimation results.</p> <p>This class stores all estimation results and provides methods for inference, testing, prediction, and reporting.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Series</code> <p>Estimated coefficients</p> required <code>std_errors</code> <code>Series</code> <p>Standard errors</p> required <code>cov_params</code> <code>DataFrame</code> <p>Covariance matrix of parameters</p> required <code>resid</code> <code>ndarray</code> <p>Residuals</p> required <code>fittedvalues</code> <code>ndarray</code> <p>Fitted values</p> required <code>model_info</code> <code>dict</code> <p>Dictionary with model information</p> required <code>data_info</code> <code>dict</code> <p>Dictionary with data information</p> required <p>Attributes:</p> Name Type Description <code>params</code> <code>Series</code> <p>Estimated coefficients with parameter names</p> <code>std_errors</code> <code>Series</code> <p>Standard errors</p> <code>tvalues</code> <code>Series</code> <p>t-statistics</p> <code>pvalues</code> <code>Series</code> <p>p-values for two-sided t-tests</p> <code>cov_params</code> <code>DataFrame</code> <p>Covariance matrix of parameters</p> <code>resid</code> <code>ndarray</code> <p>Residuals</p> <code>fittedvalues</code> <code>ndarray</code> <p>Fitted values</p> <code>nobs</code> <code>int</code> <p>Number of observations</p> <code>n_entities</code> <code>int</code> <p>Number of entities</p> <code>n_periods</code> <code>int</code> <p>Number of time periods</p> <code>df_model</code> <code>int</code> <p>Degrees of freedom for model</p> <code>df_resid</code> <code>int</code> <p>Degrees of freedom for residuals</p> <code>rsquared</code> <code>float</code> <p>R-squared</p> <code>rsquared_adj</code> <code>float</code> <p>Adjusted R-squared</p> <code>rsquared_within</code> <code>float</code> <p>Within R-squared (for panel models)</p> <code>rsquared_between</code> <code>float</code> <p>Between R-squared (for panel models)</p> <code>rsquared_overall</code> <code>float</code> <p>Overall R-squared (for panel models)</p>"},{"location":"api/results/#panelbox.core.results.PanelResults-attributes","title":"Attributes","text":""},{"location":"api/results/#panelbox.core.results.PanelResults.params","title":"params  <code>instance-attribute</code>","text":"<pre><code>params = params\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.std_errors","title":"std_errors  <code>instance-attribute</code>","text":"<pre><code>std_errors = std_errors\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.pvalues","title":"pvalues  <code>instance-attribute</code>","text":"<pre><code>pvalues = Series(pvalues_array, index=index)\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.rsquared","title":"rsquared  <code>instance-attribute</code>","text":"<pre><code>rsquared = get('rsquared', nan)\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.rsquared_within","title":"rsquared_within  <code>instance-attribute</code>","text":"<pre><code>rsquared_within = get('rsquared_within', nan)\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.rsquared_between","title":"rsquared_between  <code>instance-attribute</code>","text":"<pre><code>rsquared_between = get('rsquared_between', nan)\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.rsquared_overall","title":"rsquared_overall  <code>instance-attribute</code>","text":"<pre><code>rsquared_overall = get('rsquared_overall', nan)\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.rsquared_adj","title":"rsquared_adj  <code>instance-attribute</code>","text":"<pre><code>rsquared_adj = get('rsquared_adj', nan)\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.nobs","title":"nobs  <code>instance-attribute</code>","text":"<pre><code>nobs = data_info['nobs']\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.n_entities","title":"n_entities  <code>instance-attribute</code>","text":"<pre><code>n_entities = data_info['n_entities']\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.n_periods","title":"n_periods  <code>instance-attribute</code>","text":"<pre><code>n_periods = get('n_periods', None)\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.df_model","title":"df_model  <code>instance-attribute</code>","text":"<pre><code>df_model = data_info['df_model']\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.df_resid","title":"df_resid  <code>instance-attribute</code>","text":"<pre><code>df_resid = data_info['df_resid']\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults-functions","title":"Functions","text":""},{"location":"api/results/#panelbox.core.results.PanelResults.conf_int","title":"conf_int","text":"<pre><code>conf_int(alpha: float = 0.05) -&gt; pd.DataFrame\n</code></pre> <p>Compute confidence intervals for parameters.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level (e.g., 0.05 for 95% CI)</p> <code>0.05</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Confidence intervals with columns 'lower' and 'upper'</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ci = results.conf_int(alpha=0.05)\n&gt;&gt;&gt; print(ci)\n</code></pre>"},{"location":"api/results/#panelbox.core.results.PanelResults.summary","title":"summary","text":"<pre><code>summary(title: Optional[str] = None) -&gt; str\n</code></pre> <p>Generate formatted summary table of estimation results.</p> <p>Produces a comprehensive summary table including model information, sample statistics, goodness-of-fit measures, coefficient estimates, standard errors, test statistics, and diagnostic tests.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Custom title for the summary table. If None, defaults to \"{model_type} Estimation Results\".</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted summary table as a multi-line string, suitable for printing to console or including in reports.</p> Notes <p>Summary Structure:</p> <p>The summary table includes the following sections:</p> <ol> <li>Header: Model type and title</li> <li>Model Information: Formula, estimation method</li> <li>Sample Statistics: Number of observations, entities, time periods</li> <li>Goodness-of-Fit: R-squared (within/between/overall), F-statistic</li> <li>Coefficients Table: Estimates, standard errors, t/z-statistics, p-values</li> <li>Confidence Intervals: 95% confidence intervals (default)</li> <li>Diagnostic Tests (if applicable): Hansen J, AR tests, Hausman test</li> </ol> <p>For GMM Models:</p> <p>Additional diagnostics included: - Hansen J test statistic and p-value - Sargan test statistic and p-value - AR(1) and AR(2) test statistics and p-values - Number of instruments and instrument ratio</p> <p>Output Format:</p> <p>The output is formatted for 78-character width terminals and includes: - Aligned columns for easy reading - Separators between sections - Significance stars (, *, ***) for p-values &lt; 0.10, 0.05, 0.01</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt; data = pb.load_grunfeld()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Fixed Effects example\n&gt;&gt;&gt; fe = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\n&gt;&gt;&gt; results = fe.fit()\n&gt;&gt;&gt; print(results.summary())\n================================================================================\n                      Fixed Effects Estimation Results\n================================================================================\nFormula: invest ~ value + capital\nModel:   Fixed Effects\n...\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom title\n&gt;&gt;&gt; print(results.summary(title=\"Investment Regression Results\"))\n================================================================================\n                    Investment Regression Results\n================================================================================\n...\n</code></pre> <pre><code>&gt;&gt;&gt; # GMM example with diagnostics\n&gt;&gt;&gt; gmm = pb.SystemGMM(data, 'invest', lags=1, exog_vars=['value', 'capital'],\n...                    id_var='firm', time_var='year', collapse=True)\n&gt;&gt;&gt; gmm_results = gmm.fit()\n&gt;&gt;&gt; print(gmm_results.summary())\n================================================================================\n                       System GMM Estimation Results\n================================================================================\n...\nHansen J statistic:        12.45\nHansen J p-value:          0.189\nAR(2) p-value:             0.356\n...\n</code></pre> See Also <p>to_latex : Export results to LaTeX format params : Coefficient estimates std_errors : Standard errors pvalues : P-values for coefficients conf_int : Confidence intervals</p> References <p>.. [1] Wooldridge, J. M. (2010). Econometric Analysis of Cross Section        and Panel Data (2<sup>nd</sup> ed.). MIT Press.</p>"},{"location":"api/validation/","title":"Validation Tests API","text":"<p>API documentation for diagnostic and specification tests.</p>"},{"location":"api/validation/#specification-tests","title":"Specification Tests","text":""},{"location":"api/validation/#hausmantest","title":"HausmanTest","text":""},{"location":"api/validation/#panelbox.validation.specification.hausman.HausmanTest","title":"panelbox.validation.specification.hausman.HausmanTest","text":"<pre><code>HausmanTest(fe_results: PanelResults, re_results: PanelResults)\n</code></pre> <pre><code>Hausman specification test for panel data.\n\nTests the null hypothesis that the Random Effects estimator is consistent\n(and efficient) against the alternative that it is inconsistent.\n\nThe test compares Fixed Effects (always consistent under standard assumptions)\nwith Random Effects (consistent only if E[u_i | X_it] = 0).\n</code></pre> <pre><code>Parameters\n</code></pre> <pre><code>fe_results : PanelResults\n    Results from Fixed Effects estimation\nre_results : PanelResults\n    Results from Random Effects estimation\n</code></pre> <pre><code>Notes\n</code></pre> <pre><code>**Theoretical Foundation:**\n\nThe Hausman test is based on the principle that under the null hypothesis\n(no correlation between regressors and individual effects), both FE and RE\nare consistent, but RE is more efficient. Under the alternative (correlation\nexists), FE remains consistent while RE becomes inconsistent.\n\n**Test Statistic:**\n\nThe Hausman statistic is computed as:\n\n    H = (\u03b2\u0302_FE - \u03b2\u0302_RE)' [Var(\u03b2\u0302_FE) - Var(\u03b2\u0302_RE)]^{-1} (\u03b2\u0302_FE - \u03b2\u0302_RE)\n\nUnder H0, this follows \u03c7\u00b2(k) where k is the number of coefficients tested.\n\n**Hypotheses:**\n\n- H0: Cov(X_it, \u03b1_i) = 0 \u2192 Random Effects is consistent and efficient\n- H1: Cov(X_it, \u03b1_i) \u2260 0 \u2192 Random Effects is inconsistent, use Fixed Effects\n\n**Decision Rule:**\n\n- **Reject H0** (p-value &lt; \u03b1): Use Fixed Effects\n  - Evidence of correlation between X and \u03b1_i\n  - RE estimates are biased and inconsistent\n  - FE estimates are consistent (albeit less efficient)\n\n- **Fail to reject H0** (p-value \u2265 \u03b1): Use Random Effects\n  - No evidence of correlation between X and \u03b1_i\n  - RE estimates are consistent and efficient\n  - Gain efficiency over FE, especially with time-invariant regressors\n\n**Interpretation Guidelines:**\n\n| P-value | Decision | Interpretation |\n|---------|----------|----------------|\n| &lt; 0.01  | Strong rejection | Strong evidence for FE |\n| 0.01-0.05 | Rejection | Moderate evidence for FE |\n| 0.05-0.10 | Borderline | Consider robustness checks |\n| &gt; 0.10  | Fail to reject | Use RE for efficiency |\n\n**Common Issues:**\n\n1. **Negative test statistic**: Can occur due to:\n   - Small sample sizes\n   - Weak instruments in RE estimation\n   - Solution: Use generalized inverse (automatically handled)\n\n2. **Large differences in coefficients**: Suggests:\n   - Strong correlation between X and \u03b1_i\n   - FE and RE model different relationships\n   - Decision clear: use FE\n\n3. **Small differences but significant test**: Can indicate:\n   - Large sample size detecting small deviations\n   - Consider economic significance, not just statistical\n\n**Practical Considerations:**\n\n- Always estimate both FE and RE before testing\n- Examine coefficient differences, not just test statistic\n- Consider theory: does correlation make sense?\n- RE allows time-invariant regressors; FE does not\n- For GMM models, use Hansen/Sargan tests instead\n</code></pre> <pre><code>References\n</code></pre> <pre><code>.. [1] Hausman, J. A. (1978). \"Specification tests in econometrics.\"\n       *Econometrica*, 46(6), 1251-1271.\n\n.. [2] Wooldridge, J. M. (2010). \"Econometric Analysis of Cross Section\n       and Panel Data\" (2nd ed.). MIT Press. Chapter 10.\n\n.. [3] Baltagi, B. H. (2021). \"Econometric Analysis of Panel Data\"\n       (6th ed.). Springer. Chapter 4.\n</code></pre> <pre><code>See Also\n</code></pre> <pre><code>FixedEffects : Fixed Effects estimator (within transformation)\nRandomEffects : Random Effects estimator (GLS)\nMundlakTest : Alternative specification test including time-averages\n</code></pre> <pre><code>Examples\n</code></pre> <pre><code>**Basic usage:**\n\n&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate both models\n&gt;&gt;&gt; fe = pb.FixedEffects(data, \"y\", [\"x1\", \"x2\"], \"firm\", \"year\")\n&gt;&gt;&gt; fe_results = fe.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; re = pb.RandomEffects(data, \"y\", [\"x1\", \"x2\"], \"firm\", \"year\")\n&gt;&gt;&gt; re_results = re.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Run Hausman test\n&gt;&gt;&gt; hausman = pb.HausmanTest(fe_results, re_results)\n&gt;&gt;&gt; result = hausman.run()\n&gt;&gt;&gt; print(result)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use recommendation\n&gt;&gt;&gt; if result.recommendation == \"Fixed Effects\":\n...     final_results = fe_results\n&gt;&gt;&gt; else:\n...     final_results = re_results\n\n**Interpreting results:**\n\n&gt;&gt;&gt; # Examine test statistic and p-value\n&gt;&gt;&gt; print(f\"Chi2 statistic: {result.statistic:.3f}\")\n&gt;&gt;&gt; print(f\"P-value: {result.pvalue:.4f}\")\n&gt;&gt;&gt; print(f\"Degrees of freedom: {result.df}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check coefficient differences\n&gt;&gt;&gt; print(\"\n</code></pre> <p>Coefficient Comparison:\")     &gt;&gt;&gt; for var in result.fe_params.index:     ...     diff_pct = 100 * result.diff[var] / result.fe_params[var]     ...     print(f\"{var}: {diff_pct:.1f}% difference\")</p> <pre><code>**Different significance levels:**\n\n&gt;&gt;&gt; # Test at 1% level for more stringent requirement\n&gt;&gt;&gt; result_strict = hausman.run(alpha=0.01)\n&gt;&gt;&gt; print(result_strict.conclusion)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Test at 10% level for more lenient requirement\n&gt;&gt;&gt; result_lenient = hausman.run(alpha=0.10)\n&gt;&gt;&gt; print(result_lenient.conclusion)\n</code></pre>"},{"location":"api/validation/#panelbox.validation.specification.hausman.HausmanTest-functions","title":"Functions","text":""},{"location":"api/validation/#panelbox.validation.specification.hausman.HausmanTest.run","title":"run","text":"<pre><code>run(alpha: float = 0.05) -&gt; HausmanTestResult\n</code></pre> <p>Run the Hausman test.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level for test</p> <code>0.05</code> <p>Returns:</p> Type Description <code>HausmanTestResult</code> <p>Test results</p> Notes <p>The Hausman test statistic is:</p> <pre><code>H = (b_FE - b_RE)' [Var(b_FE) - Var(b_RE)]^{-1} (b_FE - b_RE)\n</code></pre> <p>which follows a chi-squared distribution with K degrees of freedom, where K is the number of coefficients being tested.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; result = hausman.run(alpha=0.05)\n&gt;&gt;&gt; print(f\"Chi2 statistic: {result.statistic:.3f}\")\n&gt;&gt;&gt; print(f\"P-value: {result.pvalue:.4f}\")\n&gt;&gt;&gt; print(f\"Recommendation: {result.recommendation}\")\n</code></pre>"},{"location":"api/validation/#serial-correlation-tests","title":"Serial Correlation Tests","text":""},{"location":"api/validation/#wooldridgeartest","title":"WooldridgeARTest","text":""},{"location":"api/validation/#panelbox.validation.serial_correlation.wooldridge_ar.WooldridgeARTest","title":"panelbox.validation.serial_correlation.wooldridge_ar.WooldridgeARTest","text":"<pre><code>WooldridgeARTest(results: 'PanelResults')\n</code></pre> <p>               Bases: <code>ValidationTest</code></p> <p>Wooldridge test for first-order autocorrelation in panel data.</p> <p>This test is specifically designed for fixed effects models and tests for AR(1) autocorrelation in the idiosyncratic errors.</p> <p>The test is based on regressing the first-differenced residuals on their own lag and testing if the coefficient equals -0.5 (which is the value under H0 of no serial correlation).</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>PanelResults</code> <p>Results from panel model estimation (preferably Fixed Effects)</p> required Notes <p>Test Procedure:</p> <p>The Wooldridge test implements the following steps:</p> <ol> <li> <p>Compute first differences of residuals:</p> <p>\u0394e_it = e_it - e_{i,t-1}</p> </li> <li> <p>Regress \u0394e_it on \u0394e_{i,t-1}:</p> <p>\u0394e_it = \u03b2 \u00b7 \u0394e_{i,t-1} + \u03bd_it</p> </li> <li> <p>Test H0: \u03b2 = -0.5</p> </li> </ol> <p>Under the null hypothesis of no serial correlation:</p> <pre><code>Cov(\u0394e_it, \u0394e_{i,t-1}) = E[(e_it - e_{i,t-1})(e_{i,t-1} - e_{i,t-2})]\n                        = -\u03c3\u00b2_e\n</code></pre> <p>And since Var(\u0394e_it) \u2248 2\u03c3\u00b2_e, we expect \u03b2 \u2248 -0.5.</p> <p>Test Statistic:</p> <p>The F-statistic is computed as:</p> <pre><code>F = [(\u03b2\u0302 + 0.5) / SE(\u03b2\u0302)]\u00b2  ~  F(1, N-1)\n</code></pre> <p>where N is the number of entities.</p> <p>When to Use:</p> <p>This test is particularly useful for:</p> <ul> <li>Fixed Effects models: Designed specifically for FE estimation</li> <li>GMM model validation: Testing AR(1) assumption before GMM</li> <li>Dynamic panels: Checking for residual autocorrelation after   including lagged dependent variable</li> <li>Pre-testing: Before using cluster-robust standard errors</li> </ul> <p>Advantages:</p> <ul> <li>Simple to implement and interpret</li> <li>Does not require strong distributional assumptions</li> <li>Robust to heteroskedasticity</li> <li>Works with unbalanced panels (requires T \u2265 3 for each entity)</li> </ul> <p>Limitations:</p> <ol> <li>Only tests AR(1): Does not detect higher-order autocorrelation</li> <li>Minimum T requirement: Needs T \u2265 3 per entity</li> <li>FE-specific: Less powerful for other estimators</li> <li>Small N issues: F-distribution approximation may be poor with few entities</li> </ol> <p>Interpretation:</p> P-value Decision Interpretation &lt; 0.01 Strong rejection Strong AR(1) autocorrelation 0.01-0.05 Rejection Moderate autocorrelation 0.05-0.10 Borderline Consider robust SEs &gt; 0.10 Fail to reject No evidence of AR(1) <p>If Autocorrelation is Detected:</p> <ul> <li>Use cluster-robust standard errors (cluster by entity)</li> <li>Use Driscoll-Kraay standard errors (robust to both serial   correlation and cross-sectional dependence)</li> <li>Consider AR(1) error structure in GLS estimation</li> <li>For dynamic models, use GMM estimators (System GMM)</li> </ul> <p>Comparison with Stata:</p> <p>This test is equivalent to Stata's <code>xtserial</code> command:</p> <pre><code>xtreg y x1 x2, fe\nxtserial y x1 x2\n</code></pre> References <p>.. [1] Wooldridge, J. M. (2002). \"Econometric Analysis of Cross Section        and Panel Data.\" MIT Press, Section 10.4.1.</p> <p>.. [2] Drukker, D. M. (2003). \"Testing for serial correlation in linear        panel-data models.\" Stata Journal, 3(2), 168-177.</p> <p>.. [3] Wooldridge, J. M. (2010). \"Econometric Analysis of Cross Section        and Panel Data\" (2<sup>nd</sup> ed.). MIT Press, Chapter 10.</p> See Also <p>BaltagiWuTest : Alternative test for serial correlation in panel data BreuschGodfreyTest : Lagrange Multiplier test for serial correlation</p> <p>Examples:</p> <p>Basic usage with Fixed Effects:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate Fixed Effects model\n&gt;&gt;&gt; fe = pb.FixedEffects(data, \"y\", [\"x1\", \"x2\"], \"firm\", \"year\")\n&gt;&gt;&gt; results = fe.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Test for autocorrelation\n&gt;&gt;&gt; from panelbox.validation.serial_correlation import WooldridgeARTest\n&gt;&gt;&gt; test = WooldridgeARTest(results)\n&gt;&gt;&gt; result = test.run()\n&gt;&gt;&gt; print(result)\n</code></pre> <p>Interpreting results:</p> <pre><code>&gt;&gt;&gt; print(f\"F-statistic: {result.statistic:.3f}\")\n&gt;&gt;&gt; print(f\"P-value: {result.pvalue:.4f}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; if result.pvalue &lt; 0.05:\n...     print(\"Evidence of AR(1) autocorrelation\")\n...     print(\"Consider using cluster-robust standard errors\")\n&gt;&gt;&gt; else:\n...     print(\"No evidence of autocorrelation\")\n</code></pre> <p>Accessing additional information:</p> <pre><code>&gt;&gt;&gt; # Estimated coefficient and its standard error\n&gt;&gt;&gt; print(f\"\u03b2\u0302 = {result.metadata['coefficient']:.4f}\")\n&gt;&gt;&gt; print(f\"SE(\u03b2\u0302) = {result.metadata['std_error']:.4f}\")\n&gt;&gt;&gt; print(f\"Expected under H0: \u03b2 = -0.5\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Sample information\n&gt;&gt;&gt; print(f\"Number of entities: {result.metadata['n_entities']}\")\n&gt;&gt;&gt; print(f\"Observations used: {result.metadata['n_obs_used']}\")\n</code></pre> <p>Different significance level:</p> <pre><code>&gt;&gt;&gt; # Test at 1% level\n&gt;&gt;&gt; result_strict = test.run(alpha=0.01)\n&gt;&gt;&gt; print(result_strict.conclusion)\n</code></pre> <p>Initialize Wooldridge AR test.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>PanelResults</code> <p>Results from panel model estimation (preferably Fixed Effects)</p> required"},{"location":"api/validation/#panelbox.validation.serial_correlation.wooldridge_ar.WooldridgeARTest-functions","title":"Functions","text":""},{"location":"api/validation/#panelbox.validation.serial_correlation.wooldridge_ar.WooldridgeARTest.run","title":"run","text":"<pre><code>run(alpha: float = 0.05, **kwargs) -&gt; ValidationTestResult\n</code></pre> <p>Run Wooldridge test for AR(1) autocorrelation.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level</p> <code>0.05</code> <p>Returns:</p> Type Description <code>ValidationTestResult</code> <p>Test results</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If panel has fewer than 3 time periods</p>"},{"location":"api/validation/#heteroskedasticity-tests","title":"Heteroskedasticity Tests","text":""},{"location":"api/validation/#breuschpagantest","title":"BreuschPaganTest","text":""},{"location":"api/validation/#panelbox.validation.heteroskedasticity.breusch_pagan.BreuschPaganTest","title":"panelbox.validation.heteroskedasticity.breusch_pagan.BreuschPaganTest","text":"<pre><code>BreuschPaganTest(results: 'PanelResults')\n</code></pre> <p>               Bases: <code>ValidationTest</code></p> <p>Breusch-Pagan LM test for heteroskedasticity.</p> <p>Tests the null hypothesis that the error variance is constant (homoskedasticity) against the alternative that the variance is a function of the regressors.</p> <p>H0: sigma\u00b2_i = sigma\u00b2 (homoskedasticity) H1: sigma\u00b2_i = h(X_i) (heteroskedasticity)</p> <p>The test regresses squared residuals on the original regressors and tests if the coefficients are jointly zero using an LM statistic.</p> Notes <p>The test statistic is n*R\u00b2 from the auxiliary regression, which follows a chi-squared distribution with k degrees of freedom under the null hypothesis, where k is the number of regressors (excluding the constant).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from panelbox.models.static.pooled_ols import PooledOLS\n&gt;&gt;&gt; model = PooledOLS(\"y ~ x1 + x2\", data, \"entity\", \"time\")\n&gt;&gt;&gt; results = model.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; from panelbox.validation.heteroskedasticity.breusch_pagan import BreuschPaganTest\n&gt;&gt;&gt; test = BreuschPaganTest(results)\n&gt;&gt;&gt; result = test.run()\n&gt;&gt;&gt; print(result)\n</code></pre> <p>Initialize Breusch-Pagan test.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>PanelResults</code> <p>Results from panel model estimation</p> required"},{"location":"api/validation/#panelbox.validation.heteroskedasticity.breusch_pagan.BreuschPaganTest-functions","title":"Functions","text":""},{"location":"api/validation/#panelbox.validation.heteroskedasticity.breusch_pagan.BreuschPaganTest.run","title":"run","text":"<pre><code>run(alpha: float = 0.05, **kwargs) -&gt; ValidationTestResult\n</code></pre> <p>Run Breusch-Pagan LM test for heteroskedasticity.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level</p> <code>0.05</code> <p>Returns:</p> Type Description <code>ValidationTestResult</code> <p>Test results</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If design matrix is not available</p> Notes <p>The test procedure: 1. Estimate the original model and obtain residuals e 2. Compute squared residuals e\u00b2 3. Regress e\u00b2 on the original regressors X 4. Compute LM statistic = n*R\u00b2 from this auxiliary regression 5. Compare to chi-squared(k) distribution</p>"},{"location":"api/validation/#cross-sectional-dependence-tests","title":"Cross-Sectional Dependence Tests","text":""},{"location":"api/validation/#breuschpaganlmtest","title":"BreuschPaganLMTest","text":""},{"location":"api/validation/#panelbox.validation.cross_sectional_dependence.breusch_pagan_lm.BreuschPaganLMTest","title":"panelbox.validation.cross_sectional_dependence.breusch_pagan_lm.BreuschPaganLMTest","text":"<pre><code>BreuschPaganLMTest(results: 'PanelResults')\n</code></pre> <p>               Bases: <code>ValidationTest</code></p> <p>Breusch-Pagan LM test for cross-sectional dependence.</p> <p>Tests the null hypothesis that residuals are cross-sectionally independent (no contemporaneous correlation across entities).</p> <p>H0: Corr(e_it, e_jt) = 0 for all i \u2260 j H1: Some Corr(e_it, e_jt) \u2260 0</p> <p>The test is based on the sum of squared pairwise correlation coefficients of residuals.</p> Notes <p>The test statistic is:</p> <p>LM = T * sum_{i&lt;j} rho_ij\u00b2</p> <p>where rho_ij is the sample correlation between residuals of entity i and entity j, and the sum is over all N(N-1)/2 pairs.</p> <p>Under H0, LM ~ Chi2(N(N-1)/2)</p> <p>This test is appropriate for panels with: - Fixed T (time periods) - N not too large (becomes over-sized as N \u2192 \u221e) - For large N, use Pesaran CD test instead</p> <p>The test requires a balanced panel or will use pairwise complete observations for each entity pair.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from panelbox.models.static.pooled_ols import PooledOLS\n&gt;&gt;&gt; model = PooledOLS(\"y ~ x1 + x2\", data, \"entity\", \"time\")\n&gt;&gt;&gt; results = model.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; from panelbox.validation.cross_sectional_dependence.breusch_pagan_lm import BreuschPaganLMTest\n&gt;&gt;&gt; test = BreuschPaganLMTest(results)\n&gt;&gt;&gt; result = test.run()\n&gt;&gt;&gt; print(result)\n</code></pre> <p>Initialize Breusch-Pagan LM test.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>PanelResults</code> <p>Results from panel model estimation</p> required"},{"location":"api/validation/#panelbox.validation.cross_sectional_dependence.breusch_pagan_lm.BreuschPaganLMTest-functions","title":"Functions","text":""},{"location":"api/validation/#panelbox.validation.cross_sectional_dependence.breusch_pagan_lm.BreuschPaganLMTest.run","title":"run","text":"<pre><code>run(alpha: float = 0.05, **kwargs) -&gt; ValidationTestResult\n</code></pre> <p>Run Breusch-Pagan LM test for cross-sectional dependence.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level</p> <code>0.05</code> <p>Returns:</p> Type Description <code>ValidationTestResult</code> <p>Test results</p> Warnings <p>This test can be over-sized (reject H0 too often) when N is large. For large N (&gt; 30), consider using the Pesaran CD test instead.</p> Notes <p>The test requires computing N(N-1)/2 pairwise correlations. For large N, this can be computationally intensive.</p>"},{"location":"api/validation/#pesarancdtest","title":"PesaranCDTest","text":""},{"location":"api/validation/#panelbox.validation.cross_sectional_dependence.pesaran_cd.PesaranCDTest","title":"panelbox.validation.cross_sectional_dependence.pesaran_cd.PesaranCDTest","text":"<pre><code>PesaranCDTest(results: 'PanelResults')\n</code></pre> <p>               Bases: <code>ValidationTest</code></p> <p>Pesaran CD test for cross-sectional dependence.</p> <p>Tests the null hypothesis of cross-sectional independence against the alternative of cross-sectional dependence.</p> <p>The test is based on the average of pairwise correlation coefficients of the residuals.</p> <p>H0: No cross-sectional dependence (residuals are independent across entities) H1: Cross-sectional dependence present</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>PanelResults</code> <p>Results from panel model estimation</p> required Notes <p>Test Statistic:</p> <p>The Pesaran CD statistic is computed as:</p> <pre><code>CD = \u221a(2T / (N(N-1))) \u00d7 \u03a3\u1d62&lt;\u2c7c \u03c1\u0302\u1d62\u2c7c\n</code></pre> <p>where: - N = number of entities - T = number of time periods - \u03c1\u0302\u1d62\u2c7c = sample correlation of residuals between entities i and j</p> <p>Under H0, CD ~ N(0,1) asymptotically as N \u2192 \u221e.</p> <p>When to Use:</p> <p>This test is particularly useful for:</p> <ul> <li>Checking model validity: Detecting omitted spatial effects or   common shocks not captured by time effects</li> <li>Panel VAR models: Testing for cross-sectional independence</li> <li>Large N panels: Works well even when T is small</li> <li>Pre-testing: Before applying Driscoll-Kraay or panel-corrected   standard errors</li> </ul> <p>Advantages:</p> <ul> <li>Simple and computationally efficient (O(N\u00b2) complexity)</li> <li>Valid for both balanced and unbalanced panels</li> <li>Works well for small T, large N panels</li> <li>Does not require normality assumptions</li> <li>Robust to heteroskedasticity</li> </ul> <p>Limitations:</p> <ol> <li>Requires T \u2265 3: Need minimum time periods to compute correlations</li> <li>Large N required: Asymptotic distribution requires N \u2192 \u221e</li> <li>Not powerful for weak dependence: May miss weak spatial patterns</li> <li>Assumes no structural breaks: Common shocks should be stable</li> </ol> <p>Interpretation:</p> CD Statistic P-value Interpretation CD &lt; 1.645 1.645 &lt; CD &lt; 1.96 1.96 &lt; CD &lt; 2.576 CD &gt; 2.576 <p>Average Correlation Guidelines:</p> <ul> <li>|\u03c1\u0304| &lt; 0.1: Weak dependence (likely negligible)</li> <li>0.1 \u2264 |\u03c1\u0304| &lt; 0.3: Moderate dependence (consider robust SEs)</li> <li>0.3 \u2264 |\u03c1\u0304| &lt; 0.5: Strong dependence (require spatial models)</li> <li>|\u03c1\u0304| \u2265 0.5: Very strong dependence (serious misspecification)</li> </ul> <p>If Cross-Sectional Dependence is Detected:</p> <ol> <li> <p>Include time fixed effects to control for common shocks:    <pre><code>fe = pb.FixedEffects(data, \"y\", [\"x1\", \"x2\"], \"firm\", \"year\",\n                    time_effects=True)\n</code></pre></p> </li> <li> <p>Use Driscoll-Kraay standard errors (robust to cross-sectional    and serial correlation):    <pre><code>result = fe.fit(cov_type=\"driscoll-kraay\")\n</code></pre></p> </li> <li> <p>Use panel-corrected standard errors (PCSE):    <pre><code>result = fe.fit(cov_type=\"pcse\")\n</code></pre></p> </li> <li> <p>Consider spatial panel models if geographic structure is known</p> </li> <li> <p>Add common correlated effects (Pesaran CCE estimator)</p> </li> </ol> <p>Comparison with Stata:</p> <p>This test is equivalent to Stata's <code>xtcd</code> command:</p> <pre><code>xtreg y x1 x2, fe\nxtcd, pesaran\n</code></pre> References <p>.. [1] Pesaran, M. H. (2004). \"General diagnostic tests for cross section        dependence in panels.\" University of Cambridge Working Paper,        No. 0435.</p> <p>.. [2] Pesaran, M. H. (2015). \"Testing weak cross-sectional dependence in        large panels.\" Econometric Reviews, 34(6-10), 1089-1117.</p> <p>.. [3] De Hoyos, R. E., &amp; Sarafidis, V. (2006). \"Testing for cross-sectional        dependence in panel-data models.\" Stata Journal, 6(4), 482-496.</p> See Also <p>BreuschPaganLMTest : Lagrange Multiplier test for cross-sectional dependence FreesTest : Distribution-free test for cross-sectional dependence</p> <p>Examples:</p> <p>Basic usage:</p> <pre><code>&gt;&gt;&gt; import panelbox as pb\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Estimate model\n&gt;&gt;&gt; fe = pb.FixedEffects(data, \"y\", [\"x1\", \"x2\"], \"firm\", \"year\")\n&gt;&gt;&gt; results = fe.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Test for cross-sectional dependence\n&gt;&gt;&gt; from panelbox.validation.cross_sectional_dependence import PesaranCDTest\n&gt;&gt;&gt; test = PesaranCDTest(results)\n&gt;&gt;&gt; result = test.run()\n&gt;&gt;&gt; print(result)\n</code></pre> <p>Interpreting results:</p> <pre><code>&gt;&gt;&gt; print(f\"CD statistic: {result.statistic:.3f}\")\n&gt;&gt;&gt; print(f\"P-value: {result.pvalue:.4f}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check average correlation\n&gt;&gt;&gt; avg_corr = result.metadata['avg_abs_correlation']\n&gt;&gt;&gt; print(f\"Average absolute correlation: {avg_corr:.3f}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; if result.pvalue &lt; 0.05:\n...     print(\"Evidence of cross-sectional dependence\")\n...     if avg_corr &lt; 0.3:\n...         print(\"Use Driscoll-Kraay standard errors\")\n...     else:\n...         print(\"Consider spatial panel model\")\n&gt;&gt;&gt; else:\n...     print(\"No evidence of cross-sectional dependence\")\n</code></pre> <p>Examining correlation patterns:</p> <pre><code>&gt;&gt;&gt; # Access detailed correlation statistics\n&gt;&gt;&gt; print(f\"Number of entity pairs: {result.metadata['n_pairs']}\")\n&gt;&gt;&gt; print(f\"Average correlation: {result.metadata['avg_correlation']:.3f}\")\n&gt;&gt;&gt; print(f\"Max absolute correlation: {result.metadata['max_abs_correlation']:.3f}\")\n&gt;&gt;&gt; print(f\"Range: [{result.metadata['min_correlation']:.3f}, \"\n...       f\"{result.metadata['max_correlation']:.3f}]\")\n</code></pre> <p>Testing with time effects:</p> <pre><code>&gt;&gt;&gt; # Include time effects to control for common shocks\n&gt;&gt;&gt; fe_te = pb.FixedEffects(data, \"y\", [\"x1\", \"x2\"], \"firm\", \"year\",\n...                         time_effects=True)\n&gt;&gt;&gt; results_te = fe_te.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Re-test\n&gt;&gt;&gt; test_te = PesaranCDTest(results_te)\n&gt;&gt;&gt; result_te = test_te.run()\n&gt;&gt;&gt; print(f\"CD with time effects: {result_te.statistic:.3f}\")\n&gt;&gt;&gt; print(f\"Reduction in dependence: \"\n...       f\"{(1 - result_te.statistic/result.statistic)*100:.1f}%\")\n</code></pre> <p>Initialize Pesaran CD test.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>PanelResults</code> <p>Results from panel model estimation</p> required"},{"location":"api/validation/#panelbox.validation.cross_sectional_dependence.pesaran_cd.PesaranCDTest-functions","title":"Functions","text":""},{"location":"api/validation/#panelbox.validation.cross_sectional_dependence.pesaran_cd.PesaranCDTest.run","title":"run","text":"<pre><code>run(alpha: float = 0.05, **kwargs) -&gt; ValidationTestResult\n</code></pre> <p>Run Pesaran CD test for cross-sectional dependence.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level</p> <code>0.05</code> <p>Returns:</p> Type Description <code>ValidationTestResult</code> <p>Test results</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required data indices are not available or T &lt; 3</p>"},{"location":"api/validation/#gmm-specific-tests","title":"GMM-Specific Tests","text":""},{"location":"api/validation/#hansen-j-test","title":"Hansen J Test","text":"<p>The Hansen J test is automatically computed for GMM models and available via:</p> <pre><code>results = gmm.fit()\nprint(f\"Hansen J statistic: {results.hansen_j.statistic}\")\nprint(f\"Hansen J p-value: {results.hansen_j.pvalue}\")\n</code></pre> <p>See GMM Results for details.</p>"},{"location":"api/validation/#sargan-test","title":"Sargan Test","text":"<p>Similar to Hansen J but not robust to heteroskedasticity:</p> <pre><code>print(f\"Sargan statistic: {results.sargan.statistic}\")\nprint(f\"Sargan p-value: {results.sargan.pvalue}\")\n</code></pre>"},{"location":"api/validation/#ar1-and-ar2-tests","title":"AR(1) and AR(2) Tests","text":"<p>Tests for serial correlation in differenced residuals:</p> <pre><code>print(f\"AR(1) p-value: {results.ar1_test.pvalue}\")\nprint(f\"AR(2) p-value: {results.ar2_test.pvalue}\")\n</code></pre> <p>Critical: AR(2) should NOT reject (p &gt; 0.10)</p>"},{"location":"api/validation/#difference-in-hansen-test","title":"Difference-in-Hansen Test","text":"<p>For System GMM only, tests validity of level instruments:</p> <pre><code>print(f\"Diff-Hansen p-value: {results.diff_hansen.pvalue}\")\n</code></pre>"},{"location":"assets/images/","title":"PanelBox Logo Assets","text":"<p>This directory contains logo files for the PanelBox project.</p>"},{"location":"assets/images/#files","title":"Files","text":"<ul> <li>logo.svg - Primary PanelBox logo (clean version)</li> <li>Used in: Website header, README, favicon</li> <li>Size: 38KB</li> <li> <p>Source: <code>desenvolvimento/logo_panelbox_clean.svg</code></p> </li> <li> <p>logo_panel.svg - Alternative panel design logo</p> </li> <li>Used in: Alternative branding contexts</li> <li>Size: 59KB</li> <li>Source: <code>desenvolvimento/logo_panel.svg</code></li> </ul>"},{"location":"assets/images/#usage","title":"Usage","text":""},{"location":"assets/images/#in-markdown","title":"In Markdown","text":"<pre><code>![PanelBox Logo](assets/images/logo.svg)\n</code></pre>"},{"location":"assets/images/#in-html","title":"In HTML","text":"<pre><code>&lt;img src=\"assets/images/logo.svg\" alt=\"PanelBox Logo\" width=\"400\"&gt;\n</code></pre>"},{"location":"assets/images/#in-mkdocs-config","title":"In MkDocs Config","text":"<pre><code>theme:\n  logo: assets/images/logo.svg\n  favicon: assets/images/logo.svg\n</code></pre>"},{"location":"assets/images/#license","title":"License","text":"<p>These logos are part of the PanelBox project and are subject to the same MIT License as the project itself.</p>"},{"location":"gmm/interpretation_guide/","title":"GMM Results Interpretation Guide","text":"<p>A Complete Guide to Reading and Understanding PanelBox GMM Output</p>"},{"location":"gmm/interpretation_guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Reading the Output</li> <li>Specification Tests</li> <li>Diagnostic Metrics</li> <li>Common Patterns</li> <li>Troubleshooting</li> <li>Practical Examples</li> </ol>"},{"location":"gmm/interpretation_guide/#reading-the-output","title":"Reading the Output","text":""},{"location":"gmm/interpretation_guide/#standard-gmm-output-format","title":"Standard GMM Output Format","text":"<pre><code>==============================================================================\n                                Difference GMM\n==============================================================================\nNumber of observations:            751\nNumber of groups:                  140\nNumber of instruments:               8\nInstrument ratio:                0.057\nGMM type:           Two-step (Windmeijer)\n------------------------------------------------------------------------------\nVariable                    Coef.     Std.Err.        z    P&gt;|z|     [95% Conf. Int.]\n------------------------------------------------------------------------------\nL1.y                     0.5764     0.1245     4.631    0.000 [ 0.3324,  0.8204] ***\nw                       -0.4082     0.0892    -4.577    0.000 [-0.5830, -0.2334] ***\nk                        0.2341     0.0654     3.579    0.000 [ 0.1059,  0.3623] ***\nys                       0.3892     0.0987     3.943    0.000 [ 0.1957,  0.5827] ***\n==============================================================================\nSpecification Tests:\n------------------------------------------------------------------------------\nHansen J-test: statistic=3.891, p-value=0.143, df=4 [Instruments valid]\nSargan test: statistic=4.123, p-value=0.127, df=4 [Instruments valid]\nAR(1) test: statistic=-3.214, p-value=0.001 [Expected (MA(1) by construction)]\nAR(2) test: statistic=-0.891, p-value=0.373 [Moment conditions valid]\n==============================================================================\n</code></pre>"},{"location":"gmm/interpretation_guide/#understanding-each-component","title":"Understanding Each Component","text":""},{"location":"gmm/interpretation_guide/#header-section","title":"Header Section","text":"<p>Number of observations: 751 - Number of observations used in estimation (after differencing and lags) - Should be reasonably close to input data size - Large drop may indicate:   - Unbalanced panel with many missing periods   - Too many time dummies   - Insufficient instrument availability</p> <p>Number of groups: 140 - Number of cross-sectional units (individuals, firms, countries) - Should match your panel structure</p> <p>Number of instruments: 8 - Total columns in instrument matrix Z - Depends on:   - Number of time periods   - Lag depths used   - <code>collapse=True</code> vs <code>collapse=False</code>   - Exogenous vs predetermined vs endogenous variables</p> <p>Instrument ratio: 0.057 - Formula: <code>n_instruments / n_groups</code> - Critical metric for instrument proliferation - See detailed interpretation below</p> <p>GMM type: Two-step (Windmeijer) - One-step: Uses (Z'Z)^(-1) as weight matrix - Two-step: Uses optimal weight matrix with Windmeijer (2005) finite-sample correction - Two-step generally preferred (more efficient)</p>"},{"location":"gmm/interpretation_guide/#coefficient-table","title":"Coefficient Table","text":"<p>Variable: Name of regressor - <code>L1.y</code>: First lag of dependent variable (\u03b3 coefficient) - <code>L2.y</code>: Second lag (if included) - Variable names as specified in <code>exog_vars</code> - <code>year_XXXX</code>: Time dummies (if <code>time_dummies=True</code>)</p> <p>Coef.: Point estimate of coefficient - Main result - the estimated parameter - Interpretation depends on variable units and model specification</p> <p>Std.Err.: Standard error of coefficient - Measure of estimation uncertainty - Smaller = more precise estimate - Large SE suggests:   - Weak instruments   - High variance in data   - Small sample size</p> <p>z: Test statistic (Wald test) - Formula: <code>Coef. / Std.Err.</code> - Tests H0: coefficient = 0 - |z| &gt; 1.96 \u2192 significant at 5% level - |z| &gt; 2.576 \u2192 significant at 1% level</p> <p>P&gt;|z|: P-value for two-sided test - Probability of observing this z-statistic under H0 - p &lt; 0.05 \u2192 reject H0 at 5% level (significant) - p &lt; 0.01 \u2192 reject H0 at 1% level (highly significant)</p> <p>[95% Conf. Int.]: 95% confidence interval - Range: [Coef. - 1.96\u00d7Std.Err., Coef. + 1.96\u00d7Std.Err.] - Interpretation: \"We are 95% confident the true value lies in this range\" - If interval excludes 0 \u2192 coefficient is significant</p> <p>Significance stars: - <code>*</code>: p &lt; 0.05 (significant) - <code>**</code>: p &lt; 0.01 (highly significant) - <code>***</code>: p &lt; 0.001 (very highly significant)</p>"},{"location":"gmm/interpretation_guide/#specification-tests","title":"Specification Tests","text":""},{"location":"gmm/interpretation_guide/#hansen-j-test-overidentification-test","title":"Hansen J-test (Overidentification Test)","text":"<p>What it tests: <pre><code>H0: All instruments are valid (orthogonal to errors)\nH1: At least one instrument is invalid\n</code></pre></p> <p>Interpretation Guideline:</p> p-value Range Interpretation Action p &lt; 0.05 REJECT - Instruments likely invalid Check model specification p &lt; 0.10 WARNING - Weak evidence against instruments Investigate further 0.10 &lt; p &lt; 0.25 IDEAL - Instruments appear valid Proceed with confidence 0.25 &lt; p &lt; 0.50 ACCEPTABLE - No strong evidence against Proceed cautiously p &gt; 0.50 WARNING - Possible weak instruments Check instrument relevance <p>Decision Rules:</p> <pre><code>if 0.10 &lt; hansen_p &lt; 0.25:\n    print(\"\u2713 Instruments appear valid\")\nelif hansen_p &lt; 0.10:\n    print(\"\u2717 Instruments rejected - try different specification\")\n    # Actions:\n    # - Remove potentially endogenous variables\n    # - Use fewer instruments (collapse=True)\n    # - Try different lag structure\nelse:\n    print(\"\u26a0 Very high p-value - check instrument strength\")\n    # Actions:\n    # - Examine first-stage relevance\n    # - Consider more lags as instruments\n</code></pre> <p>Why high p-value can be bad: - J-test has low power with weak instruments - Weak instruments \u2192 test fails to detect invalidity - Always combine with other diagnostics</p> <p>When test is not available: - Exactly identified: n_instruments = n_parameters \u2192 df = 0 - Under-identified: n_instruments &lt; n_parameters \u2192 impossible - Output shows: <code>[N/A (exactly/under-identified)]</code></p>"},{"location":"gmm/interpretation_guide/#sargan-test","title":"Sargan Test","text":"<p>What it is: - Non-robust version of Hansen J-test - Same interpretation as Hansen J</p> <p>When to use which:</p> <pre><code>if robust == True:\n    # Use Hansen J-test (robust to heteroskedasticity)\n    primary_test = results.hansen_j\nelse:\n    # Use Sargan test (assumes homoskedasticity)\n    primary_test = results.sargan\n</code></pre> <p>Recommendation: Always use <code>robust=True</code> \u2192 focus on Hansen J.</p>"},{"location":"gmm/interpretation_guide/#ar1-test-first-order-autocorrelation","title":"AR(1) Test (First-Order Autocorrelation)","text":"<p>What it tests: <pre><code>H0: No first-order autocorrelation in differenced errors\nH1: First-order autocorrelation present\n</code></pre></p> <p>Expected result: REJECT (p &lt; 0.10)</p> <p>Why? First-differencing mechanically induces MA(1) autocorrelation: <pre><code>\u0394\u03b5_it = \u03b5_it - \u03b5_{i,t-1}\n\u0394\u03b5_{i,t-1} = \u03b5_{i,t-1} - \u03b5_{i,t-2}\n\nCov(\u0394\u03b5_it, \u0394\u03b5_{i,t-1}) = -Var(\u03b5_{i,t-1}) &lt; 0\n</code></pre></p> <p>Interpretation:</p> p-value Interpretation p &lt; 0.10 \u2713 Expected - Normal MA(1) structure p &gt; 0.10 \u26a0 Unexpected - Investigate data structure <p>If NOT rejected: - Check if original errors have negative autocorrelation (unusual) - Verify first-differencing was applied correctly - Not necessarily a problem, but unexpected</p>"},{"location":"gmm/interpretation_guide/#ar2-test-second-order-autocorrelation","title":"AR(2) Test (Second-Order Autocorrelation)","text":"<p>What it tests: <pre><code>H0: No second-order autocorrelation in differenced errors\nH1: Second-order autocorrelation present\n</code></pre></p> <p>Expected result: DO NOT REJECT (p &gt; 0.10)</p> <p>Why it's critical: If original errors are serially uncorrelated: <pre><code>E[\u03b5_it \u00b7 \u03b5_{i,t-2}] = 0\n\nThen: E[\u0394\u03b5_it \u00b7 \u0394\u03b5_{i,t-2}] = 0\n</code></pre></p> <p>This validates the moment condition <code>E[y_{i,t-2} \u00b7 \u0394\u03b5_it] = 0</code>.</p> <p>Interpretation:</p> p-value Interpretation Validity p &gt; 0.10 \u2713 Moment conditions valid GMM consistent 0.05 &lt; p &lt; 0.10 \u26a0 Weak evidence of problem Borderline p &lt; 0.05 \u2717 Moment conditions invalid GMM inconsistent! <p>If rejected (p &lt; 0.05):</p> <p>This is serious - means GMM estimates are inconsistent.</p> <p>Possible causes: 1. Original errors have autocorrelation 2. Model is misspecified 3. Measurement error in variables 4. Dynamic misspecification (need more lags)</p> <p>Actions to take: <pre><code># 1. Try including more lags of y\ngmm = DifferenceGMM(..., lags=[1, 2], ...)\n\n# 2. Check for autocorrelation in levels\n# Run AR tests on OLS residuals\n\n# 3. Consider different model specification\n# Add omitted variables?\n\n# 4. If nothing works, GMM may not be appropriate\n</code></pre></p> <p>Critical rule: If AR(2) is rejected, do NOT trust GMM results!</p>"},{"location":"gmm/interpretation_guide/#diagnostic-metrics","title":"Diagnostic Metrics","text":""},{"location":"gmm/interpretation_guide/#instrument-ratio","title":"Instrument Ratio","text":"<p>Formula: <pre><code>instrument_ratio = n_instruments / n_groups\n</code></pre></p> <p>Rule of Thumb:</p> Ratio Assessment Recommendation &lt; 0.5 \u2713 Good Proceed with confidence 0.5 - 1.0 \u26a0 Acceptable Monitor carefully 1.0 - 2.0 \u26a0 Warning Use <code>collapse=True</code> &gt; 2.0 \u2717 Problematic Reduce instruments <p>Why it matters: - Too many instruments \u2192 overfitting - Biases coefficients toward OLS/FE - Weakens specification tests (Roodman 2009)</p> <p>Solutions for high ratio:</p> <pre><code># 1. Use collapsed instruments (most effective)\ngmm = DifferenceGMM(..., collapse=True, ...)\n\n# 2. Reduce time dummies\ngmm = DifferenceGMM(..., time_dummies=False, ...)\n# Or use trend instead of full dummies\n\n# 3. Limit lag depth (manual instrument specification - advanced)\n\n# 4. Reduce number of variables\n</code></pre>"},{"location":"gmm/interpretation_guide/#number-of-observations","title":"Number of Observations","text":"<p>What to check: <pre><code>retention_rate = results.nobs / len(input_data)\n</code></pre></p> <p>Expected rates:</p> Panel Type Expected Retention If Much Lower Balanced 70-90% Check specification Unbalanced 50-80% May be normal Very unbalanced 30-60% Use simpler spec <p>Reasons for low retention: - First-differencing loses first period - Lags lose additional periods - Time dummies in unbalanced panels - Many missing values in instruments</p> <p>Action if very low (&lt;30%): <pre><code># 1. Simplify specification\ngmm = DifferenceGMM(\n    ...,\n    time_dummies=False,  # Remove time dummies\n    collapse=True,       # Essential\n    ...\n)\n\n# 2. Check for missing data\nprint(df[['y', 'x1', 'x2']].isnull().sum())\n\n# 3. Try balanced subset\ndf_balanced = df.groupby('id').filter(lambda x: len(x) == max_T)\n</code></pre></p>"},{"location":"gmm/interpretation_guide/#common-patterns","title":"Common Patterns","text":""},{"location":"gmm/interpretation_guide/#pattern-1-good-results","title":"Pattern 1: Good Results","text":"<p>Characteristics: - \u2713 AR(2) p-value &gt; 0.10 - \u2713 Hansen J: 0.10 &lt; p &lt; 0.25 - \u2713 Instrument ratio &lt; 0.5 - \u2713 Coefficient in credible range (between FE and OLS) - \u2713 Reasonable standard errors</p> <p>Example: <pre><code>Hansen J: p = 0.183\nAR(2): p = 0.312\nInstruments: 8, Groups: 140, Ratio: 0.057\n\u03b3\u0302 = 0.576 (SE: 0.125), Range: [0.464, 0.712]\n</code></pre></p> <p>Interpretation: Proceed with confidence! Results are reliable.</p>"},{"location":"gmm/interpretation_guide/#pattern-2-weak-instruments","title":"Pattern 2: Weak Instruments","text":"<p>Characteristics: - Hansen J: p &gt; 0.50 (very high) - Very large standard errors - Wide confidence intervals - Coefficients may be implausible</p> <p>Example: <pre><code>Hansen J: p = 0.782\nAR(2): p = 0.421\n\u03b3\u0302 = 0.612 (SE: 0.456)  # SE very large\n95% CI: [-0.282, 1.506]  # Very wide\n</code></pre></p> <p>Diagnosis: Instruments not strongly correlated with endogenous variables.</p> <p>Solutions: <pre><code># 1. Try System GMM (more instruments)\nsys_gmm = SystemGMM(...)\n\n# 2. Use more lag depths\n# 3. Increase sample size if possible\n# 4. Check if GMM is really necessary (compare OLS/FE gap)\n</code></pre></p>"},{"location":"gmm/interpretation_guide/#pattern-3-invalid-instruments","title":"Pattern 3: Invalid Instruments","text":"<p>Characteristics: - Hansen J: p &lt; 0.05 (rejected) - AR(2) may or may not reject - Coefficients may be outside credible range</p> <p>Example: <pre><code>Hansen J: p = 0.023  # REJECTED\nAR(2): p = 0.156\n\u03b3\u0302 = 0.892  # Outside [0.464, 0.712]\n</code></pre></p> <p>Diagnosis: Instruments correlated with errors.</p> <p>Solutions: <pre><code># 1. Remove potentially endogenous variables\nexog_vars = ['x1']  # Remove x2 if suspect\n\n# 2. Treat more variables as endogenous\npredetermined_vars = ['x2']  # Instead of exog_vars\n\n# 3. Check for model misspecification\n# - Missing variables?\n# - Wrong functional form?\n# - Measurement error?\n\n# 4. Try different lag structure\n</code></pre></p>"},{"location":"gmm/interpretation_guide/#pattern-4-serial-correlation-problem","title":"Pattern 4: Serial Correlation Problem","text":"<p>Characteristics: - AR(2): p &lt; 0.05 (REJECTED) - Hansen J may pass or fail - Critical issue</p> <p>Example: <pre><code>Hansen J: p = 0.142\nAR(2): p = 0.018  # REJECTED - PROBLEM!\n</code></pre></p> <p>Diagnosis: Moment conditions invalid, GMM inconsistent.</p> <p>Solutions: <pre><code># 1. Add more lags of y\ngmm = DifferenceGMM(..., lags=[1, 2], ...)\n\n# 2. Check original specification\n# - Omitted variables?\n# - Need different dynamics?\n\n# 3. Try System GMM\nsys_gmm = SystemGMM(...)\n\n# 4. If all fail, GMM may not be appropriate for this data\n</code></pre></p>"},{"location":"gmm/interpretation_guide/#pattern-5-too-many-instruments","title":"Pattern 5: Too Many Instruments","text":"<p>Characteristics: - Instrument ratio &gt; 1.0 - Hansen J: p &gt; 0.50 (very high) - Results close to OLS/FE</p> <p>Example: <pre><code>Instruments: 187, Groups: 140, Ratio: 1.336\nHansen J: p = 0.892\n\u03b3\u0302 = 0.698 (very close to OLS)\n</code></pre></p> <p>Diagnosis: Instrument proliferation, overfitting.</p> <p>Solution: <pre><code># Use collapsed instruments\ngmm = DifferenceGMM(..., collapse=True, ...)\n</code></pre></p>"},{"location":"gmm/interpretation_guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"gmm/interpretation_guide/#problem-number-of-observations-0","title":"Problem: \"Number of observations: 0\"","text":"<p>Cause: No observations have sufficient valid instruments.</p> <p>Solutions: 1. Set <code>collapse=True</code> 2. Set <code>time_dummies=False</code> 3. Simplify specification (fewer variables) 4. Check for missing data</p>"},{"location":"gmm/interpretation_guide/#problem-all-coefficients-are-zero","title":"Problem: \"All coefficients are zero\"","text":"<p>Cause: Estimation failed, no valid observations.</p> <p>Same solutions as above.</p>"},{"location":"gmm/interpretation_guide/#problem-singular-matrix-warnings","title":"Problem: \"Singular matrix\" warnings","text":"<p>Cause: Perfect multicollinearity or insufficient variation.</p> <p>Solutions: 1. Check for redundant variables 2. Remove time dummies causing perfect collinearity 3. Ensure sufficient variation in data</p>"},{"location":"gmm/interpretation_guide/#problem-very-large-standard-errors","title":"Problem: Very large standard errors","text":"<p>Cause: Weak instruments.</p> <p>Solutions: 1. Try System GMM 2. Use more lag depths 3. Increase sample size 4. Check if GMM is necessary</p>"},{"location":"gmm/interpretation_guide/#problem-results-very-different-from-olsfe","title":"Problem: Results very different from OLS/FE","text":"<p>Not necessarily a problem! This is expected if OLS/FE are biased.</p> <p>But check: 1. Coefficient in credible range [FE, OLS]? 2. All diagnostics pass? 3. Results make economic sense?</p>"},{"location":"gmm/interpretation_guide/#practical-examples","title":"Practical Examples","text":""},{"location":"gmm/interpretation_guide/#example-1-employment-equation","title":"Example 1: Employment Equation","text":"<pre><code>Variable        Coef.   Std.Err.    Interpretation\nL1.n          0.6860    0.1370     High persistence in employment\nw            -0.5210    0.1490     Wages negatively affect employment\nk             0.2940    0.0890     Capital positively affects employment\n\nHansen J: p = 0.163  \u2713 Valid\nAR(2): p = 0.289     \u2713 Valid\nRatio: 0.057         \u2713 Good\n</code></pre> <p>Interpretation: - 68.6% of employment persists from previous year - 10% wage increase \u2192 5.2% employment decrease - 10% capital increase \u2192 2.9% employment increase - All diagnostics pass \u2192 results are reliable</p>"},{"location":"gmm/interpretation_guide/#example-2-firm-growth","title":"Example 2: Firm Growth","text":"<pre><code>Variable        Coef.   Std.Err.    Interpretation\nL1.size       0.8520    0.0890     Very persistent size\ninvestment    0.1230    0.0340     Investment promotes growth\nage          -0.0120    0.0056     Older firms grow slower\n\nHansen J: p = 0.201  \u2713 Valid\nAR(2): p = 0.412     \u2713 Valid\nRatio: 0.071         \u2713 Good\n</code></pre> <p>Interpretation: - 85.2% persistence \u2192 highly persistent process - System GMM might be more efficient (high \u03b3) - All diagnostics excellent</p>"},{"location":"gmm/interpretation_guide/#summary-checklist","title":"Summary Checklist","text":"<p>Before accepting GMM results, verify:</p> <ul> <li> AR(2) p-value &gt; 0.10 (critical!)</li> <li> Hansen J: 0.10 &lt; p &lt; 0.25 (ideal) or at least p &gt; 0.10</li> <li> Instrument ratio &lt; 1.0</li> <li> Coefficient in credible range [FE, OLS]</li> <li> Standard errors reasonable (not huge)</li> <li> Number of observations reasonable</li> <li> Results make economic sense</li> </ul> <p>If all checks pass: Results are reliable!</p> <p>If any fail: Investigate, revise specification, or consider alternatives.</p> <p>Guide Version: 1.0 Last Updated: January 2026 Author: PanelBox Development Team</p>"},{"location":"gmm/tutorial/","title":"Complete GMM Tutorial for Dynamic Panel Data","text":"<p>A Hands-On Guide to Generalized Method of Moments with PanelBox</p>"},{"location":"gmm/tutorial/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Understanding the Problem</li> <li>The GMM Solution</li> <li>Hands-On Example</li> <li>Diagnostic Checklist</li> <li>Advanced Topics</li> </ol>"},{"location":"gmm/tutorial/#part-1-understanding-the-problem","title":"Part 1: Understanding the Problem","text":""},{"location":"gmm/tutorial/#the-challenge-dynamic-panel-data-with-fixed-effects","title":"The Challenge: Dynamic Panel Data with Fixed Effects","text":"<p>Consider a typical dynamic panel data model:</p> <pre><code>y_it = \u03b3 y_{i,t-1} + \u03b2 x_it + \u03b7_i + \u03b5_it\n</code></pre> <p>Where: - <code>y_it</code>: Dependent variable (e.g., log employment) - <code>y_{i,t-1}</code>: Lagged dependent variable (persistence) - <code>x_it</code>: Exogenous variables (e.g., wages, capital) - <code>\u03b7_i</code>: Individual fixed effect (unobserved heterogeneity) - <code>\u03b5_it</code>: Idiosyncratic error term</p> <p>The problem: Standard estimators fail!</p>"},{"location":"gmm/tutorial/#why-ols-fails-upward-bias","title":"Why OLS Fails (Upward Bias)","text":"<p>Pooled OLS ignores the fixed effect <code>\u03b7_i</code>, leading to omitted variable bias.</p> <p>The correlation: <pre><code>Cov(y_{i,t-1}, \u03b7_i) \u2260 0\n</code></pre></p> <p>Because <code>\u03b7_i</code> affects both current and past values of <code>y</code>, the lagged dependent variable is correlated with the unobserved effect.</p> <p>Result: OLS coefficient on <code>y_{i,t-1}</code> is biased upward (too high).</p>"},{"location":"gmm/tutorial/#why-fixed-effects-fails-nickell-bias","title":"Why Fixed Effects Fails (Nickell Bias)","text":"<p>The within (FE) estimator removes <code>\u03b7_i</code> by demeaning:</p> <pre><code>(y_it - \u0233_i) = \u03b3(y_{i,t-1} - \u0233_i) + \u03b2(x_it - x\u0304_i) + (\u03b5_it - \u03b5\u0304_i)\n</code></pre> <p>The problem: <pre><code>Cov(y_{i,t-1} - \u0233_i, \u03b5_it - \u03b5\u0304_i) \u2260 0\n</code></pre></p> <p>Because \u0233_i includes y_{i,t-1} and \u03b5\u0304i includes \u03b5, the demeaned lagged variable is correlated with the demeaned error.</p> <p>Result: FE coefficient is biased downward (Nickell 1981).</p> <p>Magnitude: Bias \u2248 -(1+\u03b3)/(T-1) \u2192 Severe when T is small!</p>"},{"location":"gmm/tutorial/#why-random-effects-fails","title":"Why Random Effects Fails","text":"<p>RE assumes strict exogeneity: <pre><code>E[\u03b5_it | x_i1, ..., x_iT, \u03b7_i] = 0 for all t, s\n</code></pre></p> <p>With a lagged dependent variable, this is violated because y_{i,t-1} depends on past shocks.</p> <p>Result: RE is also inconsistent.</p>"},{"location":"gmm/tutorial/#summary-the-estimator-ranking","title":"Summary: The Estimator Ranking","text":"<p>For a dynamic panel with true coefficient \u03b3:</p> <pre><code>OLS &gt; \u03b3_true &gt; System GMM \u2248 \u03b3_true &gt; Difference GMM \u2248 \u03b3_true &gt; FE\n</code></pre> <p>All standard methods fail! We need GMM.</p>"},{"location":"gmm/tutorial/#part-2-the-gmm-solution","title":"Part 2: The GMM Solution","text":""},{"location":"gmm/tutorial/#the-key-insight-moment-conditions","title":"The Key Insight: Moment Conditions","text":"<p>GMM exploits the fact that past values of y are valid instruments for the first-differenced equation.</p>"},{"location":"gmm/tutorial/#difference-gmm-arellano-bond-1991","title":"Difference GMM (Arellano-Bond 1991)","text":"<p>Step 1: First-Difference to Remove Fixed Effects</p> <pre><code>\u0394y_it = \u03b3 \u0394y_{i,t-1} + \u03b2 \u0394x_it + \u0394\u03b5_it\n</code></pre> <p>where <code>\u0394y_it = y_it - y_{i,t-1}</code>.</p> <p>This eliminates <code>\u03b7_i</code> without introducing bias (unlike FE demeaning).</p> <p>Step 2: Instrument with Lags</p> <p>The key moment conditions: <pre><code>E[y_{i,t-s} \u00b7 \u0394\u03b5_it] = 0  for s \u2265 2\n</code></pre></p> <p>Why? - y_{i,t-2} is determined before \u03b5_it occurs - First-differencing creates MA(1) error structure - y_{i,t-2} is orthogonal to \u0394\u03b5_it</p> <p>Valid instruments: - For \u0394y_{i3}: y_{i1} - For \u0394y_{i4}: y_{i1}, y_{i2} - For \u0394y_{i5}: y_{i1}, y_{i2}, y_{i3} - etc.</p> <p>GMM-style: Separate column per instrument (many instruments) GMM-style collapsed: One column per lag depth (fewer instruments, recommended)</p>"},{"location":"gmm/tutorial/#system-gmm-blundell-bond-1998","title":"System GMM (Blundell-Bond 1998)","text":"<p>Problem with Difference GMM: If y is highly persistent (\u03b3 \u2248 1), lagged levels are weak instruments for differences.</p> <p>Solution: Combine two equations:</p> <ol> <li> <p>Difference equation: <pre><code>\u0394y_it = \u03b3 \u0394y_{i,t-1} + \u03b2 \u0394x_it + \u0394\u03b5_it\n</code></pre>    Instruments: y_{i,t-2}, y_{i,t-3}, ...</p> </li> <li> <p>Level equation: <pre><code>y_it = \u03b3 y_{i,t-1} + \u03b2 x_it + \u03b7_i + \u03b5_it\n</code></pre>    Instruments: \u0394y_{i,t-1}, \u0394x_{i,t-1}</p> </li> </ol> <p>Additional moment condition: <pre><code>E[\u0394y_{i,t-1} \u00b7 (\u03b7_i + \u03b5_it)] = 0\n</code></pre></p> <p>Requires: Initial conditions uncorrelated with fixed effects (stationarity).</p> <p>Result: More instruments, more efficient, better with persistent series.</p>"},{"location":"gmm/tutorial/#choosing-difference-vs-system-gmm","title":"Choosing Difference vs System GMM","text":"Criterion Difference GMM System GMM Persistence (\u03b3) \u03b3 &lt; 0.8 \u03b3 \u2265 0.8 Stationarity Not required Required Weak instruments Risk if persistent Stronger instruments Efficiency Less efficient More efficient Robustness More robust Relies on stationarity <p>Rule of thumb: Start with Difference GMM. If instruments are weak (large SEs), try System GMM.</p>"},{"location":"gmm/tutorial/#part-3-hands-on-example","title":"Part 3: Hands-On Example","text":""},{"location":"gmm/tutorial/#step-1-load-and-prepare-data","title":"Step 1: Load and Prepare Data","text":"<pre><code>import pandas as pd\nimport numpy as np\nfrom panelbox.gmm import DifferenceGMM, SystemGMM\n\n# Load your panel data\n# Required: panel identifier (id), time variable (year), outcome (y), regressors (x1, x2, ...)\ndf = pd.read_csv('panel_data.csv')\n\n# Check panel structure\nprint(f\"Panels: {df['id'].nunique()}\")\nprint(f\"Time periods: {df['year'].nunique()}\")\nprint(f\"Observations: {len(df)}\")\n\n# Check for missing values\nprint(\"\\nMissing values:\")\nprint(df.isnull().sum())\n\n# Basic descriptive statistics\nprint(\"\\nDescriptive statistics:\")\nprint(df[['y', 'x1', 'x2']].describe())\n</code></pre>"},{"location":"gmm/tutorial/#step-2-exploratory-analysis","title":"Step 2: Exploratory Analysis","text":"<p>Before GMM, check if you need it:</p> <pre><code>from sklearn.linear_model import LinearRegression\n\n# Create lagged y\ndf_sorted = df.sort_values(['id', 'year']).copy()\ndf_sorted['y_lag'] = df_sorted.groupby('id')['y'].shift(1)\ndf_clean = df_sorted.dropna()\n\n# Compare OLS and FE estimates (bounds for \u03b3)\n# OLS (upper bound)\nX_ols = df_clean[['y_lag', 'x1', 'x2']].values\ny_ols = df_clean['y'].values\nols = LinearRegression().fit(X_ols, y_ols)\ngamma_ols = ols.coef_[0]\n\n# FE (lower bound)\nfor var in ['y', 'y_lag', 'x1', 'x2']:\n    df_clean[f'{var}_dm'] = df_clean[var] - df_clean.groupby('id')[var].transform('mean')\n\nX_fe = df_clean[['y_lag_dm', 'x1_dm', 'x2_dm']].values\ny_fe = df_clean['y_dm'].values\nfe = LinearRegression(fit_intercept=False).fit(X_fe, y_fe)\ngamma_fe = fe.coef_[0]\n\nprint(f\"Credible range for \u03b3: [{gamma_fe:.3f}, {gamma_ols:.3f}]\")\nprint(f\"  FE (lower bound): {gamma_fe:.3f}\")\nprint(f\"  OLS (upper bound): {gamma_ols:.3f}\")\nprint(f\"  Range width: {gamma_ols - gamma_fe:.3f}\")\n\nif gamma_ols - gamma_fe &gt; 0.1:\n    print(\"\\n\u2713 Large gap suggests fixed effects matter - GMM recommended\")\nelse:\n    print(\"\\n\u26a0 Small gap - GMM may not be necessary\")\n</code></pre>"},{"location":"gmm/tutorial/#step-3-estimate-difference-gmm","title":"Step 3: Estimate Difference GMM","text":"<pre><code># Basic Difference GMM specification\ngmm_diff = DifferenceGMM(\n    data=df,\n    dep_var='y',              # Dependent variable\n    lags=1,                   # Include y_{t-1}\n    id_var='id',              # Panel identifier\n    time_var='year',          # Time variable\n    exog_vars=['x1', 'x2'],   # Strictly exogenous variables\n    time_dummies=True,        # Include time fixed effects\n    collapse=True,            # Use collapsed instruments (recommended)\n    two_step=True,            # Two-step GMM with Windmeijer correction\n    robust=True               # Robust standard errors\n)\n\n# Fit the model\nresults_diff = gmm_diff.fit()\n\n# Print results\nprint(results_diff.summary())\n</code></pre>"},{"location":"gmm/tutorial/#step-4-interpret-results","title":"Step 4: Interpret Results","text":"<pre><code># Extract key coefficient\ngamma_diff = results_diff.params['L1.y']\nse_diff = results_diff.std_errors['L1.y']\n\nprint(f\"\\nDifference GMM Results:\")\nprint(f\"  \u03b3\u0302 (lagged y): {gamma_diff:.4f} (SE: {se_diff:.4f})\")\nprint(f\"  95% CI: [{gamma_diff - 1.96*se_diff:.4f}, {gamma_diff + 1.96*se_diff:.4f}]\")\n\n# Check if in credible range\nin_range = gamma_fe &lt; gamma_diff &lt; gamma_ols\nprint(f\"\\nCredibility check: {gamma_diff:.3f} in [{gamma_fe:.3f}, {gamma_ols:.3f}]? {in_range}\")\n\nif not in_range:\n    print(\"\u26a0 Warning: Estimate outside credible bounds - check specification\")\n</code></pre>"},{"location":"gmm/tutorial/#step-5-run-diagnostic-tests","title":"Step 5: Run Diagnostic Tests","text":"<pre><code>print(\"\\n\" + \"=\"*70)\nprint(\"DIAGNOSTIC TESTS\")\nprint(\"=\"*70)\n\n# 1. Hansen J-test (overidentification)\nhansen_j = results_diff.hansen_j\nprint(f\"\\n1. Hansen J-test (H0: instruments valid)\")\nprint(f\"   Statistic: {hansen_j.statistic:.3f}\")\nprint(f\"   p-value: {hansen_j.pvalue:.3f}\")\n\nif 0.10 &lt; hansen_j.pvalue &lt; 0.25:\n    print(\"   \u2713 PASS: Instruments appear valid\")\nelif hansen_j.pvalue &lt; 0.10:\n    print(\"   \u2717 FAIL: Instruments rejected - check model specification\")\nelse:\n    print(\"   \u26a0 WARNING: p-value very high - possible weak instruments\")\n\n# 2. AR(2) test (critical!)\nar2 = results_diff.ar2_test\nprint(f\"\\n2. AR(2) test (H0: no 2nd-order autocorrelation)\")\nprint(f\"   Statistic: {ar2.statistic:.3f}\")\nprint(f\"   p-value: {ar2.pvalue:.3f}\")\n\nif ar2.pvalue &gt; 0.10:\n    print(\"   \u2713 PASS: Moment conditions appear valid\")\nelse:\n    print(\"   \u2717 FAIL: Moment conditions rejected - GMM invalid!\")\n\n# 3. AR(1) test (should reject)\nar1 = results_diff.ar1_test\nprint(f\"\\n3. AR(1) test (H0: no 1st-order autocorrelation)\")\nprint(f\"   Statistic: {ar1.statistic:.3f}\")\nprint(f\"   p-value: {ar1.pvalue:.3f}\")\n\nif ar1.pvalue &lt; 0.10:\n    print(\"   \u2713 Expected: First-differencing induces MA(1)\")\nelse:\n    print(\"   \u26a0 Unexpected: AR(1) not rejected\")\n\n# 4. Instrument count\nprint(f\"\\n4. Instrument diagnostics\")\nprint(f\"   Observations: {results_diff.nobs}\")\nprint(f\"   Groups: {results_diff.n_groups}\")\nprint(f\"   Instruments: {results_diff.n_instruments}\")\nprint(f\"   Instrument ratio: {results_diff.instrument_ratio:.3f}\")\n\nif results_diff.instrument_ratio &lt; 0.5:\n    print(\"   \u2713 Good instrument count\")\nelif results_diff.instrument_ratio &lt; 1.0:\n    print(\"   \u26a0 Moderate instrument count - acceptable\")\nelse:\n    print(\"   \u2717 Too many instruments - risk of overfitting\")\n</code></pre>"},{"location":"gmm/tutorial/#step-6-try-system-gmm","title":"Step 6: Try System GMM","text":"<pre><code>print(\"\\n\" + \"=\"*70)\nprint(\"SYSTEM GMM (for comparison)\")\nprint(\"=\"*70)\n\ngmm_sys = SystemGMM(\n    data=df,\n    dep_var='y',\n    lags=1,\n    id_var='id',\n    time_var='year',\n    exog_vars=['x1', 'x2'],\n    time_dummies=True,\n    collapse=True,\n    two_step=True,\n    robust=True,\n    level_instruments={'max_lags': 1}  # Use \u0394y_{t-1} as instrument for levels\n)\n\nresults_sys = gmm_sys.fit()\nprint(results_sys.summary())\n\ngamma_sys = results_sys.params['L1.y']\nse_sys = results_sys.std_errors['L1.y']\n\nprint(f\"\\nComparison of Estimates:\")\nprint(f\"  OLS:            {gamma_ols:.4f} (upper bound)\")\nprint(f\"  System GMM:     {gamma_sys:.4f} (SE: {se_sys:.4f})\")\nprint(f\"  Difference GMM: {gamma_diff:.4f} (SE: {se_diff:.4f})\")\nprint(f\"  FE:             {gamma_fe:.4f} (lower bound)\")\n\n# System GMM should be more efficient (smaller SE)\nefficiency_gain = (se_diff - se_sys) / se_diff * 100\nprint(f\"\\nEfficiency gain: {efficiency_gain:.1f}% reduction in SE\")\n\n# Check System GMM diagnostics\nprint(f\"\\nSystem GMM Diagnostics:\")\nprint(f\"  Hansen J: {results_sys.hansen_j.pvalue:.3f}\")\nprint(f\"  AR(2): {results_sys.ar2_test.pvalue:.3f}\")\nprint(f\"  Instruments: {results_sys.n_instruments}\")\n</code></pre>"},{"location":"gmm/tutorial/#step-7-choose-final-model","title":"Step 7: Choose Final Model","text":"<pre><code>print(\"\\n\" + \"=\"*70)\nprint(\"MODEL SELECTION\")\nprint(\"=\"*70)\n\n# Decision criteria\ndiff_valid = (results_diff.ar2_test.pvalue &gt; 0.10 and\n              0.10 &lt; results_diff.hansen_j.pvalue &lt; 0.25)\nsys_valid = (results_sys.ar2_test.pvalue &gt; 0.10 and\n             0.10 &lt; results_sys.hansen_j.pvalue &lt; 0.25)\n\nprint(\"\\nDifference GMM:\")\nprint(f\"  Valid diagnostics: {diff_valid}\")\nprint(f\"  Coefficient: {gamma_diff:.4f} ({se_diff:.4f})\")\n\nprint(\"\\nSystem GMM:\")\nprint(f\"  Valid diagnostics: {sys_valid}\")\nprint(f\"  Coefficient: {gamma_sys:.4f} ({se_sys:.4f})\")\n\nif diff_valid and sys_valid:\n    if se_sys &lt; se_diff * 0.9:\n        print(\"\\n\u2713 RECOMMENDATION: Use System GMM (more efficient)\")\n        final_results = results_sys\n    else:\n        print(\"\\n\u2713 RECOMMENDATION: Use Difference GMM (more robust)\")\n        final_results = results_diff\nelif diff_valid:\n    print(\"\\n\u2713 RECOMMENDATION: Use Difference GMM (System GMM fails diagnostics)\")\n    final_results = results_diff\nelif sys_valid:\n    print(\"\\n\u2713 RECOMMENDATION: Use System GMM (Difference GMM fails diagnostics)\")\n    final_results = results_sys\nelse:\n    print(\"\\n\u2717 WARNING: Both models fail diagnostics - check specification\")\n    final_results = None\n</code></pre>"},{"location":"gmm/tutorial/#step-8-report-results","title":"Step 8: Report Results","text":"<pre><code>if final_results is not None:\n    print(\"\\n\" + \"=\"*70)\n    print(\"FINAL RESULTS\")\n    print(\"=\"*70)\n\n    # Coefficient table\n    coef_table = pd.DataFrame({\n        'Coefficient': final_results.params,\n        'Std. Error': final_results.std_errors,\n        't-stat': final_results.tvalues,\n        'p-value': final_results.pvalues\n    })\n    print(\"\\n\", coef_table.to_string())\n\n    # LaTeX export (for papers)\n    print(\"\\n\" + \"=\"*70)\n    print(\"LATEX OUTPUT\")\n    print(\"=\"*70)\n    print(final_results.to_latex())\n</code></pre>"},{"location":"gmm/tutorial/#part-4-diagnostic-checklist","title":"Part 4: Diagnostic Checklist","text":"<p>Use this checklist to validate your GMM results:</p>"},{"location":"gmm/tutorial/#essential-tests-must-pass","title":"Essential Tests (Must Pass)","text":"<ul> <li> <p> AR(2) test p-value &gt; 0.10   Critical! If rejected, moment conditions are invalid.</p> </li> <li> <p> Hansen J-test: 0.10 &lt; p &lt; 0.25   If p &lt; 0.10: instruments rejected (try different spec)   If p &gt; 0.25: possible weak instruments (check relevance)</p> </li> <li> <p> Instrument ratio &lt; 1.0   If &gt; 1.0: too many instruments, use <code>collapse=True</code></p> </li> <li> <p> Coefficient in credible range   Should be between FE (lower) and OLS (upper) bounds</p> </li> </ul>"},{"location":"gmm/tutorial/#recommended-checks","title":"Recommended Checks","text":"<ul> <li> <p> AR(1) test rejected (p &lt; 0.10)   Expected due to first-differencing</p> </li> <li> <p> Standard errors reasonable   Very large SEs suggest weak instruments</p> </li> <li> <p> Number of observations reasonable   Large drop from input suggests specification issue</p> </li> <li> <p> Compare Difference and System GMM   System should be more efficient if valid</p> </li> </ul>"},{"location":"gmm/tutorial/#red-flags","title":"Red Flags","text":"<ul> <li>\ud83d\udea9 AR(2) p-value &lt; 0.05 \u2192 Serious problem, model invalid</li> <li>\ud83d\udea9 Hansen J p-value &lt; 0.01 \u2192 Model misspecified</li> <li>\ud83d\udea9 Instrument ratio &gt; 2.0 \u2192 Severe overfitting risk</li> <li>\ud83d\udea9 Coefficient outside [FE, OLS] range \u2192 Check specification</li> <li>\ud83d\udea9 Very few observations retained \u2192 Simplify specification</li> </ul>"},{"location":"gmm/tutorial/#part-5-advanced-topics","title":"Part 5: Advanced Topics","text":""},{"location":"gmm/tutorial/#predetermined-vs-endogenous-variables","title":"Predetermined vs Endogenous Variables","text":"<p>Not all regressors are strictly exogenous. GMM can handle different types:</p> <ol> <li> <p>Strictly exogenous: E[x_it \u03b5_is] = 0 for all s, t    Example: weather, policy changes    Instruments: All lags valid</p> </li> <li> <p>Predetermined: E[x_it \u03b5_is] = 0 for s \u2265 t    Example: lagged inputs    Instruments: t-1 and earlier</p> </li> <li> <p>Endogenous: E[x_it \u03b5_is] \u2260 0    Example: contemporaneous inputs    Instruments: t-2 and earlier</p> </li> </ol> <p>Example:</p> <pre><code>gmm = DifferenceGMM(\n    data=df,\n    dep_var='y',\n    lags=1,\n    id_var='id',\n    time_var='year',\n    exog_vars=['policy'],           # Strictly exogenous\n    predetermined_vars=['capital'],  # Predetermined (t-1 valid)\n    endogenous_vars=['labor'],      # Endogenous (need t-2)\n    collapse=True,\n    two_step=True\n)\n</code></pre>"},{"location":"gmm/tutorial/#handling-unbalanced-panels","title":"Handling Unbalanced Panels","text":"<p>Unbalanced panels (missing observations) require special care:</p> <p>Recommendations:</p> <ol> <li> <p>Always use <code>collapse=True</code>    Reduces instruments and handles missing better</p> </li> <li> <p>Avoid many time dummies    Each dummy increases parameter count    Use trend or subset of dummies instead</p> </li> <li> <p>Keep specifications parsimonious    More parameters = harder to overidentify with missing data</p> </li> <li> <p>Check observations retained    If very low, simplify specification</p> </li> </ol> <p>Example for unbalanced panels:</p> <pre><code># Good: Simple specification\ngmm = DifferenceGMM(\n    data=df_unbalanced,\n    dep_var='y',\n    lags=1,\n    id_var='id',\n    time_var='year',\n    exog_vars=['x1', 'x2'],\n    time_dummies=False,  # Use trend instead\n    collapse=True,       # Essential!\n    two_step=True\n)\n\n# Add linear trend if needed\ndf_unbalanced['trend'] = df_unbalanced['year'] - df_unbalanced['year'].min()\n</code></pre>"},{"location":"gmm/tutorial/#instrument-selection-strategies","title":"Instrument Selection Strategies","text":"<p>Problem: Too many instruments \u2192 overfitting Solution: Limit instrument lags</p> <pre><code># Limit maximum lags used as instruments\n# Not directly supported yet, but use collapse=True to reduce\n</code></pre> <p>Rule of thumb: Keep <code>n_instruments / n_groups &lt; 1.0</code></p>"},{"location":"gmm/tutorial/#weak-instruments","title":"Weak Instruments","text":"<p>Symptoms: - Very large standard errors - Hansen J p-value &gt; 0.50 - Implausible coefficient estimates</p> <p>Solutions: 1. Try System GMM (additional instruments) 2. Use fewer but more relevant instruments 3. Increase sample size (more groups or periods) 4. Check instrument relevance (first-stage F-test concept)</p>"},{"location":"gmm/tutorial/#small-sample-corrections","title":"Small Sample Corrections","text":"<p>For small N or T:</p> <ol> <li> <p>Use Windmeijer (2005) correction    Automatically applied with <code>two_step=True</code></p> </li> <li> <p>Prefer one-step GMM    Less efficient but more robust in small samples    Set <code>two_step=False</code></p> </li> <li> <p>Be conservative with instruments    Use <code>collapse=True</code> always</p> </li> </ol>"},{"location":"gmm/tutorial/#summary-your-gmm-workflow","title":"Summary: Your GMM Workflow","text":"<ol> <li> <p>Check if you need GMM    Lagged dependent variable + fixed effects + small T</p> </li> <li> <p>Explore OLS and FE bounds    Establishes credible range for coefficients</p> </li> <li> <p>Start with Difference GMM <code>collapse=True</code>, <code>two_step=True</code>, <code>robust=True</code></p> </li> <li> <p>Run full diagnostics    AR(2) &gt; 0.10, Hansen J in [0.10, 0.25], ratio &lt; 1.0</p> </li> <li> <p>Try System GMM if persistent    Compare efficiency and diagnostics</p> </li> <li> <p>Choose best model    Valid diagnostics + smaller SE</p> </li> <li> <p>Report results clearly    Include all diagnostic tests</p> </li> </ol>"},{"location":"gmm/tutorial/#further-reading","title":"Further Reading","text":"<p>Essential Papers: - Arellano &amp; Bond (1991) - Review of Economic Studies - Blundell &amp; Bond (1998) - Journal of Econometrics - Windmeijer (2005) - Journal of Econometrics - Roodman (2009) - Stata Journal (excellent practical guide)</p> <p>Textbooks: - Baltagi (2021) - Econometric Analysis of Panel Data - Wooldridge (2010) - Econometric Analysis of Cross Section and Panel Data</p> <p>Software Documentation: - Stata xtabond2 - PanelBox README and examples</p> <p>Tutorial Version: 1.0 Last Updated: January 2026 Author: PanelBox Development Team</p>"},{"location":"guides/fixed_vs_random/","title":"Fixed Effects vs Random Effects: A Deep Dive","text":"<p>Detailed comparison of Fixed Effects and Random Effects models with theory, intuition, and practical guidance.</p>"},{"location":"guides/fixed_vs_random/#overview","title":"Overview","text":"<p>The choice between Fixed Effects (FE) and Random Effects (RE) is one of the most important decisions in panel data analysis. This guide provides:</p> <ul> <li>Mathematical foundations of both models</li> <li>Intuition for when each is appropriate</li> <li>Theoretical comparison of assumptions and properties</li> <li>Practical guidance for applied work</li> </ul>"},{"location":"guides/fixed_vs_random/#the-models","title":"The Models","text":""},{"location":"guides/fixed_vs_random/#fixed-effects-within-estimator","title":"Fixed Effects (Within Estimator)","text":"<p>Model: <pre><code>y_it = \u03b1_i + X_it'\u03b2 + \u03b5_it\n</code></pre></p> <p>Where: - <code>\u03b1_i</code> = entity-specific fixed effect (constant for entity i) - <code>X_it</code> = regressors (can vary over i and t) - <code>\u03b2</code> = coefficients of interest - <code>\u03b5_it</code> = idiosyncratic error</p> <p>Key feature: <code>\u03b1_i</code> can be correlated with <code>X_it</code></p> <p>Estimation: Within transformation (demeaning)</p> <pre><code>(y_it - \u0233_i) = (X_it - X\u0304_i)'\u03b2 + (\u03b5_it - \u03b5\u0304_i)\n</code></pre>"},{"location":"guides/fixed_vs_random/#random-effects-gls-estimator","title":"Random Effects (GLS Estimator)","text":"<p>Model: <pre><code>y_it = \u03b2\u2080 + X_it'\u03b2 + u_i + \u03b5_it\n</code></pre></p> <p>Where: - <code>u_i ~ N(0, \u03c3\u00b2_u)</code> = entity-specific random effect - <code>\u03b5_it ~ N(0, \u03c3\u00b2_\u03b5)</code> = idiosyncratic error - <code>u_i \u22a5 \u03b5_it</code> (independent)</p> <p>Key assumption: <code>u_i \u22a5 X_it</code> (uncorrelated)</p> <p>Estimation: Generalized Least Squares (GLS)</p> <pre><code>(y_it - \u03b8\u0233_i) = \u03b2\u2080(1 - \u03b8) + (X_it - \u03b8X\u0304_i)'\u03b2 + error\n</code></pre> <p>where <code>\u03b8 = 1 - \u221a(\u03c3\u00b2_\u03b5 / (\u03c3\u00b2_\u03b5 + T\u03c3\u00b2_u))</code></p>"},{"location":"guides/fixed_vs_random/#fundamental-difference","title":"Fundamental Difference","text":"<p>The critical distinction is the correlation assumption:</p> Model Assumption Interpretation Fixed Effects E[\u03b1_i | X_it] \u2260 0 allowed Effects correlated with X Random Effects E[u_i | X_it] = 0 required Effects uncorrelated with X <p>Example (firm profitability):</p> <p>Suppose unobserved <code>\u03b1_i</code> = \"management quality\"</p> <p>FE allows: Good managers choose higher investment (correlation)</p> <p>RE requires: Management quality independent of investment (unlikely!)</p> <p>Implication: FE is consistent in both cases; RE only if assumption holds</p>"},{"location":"guides/fixed_vs_random/#mathematical-details","title":"Mathematical Details","text":""},{"location":"guides/fixed_vs_random/#fixed-effects-estimation","title":"Fixed Effects Estimation","text":"<p>Step 1: Within transformation</p> <p>For each variable, subtract entity mean:</p> <pre><code>\u1ef9_it = y_it - \u0233_i\nX\u0303_it = X_it - X\u0304_i\n</code></pre> <p>Step 2: OLS on demeaned data</p> <pre><code>\u03b2\u0302_FE = (\u03a3_i \u03a3_t X\u0303_it X\u0303_it')^(-1) (\u03a3_i \u03a3_t X\u0303_it \u1ef9_it)\n</code></pre> <p>Properties: - Consistent even if <code>\u03b1_i</code> correlated with <code>X_it</code> - Asymptotically normal as N \u2192 \u221e (with fixed T) - Inefficient if <code>\u03b1_i \u22a5 X_it</code> (larger SEs than RE)</p> <p>Loss: Cannot estimate time-invariant variables (they get absorbed)</p>"},{"location":"guides/fixed_vs_random/#random-effects-estimation","title":"Random Effects Estimation","text":"<p>Step 1: Estimate variance components</p> <p>Using ANOVA, Swamy-Arora, or maximum likelihood:</p> <pre><code>\u03c3\u0302\u00b2_\u03b5 = (1/N(T-1)) \u03a3_i \u03a3_t \u03b5\u0302\u00b2_it  (within residuals)\n\u03c3\u0302\u00b2_u = (1/N) \u03a3_i (\u016b_i\u00b2 - \u03c3\u0302\u00b2_\u03b5/T)  (between - within)\n</code></pre> <p>Step 2: Compute \u03b8</p> <pre><code>\u03b8\u0302 = 1 - \u221a(\u03c3\u0302\u00b2_\u03b5 / (\u03c3\u0302\u00b2_\u03b5 + T\u03c3\u0302\u00b2_u))\n</code></pre> <p>Step 3: Quasi-demean and estimate</p> <pre><code>y*_it = y_it - \u03b8\u0302\u0233_i\nX*_it = X_it - \u03b8\u0302X\u0304_i\n\n\u03b2\u0302_RE = (\u03a3_i \u03a3_t X*_it X*_it')^(-1) (\u03a3_i \u03a3_t X*_it y*_it)\n</code></pre> <p>Properties: - Consistent only if <code>u_i \u22a5 X_it</code> - More efficient than FE (smaller SEs) when assumption holds - Can estimate time-invariant variables</p> <p>Interpretation of \u03b8:</p> <ul> <li><code>\u03b8 = 0</code>: No entity effects (\u03c3\u00b2_u = 0) \u2192 Pooled OLS</li> <li><code>\u03b8 = 1</code>: All variation is between-entity \u2192 Fixed Effects</li> <li><code>0 &lt; \u03b8 &lt; 1</code>: Partial quasi-demeaning (typical)</li> </ul>"},{"location":"guides/fixed_vs_random/#assumptions-comparison","title":"Assumptions Comparison","text":""},{"location":"guides/fixed_vs_random/#fixed-effects-assumptions","title":"Fixed Effects Assumptions","text":"<p>Strict exogeneity: <pre><code>E[\u03b5_it | X_i1, ..., X_iT, \u03b1_i] = 0\n</code></pre></p> <p>For all t and s: errors uncorrelated with all X's</p> <p>No correlation assumption for \u03b1_i: - <code>\u03b1_i</code> can correlate with <code>X_it</code> (key advantage!) - <code>\u03b1_i</code> captures all time-invariant confounders</p> <p>Homoskedasticity (for efficiency, not consistency): <pre><code>Var(\u03b5_it | X_i, \u03b1_i) = \u03c3\u00b2_\u03b5\n</code></pre></p> <p>No serial correlation (for standard SEs): <pre><code>E[\u03b5_it \u03b5_is | X_i, \u03b1_i] = 0  for t \u2260 s\n</code></pre></p>"},{"location":"guides/fixed_vs_random/#random-effects-assumptions","title":"Random Effects Assumptions","text":"<p>All FE assumptions plus:</p> <p>Orthogonality of random effect: <pre><code>E[u_i | X_it] = 0  for all i, t\n</code></pre></p> <p>This is very restrictive!</p> <p>Random effect homoskedasticity: <pre><code>Var(u_i) = \u03c3\u00b2_u  (constant across i)\n</code></pre></p> <p>No correlation between u_i and X_it:</p> <p>This is the key additional assumption that makes RE stronger than FE.</p>"},{"location":"guides/fixed_vs_random/#when-each-assumption-holds","title":"When Each Assumption Holds","text":""},{"location":"guides/fixed_vs_random/#fe-orthogonality-holds-when","title":"FE Orthogonality Holds When:","text":"<p>\u2705 Fixed T, no dynamics: - No lagged dependent variables - X's are strictly exogenous</p> <p>\u2705 Example: - Wage regression: education, experience (predetermined) - No feedback from current wage to past education</p>"},{"location":"guides/fixed_vs_random/#fe-orthogonality-fails-when","title":"FE Orthogonality Fails When:","text":"<p>\u274c Lagged dependent variable: <pre><code>y_it = \u03b3 y_i,t-1 + X_it'\u03b2 + \u03b1_i + \u03b5_it\n</code></pre> - <code>y_i,t-1</code> correlated with <code>(\u03b5_it - \u03b5\u0304_i)</code> \u2192 Nickell bias - Solution: Use GMM</p> <p>\u274c Feedback effects: - Current shock affects future X - Example: Firm profit shock \u2192 affects next year's investment</p>"},{"location":"guides/fixed_vs_random/#re-orthogonality-holds-when","title":"RE Orthogonality Holds When:","text":"<p>\u2705 Random sampling from population: - Entities are random draws - Example: Survey of individuals from general population</p> <p>\u2705 No selection: - Unobserved <code>u_i</code> is not related to why entity is in sample</p>"},{"location":"guides/fixed_vs_random/#re-orthogonality-fails-when","title":"RE Orthogonality Fails When:","text":"<p>\u274c Omitted variable bias: - Any time-invariant factor correlated with X - Example: Ability correlated with education</p> <p>\u274c Common in practice: - Management quality \u2192 investment choices - Individual preferences \u2192 consumption choices - Institutions \u2192 policy choices</p>"},{"location":"guides/fixed_vs_random/#efficiency-comparison","title":"Efficiency Comparison","text":""},{"location":"guides/fixed_vs_random/#when-both-are-consistent-re-assumption-holds","title":"When Both Are Consistent (RE assumption holds)","text":"<p>Variance comparison:</p> <pre><code>Var(\u03b2\u0302_RE) \u2264 Var(\u03b2\u0302_FE)\n</code></pre> <p>Why RE is more efficient:</p> <ol> <li>Uses between-entity variation:</li> <li>FE only uses within-entity variation (over time)</li> <li> <p>RE uses both within and between</p> </li> <li> <p>Example:</p> </li> <li>FE: How does X affect Y within firm i over time?</li> <li>RE: How does X affect Y within and across firms?</li> </ol> <p>Efficiency gain: Typically 10-40% reduction in standard errors</p>"},{"location":"guides/fixed_vs_random/#when-re-is-inconsistent-assumption-fails","title":"When RE Is Inconsistent (assumption fails)","text":"<p>Bias vs Efficiency trade-off:</p> <ul> <li>RE: Smaller SEs but biased estimates</li> <li>FE: Larger SEs but consistent estimates</li> </ul> <p>Decision: Always prefer consistency over efficiency</p> <p>Rule: Use Hausman test to decide</p>"},{"location":"guides/fixed_vs_random/#the-hausman-test","title":"The Hausman Test","text":""},{"location":"guides/fixed_vs_random/#purpose","title":"Purpose","text":"<p>Test whether <code>E[u_i | X_it] = 0</code> holds</p>"},{"location":"guides/fixed_vs_random/#intuition","title":"Intuition","text":"<ul> <li>FE is always consistent (robust to correlation)</li> <li>RE is consistent only if <code>u_i \u22a5 X_it</code></li> </ul> <p>If both are consistent: Estimates should be similar</p> <p>If RE is inconsistent: Estimates will differ systematically</p>"},{"location":"guides/fixed_vs_random/#test-statistic","title":"Test Statistic","text":"<pre><code>H = (\u03b2\u0302_FE - \u03b2\u0302_RE)' [Var(\u03b2\u0302_FE) - Var(\u03b2\u0302_RE)]^(-1) (\u03b2\u0302_FE - \u03b2\u0302_RE)\n</code></pre> <p>Under H\u2080: <code>H ~ \u03c7\u00b2(K)</code> where K = number of coefficients</p>"},{"location":"guides/fixed_vs_random/#decision-rule","title":"Decision Rule","text":"p-value Interpretation Recommendation p &lt; 0.05 Reject H\u2080 Use FE (RE is inconsistent) p \u2265 0.05 Fail to reject Use RE (more efficient)"},{"location":"guides/fixed_vs_random/#example","title":"Example","text":"<pre><code>import panelbox as pb\nfrom panelbox.validation import HausmanTest\n\nfe = pb.FixedEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\nre = pb.RandomEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\n\nhausman = HausmanTest(fe, re)\nprint(hausman)\n</code></pre> <p>Output: <pre><code>Hausman Test: \u03c7\u00b2 = 15.67, p = 0.0004\nDecision: Reject H\u2080 \u2192 Use Fixed Effects\n</code></pre></p> <p>Interpretation: RE assumption violated \u2192 FE is preferred</p>"},{"location":"guides/fixed_vs_random/#practical-guidance","title":"Practical Guidance","text":""},{"location":"guides/fixed_vs_random/#prefer-fixed-effects-when","title":"Prefer Fixed Effects When:","text":"<p>\u2705 Applied microeconomics: - Firms, individuals, households - Unobserved heterogeneity likely correlated with X</p> <p>\u2705 Not a random sample: - Selection bias - Specific set of entities (e.g., Fortune 500 firms)</p> <p>\u2705 Time-invariant variables not of interest: - Focus is on time-varying effects - OK to lose constant characteristics</p> <p>\u2705 Conservative approach: - FE is robust to correlation - \"Safest\" choice</p>"},{"location":"guides/fixed_vs_random/#prefer-random-effects-when","title":"Prefer Random Effects When:","text":"<p>\u2705 Random sample from population: - Survey data with random sampling - Cross-country with representative selection</p> <p>\u2705 Time-invariant variables are key: - Gender, race, country fixed characteristics - Need to estimate their effects</p> <p>\u2705 Hausman test supports RE: - p &gt; 0.10 - No evidence of correlation</p> <p>\u2705 Efficiency matters: - Small sample, large standard errors - RE provides tighter confidence intervals</p>"},{"location":"guides/fixed_vs_random/#mundlak-approach-hybrid","title":"Mundlak Approach (Hybrid)","text":"<p>Problem: Want RE efficiency but worried about correlation</p> <p>Solution: Correlated Random Effects (Mundlak 1978)</p> <p>Model: <pre><code>y_it = \u03b2\u2080 + X_it'\u03b2 + X\u0304_i'\u03b3 + u_i + \u03b5_it\n</code></pre></p> <p>Include entity means <code>X\u0304_i</code> as regressors</p> <p>Properties: - If <code>\u03b3 = 0</code>: No correlation \u2192 Standard RE - If <code>\u03b3 \u2260 0</code>: Controls for correlation - Allows time-invariant variables - Can test for correlation</p> <p>In PanelBox:</p> <pre><code># Create entity means\ndata['x1_mean'] = data.groupby('firm')['x1'].transform('mean')\n\n# Mundlak model\nre_mundlak = pb.RandomEffects(\n    \"y ~ x1 + x1_mean\",\n    data, \"firm\", \"year\"\n).fit()\n\n# Test \u03b3 = 0\n# If significant \u2192 correlation exists\n</code></pre>"},{"location":"guides/fixed_vs_random/#common-scenarios","title":"Common Scenarios","text":""},{"location":"guides/fixed_vs_random/#scenario-1-wage-determination","title":"Scenario 1: Wage Determination","text":"<p>Setup: Individual wages over time</p> <p>Model: wage_it = education_it + experience_it + ...</p> <p>Unobserved: Ability (\u03b1_i)</p> <p>Question: Is ability correlated with education?</p> <p>Answer: Almost certainly YES (able people get more education)</p> <p>Conclusion: Use Fixed Effects</p>"},{"location":"guides/fixed_vs_random/#scenario-2-country-growth","title":"Scenario 2: Country Growth","text":"<p>Setup: GDP growth across 100+ countries</p> <p>Model: growth_it = investment_it + institutions_i + ...</p> <p>Unobserved: Geography, culture (u_i)</p> <p>Question: Are institutions time-invariant and of interest?</p> <p>Answer: YES, and likely random sample of countries</p> <p>Conclusion: Use Random Effects (can estimate institution effects)</p>"},{"location":"guides/fixed_vs_random/#scenario-3-firm-investment","title":"Scenario 3: Firm Investment","text":"<p>Setup: Investment decisions of S&amp;P 500 firms</p> <p>Model: invest_it = cash_flow_it + debt_it + ...</p> <p>Unobserved: Management quality (\u03b1_i)</p> <p>Question: Do good managers have different cash flows?</p> <p>Answer: Probably (selection into S&amp;P 500)</p> <p>Conclusion: Use Fixed Effects (not a random sample)</p>"},{"location":"guides/fixed_vs_random/#scenario-4-school-performance","title":"Scenario 4: School Performance","text":"<p>Setup: Test scores across schools over time</p> <p>Model: score_it = class_size_it + funding_it + ...</p> <p>Unobserved: School quality, neighborhood (\u03b1_i)</p> <p>Question: Does school quality affect class size choice?</p> <p>Answer: Likely (better schools attract more students)</p> <p>Conclusion: Use Fixed Effects, or run Hausman test</p>"},{"location":"guides/fixed_vs_random/#comparison-table","title":"Comparison Table","text":"Feature Fixed Effects Random Effects Assumption E[\u03b1_i | X_it] unrestricted E[u_i | X_it] = 0 required Consistency Always (if strict exogeneity) Only if orthogonality holds Efficiency Less efficient More efficient (if consistent) Time-invariant X Cannot estimate Can estimate Interpretation Within-entity effects Weighted within/between Typical use Micro (firms, individuals) Macro (countries), surveys Sample Any Preferably random Robustness Very robust Sensitive to violations"},{"location":"guides/fixed_vs_random/#summary-workflow","title":"Summary Workflow","text":"<pre><code>START: Panel data with entity-specific effects\n\n    \u2193\n\nQ1: Do you NEED to estimate time-invariant variables?\n\n    YES \u2192 Consider Random Effects (run Hausman test)\n    NO \u2192 Continue\n\n    \u2193\n\nQ2: Is sample a random draw from population?\n\n    YES \u2192 Consider Random Effects (run Hausman test)\n    NO \u2192 Prefer Fixed Effects\n\n    \u2193\n\nQ3: Run Hausman Test\n\n    p &lt; 0.05 \u2192 Use Fixed Effects\n    p \u2265 0.05 \u2192 Use Random Effects\n\n    \u2193\n\nDECISION MADE\n</code></pre>"},{"location":"guides/fixed_vs_random/#key-takeaways","title":"Key Takeaways","text":"<p>\ud83d\udd11 Core difference: Correlation assumption - FE allows correlation between \u03b1_i and X_it - RE requires no correlation</p> <p>\ud83d\udd11 Trade-off: Consistency vs Efficiency - FE: Consistent but less efficient - RE: More efficient but only if assumption holds</p> <p>\ud83d\udd11 Practical rule: - When in doubt, use Fixed Effects (safer) - Only use RE if Hausman test supports it</p> <p>\ud83d\udd11 Hausman test is your friend: - Let the data decide - Don't pre-commit to one model</p>"},{"location":"guides/fixed_vs_random/#next-steps","title":"Next Steps","text":"<p>Learn more:</p> <ol> <li> <p>Tutorial 2: Static Models: Hands-on FE vs RE</p> </li> <li> <p>How-To: Interpret Tests: Hausman test details</p> </li> <li> <p>How-To: Choose Model: Decision flowchart</p> </li> </ol> <p>Advanced topics: - Correlated Random Effects (Mundlak, Chamberlain) - Hausman-Taylor estimator (IV for RE) - Clustered standard errors for both FE and RE</p> <p>Further reading:</p> <ul> <li>Wooldridge (2010), Chapter 10: Comprehensive treatment</li> <li>Hausman (1978): Original specification test paper</li> <li>Mundlak (1978): Correlated random effects</li> <li>Baltagi (2021), Chapters 2-3: Detailed comparison</li> </ul> <p>Remember: The choice between FE and RE is fundamentally about whether unobserved effects are correlated with your regressors. When in doubt, FE is the conservative choice.</p>"},{"location":"guides/gmm_explained/","title":"GMM for Panel Data: A Complete Explanation","text":"<p>Deep dive into the theory, mechanics, and intuition behind Generalized Method of Moments (GMM) estimators for dynamic panel data.</p>"},{"location":"guides/gmm_explained/#overview","title":"Overview","text":"<p>This guide provides a comprehensive explanation of GMM for panel data:</p> <ul> <li>Why GMM is needed (the dynamic panel bias problem)</li> <li>Moment conditions and instrument construction</li> <li>Difference GMM (Arellano-Bond 1991)</li> <li>System GMM (Blundell-Bond 1998)</li> <li>Estimation mechanics (one-step, two-step)</li> <li>Diagnostic tests and their interpretation</li> <li>When GMM works and when it fails</li> </ul>"},{"location":"guides/gmm_explained/#the-dynamic-panel-problem","title":"The Dynamic Panel Problem","text":""},{"location":"guides/gmm_explained/#the-model","title":"The Model","text":"<p>Consider a dynamic panel model:</p> <pre><code>y_it = \u03b3 y_{i,t-1} + X_it'\u03b2 + \u03b1_i + \u03b5_it\n</code></pre> <p>Where: - <code>y_{i,t-1}</code> = lagged dependent variable (dynamics) - <code>X_it</code> = exogenous regressors - <code>\u03b1_i</code> = entity-specific fixed effect - <code>\u03b5_it</code> = idiosyncratic error</p> <p>Assumptions: - E[\u03b1_i] = 0 - E[\u03b5_it] = 0 - E[\u03b5_it | \u03b5_is] = 0 for all t \u2260 s (no serial correlation) - E[X_it \u03b5_is] = 0 for all t, s (strict exogeneity of X)</p>"},{"location":"guides/gmm_explained/#why-fixed-effects-fails","title":"Why Fixed Effects Fails","text":"<p>Naive approach: Use Fixed Effects (within transformation)</p> <p>Problem: Within transformation creates correlation!</p> <p>Proof:</p> <p>Within transformation: <pre><code>(y_it - \u0233_i) = \u03b3(y_{i,t-1} - \u0233_i) + (X_it - X\u0304_i)'\u03b2 + (\u03b5_it - \u03b5\u0304_i)\n</code></pre></p> <p>Note: - <code>\u0233_i = (1/T)\u03a3_t y_it</code> includes <code>y_i,t-1</code>, <code>y_it</code>, <code>y_{i,t+1}</code>, etc. - <code>\u03b5\u0304_i = (1/T)\u03a3_t \u03b5_it</code> includes <code>\u03b5_it</code></p> <p>Correlation: <pre><code>Cov(y_{i,t-1} - \u0233_i, \u03b5_it - \u03b5\u0304_i) \u2260 0\n</code></pre></p> <p>Even though <code>E[y_{i,t-1} \u03b5_it] = 0</code>, the demeaning creates dependence!</p> <p>Result: Nickell bias (biased and inconsistent estimates)</p> <p>Magnitude: Bias = O(1/T) - T = 5: Bias \u2248 20% - T = 10: Bias \u2248 10% - T = 20: Bias \u2248 5%</p> <p>Implication: Severe for short panels (T &lt; 10)</p>"},{"location":"guides/gmm_explained/#the-gmm-solution-moment-conditions","title":"The GMM Solution: Moment Conditions","text":""},{"location":"guides/gmm_explained/#key-insight","title":"Key Insight","text":"<p>Cannot use levels with FE (demeaning causes correlation)</p> <p>Solution: Use first-differences to eliminate \u03b1_i</p>"},{"location":"guides/gmm_explained/#first-differencing","title":"First-Differencing","text":"<p>Difference equation: <pre><code>\u0394y_it = \u03b3 \u0394y_{i,t-1} + \u0394 X_it'\u03b2 + \u0394\u03b5_it\n\nwhere \u0394y_it = y_it - y_{i,t-1}\n</code></pre></p> <p>Success: Fixed effect \u03b1_i is gone!</p> <p>New problem: <code>\u0394y_{i,t-1}</code> is still correlated with <code>\u0394\u03b5_it</code></p> <p>Proof: <pre><code>\u0394y_{i,t-1} = y_{i,t-1} - y_{i,t-2}\n\n\u0394\u03b5_it = \u03b5_it - \u03b5_{i,t-1}\n</code></pre></p> <p>So <code>\u0394y_{i,t-1}</code> includes <code>y_{i,t-1}</code> which depends on <code>\u03b5_{i,t-1}</code>, which appears in <code>\u0394\u03b5_it</code>!</p> <p>Conclusion: OLS on differenced equation is still biased</p>"},{"location":"guides/gmm_explained/#instruments-the-gmm-idea","title":"Instruments: The GMM Idea","text":"<p>Question: What variables are: 1. Correlated with <code>\u0394y_{i,t-1}</code> (relevant) 2. Uncorrelated with <code>\u0394\u03b5_it</code> (exogenous)</p> <p>Answer: Lagged levels <code>y_{i,t-2}, y_{i,t-3}, ...</code></p> <p>Why this works:</p> <p>Moment condition: <pre><code>E[y_{i,t-s} \u0394\u03b5_it] = E[y_{i,t-s} (\u03b5_it - \u03b5_{i,t-1})] = 0  for s \u2265 2\n</code></pre></p> <p>Proof (for s = 2): <pre><code>E[y_{i,t-2} \u03b5_it] = 0  (\u03b5_it is future, y_{i,t-2} is past)\nE[y_{i,t-2} \u03b5_{i,t-1}] = 0  (no serial correlation in \u03b5)\n\n\u2192 E[y_{i,t-2} \u0394\u03b5_it] = 0 \u2713\n</code></pre></p> <p>This is the foundation of GMM!</p>"},{"location":"guides/gmm_explained/#difference-gmm-arellano-bond-1991","title":"Difference GMM (Arellano-Bond 1991)","text":""},{"location":"guides/gmm_explained/#moment-conditions","title":"Moment Conditions","text":"<p>For each time period t, we have moment conditions:</p> <p>t = 3: <pre><code>E[y_{i1} (\u0394y_{i3} - \u03b3 \u0394y_{i2} - \u0394 X_{i3}'\u03b2)] = 0\n</code></pre></p> <p>t = 4: <pre><code>E[y_{i1} (\u0394y_{i4} - \u03b3 \u0394y_{i3} - \u0394 X_{i4}'\u03b2)] = 0\nE[y_{i2} (\u0394y_{i4} - \u03b3 \u0394y_{i3} - \u0394 X_{i4}'\u03b2)] = 0\n</code></pre></p> <p>General (for period t): <pre><code>E[y_is \u0394\u03b5_it] = 0  for s = 1, ..., t-2\n</code></pre></p> <p>Number of moment conditions: Grows with T - t = 3: 1 instrument - t = 4: 2 instruments - t = T: T-2 instruments - Total: (T-2)(T-1)/2 instruments (without collapse)</p>"},{"location":"guides/gmm_explained/#instrument-matrix-without-collapse","title":"Instrument Matrix (Without Collapse)","text":"<p>For T = 5:</p> <pre><code>Period | Instruments\n-------|------------------\n  3    | y_i1\n  4    | y_i1, y_i2\n  5    | y_i1, y_i2, y_i3\n</code></pre> <p>Matrix Z_i: <pre><code>        [y_i1   0     0    0  ]\nZ_i =   [  0  y_i1  y_i2  0  ]\n        [  0    0   y_i1 y_i2 y_i3]\n</code></pre></p> <p>Problem: Instrument count explodes!</p>"},{"location":"guides/gmm_explained/#collapsed-instruments-roodman-2009","title":"Collapsed Instruments (Roodman 2009)","text":"<p>Instead of using all lags separately...</p> <p>Use: One instrument per period (linear combination)</p> <p>Collapsed Z_i for T = 5: <pre><code>        [y_i1         0            0      ]\nZ_i =   [  0     (y_i1+y_i2)/2      0      ]\n        [  0          0      (y_i1+y_i2+y_i3)/3]\n</code></pre></p> <p>Result: Number of instruments = T - 2 (linear in T, not quadratic!)</p> <p>In PanelBox: <code>collapse=True</code> always does this</p>"},{"location":"guides/gmm_explained/#gmm-estimation","title":"GMM Estimation","text":"<p>Step 1: Form moment conditions</p> <pre><code>m_i(\u03b8) = Z_i' \u0394\u03b5_i(\u03b8)\n\nwhere \u0394\u03b5_i(\u03b8) = \u0394y_i - \u03b3 \u0394y_i,(-1) - \u0394X_i \u03b2\n</code></pre> <p>Step 2: Minimize objective function</p> <pre><code>\u03b8\u0302 = argmin_\u03b8 [\u03a3_i m_i(\u03b8)]' W [\u03a3_i m_i(\u03b8)]\n</code></pre> <p>where W is a weighting matrix</p> <p>Step 3: Choose W</p> <p>One-step GMM: W = I (identity matrix)</p> <p>Two-step GMM: 1. Estimate with W = I, get residuals 2. Estimate optimal W = \u03a3\u0302^(-1) where \u03a3\u0302 = (1/N)\u03a3_i Z_i' \u0394\u03b5\u0302_i \u0394\u03b5\u0302_i' Z_i 3. Re-estimate with optimal W</p> <p>Two-step is asymptotically efficient (smallest variance)</p>"},{"location":"guides/gmm_explained/#windmeijer-correction-2005","title":"Windmeijer Correction (2005)","text":"<p>Problem: Two-step SEs are downward biased in finite samples</p> <p>Magnitude: Bias can be 30-50% (SEs too small!)</p> <p>Solution: Windmeijer finite-sample correction</p> <p>In PanelBox: Automatically applied when <code>robust=True</code></p>"},{"location":"guides/gmm_explained/#system-gmm-blundell-bond-1998","title":"System GMM (Blundell-Bond 1998)","text":""},{"location":"guides/gmm_explained/#motivation","title":"Motivation","text":"<p>Problem with Difference GMM: When y_it is persistent (near unit root), lagged levels are weak instruments for first-differences.</p> <p>Intuition: - If <code>y_it \u2248 y_{i,t-1}</code> (highly persistent) - Then <code>\u0394y_it \u2248 0</code> (small variation) - And <code>y_{i,t-2}</code> doesn't predict <code>\u0394y_it</code> well (weak instrument)</p> <p>Consequence: Large standard errors, imprecise estimates</p>"},{"location":"guides/gmm_explained/#the-system-gmm-idea","title":"The System GMM Idea","text":"<p>Add level equations to the system with lagged differences as instruments</p> <p>System:</p> <ol> <li> <p>Difference equations (Arellano-Bond):    <pre><code>\u0394y_it = \u03b3 \u0394y_{i,t-1} + \u0394X_it'\u03b2 + \u0394\u03b5_it\nInstruments: y_{i,t-2}, y_{i,t-3}, ... (levels)\n</code></pre></p> </li> <li> <p>Level equations (additional):    <pre><code>y_it = \u03b3 y_{i,t-1} + X_it'\u03b2 + \u03b7_i + \u03b5_it\nInstruments: \u0394y_{i,t-1}, \u0394y_{i,t-2}, ... (differences)\n</code></pre></p> </li> </ol> <p>Key: Use lags of differences as instruments for levels</p>"},{"location":"guides/gmm_explained/#additional-moment-conditions","title":"Additional Moment Conditions","text":"<p>For level equation: <pre><code>E[\u0394y_{i,t-1} (\u03b1_i + \u03b5_it)] = 0\n</code></pre></p> <p>Critical assumption (stationarity of initial conditions): <pre><code>E[\u0394y_{i,1} \u03b1_i] = 0\n</code></pre></p> <p>Interpretation: Initial deviations from steady-state are uncorrelated with fixed effects</p> <p>When this holds: - Time-series is stationary - Panel doesn't start at \"event time\" (e.g., firm entry)</p> <p>When this fails: - Panel starts at event (firm entry, policy change) - Initial period is special</p>"},{"location":"guides/gmm_explained/#efficiency-gain","title":"Efficiency Gain","text":"<p>Why System GMM is more efficient:</p> <ol> <li>More moment conditions (level equations added)</li> <li>Uses level variation (not just differences)</li> <li>Better instruments for persistent series</li> </ol> <p>Typical gain: 20-50% reduction in standard errors</p> <p>Trade-off: Stronger assumption (stationarity of initial conditions)</p>"},{"location":"guides/gmm_explained/#estimation-steps-detailed","title":"Estimation Steps (Detailed)","text":""},{"location":"guides/gmm_explained/#two-step-system-gmm","title":"Two-Step System GMM","text":"<p>Step 1: First-step estimation</p> <ol> <li>Form instrument matrix Z_i (difference + level instruments)</li> <li>Set W = I (identity)</li> <li>Compute:    <pre><code>\u03b8\u0302\u2081 = (\u03a3_i Z_i' X\u0303_i)' W (\u03a3_i Z_i' X\u0303_i))^(-1) (\u03a3_i Z_i' X\u0303_i)' W (\u03a3_i Z_i' \u1ef9_i)\n</code></pre></li> <li>Compute residuals: \u03b5\u0302\u2081 = \u1ef9 - X\u0303 \u03b8\u0302\u2081</li> </ol> <p>Step 2: Optimal weighting matrix</p> <ol> <li>Construct \u03a3\u0302\u2081 = (1/N) \u03a3_i Z_i' \u03b5\u0302\u2081 \u03b5\u0302\u2081' Z_i</li> <li>Set W = \u03a3\u0302\u2081^(-1)</li> </ol> <p>Step 3: Second-step estimation</p> <ol> <li>Re-estimate with optimal W:    <pre><code>\u03b8\u0302\u2082 = (\u03a3_i Z_i' X\u0303_i)' W (\u03a3_i Z_i' X\u0303_i))^(-1) (\u03a3_i Z_i' X\u0303_i)' W (\u03a3_i Z_i' \u1ef9_i)\n</code></pre></li> </ol> <p>Step 4: Windmeijer correction</p> <ol> <li>Compute corrected variance:    <pre><code>Var(\u03b8\u0302\u2082) = (1/N) D'_N \u03a3\u0302_corr D_N\n</code></pre>    with finite-sample adjustment</li> </ol>"},{"location":"guides/gmm_explained/#diagnostic-tests","title":"Diagnostic Tests","text":""},{"location":"guides/gmm_explained/#hansen-j-test","title":"Hansen J Test","text":"<p>Purpose: Test overidentifying restrictions</p> <p>Statistic: <pre><code>J = N \u00b7 (\u03a3_i Z_i' \u00ea_i)' \u03a3\u0302^(-1) (\u03a3_i Z_i' \u00ea_i) ~ \u03c7\u00b2(q - k)\n</code></pre></p> <p>where q = # instruments, k = # parameters</p> <p>Interpretation:</p> J statistic p-value Interpretation Small p &gt; 0.25 Strong evidence instruments valid Moderate 0.10 &lt; p &lt; 0.25 Instruments likely valid Large p &lt; 0.10 Instruments may be invalid <p>Problem: With too many instruments, J \u2192 0 (always p \u2248 1)</p> <p>Solution: Always use collapse=True</p>"},{"location":"guides/gmm_explained/#ar1-and-ar2-tests","title":"AR(1) and AR(2) Tests","text":"<p>Purpose: Test for serial correlation in differenced errors</p> <p>AR(m) statistic: <pre><code>AR(m) = (\u03a3_i \u0394\u00ea_it \u0394\u00ea_{i,t-m}) / \u221aVar(\u03a3_i \u0394\u00ea_it \u0394\u00ea_{i,t-m})\n</code></pre></p> <p>Under H\u2080: AR(m) ~ N(0, 1)</p> <p>Expected results:</p> <p>AR(1) test: - Typically rejects (p &lt; 0.05) \u2192 Expected! - Mechanical due to MA(1) structure in \u0394\u03b5_it</p> <p>AR(2) test: - Should NOT reject (p &gt; 0.10) \u2192 Critical! - If rejects \u2192 moment conditions E[y_{i,t-2} \u0394\u03b5_it] = 0 invalid</p> <p>Intuition:</p> <p>If AR(2) rejects: - Serial correlation in levels: E[\u03b5_it \u03b5_{i,t-2}] \u2260 0 - Then E[y_{i,t-2} \u0394\u03b5_it] \u2260 0 (instruments invalid!) - GMM estimator is inconsistent</p>"},{"location":"guides/gmm_explained/#difference-in-hansen-test-system-gmm-only","title":"Difference-in-Hansen Test (System GMM only)","text":"<p>Purpose: Test validity of additional level instruments</p> <p>Statistic: <pre><code>Diff-Hansen = J_system - J_difference\n</code></pre></p> <p>Under H\u2080: Diff-Hansen ~ \u03c7\u00b2(q_level)</p> <p>Interpretation:</p> p-value Interpretation p &gt; 0.10 Level instruments valid p &lt; 0.10 Level instruments invalid \u2192 Use Difference GMM <p>When to use: To check if System GMM assumptions hold</p>"},{"location":"guides/gmm_explained/#when-gmm-works-and-when-it-fails","title":"When GMM Works and When It Fails","text":""},{"location":"guides/gmm_explained/#gmm-works-well-when","title":"GMM Works Well When:","text":"<p>\u2705 Short panel (small T, large N) - T = 5-10 years, N = 500+ entities - Asymptotic theory relies on N \u2192 \u221e</p> <p>\u2705 No serial correlation in \u03b5_it - Critical for moment conditions - AR(2) test should pass</p> <p>\u2705 Moderate persistence (for Difference GMM) - 0.3 &lt; \u03b3 &lt; 0.8 - Instruments have enough variation</p> <p>\u2705 High persistence (for System GMM) - \u03b3 &gt; 0.8 - Additional level moments help</p> <p>\u2705 Enough lags available - Need t \u2265 3 for Difference GMM - Preferably T \u2265 5</p>"},{"location":"guides/gmm_explained/#gmm-fails-when","title":"GMM Fails When:","text":"<p>\u274c Too many instruments - Without collapse: q/N &gt; 1 - Overfitting, Hansen J loses power</p> <p>\u274c Serial correlation in levels - E[\u03b5_it \u03b5_{i,t-s}] \u2260 0 for s &gt; 0 - Invalidates moment conditions - AR(2) test will reject</p> <p>\u274c Weak instruments (Difference GMM) - Near unit root (\u03b3 \u2248 1) - Very persistent series - Solution: Use System GMM</p> <p>\u274c Very short panel (T &lt; 5) - Too few instruments - Large bias</p> <p>\u274c Measurement error - Amplified in differences - Larger bias than levels</p> <p>\u274c Initial conditions violated (System GMM) - Panel starts at event time - E[\u0394y_{i1} \u03b1_i] \u2260 0 - Solution: Use Difference GMM</p>"},{"location":"guides/gmm_explained/#practical-workflow","title":"Practical Workflow","text":""},{"location":"guides/gmm_explained/#step-1-choose-difference-or-system-gmm","title":"Step 1: Choose Difference or System GMM","text":"<p>Flow:</p> <pre><code>Is series highly persistent (\u03c1 &gt; 0.8)?\n  YES \u2192 Try System GMM (more efficient)\n  NO \u2192 Start with Difference GMM (fewer assumptions)\n\nDoes panel start at event time?\n  YES \u2192 Use Difference GMM\n  NO \u2192 System GMM OK\n</code></pre>"},{"location":"guides/gmm_explained/#step-2-start-conservative","title":"Step 2: Start Conservative","text":"<pre><code>gmm = pb.DifferenceGMM(\n    data=data,\n    dep_var='y',\n    lags=1,              # One lag of y\n    exog_vars=['x1'],    # Few exog vars\n    id_var='id',\n    time_var='year',\n    collapse=True,       # ALWAYS\n    robust=True          # Windmeijer correction\n)\n\nresults = gmm.fit()\n</code></pre>"},{"location":"guides/gmm_explained/#step-3-check-diagnostics","title":"Step 3: Check Diagnostics","text":"<pre><code># Hansen J test\nprint(f\"Hansen J p-value: {results.hansen_j.pvalue:.3f}\")\n# Want: p &gt; 0.10\n\n# AR(2) test\nprint(f\"AR(2) p-value: {results.ar2_test.pvalue:.3f}\")\n# Want: p &gt; 0.10\n\n# Instrument ratio\nprint(f\"Instrument ratio: {results.instrument_ratio:.2f}\")\n# Want: &lt; 1.0 (or at most &lt; 2.0)\n</code></pre>"},{"location":"guides/gmm_explained/#step-4-if-tests-fail","title":"Step 4: If Tests Fail","text":"<p>If Hansen J fails (p &lt; 0.10): 1. Check instrument count (collapse=True?) 2. Remove potentially endogenous X variables 3. Reduce number of lags used</p> <p>If AR(2) fails (p &lt; 0.10): 1. Add more lags of dependent variable (lags=2) 2. Check for misspecification (omitted variables) 3. Consider deeper lags as instruments (minlags=3)</p>"},{"location":"guides/gmm_explained/#step-5-compare-difference-and-system","title":"Step 5: Compare Difference and System","text":"<pre><code># Estimate both\ndiff_gmm = pb.DifferenceGMM(..., collapse=True).fit()\nsys_gmm = pb.SystemGMM(..., collapse=True).fit()\n\n# Compare\nprint(\"\\nCoefficient Comparison:\")\nprint(f\"Difference GMM: {diff_gmm.params['y_lag1']:.3f} (SE: {diff_gmm.std_errors['y_lag1']:.3f})\")\nprint(f\"System GMM: {sys_gmm.params['y_lag1']:.3f} (SE: {sys_gmm.std_errors['y_lag1']:.3f})\")\n\n# Efficiency gain\nse_reduction = (1 - sys_gmm.std_errors['y_lag1'] / diff_gmm.std_errors['y_lag1']) * 100\nprint(f\"SE reduction: {se_reduction:.1f}%\")\n\n# Check System GMM assumptions\nprint(f\"\\nDifference-in-Hansen p-value: {sys_gmm.diff_hansen.pvalue:.3f}\")\n</code></pre>"},{"location":"guides/gmm_explained/#key-takeaways","title":"Key Takeaways","text":"<p>\ud83d\udd11 GMM is needed when: - Lagged dependent variable (dynamics) - Fixed Effects creates Nickell bias - Short panel (T &lt; 20)</p> <p>\ud83d\udd11 Difference GMM: - First-difference to eliminate \u03b1_i - Use lagged levels as instruments - Moment condition: E[y_{i,t-s} \u0394\u03b5_it] = 0</p> <p>\ud83d\udd11 System GMM: - Add level equations to Difference GMM - Use lagged differences as instruments for levels - More efficient for persistent series - Extra assumption: E[\u0394y_{i1} \u03b1_i] = 0</p> <p>\ud83d\udd11 Always collapse: - Avoid instrument proliferation - Keep q/N &lt; 1 - Instrument ratio &lt; 2.0</p> <p>\ud83d\udd11 Diagnostic tests are mandatory: - Hansen J &gt; 0.10 (instruments valid) - AR(2) &gt; 0.10 (no serial correlation) - If tests fail, do not use results!</p>"},{"location":"guides/gmm_explained/#next-steps","title":"Next Steps","text":"<p>Hands-on learning:</p> <ol> <li> <p>Tutorial 3: GMM Intro: Practical GMM estimation</p> </li> <li> <p>How-To: Interpret Tests: Test interpretation details</p> </li> </ol> <p>Further reading:</p> <p>Foundational papers: - Arellano &amp; Bond (1991): \"Some Tests of Specification for Panel Data\", Review of Economic Studies - Blundell &amp; Bond (1998): \"Initial Conditions and Moment Restrictions\", Journal of Econometrics - Windmeijer (2005): \"A Finite Sample Correction\", Journal of Econometrics</p> <p>Practical guides: - Roodman (2009): \"How to do xtabond2\", The Stata Journal (best practical guide) - Bond (2002): \"Dynamic Panel Data Models: A Guide\", Portuguese Economic Journal</p> <p>Textbooks: - Baltagi (2021): Econometric Analysis of Panel Data, Chapter 8 - Wooldridge (2010): Cross Section and Panel Data, Chapter 11 - Arellano (2003): Panel Data Econometrics (advanced)</p> <p>GMM is powerful for dynamic panels, but requires careful diagnostic checking. Always use collapse, always check Hansen J and AR(2), and never report results if tests fail!</p>"},{"location":"guides/panel_data_intro/","title":"Introduction to Panel Data","text":"<p>Understanding panel data structure, advantages, and when to use panel methods.</p>"},{"location":"guides/panel_data_intro/#what-is-panel-data","title":"What is Panel Data?","text":"<p>Panel data (also called longitudinal data or cross-sectional time-series data) combines two dimensions:</p> <ol> <li>Cross-sectional: Multiple entities (firms, individuals, countries, etc.)</li> <li>Time-series: Each entity observed over multiple time periods</li> </ol> <p>Example:</p> <pre><code>   firm  year   sales  profit\n0     1  2020   100.0    10.0\n1     1  2021   120.0    15.0\n2     1  2022   135.0    18.0\n3     2  2020    80.0     8.0\n4     2  2021    85.0     9.0\n5     2  2022    90.0    10.0\n</code></pre> <p>Structure: - N = 2 firms (cross-sectional units) - T = 3 years (time periods) - N \u00d7 T = 6 observations</p>"},{"location":"guides/panel_data_intro/#panel-data-vs-other-data-types","title":"Panel Data vs Other Data Types","text":""},{"location":"guides/panel_data_intro/#cross-sectional-data","title":"Cross-Sectional Data","text":"<p>One observation per entity at one point in time:</p> <pre><code>   firm   sales  profit\n0     1   120.0    15.0\n1     2    85.0     9.0\n2     3   150.0    20.0\n</code></pre> <ul> <li>N entities, T = 1</li> <li>Cannot study dynamics (changes over time)</li> <li>Cannot control for unobserved time-invariant characteristics</li> </ul>"},{"location":"guides/panel_data_intro/#time-series-data","title":"Time-Series Data","text":"<p>One entity observed over multiple time periods:</p> <pre><code>   year   gdp  inflation\n0  2020  20.5       2.1\n1  2021  21.2       2.5\n2  2022  21.8       3.2\n</code></pre> <ul> <li>N = 1 entity, T periods</li> <li>Can study dynamics</li> <li>Cannot control for cross-sectional heterogeneity</li> </ul>"},{"location":"guides/panel_data_intro/#panel-data","title":"Panel Data","text":"<p>Multiple entities over multiple time periods:</p> <pre><code>   country  year   gdp  inflation\n0      USA  2020  20.5       2.1\n1      USA  2021  21.2       2.5\n2      CAN  2020  1.65       0.7\n3      CAN  2021  1.72       1.2\n</code></pre> <ul> <li>N entities, T periods</li> <li>Can study both dynamics AND control for heterogeneity</li> <li>Best of both worlds!</li> </ul>"},{"location":"guides/panel_data_intro/#types-of-panel-data","title":"Types of Panel Data","text":""},{"location":"guides/panel_data_intro/#balanced-panel","title":"Balanced Panel","text":"<p>Every entity observed in all time periods.</p> <p>Example:</p> <pre><code>   firm  year  sales\n0     1  2020    100\n1     1  2021    120  \u2190 Firm 1: all 3 years \u2713\n2     1  2022    135\n3     2  2020     80\n4     2  2021     85  \u2190 Firm 2: all 3 years \u2713\n5     2  2022     90\n</code></pre> <p>Characteristics: - All N entities have exactly T observations - Total observations = N \u00d7 T - Easier to analyze (some methods require balance)</p>"},{"location":"guides/panel_data_intro/#unbalanced-panel","title":"Unbalanced Panel","text":"<p>Some entities missing in some periods.</p> <p>Example:</p> <pre><code>   firm  year  sales\n0     1  2020    100\n1     1  2021    120  \u2190 Firm 1: only 2 years\n2     2  2020     80\n3     2  2021     85\n4     2  2022     90  \u2190 Firm 2: all 3 years\n5     3  2021    200\n6     3  2022    215  \u2190 Firm 3: only 2 years\n</code></pre> <p>Characteristics: - Different T_i for different entities - Total observations &lt; N \u00d7 T_max - Common in practice (attrition, entry/exit) - PanelBox handles unbalanced panels automatically</p>"},{"location":"guides/panel_data_intro/#short-vs-long-panels","title":"Short vs Long Panels","text":"<p>Short (wide) panel: Large N, small T - Example: N = 10,000 individuals, T = 5 years - Typical in microeconometrics (firm, household data) - Asymptotic theory: N \u2192 \u221e, T fixed - Use: Fixed Effects, Random Effects, GMM</p> <p>Long (narrow) panel: Small N, large T - Example: N = 50 countries, T = 60 years - Typical in macroeconomics - Asymptotic theory: T \u2192 \u221e (or both N,T \u2192 \u221e) - Use: Panel cointegration, panel VARs, unit root tests</p>"},{"location":"guides/panel_data_intro/#advantages-of-panel-data","title":"Advantages of Panel Data","text":""},{"location":"guides/panel_data_intro/#1-control-for-unobserved-heterogeneity","title":"1. Control for Unobserved Heterogeneity","text":"<p>Problem (cross-sectional): Omitted variable bias</p> <p>Example: Estimate effect of education on wages</p> <pre><code>wage_i = \u03b2\u2080 + \u03b2\u2081\u00b7education_i + \u03b5_i\n</code></pre> <p>Omitted: \"Ability\" (unobserved, correlated with education)</p> <p>Bias: \u03b2\u0302\u2081 overestimates education effect</p> <p>Solution (panel): Individual fixed effects</p> <pre><code>wage_it = \u03b1_i + \u03b2\u2081\u00b7education_it + \u03b5_it\n</code></pre> <p>Where <code>\u03b1_i</code> captures time-invariant ability.</p> <p>Result: Consistent estimate of \u03b2\u2081 (controls for ability)</p>"},{"location":"guides/panel_data_intro/#2-more-degrees-of-freedom","title":"2. More Degrees of Freedom","text":"<p>Cross-sectional: N = 500 observations</p> <p>Panel: N = 500 firms, T = 10 years \u2192 5,000 observations</p> <p>Benefits: - More precise estimates (smaller standard errors) - Can estimate more parameters - Better power for hypothesis tests</p>"},{"location":"guides/panel_data_intro/#3-study-dynamics","title":"3. Study Dynamics","text":"<p>Panel allows: Including lagged dependent variables</p> <pre><code>y_it = \u03b3\u00b7y_i,t-1 + \u03b2\u00b7x_it + \u03b1_i + \u03b5_it\n</code></pre> <p>Examples: - Investment depends on past investment (habit formation) - Current health depends on past health (state dependence) - GDP growth exhibits persistence</p> <p>Cross-sectional data: Cannot estimate \u03b3</p>"},{"location":"guides/panel_data_intro/#4-identify-effects-better","title":"4. Identify Effects Better","text":"<p>With panel data, you can identify:</p> <ul> <li>Within-entity effects: How does X affect Y within the same firm over time?</li> <li>Between-entity effects: How do differences in X across firms relate to Y?</li> </ul> <p>Example: Effect of firm size on productivity</p> <ul> <li>Within: As a firm grows, does productivity increase?</li> <li>Between: Are larger firms more productive than smaller ones?</li> </ul> <p>These can differ! Panel data lets you distinguish them.</p>"},{"location":"guides/panel_data_intro/#5-reduce-collinearity","title":"5. Reduce Collinearity","text":"<p>Problem (cross-sectional): Two variables highly correlated</p> <p>Panel: Variation within entities over time may differ from variation between entities</p> <p>Example: - Cross-sectionally: Education and income highly correlated - Within-person over time: Education changes slowly, income fluctuates</p> <p>Result: Better identification of separate effects</p>"},{"location":"guides/panel_data_intro/#disadvantages-and-challenges","title":"Disadvantages and Challenges","text":""},{"location":"guides/panel_data_intro/#1-data-collection-costs","title":"1. Data Collection Costs","text":"<p>Panel data requires: - Tracking same entities over time - Consistent measurement across periods - Dealing with attrition (entities leaving sample)</p> <p>Cost: More expensive than single cross-section</p>"},{"location":"guides/panel_data_intro/#2-attrition-bias","title":"2. Attrition Bias","text":"<p>Problem: Entities drop out non-randomly</p> <p>Example: Less profitable firms exit market</p> <p>Bias: Surviving firms are systematically different</p> <p>Solutions: - Attrition correction models - Selection models (Heckman) - Inverse probability weighting</p>"},{"location":"guides/panel_data_intro/#3-limited-time-variation","title":"3. Limited Time Variation","text":"<p>Problem: Some variables don't change much over time</p> <p>Example: Education, gender, country of birth</p> <p>Issue: Fixed Effects drops time-invariant variables</p> <p>Trade-off: Can't estimate effect of time-invariant X with FE</p>"},{"location":"guides/panel_data_intro/#4-short-panels-and-bias","title":"4. Short Panels and Bias","text":"<p>Problem: With small T, Fixed Effects has bias (Nickell bias)</p> <p>Magnitude: O(1/T), so T &lt; 10 can be problematic</p> <p>Solution: Use GMM estimators instead</p>"},{"location":"guides/panel_data_intro/#5-complex-analysis","title":"5. Complex Analysis","text":"<p>Panel methods are more complex: - Need to choose between Pooled OLS, FE, RE, GMM - More diagnostic tests required - More assumptions to verify - Computational burden (large N \u00d7 T)</p>"},{"location":"guides/panel_data_intro/#panel-data-notation","title":"Panel Data Notation","text":""},{"location":"guides/panel_data_intro/#standard-notation","title":"Standard Notation","text":"<p>Entity index: i = 1, 2, ..., N</p> <p>Time index: t = 1, 2, ..., T (or T_i if unbalanced)</p> <p>Observation: y_it (outcome for entity i at time t)</p> <p>Regressor: X_it (can be scalar or vector)</p>"},{"location":"guides/panel_data_intro/#common-subscript-conventions","title":"Common Subscript Conventions","text":"Symbol Meaning Example y_it Observation i at time t sales_it y_i,t-1 Observation i at time t-1 (lag) sales_i,t-1 \u0233_i Entity i mean over time \u0233_i = (1/T)\u03a3_t y_it \u0233_t Time t mean over entities \u0233_t = (1/N)\u03a3_i y_it \u0233 Grand mean \u0233 = (1/NT)\u03a3_i \u03a3_t y_it"},{"location":"guides/panel_data_intro/#panel-transformations","title":"Panel Transformations","text":"<p>Within (demeaning): <pre><code>\u1ef9_it = y_it - \u0233_i\n</code></pre> Removes entity-specific means (used in Fixed Effects)</p> <p>Between (entity means): <pre><code>\u0233_i = (1/T_i)\u03a3_t y_it\n</code></pre> Cross-sectional regression of entity means</p> <p>First-difference: <pre><code>\u0394y_it = y_it - y_i,t-1\n</code></pre> Removes time-invariant effects (used in Difference GMM)</p>"},{"location":"guides/panel_data_intro/#when-to-use-panel-methods","title":"When to Use Panel Methods","text":""},{"location":"guides/panel_data_intro/#use-panel-methods-when","title":"Use Panel Methods When:","text":"<p>\u2705 You have multiple entities observed over multiple periods</p> <p>\u2705 Unobserved entity-specific effects likely exist</p> <p>\u2705 These effects may be correlated with regressors</p> <p>\u2705 You want to study dynamics or changes over time</p> <p>\u2705 You want more precise estimates (more data)</p>"},{"location":"guides/panel_data_intro/#use-cross-sectional-methods-when","title":"Use Cross-Sectional Methods When:","text":"<p>\u274c Only one time period available</p> <p>\u274c No unobserved heterogeneity</p> <p>\u274c Pooled OLS is sufficient (Breusch-Pagan test confirms)</p> <p>\u274c Time dimension is irrelevant to research question</p>"},{"location":"guides/panel_data_intro/#use-time-series-methods-when","title":"Use Time-Series Methods When:","text":"<p>\u274c Only one entity</p> <p>\u274c Focus is on aggregate dynamics, forecasting</p> <p>\u274c Interested in unit roots, cointegration for single series</p>"},{"location":"guides/panel_data_intro/#common-applications","title":"Common Applications","text":""},{"location":"guides/panel_data_intro/#microeconometrics","title":"Microeconometrics","text":"<p>Labor economics: - Wage determination over worker careers - Effect of education/training on earnings - Employment dynamics</p> <p>Corporate finance: - Firm investment decisions - Capital structure choices - Dividend policy</p> <p>Industrial organization: - Firm productivity evolution - Market entry/exit - Price dynamics</p>"},{"location":"guides/panel_data_intro/#macroeconomics","title":"Macroeconomics","text":"<p>Growth: - Determinants of economic growth across countries - Convergence testing - Institutions and development</p> <p>Trade: - Gravity models of bilateral trade - Effects of trade agreements - Exchange rate effects</p> <p>Public finance: - Tax competition between jurisdictions - Government spending effects - Fiscal policy effectiveness</p>"},{"location":"guides/panel_data_intro/#health-economics","title":"Health Economics","text":"<p>Individual health: - Health production functions - Effect of insurance on utilization - Lifestyle choices and outcomes</p> <p>Hospital performance: - Quality and efficiency over time - Policy interventions - Technology adoption</p>"},{"location":"guides/panel_data_intro/#development-economics","title":"Development Economics","text":"<p>Households: - Poverty dynamics - Consumption smoothing - Migration decisions</p> <p>Villages/regions: - Development program effects - Infrastructure impact - Climate shocks</p>"},{"location":"guides/panel_data_intro/#example-why-panel-data-matters","title":"Example: Why Panel Data Matters","text":""},{"location":"guides/panel_data_intro/#cross-sectional-analysis-wrong","title":"Cross-Sectional Analysis (Wrong)","text":"<p>Data: 100 firms in 2022</p> <p>Model: <pre><code>profit_i = \u03b2\u2080 + \u03b2\u2081\u00b7size_i + \u03b5_i\n</code></pre></p> <p>Result: \u03b2\u0302\u2081 = 0.15 (larger firms more profitable)</p> <p>Problem: Omitted variable bias! - Management quality (\u03b1_i) affects both size and profit - Correlation between \u03b1_i and size biases \u03b2\u0302\u2081 upward</p>"},{"location":"guides/panel_data_intro/#panel-analysis-correct","title":"Panel Analysis (Correct)","text":"<p>Data: Same 100 firms, 2015-2022 (T=8 years)</p> <p>Model: <pre><code>profit_it = \u03b1_i + \u03b2\u2081\u00b7size_it + \u03b5_it\n</code></pre></p> <p>Result: \u03b2\u0302\u2081 = 0.08 (smaller effect after controlling for \u03b1_i)</p> <p>Interpretation: Within a firm, size increases profit by 0.08 (not 0.15)</p> <p>Key insight: Cross-sectional estimate was biased by 87.5%!</p>"},{"location":"guides/panel_data_intro/#what-changed","title":"What Changed?","text":"<p>Fixed Effects controls for time-invariant firm characteristics: - Management quality - Industry - Location - Culture - Brand value</p> <p>Result: Estimates the causal effect of size on profit</p>"},{"location":"guides/panel_data_intro/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 Panel data = Cross-sectional + Time-series</p> <p>\u2705 Advantages: - Control for unobserved heterogeneity - Study dynamics - More data (precision) - Better identification</p> <p>\u26a0\ufe0f Challenges: - Data collection costs - Attrition - Complexity of methods - Short panel bias</p> <p>\ud83c\udfaf When to use: - Multiple entities, multiple periods - Unobserved effects likely correlated with X - Want to study changes over time</p>"},{"location":"guides/panel_data_intro/#next-steps","title":"Next Steps","text":"<p>Learn the methods:</p> <ol> <li> <p>Tutorial 1: Getting Started: Your first panel model</p> </li> <li> <p>Tutorial 2: Static Models: Pooled OLS, FE, RE</p> </li> <li> <p>How-To: Choose Model: Decision guide</p> </li> </ol> <p>Deep dives:</p> <ol> <li> <p>Guide: Fixed vs Random: Detailed comparison</p> </li> <li> <p>Guide: GMM Explained: Dynamic panel methods</p> </li> </ol> <p>Further reading:</p> <ul> <li>Hsiao (2014): Analysis of Panel Data (3<sup>rd</sup> ed.)</li> <li>Wooldridge (2010): Econometric Analysis of Cross Section and Panel Data</li> <li>Baltagi (2021): Econometric Analysis of Panel Data (6<sup>th</sup> ed.)</li> </ul> <p>Panel data is powerful because it lets you see both across entities AND over time\u2014giving you two sources of variation to identify effects more credibly.</p>"},{"location":"how-to/choose_model/","title":"How to Choose the Right Panel Model","text":"<p>Decision guide for selecting the appropriate estimator for your data and research question.</p>"},{"location":"how-to/choose_model/#quick-decision-tree","title":"Quick Decision Tree","text":"<pre><code>START: Do you have panel data (entities \u00d7 time)?\n\u2502\n\u251c\u2500 NO \u2192 Use cross-sectional or time-series methods\n\u2502\n\u2514\u2500 YES \u2192 Continue below\n    \u2502\n    \u251c\u2500 Q1: Does y_it depend on y_i,t-1 (lagged dependent)?\n    \u2502   \u2502\n    \u2502   \u251c\u2500 YES \u2192 **Use GMM** (go to GMM Decision Tree)\n    \u2502   \u2502\n    \u2502   \u2514\u2500 NO \u2192 Q2: Is there unobserved heterogeneity?\n    \u2502       \u2502\n    \u2502       \u251c\u2500 NO \u2192 **Pooled OLS**\n    \u2502       \u2502\n    \u2502       \u2514\u2500 YES \u2192 Q3: Are effects correlated with X?\n    \u2502           \u2502\n    \u2502           \u251c\u2500 YES \u2192 **Fixed Effects**\n    \u2502           \u2502\n    \u2502           \u251c\u2500 NO \u2192 **Random Effects**\n    \u2502           \u2502\n    \u2502           \u2514\u2500 UNSURE \u2192 Run **Hausman Test**\n    \u2502               \u251c\u2500 p &lt; 0.05 \u2192 **Fixed Effects**\n    \u2502               \u2514\u2500 p \u2265 0.05 \u2192 **Random Effects**\n</code></pre>"},{"location":"how-to/choose_model/#detailed-decision-guide","title":"Detailed Decision Guide","text":""},{"location":"how-to/choose_model/#step-1-check-for-dynamics","title":"Step 1: Check for Dynamics","text":"<p>Question: Does your dependent variable depend on its past values?</p> <p>Examples of dynamic models: - Employment depends on past employment - Investment depends on past investment - GDP growth depends on past growth</p> <p>Decision: - YES \u2192 Use GMM (Difference or System GMM) - NO \u2192 Continue to Step 2</p> <p>Why GMM? Including y_{t-1} as a regressor creates correlation with the error term. Fixed Effects and Random Effects are biased in this case. GMM uses instruments to handle this endogeneity.</p>"},{"location":"how-to/choose_model/#step-2-test-for-unobserved-heterogeneity","title":"Step 2: Test for Unobserved Heterogeneity","text":"<p>Question: Are there entity-specific factors you can't observe but matter?</p> <p>Examples: - Firm \"culture\" or management quality - Individual \"ability\" or preferences - Country institutions or geography</p> <p>How to test: 1. Estimate both Pooled OLS and Fixed Effects 2. Compare R-squared values 3. Run F-test for fixed effects</p> <pre><code>import panelbox as pb\n\n# Pooled OLS\npooled = pb.PooledOLS(\"y ~ x1 + x2\", data, \"entity\", \"time\")\npooled_results = pooled.fit()\n\n# Fixed Effects\nfe = pb.FixedEffects(\"y ~ x1 + x2\", data, \"entity\", \"time\")\nfe_results = fe.fit()\n\n# Compare R-squared\nprint(f\"Pooled R\u00b2: {pooled_results.rsquared:.4f}\")\nprint(f\"FE R\u00b2: {fe_results.rsquared_within:.4f}\")\n\n# If FE R\u00b2 much higher \u2192 unobserved heterogeneity exists\n</code></pre> <p>Decision: - NO heterogeneity \u2192 Pooled OLS - YES heterogeneity \u2192 Continue to Step 3</p>"},{"location":"how-to/choose_model/#step-3-hausman-test-fe-vs-re","title":"Step 3: Hausman Test (FE vs RE)","text":"<p>Question: Are the entity-specific effects correlated with your regressors?</p> <p>Run Hausman test:</p> <pre><code># Estimate both models\nfe = pb.FixedEffects(\"y ~ x1 + x2\", data, \"entity\", \"time\")\nre = pb.RandomEffects(\"y ~ x1 + x2\", data, \"entity\", \"time\")\n\nfe_results = fe.fit()\nre_results = re.fit()\n\n# Hausman test\nhausman = pb.HausmanTest(fe_results, re_results)\nprint(hausman)\n</code></pre> <p>Interpretation:</p> <ul> <li>p &lt; 0.05 (reject H0) \u2192 Use Fixed Effects</li> <li>Effects are correlated with X</li> <li> <p>RE is biased and inconsistent</p> </li> <li> <p>p \u2265 0.05 (fail to reject) \u2192 Use Random Effects</p> </li> <li>No evidence of correlation</li> <li>RE is more efficient (smaller standard errors)</li> </ul>"},{"location":"how-to/choose_model/#model-comparison-table","title":"Model Comparison Table","text":"Model Use When Assumptions Pros Cons Pooled OLS No heterogeneity, no dynamics - Strict exogeneity- No unobserved effects - Simple- Efficient - Biased if heterogeneity- Ignores panel structure Fixed Effects Unobserved heterogeneity correlated with X - Strict exogeneity- E[\u03b1_i X_it] \u2260 0 allowed - Consistent- Controls unobserved factors - Can't estimate time-invariant effects- Less efficient than RE Random Effects Unobserved heterogeneity uncorrelated with X - E[\u03b1_i X_it] = 0 - Can estimate time-invariant- More efficient - Inconsistent if E[\u03b1_i X_it] \u2260 0- Stronger assumptions Difference GMM Dynamics + short T - Lagged dependent- E[y_{t-s} \u0394\u03b5_t] = 0 - Handles dynamics- Allows endogeneity - Weak instruments if persistent- Requires T \u2265 3 System GMM Dynamics + persistent series - Same as Diff GMM- E[\u0394y_{i1} \u03b7_i] = 0 - More efficient- Better for persistent - Extra assumption- More complex"},{"location":"how-to/choose_model/#gmm-decision-tree","title":"GMM Decision Tree","text":"<p>If your model has dynamics (lagged dependent variable):</p> <pre><code>GMM DECISION TREE\n\u2502\n\u251c\u2500 Q1: How persistent is your series?\n\u2502   \u2502\n\u2502   \u251c\u2500 Highly persistent (AR coef &gt; 0.8)\n\u2502   \u2502   \u2192 **System GMM**\n\u2502   \u2502       - Lagged levels are weak instruments\n\u2502   \u2502       - Need additional moment conditions\n\u2502   \u2502\n\u2502   \u2514\u2500 Moderately persistent (AR coef &lt; 0.8)\n\u2502       \u2192 **Difference GMM**\n\u2502           - Sufficient instrument strength\n\u2502           - Fewer assumptions\n\u2502\n\u251c\u2500 Q2: Panel starts at event time? (firm entry, policy change)\n\u2502   \u2502\n\u2502   \u251c\u2500 YES \u2192 **Difference GMM**\n\u2502   \u2502       - Initial conditions assumption violated\n\u2502   \u2502\n\u2502   \u2514\u2500 NO \u2192 Can use either (System GMM more efficient)\n\u2502\n\u2514\u2500 Q3: How many time periods?\n    \u2502\n    \u251c\u2500 T &lt; 5 \u2192 **Difficult** (consider static FE)\n    \u251c\u2500 5 \u2264 T &lt; 10 \u2192 **Difference or System GMM**\n    \u2514\u2500 T \u2265 10 \u2192 **Either works well**\n</code></pre>"},{"location":"how-to/choose_model/#checklist-approach","title":"Checklist Approach","text":"<p>Use this checklist to narrow down your choice:</p>"},{"location":"how-to/choose_model/#pooled-ols","title":"[ ] Pooled OLS","text":"<ul> <li> No unobserved entity-specific effects</li> <li> All entities are homogeneous</li> <li> Errors are i.i.d. across entities and time</li> <li> Just want a baseline/benchmark</li> </ul>"},{"location":"how-to/choose_model/#fixed-effects","title":"[ ] Fixed Effects","text":"<ul> <li> Unobserved heterogeneity exists</li> <li> Effects likely correlated with regressors</li> <li> Don't need to estimate time-invariant effects</li> <li> Have T \u2265 2 observations per entity</li> <li> Hausman test rejects Random Effects</li> </ul>"},{"location":"how-to/choose_model/#random-effects","title":"[ ] Random Effects","text":"<ul> <li> Unobserved heterogeneity exists</li> <li> Effects uncorrelated with regressors</li> <li> Want to estimate time-invariant effects (e.g., gender, geography)</li> <li> Sample is random draw from population</li> <li> Hausman test supports Random Effects</li> </ul>"},{"location":"how-to/choose_model/#difference-gmm","title":"[ ] Difference GMM","text":"<ul> <li> Dependent variable depends on its lag</li> <li> Short panel (small T, large N)</li> <li> Series not highly persistent</li> <li> Panel may start at \"event time\"</li> <li> Strict exogeneity fails</li> </ul>"},{"location":"how-to/choose_model/#system-gmm","title":"[ ] System GMM","text":"<ul> <li> Dependent variable depends on its lag</li> <li> Series is highly persistent (\u03c1 &gt; 0.8)</li> <li> Panel is stationary (not starting at event)</li> <li> Want most efficient estimates</li> <li> Can justify initial conditions assumption</li> </ul>"},{"location":"how-to/choose_model/#common-scenarios","title":"Common Scenarios","text":""},{"location":"how-to/choose_model/#scenario-1-firm-investment","title":"Scenario 1: Firm Investment","text":"<p>Setup: Studying firm investment decisions - N = 500 firms, T = 10 years - Variables: Investment, sales, debt, size</p> <p>Decision: 1. Investment likely depends on past investment \u2192 Dynamic 2. Firms differ in unmeasured ways (management, culture) 3. These likely correlate with sales/debt</p> <p>Choice: System GMM (dynamic + persistent) or Difference GMM (conservative)</p>"},{"location":"how-to/choose_model/#scenario-2-wage-determination","title":"Scenario 2: Wage Determination","text":"<p>Setup: Worker wages over career - N = 5,000 individuals, T = 5 years - Variables: Wage, experience, education, industry</p> <p>Decision: 1. No strong dynamic component (wage_{t-1} doesn't directly cause wage_t) 2. Individual \"ability\" is unobserved and correlated with education 3. Want to control for this</p> <p>Choice: Fixed Effects</p>"},{"location":"how-to/choose_model/#scenario-3-country-growth","title":"Scenario 3: Country Growth","text":"<p>Setup: Economic growth across countries - N = 100 countries, T = 40 years - Variables: GDP growth, investment, education, institutions</p> <p>Decision: 1. Growth may depend on past growth \u2192 Dynamic 2. Institutions are time-invariant and important 3. Want to estimate institutional effects</p> <p>Choice: Random Effects if no dynamics, System GMM if including lagged growth</p>"},{"location":"how-to/choose_model/#testing-your-choice","title":"Testing Your Choice","text":"<p>After selecting a model, validate your choice:</p>"},{"location":"how-to/choose_model/#1-specification-tests","title":"1. Specification Tests","text":"<pre><code># Run diagnostic tests\nresults = model.fit()\n\n# Check residuals\nresults.plot_residuals()  # Should be random\n\n# Heteroskedasticity test\nfrom panelbox.validation import BreuschPaganTest\nbp_test = BreuschPaganTest(results)\nprint(bp_test)  # p &gt; 0.05 is good\n</code></pre>"},{"location":"how-to/choose_model/#2-robustness-checks","title":"2. Robustness Checks","text":"<ul> <li>Try alternative models and compare</li> <li>Add/remove variables to check stability</li> <li>Different subsamples (time periods, entity groups)</li> <li>Different standard errors (robust, clustered)</li> </ul>"},{"location":"how-to/choose_model/#3-for-gmm-diagnostic-tests","title":"3. For GMM: Diagnostic Tests","text":"<pre><code># Hansen J-test (overidentification)\nprint(f\"Hansen J p-value: {results.hansen_j.pvalue:.3f}\")\n# p &gt; 0.10 is good\n\n# AR(2) test (no serial correlation)\nprint(f\"AR(2) p-value: {results.ar2_test.pvalue:.3f}\")\n# p &gt; 0.10 is good\n\n# Instrument ratio\nprint(f\"Instrument ratio: {results.instrument_ratio:.2f}\")\n# &lt; 1.0 is good\n</code></pre>"},{"location":"how-to/choose_model/#common-mistakes","title":"Common Mistakes","text":"<p>\u274c Using Pooled OLS when FE/RE is needed - Leads to omitted variable bias - Standard errors are too small (over-rejection)</p> <p>\u274c Using Random Effects when Fixed Effects is correct - Estimates are biased and inconsistent - Hausman test will reject</p> <p>\u274c Using Fixed Effects for dynamics - Nickell bias (biased estimates) - Use GMM instead</p> <p>\u274c Using too many instruments in GMM - Overfitting (instrument proliferation) - Always use <code>collapse=True</code></p> <p>\u274c Ignoring diagnostic tests - GMM tests tell you if estimates are valid - Don't skip Hansen J and AR(2) tests!</p>"},{"location":"how-to/choose_model/#summary-flowchart","title":"Summary Flowchart","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Do you have lagged dependent var?  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502           \u2502\n    YES         NO\n     \u2502           \u2502\n     v           v\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 GMM  \u2502   \u2502 Static   \u2502\n  \u2502      \u2502   \u2502 Models   \u2502\n  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502            \u2502\n     \u2502            v\n     \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502       \u2502 Hausman    \u2502\n     \u2502       \u2502 Test       \u2502\n     \u2502       \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n     \u2502          \u2502     \u2502\n     \u2502          \u2502     v\n     \u2502          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502          \u2502  \u2502  RE  \u2502\n     \u2502          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502          v\n     \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502       \u2502  FE  \u2502\n     \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Persistent?  \u2502\n\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2518\n   \u2502        \u2502\nSystem    Difference\n GMM        GMM\n</code></pre>"},{"location":"how-to/choose_model/#further-reading","title":"Further Reading","text":"<ul> <li>Wooldridge (2010) Chapter 10-11: FE vs RE, dynamics</li> <li>Baltagi (2021) Chapter 2-8: All static models</li> <li>Arellano &amp; Bond (1991): Difference GMM</li> <li>Blundell &amp; Bond (1998): System GMM</li> <li>Roodman (2009): Practical guide to GMM</li> </ul>"},{"location":"how-to/choose_model/#need-help","title":"Need Help?","text":"<p>Still unsure which model to use?</p> <ol> <li>Static Models Tutorial: Compare FE, RE, Pooled</li> <li>GMM Tutorial: Learn when GMM is needed</li> <li>GitHub Discussions: Ask the community</li> </ol> <p>Remember: The right model depends on your data structure, research question, and the assumptions you're willing to make. When in doubt, estimate multiple models and compare!</p>"},{"location":"how-to/install/","title":"How to Install PanelBox","text":"<p>Quick guide to installing PanelBox in various environments.</p>"},{"location":"how-to/install/#quick-install-recommended","title":"Quick Install (Recommended)","text":"<p>Install the latest stable version from PyPI:</p> <pre><code>pip install panelbox\n</code></pre> <p>That's it! PanelBox and all its dependencies will be installed.</p>"},{"location":"how-to/install/#requirements","title":"Requirements","text":"<p>Python Version: - Python \u2265 3.9 (3.9, 3.10, 3.11, 3.12 supported)</p> <p>Core Dependencies (installed automatically): - NumPy \u2265 1.24.0 - Pandas \u2265 2.0.0 - SciPy \u2265 1.10.0 - statsmodels \u2265 0.14.0 - patsy \u2265 0.5.3</p> <p>Optional Dependencies: - matplotlib \u2265 3.5.0 (for plotting) - numba \u2265 0.56.0 (for performance optimization)</p>"},{"location":"how-to/install/#installation-methods","title":"Installation Methods","text":""},{"location":"how-to/install/#1-using-pip-recommended","title":"1. Using pip (Recommended)","text":"<p>Standard installation: <pre><code>pip install panelbox\n</code></pre></p> <p>With optional dependencies: <pre><code># With plotting support\npip install panelbox[plots]\n\n# With performance optimization\npip install panelbox[performance]\n\n# With development tools\npip install panelbox[dev]\n\n# Everything\npip install panelbox[all]\n</code></pre></p> <p>Upgrade to latest version: <pre><code>pip install --upgrade panelbox\n</code></pre></p>"},{"location":"how-to/install/#2-using-conda","title":"2. Using conda","text":"<p>PanelBox is also available via conda-forge:</p> <pre><code>conda install -c conda-forge panelbox\n</code></pre>"},{"location":"how-to/install/#3-from-source-development","title":"3. From Source (Development)","text":"<p>Install the latest development version from GitHub:</p> <pre><code># Clone repository\ngit clone https://github.com/PanelBox-Econometrics-Model/panelbox.git\ncd panelbox\n\n# Install in editable mode\npip install -e .\n\n# Or with development dependencies\npip install -e \".[dev]\"\n</code></pre>"},{"location":"how-to/install/#virtual-environments","title":"Virtual Environments","text":"<p>Recommended: Always use a virtual environment to avoid dependency conflicts.</p>"},{"location":"how-to/install/#using-venv-built-in","title":"Using venv (Built-in)","text":"<pre><code># Create virtual environment\npython -m venv panelbox_env\n\n# Activate (Linux/Mac)\nsource panelbox_env/bin/activate\n\n# Activate (Windows)\npanelbox_env\\Scripts\\activate\n\n# Install PanelBox\npip install panelbox\n</code></pre>"},{"location":"how-to/install/#using-conda","title":"Using conda","text":"<pre><code># Create environment\nconda create -n panelbox_env python=3.11\n\n# Activate\nconda activate panelbox_env\n\n# Install\nconda install -c conda-forge panelbox\n# or: pip install panelbox\n</code></pre>"},{"location":"how-to/install/#verify-installation","title":"Verify Installation","text":"<p>Check that PanelBox is installed correctly:</p> <pre><code>import panelbox as pb\nprint(f\"PanelBox version: {pb.__version__}\")\n\n# Test basic functionality\ndata = pb.load_grunfeld()\nprint(f\"Loaded {len(data)} observations\")\n</code></pre> <p>Expected output: <pre><code>PanelBox version: 1.0.0\nLoaded 200 observations\n</code></pre></p>"},{"location":"how-to/install/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"how-to/install/#windows","title":"Windows","text":"<p>Issue: Some users report installation errors related to NumPy/SciPy.</p> <p>Solution: Install via Anaconda/Miniconda: <pre><code>conda install -c conda-forge panelbox\n</code></pre></p> <p>Or use pre-built wheels: <pre><code>pip install --only-binary :all: panelbox\n</code></pre></p>"},{"location":"how-to/install/#macos-apple-silicon-m1m2","title":"macOS (Apple Silicon M1/M2)","text":"<p>Issue: Native ARM64 wheels may not be available for all dependencies.</p> <p>Solution 1 - Rosetta (stable): <pre><code>arch -x86_64 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\narch -x86_64 pip install panelbox\n</code></pre></p> <p>Solution 2 - Native ARM64 (recommended): <pre><code># Use miniforge (ARM64-native conda)\nconda install -c conda-forge panelbox\n</code></pre></p>"},{"location":"how-to/install/#linux","title":"Linux","text":"<p>Should work out-of-the-box on all major distributions.</p> <p>If build tools are missing: <pre><code># Ubuntu/Debian\nsudo apt-get install python3-dev build-essential\n\n# RHEL/CentOS/Fedora\nsudo yum install python3-devel gcc gcc-c++\n\n# Then install\npip install panelbox\n</code></pre></p>"},{"location":"how-to/install/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/install/#import-error-no-module-named-panelbox","title":"Import Error: No module named 'panelbox'","text":"<p>Cause: PanelBox not installed or wrong Python environment</p> <p>Solution: <pre><code># Check if installed\npip list | grep panelbox\n\n# If not found, install\npip install panelbox\n\n# Check Python executable\nwhich python  # Linux/Mac\nwhere python  # Windows\n</code></pre></p>"},{"location":"how-to/install/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>Cause: Conflicting package versions</p> <p>Solution 1 - Fresh virtual environment: <pre><code>python -m venv fresh_env\nsource fresh_env/bin/activate  # Linux/Mac\npip install panelbox\n</code></pre></p> <p>Solution 2 - Update dependencies: <pre><code>pip install --upgrade numpy pandas scipy statsmodels\npip install panelbox\n</code></pre></p>"},{"location":"how-to/install/#importerror-dll-load-failed-windows","title":"ImportError: DLL load failed (Windows)","text":"<p>Cause: Missing Microsoft Visual C++ Redistributable</p> <p>Solution: Download and install from: https://aka.ms/vs/17/release/vc_redist.x64.exe</p>"},{"location":"how-to/install/#performance-warning-numba-not-available","title":"Performance Warning: Numba not available","text":"<p>Not critical: PanelBox works without Numba, just slower for large datasets</p> <p>Solution (optional): <pre><code>pip install numba\n</code></pre></p>"},{"location":"how-to/install/#jupyter-notebook-setup","title":"Jupyter Notebook Setup","text":"<p>Install PanelBox in your Jupyter environment:</p> <pre><code># Activate your Jupyter environment\nsource ~/jupyter_env/bin/activate\n\n# Install PanelBox\npip install panelbox\n\n# Install Jupyter kernel\npython -m ipykernel install --user --name=panelbox_env\n</code></pre> <p>In notebook: <pre><code>import panelbox as pb\ndata = pb.load_grunfeld()\n</code></pre></p>"},{"location":"how-to/install/#upgrading","title":"Upgrading","text":"<p>Check current version: <pre><code>pip show panelbox\n</code></pre></p> <p>Upgrade to latest: <pre><code>pip install --upgrade panelbox\n</code></pre></p> <p>Upgrade with dependencies: <pre><code>pip install --upgrade --upgrade-strategy eager panelbox\n</code></pre></p>"},{"location":"how-to/install/#uninstalling","title":"Uninstalling","text":"<pre><code>pip uninstall panelbox\n</code></pre>"},{"location":"how-to/install/#getting-help","title":"Getting Help","text":"<p>Installation issues: - GitHub Issues: https://github.com/PanelBox-Econometrics-Model/panelbox/issues - Check existing issues first - Provide your system info: Python version, OS, error message</p> <p>System information for bug reports: <pre><code>import sys\nimport platform\nimport panelbox as pb\n\nprint(f\"Python: {sys.version}\")\nprint(f\"Platform: {platform.platform()}\")\nprint(f\"PanelBox: {pb.__version__}\")\n</code></pre></p>"},{"location":"how-to/install/#next-steps","title":"Next Steps","text":"<p>\u2705 Installation complete! Now:</p> <ol> <li>Getting Started Tutorial: Your first panel model</li> <li>API Reference: Complete documentation</li> <li>Examples: Real-world use cases</li> </ol> <p>Need help? Open an issue on GitHub.</p>"},{"location":"how-to/interpret_tests/","title":"How to Interpret Diagnostic Tests","text":"<p>Complete guide to understanding and interpreting panel data diagnostic tests in PanelBox.</p>"},{"location":"how-to/interpret_tests/#overview","title":"Overview","text":"<p>Panel data models come with various diagnostic tests to validate assumptions and assess model quality. This guide explains:</p> <ul> <li>What each test does</li> <li>When to use it</li> <li>How to interpret results</li> <li>What to do if tests fail</li> </ul>"},{"location":"how-to/interpret_tests/#test-categories","title":"Test Categories","text":"<p>PanelBox provides tests in four categories:</p> <ol> <li>Specification Tests: Choose between models (Hausman, LM tests)</li> <li>Serial Correlation: Test for autocorrelation (AR tests, Wooldridge)</li> <li>Heteroskedasticity: Test for non-constant variance (Breusch-Pagan)</li> <li>GMM-Specific: Validate instruments (Hansen J, Sargan, AR tests)</li> </ol>"},{"location":"how-to/interpret_tests/#specification-tests","title":"Specification Tests","text":""},{"location":"how-to/interpret_tests/#hausman-test-fe-vs-re","title":"Hausman Test (FE vs RE)","text":"<p>Purpose: Choose between Fixed Effects and Random Effects</p> <p>Hypotheses: - H\u2080: Random Effects is consistent (no correlation between u_i and X) - H\u2081: Fixed Effects is preferred (correlation exists)</p> <p>Usage:</p> <pre><code>from panelbox.validation import HausmanTest\n\n# Estimate both models\nfe_results = pb.FixedEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\nre_results = pb.RandomEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\n\n# Run test\nhausman = HausmanTest(fe_results, re_results)\nprint(hausman)\n</code></pre> <p>Output: <pre><code>================================================================================\n                            Hausman Test Results\n================================================================================\nTest statistic:                  12.456\nDegrees of freedom:                   2\nP-value:                         0.0020\n================================================================================\nH0: Random Effects model is consistent\nH1: Fixed Effects model is preferred\n\nDecision: Reject H0 (p = 0.0020)\nRecommendation: Use Fixed Effects (Random Effects is inconsistent)\n================================================================================\n</code></pre></p> <p>Interpretation:</p> P-value Decision Interpretation Action p &lt; 0.01 Reject H\u2080 Strong evidence RE inconsistent \u2705 Use Fixed Effects 0.01 \u2264 p &lt; 0.05 Reject H\u2080 Moderate evidence against RE \u2705 Use Fixed Effects 0.05 \u2264 p &lt; 0.10 Borderline Weak evidence against RE \u26a0\ufe0f Report both, prefer FE p \u2265 0.10 Fail to reject No evidence against RE \u2705 Use Random Effects <p>Common issues:</p> <p>\u274c Test fails (negative statistic) - Cause: Variance difference matrix not positive definite - Solution: Use cluster-robust SEs or different variance estimator</p> <p>\u274c Very small p-value (p &lt; 0.001) - Interpretation: Strong rejection, definitely use FE - Common in practice (RE assumption is restrictive)</p>"},{"location":"how-to/interpret_tests/#breusch-pagan-lm-test-pooled-vs-re","title":"Breusch-Pagan LM Test (Pooled vs RE)","text":"<p>Purpose: Test for random effects (is there unobserved heterogeneity?)</p> <p>Hypotheses: - H\u2080: Var(u_i) = 0 (no random effects, use Pooled OLS) - H\u2081: Var(u_i) &gt; 0 (random effects exist)</p> <p>Usage:</p> <pre><code>from panelbox.validation import BreuschPaganLM\n\nre_results = pb.RandomEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\n\n# Test for random effects\nbp_test = BreuschPaganLM(re_results)\nprint(bp_test)\n</code></pre> <p>Output: <pre><code>Breusch-Pagan LM Test for Random Effects\nLM statistic: 45.23\nP-value: 0.0000\nH0: Var(u_i) = 0 (no panel effect)\nDecision: Reject H0 - Random effects model is appropriate\n</code></pre></p> <p>Interpretation:</p> P-value Decision Interpretation Action p &lt; 0.05 Reject H\u2080 Unobserved heterogeneity exists \u2705 Use RE or FE p \u2265 0.05 Fail to reject No evidence of heterogeneity \u2705 Pooled OLS sufficient <p>Workflow:</p> <ol> <li>BP test rejects (p &lt; 0.05) \u2192 Heterogeneity exists \u2192 Run Hausman test</li> <li>BP test fails to reject (p \u2265 0.05) \u2192 No heterogeneity \u2192 Use Pooled OLS</li> </ol>"},{"location":"how-to/interpret_tests/#serial-correlation-tests","title":"Serial Correlation Tests","text":""},{"location":"how-to/interpret_tests/#wooldridge-test-first-order-autocorrelation","title":"Wooldridge Test (First-order Autocorrelation)","text":"<p>Purpose: Test for AR(1) serial correlation in idiosyncratic errors</p> <p>Hypotheses: - H\u2080: No first-order autocorrelation (Cov(\u03b5_it, \u03b5_i,t-1) = 0) - H\u2081: AR(1) autocorrelation exists</p> <p>Usage:</p> <pre><code>from panelbox.validation import WooldridgeTest\n\nfe_results = pb.FixedEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\n\n# Test for serial correlation\nwool_test = WooldridgeTest(fe_results)\nprint(wool_test)\n</code></pre> <p>Output: <pre><code>Wooldridge Test for Serial Correlation\nF-statistic: 23.45\nP-value: 0.0001\nH0: No first-order autocorrelation\nDecision: Reject H0 - Serial correlation detected\n</code></pre></p> <p>Interpretation:</p> P-value Decision Interpretation Action p &lt; 0.05 Reject H\u2080 Serial correlation exists \u26a0\ufe0f Use robust SEs or Driscoll-Kraay p \u2265 0.05 Fail to reject No serial correlation \u2705 Standard SEs OK <p>What to do if test rejects:</p> <pre><code># Option 1: Cluster-robust SEs (accounts for serial correlation)\nfe_results = fe.fit(cov_type='clustered')\n\n# Option 2: Driscoll-Kraay SEs (HAC for panels)\nfe_results = fe.fit(cov_type='driscoll_kraay')\n\n# Option 3: Newey-West SEs\nfe_results = fe.fit(cov_type='newey_west', maxlags=2)\n</code></pre>"},{"location":"how-to/interpret_tests/#heteroskedasticity-tests","title":"Heteroskedasticity Tests","text":""},{"location":"how-to/interpret_tests/#breusch-pagan-test-heteroskedasticity","title":"Breusch-Pagan Test (Heteroskedasticity)","text":"<p>Purpose: Test for heteroskedasticity in panel residuals</p> <p>Hypotheses: - H\u2080: Homoskedasticity (constant variance) - H\u2081: Heteroskedasticity (variance depends on X)</p> <p>Usage:</p> <pre><code>from panelbox.validation import BreuschPaganTest\n\nfe_results = pb.FixedEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\n\nbp_het = BreuschPaganTest(fe_results)\nprint(bp_het)\n</code></pre> <p>Output: <pre><code>Breusch-Pagan Test for Heteroskedasticity\nLM statistic: 67.89\nP-value: 0.0000\nH0: Homoskedasticity\nDecision: Reject H0 - Heteroskedasticity detected\n</code></pre></p> <p>Interpretation:</p> P-value Decision Interpretation Action p &lt; 0.05 Reject H\u2080 Heteroskedasticity exists \u26a0\ufe0f Use robust SEs p \u2265 0.05 Fail to reject Homoskedasticity \u2705 Standard SEs OK <p>What to do if test rejects:</p> <pre><code># Use heteroskedasticity-robust SEs\nfe_results = fe.fit(cov_type='HC1')  # or HC2, HC3\n\n# Or cluster-robust (handles both hetero and clustering)\nfe_results = fe.fit(cov_type='clustered')\n</code></pre>"},{"location":"how-to/interpret_tests/#gmm-specific-tests","title":"GMM-Specific Tests","text":""},{"location":"how-to/interpret_tests/#hansen-j-test-overidentification","title":"Hansen J Test (Overidentification)","text":"<p>Purpose: Test validity of instruments (overidentification test)</p> <p>Hypotheses: - H\u2080: All instruments are valid (orthogonality conditions hold) - H\u2081: Some instruments are invalid</p> <p>Available in: DifferenceGMM, SystemGMM results</p> <p>Usage:</p> <pre><code>gmm_results = pb.DifferenceGMM(...).fit()\n\n# Hansen J test (automatically computed)\nprint(f\"Hansen J statistic: {gmm_results.hansen_j.statistic:.2f}\")\nprint(f\"P-value: {gmm_results.hansen_j.pvalue:.3f}\")\n</code></pre> <p>Interpretation:</p> P-value Decision Interpretation Action p &gt; 0.25 Strong support Instruments appear valid \u2705 Continue with model 0.10 &lt; p \u2264 0.25 Acceptable Instruments likely valid \u2705 OK but check robustness 0.05 &lt; p \u2264 0.10 Borderline Weak evidence against instruments \u26a0\ufe0f Re-examine specification p \u2264 0.05 Reject H\u2080 Instruments likely invalid \u274c Do not use results <p>Critical thresholds: - p &gt; 0.10: Generally acceptable in applied work - p &gt; 0.25: Strong evidence of validity - p \u2248 1.0: Warning! May indicate too many instruments (overfitting)</p> <p>What to do if test rejects (p &lt; 0.10):</p> <ol> <li> <p>Use collapse=True (if not already):    <pre><code>gmm = pb.DifferenceGMM(..., collapse=True)\n</code></pre></p> </li> <li> <p>Reduce lags used as instruments: <pre><code>gmm = pb.DifferenceGMM(..., maxlags=3)  # Limit to 3 lags\n</code></pre></p> </li> <li> <p>Remove potentially endogenous variables:</p> </li> <li>Treat fewer variables as exogenous</li> <li> <p>Use different instruments</p> </li> <li> <p>Check for instrument proliferation: <pre><code>print(f\"Instrument ratio: {gmm_results.instrument_ratio:.2f}\")\n# Should be &lt; 1.0 ideally, &lt; 2.0 acceptable\n</code></pre></p> </li> </ol>"},{"location":"how-to/interpret_tests/#sargan-test-alternative-to-hansen-j","title":"Sargan Test (Alternative to Hansen J)","text":"<p>Purpose: Same as Hansen J, but not robust to heteroskedasticity</p> <p>When to use: One-step GMM with homoskedastic errors (rare)</p> <p>Typical use: Hansen J is preferred (robust to heteroskedasticity)</p>"},{"location":"how-to/interpret_tests/#ar1-and-ar2-tests-gmm-serial-correlation","title":"AR(1) and AR(2) Tests (GMM Serial Correlation)","text":"<p>Purpose: Test for autocorrelation in differenced errors</p> <p>Hypotheses: - AR(1): E[\u0394\u03b5_it \u00b7 \u0394\u03b5_i,t-1] = 0 - AR(2): E[\u0394\u03b5_it \u00b7 \u0394\u03b5_i,t-2] = 0</p> <p>Usage:</p> <pre><code>gmm_results = pb.DifferenceGMM(...).fit()\n\n# Automatically computed\nprint(f\"AR(1) p-value: {gmm_results.ar1_test.pvalue:.3f}\")\nprint(f\"AR(2) p-value: {gmm_results.ar2_test.pvalue:.3f}\")\n</code></pre> <p>Interpretation:</p> <p>AR(1) Test:</p> P-value Decision Interpretation p &lt; 0.05 Reject H\u2080 Expected and OK (mechanical due to differencing) p \u2265 0.05 Fail to reject Unusual but not necessarily bad <p>AR(2) Test (CRITICAL!):</p> P-value Decision Interpretation Action p &gt; 0.10 Fail to reject No second-order autocorrelation \u2705 Model is valid 0.05 &lt; p \u2264 0.10 Borderline Weak evidence of AR(2) \u26a0\ufe0f Check robustness p \u2264 0.05 Reject H\u2080 Second-order autocorrelation \u274c Model invalid <p>Why AR(2) matters:</p> <p>If AR(2) test rejects (p &lt; 0.05): - Moment conditions E[y_{t-2} \u00b7 \u0394\u03b5_t] = 0 are violated - Instruments starting at t-2 are invalid - GMM estimates are inconsistent</p> <p>What to do if AR(2) rejects:</p> <ol> <li> <p>Add more lags of dependent variable: <pre><code>gmm = pb.DifferenceGMM(..., lags=2)  # Include y_{t-2}\n</code></pre></p> </li> <li> <p>Use deeper lags as instruments: <pre><code>gmm = pb.DifferenceGMM(..., minlags=3)  # Start instruments at t-3\n</code></pre></p> </li> <li> <p>Check for misspecification:</p> </li> <li>Missing relevant variables</li> <li>Wrong functional form</li> </ol>"},{"location":"how-to/interpret_tests/#difference-in-hansen-test-system-gmm","title":"Difference-in-Hansen Test (System GMM)","text":"<p>Purpose: Test validity of additional instruments in System GMM (level equations)</p> <p>Hypotheses: - H\u2080: Level instruments are valid - H\u2081: Level instruments are invalid</p> <p>Usage:</p> <pre><code>gmm_sys_results = pb.SystemGMM(...).fit()\n\nprint(f\"Difference-in-Hansen p-value: {gmm_sys_results.diff_hansen.pvalue:.3f}\")\n</code></pre> <p>Interpretation:</p> P-value Decision Interpretation Action p &gt; 0.10 Fail to reject Level instruments valid \u2705 System GMM OK p \u2264 0.10 Reject H\u2080 Level instruments invalid \u274c Use Difference GMM <p>What to do if test rejects:</p> <ul> <li>Fall back to Difference GMM (doesn't use level instruments)</li> <li>Check if initial conditions assumption E[\u0394y_{i1} \u00b7 \u03b7_i] = 0 is violated</li> </ul>"},{"location":"how-to/interpret_tests/#complete-testing-workflow","title":"Complete Testing Workflow","text":""},{"location":"how-to/interpret_tests/#static-panel-models-pooled-fe-re","title":"Static Panel Models (Pooled, FE, RE)","text":"<pre><code>import panelbox as pb\nfrom panelbox.validation import BreuschPaganLM, HausmanTest, WooldridgeTest\n\n# Step 1: Estimate all models\npooled = pb.PooledOLS(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\nfe = pb.FixedEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\nre = pb.RandomEffects(\"y ~ x1 + x2\", data, \"firm\", \"year\").fit()\n\n# Step 2: Test for random effects\nbp_lm = BreuschPaganLM(re)\nprint(bp_lm)\n\nif bp_lm.pvalue &lt; 0.05:\n    print(\"\u2713 Random effects exist (use FE or RE)\")\n\n    # Step 3: Hausman test (FE vs RE)\n    hausman = HausmanTest(fe, re)\n    print(hausman)\n\n    if hausman.pvalue &lt; 0.05:\n        print(\"\u2713 Use Fixed Effects\")\n        final_model = fe\n    else:\n        print(\"\u2713 Use Random Effects\")\n        final_model = re\nelse:\n    print(\"\u2713 No random effects (use Pooled OLS)\")\n    final_model = pooled\n\n# Step 4: Test for serial correlation\nwool = WooldridgeTest(final_model)\nprint(wool)\n\nif wool.pvalue &lt; 0.05:\n    print(\"\u26a0 Serial correlation detected - use Driscoll-Kraay SEs\")\n    if isinstance(final_model, pb.FixedEffects):\n        final_model = fe.fit(cov_type='driscoll_kraay')\n\n# Step 5: Report final model\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL MODEL\")\nprint(\"=\"*80)\nprint(final_model.summary())\n</code></pre>"},{"location":"how-to/interpret_tests/#gmm-models","title":"GMM Models","text":"<pre><code>import panelbox as pb\n\n# Estimate GMM\ngmm = pb.DifferenceGMM(\n    data=data,\n    dep_var='y',\n    lags=1,\n    exog_vars=['x1', 'x2'],\n    id_var='firm',\n    time_var='year',\n    collapse=True,\n    robust=True\n)\n\nresults = gmm.fit()\n\n# Check diagnostics\nprint(\"=\"*80)\nprint(\"GMM DIAGNOSTIC TESTS\")\nprint(\"=\"*80)\n\n# 1. Hansen J test\nhansen_ok = results.hansen_j.pvalue &gt; 0.10\nprint(f\"Hansen J p-value: {results.hansen_j.pvalue:.3f} {'\u2713' if hansen_ok else '\u2717'}\")\n\n# 2. AR(2) test\nar2_ok = results.ar2_test.pvalue &gt; 0.10\nprint(f\"AR(2) p-value: {results.ar2_test.pvalue:.3f} {'\u2713' if ar2_ok else '\u2717'}\")\n\n# 3. Instrument count\ninst_ok = results.instrument_ratio &lt; 2.0\nprint(f\"Instrument ratio: {results.instrument_ratio:.2f} {'\u2713' if inst_ok else '\u2717'}\")\n\n# Decision\nif hansen_ok and ar2_ok and inst_ok:\n    print(\"\\n\u2713\u2713\u2713 All tests pass - GMM estimates are valid\")\n    print(results.summary())\nelse:\n    print(\"\\n\u2717\u2717\u2717 Some tests fail - reconsider specification\")\n    if not hansen_ok:\n        print(\"  - Hansen J failed: Instruments may be invalid\")\n    if not ar2_ok:\n        print(\"  - AR(2) failed: Moment conditions violated\")\n    if not inst_ok:\n        print(\"  - Too many instruments: Use collapse or reduce lags\")\n</code></pre>"},{"location":"how-to/interpret_tests/#quick-reference-table","title":"Quick Reference Table","text":"Test What it tests Good result Bad result Fix Hausman FE vs RE p \u2265 0.05 (use RE) p &lt; 0.05 (use FE) Switch to FE BP LM Random effects exist p &lt; 0.05 (yes) p \u2265 0.05 (no) Use Pooled OLS Wooldridge Serial correlation p \u2265 0.05 (none) p &lt; 0.05 (exists) Robust SEs BP Hetero Heteroskedasticity p \u2265 0.05 (homo) p &lt; 0.05 (hetero) Robust SEs Hansen J GMM instruments p &gt; 0.10 (valid) p \u2264 0.10 (invalid) Collapse, reduce lags AR(1) GMM serial corr p &lt; 0.05 (expected) - - AR(2) GMM serial corr p &gt; 0.10 (good) p \u2264 0.10 (bad) Add lags, respecify Diff-Hansen System GMM levels p &gt; 0.10 (valid) p \u2264 0.10 (invalid) Use Difference GMM"},{"location":"how-to/interpret_tests/#common-questions","title":"Common Questions","text":"<p>Q: My Hausman test has negative statistic. What does that mean?</p> <p>A: The variance difference matrix is not positive definite. This can happen with: - Small samples - High correlation between FE and RE estimates - Numerical precision issues</p> <p>Solution: Use alternative Hausman test formulation or cluster-robust SEs</p> <p>Q: Hansen J p-value is 1.000. Is that good?</p> <p>A: No! p \u2248 1.0 usually means too many instruments (overfitting). The test loses power.</p> <p>Solution: Reduce instruments with <code>collapse=True</code> and check instrument ratio &lt; 2.0</p> <p>Q: AR(1) test fails to reject (p = 0.45). Is my GMM invalid?</p> <p>A: No. AR(1) rejection (p &lt; 0.05) is expected but not required. Focus on AR(2).</p> <p>Q: All my tests reject. What do I do?</p> <p>A: This is common! Tests are meant to guide specification: 1. Serial correlation \u2192 Use robust SEs 2. Heteroskedasticity \u2192 Use robust SEs 3. Hausman rejects \u2192 Use FE (not a problem, just a choice) 4. Hansen J / AR(2) reject \u2192 Problem! Respecify model</p> <p>Q: Can I ignore test results?</p> <p>A: Depends: - Hausman, BP LM, Wooldridge: Guide specification but estimates still valid with robust SEs - Hansen J, AR(2): Cannot ignore! If these fail, GMM estimates are inconsistent</p>"},{"location":"how-to/interpret_tests/#next-steps","title":"Next Steps","text":"<p>Learn more about models: 1. Tutorial 2: Static Models: FE vs RE 2. Tutorial 3: GMM Intro: GMM diagnostics</p> <p>Deep dives: 1. Guide: Fixed vs Random: When to use each 2. Guide: GMM Explained: How GMM works</p> <p>API Reference: - Validation Tests API: Complete documentation</p> <p>Remember: Tests are tools to validate assumptions, not obstacles. Use them to improve your model specification!</p>"},{"location":"how-to/load_data/","title":"How to Load Your Own Panel Data","text":"<p>Step-by-step guide for preparing and loading your panel datasets into PanelBox.</p>"},{"location":"how-to/load_data/#overview","title":"Overview","text":"<p>PanelBox works with pandas DataFrames that have: - An entity column (firm ID, country code, individual ID, etc.) - A time column (year, quarter, date, etc.) - One or more variable columns (dependent and independent variables)</p> <p>This guide shows you how to prepare your data from various sources.</p>"},{"location":"how-to/load_data/#quick-start","title":"Quick Start","text":"<p>Minimal example:</p> <pre><code>import pandas as pd\nimport panelbox as pb\n\n# Load your CSV\ndata = pd.read_csv('my_panel_data.csv')\n\n# Ensure proper column names\n# data should have: entity_id, time, y, x1, x2, ...\n\n# Estimate a model\nmodel = pb.FixedEffects(\n    formula=\"y ~ x1 + x2\",\n    data=data,\n    entity_col=\"entity_id\",  # Your entity column name\n    time_col=\"time\"          # Your time column name\n)\n\nresults = model.fit()\nprint(results.summary())\n</code></pre>"},{"location":"how-to/load_data/#data-format-requirements","title":"Data Format Requirements","text":""},{"location":"how-to/load_data/#1-long-format-required","title":"1. Long Format (Required)","text":"<p>PanelBox requires long format where each row is an entity-time observation:</p> <p>\u2705 Correct (Long Format): <pre><code>   firm  year   sales  assets\n0     1  2020   100.0   500.0\n1     1  2021   120.0   520.0\n2     1  2022   135.0   540.0\n3     2  2020    80.0   300.0\n4     2  2021    85.0   310.0\n5     2  2022    90.0   320.0\n</code></pre></p> <p>\u274c Incorrect (Wide Format): <pre><code>   firm  sales_2020  sales_2021  sales_2022\n0     1       100.0       120.0       135.0\n1     2        80.0        85.0        90.0\n</code></pre></p> <p>Convert wide to long:</p> <pre><code># If your data is in wide format\ndata_wide = pd.read_csv('data_wide.csv')\n\n# Convert to long\ndata_long = pd.melt(\n    data_wide,\n    id_vars=['firm'],\n    value_vars=['sales_2020', 'sales_2021', 'sales_2022'],\n    var_name='year',\n    value_name='sales'\n)\n\n# Clean year column\ndata_long['year'] = data_long['year'].str.extract('(\\d+)').astype(int)\n\nprint(data_long.head())\n</code></pre>"},{"location":"how-to/load_data/#2-column-types","title":"2. Column Types","text":"<p>Entity column: - Can be <code>int</code>, <code>str</code>, or <code>categorical</code> - Examples: firm ID (1, 2, 3), country code ('USA', 'CAN'), CUSIP</p> <p>Time column: - Can be <code>int</code>, <code>datetime</code>, or <code>period</code> - Examples: year (2020, 2021), date ('2020-01-01'), quarter ('2020Q1')</p> <p>Variable columns: - Must be numeric (<code>float</code> or <code>int</code>) - Missing values: Use <code>NaN</code> (PanelBox handles them automatically)</p> <p>Check types:</p> <pre><code>print(data.dtypes)\n\n# entity_id      int64\n# time           int64\n# y            float64\n# x1           float64\n# x2           float64\n</code></pre> <p>Fix types if needed:</p> <pre><code># Convert entity to integer\ndata['entity_id'] = data['entity_id'].astype(int)\n\n# Convert time to integer (if year)\ndata['time'] = data['time'].astype(int)\n\n# Convert date string to datetime\ndata['time'] = pd.to_datetime(data['time'])\n\n# Convert datetime to year\ndata['year'] = data['time'].dt.year\n</code></pre>"},{"location":"how-to/load_data/#3-panel-structure","title":"3. Panel Structure","text":"<p>Check your panel:</p> <pre><code># Number of entities\nn_entities = data['entity_id'].nunique()\nprint(f\"Entities (N): {n_entities}\")\n\n# Number of time periods\nn_periods = data['time'].nunique()\nprint(f\"Time periods (T): {n_periods}\")\n\n# Total observations\nprint(f\"Total obs: {len(data)}\")\n\n# Is it balanced?\nobs_per_entity = data.groupby('entity_id').size()\nis_balanced = (obs_per_entity == n_periods).all()\nprint(f\"Balanced: {is_balanced}\")\n\nif not is_balanced:\n    print(f\"Obs per entity: min={obs_per_entity.min()}, max={obs_per_entity.max()}\")\n</code></pre>"},{"location":"how-to/load_data/#loading-from-different-sources","title":"Loading from Different Sources","text":""},{"location":"how-to/load_data/#from-csv","title":"From CSV","text":"<pre><code>import pandas as pd\n\n# Basic CSV load\ndata = pd.read_csv('panel_data.csv')\n\n# With options\ndata = pd.read_csv(\n    'panel_data.csv',\n    sep=',',              # Delimiter\n    encoding='utf-8',     # Encoding\n    parse_dates=['date'], # Parse date columns\n    dtype={'firm_id': int, 'year': int}  # Specify types\n)\n\nprint(data.head())\n</code></pre>"},{"location":"how-to/load_data/#from-excel","title":"From Excel","text":"<pre><code># Single sheet\ndata = pd.read_excel('panel_data.xlsx', sheet_name='Sheet1')\n\n# Multiple sheets (if different years)\nimport pandas as pd\n\nsheets = pd.read_excel('panel_data.xlsx', sheet_name=None)  # Load all sheets\n\n# Combine sheets (assuming each sheet is a year)\nframes = []\nfor year, df in sheets.items():\n    df['year'] = int(year)\n    frames.append(df)\n\ndata = pd.concat(frames, ignore_index=True)\nprint(data.head())\n</code></pre>"},{"location":"how-to/load_data/#from-stata-dta","title":"From Stata (.dta)","text":"<pre><code># Load Stata file\ndata = pd.read_stata('panel_data.dta')\n\n# Convert Stata index to columns if needed\ndata = data.reset_index()\n\nprint(data.head())\n</code></pre>"},{"location":"how-to/load_data/#from-sql-database","title":"From SQL Database","text":"<pre><code>import pandas as pd\nimport sqlite3  # or pymysql, psycopg2, etc.\n\n# Connect to database\nconn = sqlite3.connect('database.db')\n\n# Query panel data\nquery = \"\"\"\nSELECT firm_id, year, sales, assets, employees\nFROM panel_table\nWHERE year BETWEEN 2015 AND 2023\nORDER BY firm_id, year\n\"\"\"\n\ndata = pd.read_sql_query(query, conn)\nconn.close()\n\nprint(data.head())\n</code></pre>"},{"location":"how-to/load_data/#from-r-rds-rdata","title":"From R (.rds, .RData)","text":"<pre><code>import pyreadr\n\n# Load .rds file\nresult = pyreadr.read_r('panel_data.rds')\ndata = result[None]  # Default object\n\n# Load .RData file\nresult = pyreadr.read_r('panel_data.RData')\ndata = result['df_name']  # Specify object name\n\nprint(data.head())\n</code></pre>"},{"location":"how-to/load_data/#from-web-apis","title":"From Web APIs","text":"<pre><code>import pandas as pd\nimport requests\n\n# Example: World Bank API (GDP data)\nurl = \"http://api.worldbank.org/v2/country/all/indicator/NY.GDP.MKTP.CD\"\nparams = {\n    'format': 'json',\n    'date': '2010:2020',\n    'per_page': 1000\n}\n\nresponse = requests.get(url, params=params)\njson_data = response.json()\n\n# Parse JSON to DataFrame (structure depends on API)\ndata = pd.DataFrame(json_data[1])\n\n# Clean and reshape as needed\n# ...\n</code></pre>"},{"location":"how-to/load_data/#common-data-preparation-tasks","title":"Common Data Preparation Tasks","text":""},{"location":"how-to/load_data/#1-handling-missing-values","title":"1. Handling Missing Values","text":"<p>Inspect missingness:</p> <pre><code># Count missing by variable\nprint(data.isnull().sum())\n\n# Percentage missing\nprint(data.isnull().mean() * 100)\n\n# Missing pattern by entity\nmissing_by_entity = data.groupby('entity_id').apply(lambda x: x.isnull().sum())\nprint(missing_by_entity)\n</code></pre> <p>Options:</p> <pre><code># Option 1: Drop rows with any missing\ndata_clean = data.dropna()\n\n# Option 2: Drop rows with missing in specific columns\ndata_clean = data.dropna(subset=['y', 'x1', 'x2'])\n\n# Option 3: Forward fill within entities\ndata_clean = data.sort_values(['entity_id', 'time'])\ndata_clean['x1'] = data_clean.groupby('entity_id')['x1'].ffill()\n\n# Option 4: Keep missing (PanelBox handles NaN automatically)\n# Just ensure no missing in dependent variable\ndata_clean = data.dropna(subset=['y'])\n</code></pre>"},{"location":"how-to/load_data/#2-creating-lagged-variables","title":"2. Creating Lagged Variables","text":"<pre><code># Sort by entity and time first!\ndata = data.sort_values(['entity_id', 'time'])\n\n# Create lag within each entity\ndata['y_lag1'] = data.groupby('entity_id')['y'].shift(1)\ndata['x1_lag1'] = data.groupby('entity_id')['x1'].shift(1)\n\n# Multiple lags\ndata['y_lag2'] = data.groupby('entity_id')['y'].shift(2)\n\n# Lead (forward shift)\ndata['y_lead1'] = data.groupby('entity_id')['y'].shift(-1)\n\nprint(data.head(10))\n</code></pre>"},{"location":"how-to/load_data/#3-creating-differences","title":"3. Creating Differences","text":"<pre><code># First difference\ndata['delta_y'] = data.groupby('entity_id')['y'].diff()\n\n# Log difference (growth rate)\nimport numpy as np\ndata['log_y'] = np.log(data['y'])\ndata['growth_y'] = data.groupby('entity_id')['log_y'].diff()\n\nprint(data[['entity_id', 'time', 'y', 'delta_y', 'growth_y']].head(10))\n</code></pre>"},{"location":"how-to/load_data/#4-creating-time-invariant-variables","title":"4. Creating Time-Invariant Variables","text":"<pre><code># Entity mean\ndata['y_mean'] = data.groupby('entity_id')['y'].transform('mean')\n\n# Entity-specific constant (e.g., size category)\nentity_size = data.groupby('entity_id')['assets'].mean()\nentity_size_cat = pd.cut(entity_size, bins=3, labels=['Small', 'Medium', 'Large'])\n\ndata = data.merge(\n    entity_size_cat.rename('size_category').reset_index(),\n    on='entity_id',\n    how='left'\n)\n\nprint(data[['entity_id', 'time', 'assets', 'size_category']].head())\n</code></pre>"},{"location":"how-to/load_data/#5-encoding-categorical-variables","title":"5. Encoding Categorical Variables","text":"<pre><code># For time-varying categoricals\ndata = pd.get_dummies(data, columns=['industry'], drop_first=True)\n\n# For time-invariant categoricals (will be dropped in FE)\n# Keep as is or create separate variable\n</code></pre>"},{"location":"how-to/load_data/#6-winsorizing-outliers","title":"6. Winsorizing Outliers","text":"<pre><code>from scipy.stats import mstats\n\n# Winsorize at 1st and 99th percentiles\ndata['x1_wins'] = mstats.winsorize(data['x1'], limits=[0.01, 0.01])\n\n# Or manually\np01 = data['x1'].quantile(0.01)\np99 = data['x1'].quantile(0.99)\ndata['x1_wins'] = data['x1'].clip(lower=p01, upper=p99)\n</code></pre>"},{"location":"how-to/load_data/#7-balancing-panel","title":"7. Balancing Panel","text":"<p>Keep only balanced subset:</p> <pre><code># Count observations per entity\nobs_counts = data.groupby('entity_id').size()\n\n# Keep entities with all time periods\nn_periods = data['time'].nunique()\nbalanced_entities = obs_counts[obs_counts == n_periods].index\n\ndata_balanced = data[data['entity_id'].isin(balanced_entities)]\n\nprint(f\"Original: {data['entity_id'].nunique()} entities\")\nprint(f\"Balanced: {data_balanced['entity_id'].nunique()} entities\")\n</code></pre>"},{"location":"how-to/load_data/#complete-example-workflow","title":"Complete Example Workflow","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport panelbox as pb\n\n# 1. Load data\ndata = pd.read_csv('firm_data.csv')\n\n# 2. Check structure\nprint(\"Original data:\")\nprint(data.head())\nprint(f\"\\nShape: {data.shape}\")\nprint(f\"Columns: {list(data.columns)}\")\n\n# 3. Rename columns to standard names\ndata = data.rename(columns={\n    'company_id': 'firm_id',\n    'fiscal_year': 'year',\n    'total_sales': 'sales',\n    'total_assets': 'assets',\n    'num_employees': 'employees'\n})\n\n# 4. Convert types\ndata['firm_id'] = data['firm_id'].astype(int)\ndata['year'] = data['year'].astype(int)\n\n# 5. Sort by entity and time\ndata = data.sort_values(['firm_id', 'year'])\n\n# 6. Handle missing values\nprint(\"\\nMissing values:\")\nprint(data.isnull().sum())\n\n# Drop rows with missing dependent variable\ndata = data.dropna(subset=['sales'])\n\n# Forward-fill missing regressors within firms\nfor col in ['assets', 'employees']:\n    data[col] = data.groupby('firm_id')[col].ffill()\n\n# Drop remaining missing\ndata = data.dropna()\n\n# 7. Create additional variables\n# Log variables\ndata['log_sales'] = np.log(data['sales'])\ndata['log_assets'] = np.log(data['assets'])\n\n# Lagged sales\ndata['log_sales_lag1'] = data.groupby('firm_id')['log_sales'].shift(1)\n\n# Sales growth\ndata['sales_growth'] = data.groupby('firm_id')['log_sales'].diff()\n\n# 8. Winsorize outliers\nfrom scipy.stats import mstats\ndata['sales_growth_wins'] = mstats.winsorize(\n    data['sales_growth'].dropna(),\n    limits=[0.01, 0.01]\n)\n\n# 9. Check final panel structure\nprint(\"\\nFinal panel structure:\")\nprint(f\"Entities: {data['firm_id'].nunique()}\")\nprint(f\"Time periods: {data['year'].nunique()}\")\nprint(f\"Total obs: {len(data)}\")\n\nobs_per_firm = data.groupby('firm_id').size()\nprint(f\"Balanced: {(obs_per_firm == obs_per_firm.iloc[0]).all()}\")\n\n# 10. Estimate model\nmodel = pb.FixedEffects(\n    formula=\"log_sales ~ log_assets + employees\",\n    data=data,\n    entity_col=\"firm_id\",\n    time_col=\"year\",\n    entity_effects=True,\n    time_effects=True\n)\n\nresults = model.fit(cov_type='clustered')\nprint(\"\\n\" + \"=\"*80)\nprint(results.summary())\n\n# 11. Save cleaned data\ndata.to_csv('firm_data_cleaned.csv', index=False)\nprint(\"\\nCleaned data saved to 'firm_data_cleaned.csv'\")\n</code></pre>"},{"location":"how-to/load_data/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/load_data/#error-keyerror-entity_col","title":"Error: \"KeyError: 'entity_col'\"","text":"<p>Cause: Column name doesn't match</p> <p>Solution: Check exact column name (case-sensitive)</p> <pre><code>print(data.columns)  # Check exact names\n# Use correct name in entity_col parameter\n</code></pre>"},{"location":"how-to/load_data/#error-valueerror-could-not-convert-string-to-float","title":"Error: \"ValueError: could not convert string to float\"","text":"<p>Cause: Non-numeric data in variable columns</p> <p>Solution: Check and convert</p> <pre><code># Find non-numeric values\nprint(data['x1'].dtype)\nprint(data[pd.to_numeric(data['x1'], errors='coerce').isnull()])\n\n# Convert, forcing errors to NaN\ndata['x1'] = pd.to_numeric(data['x1'], errors='coerce')\n</code></pre>"},{"location":"how-to/load_data/#warning-panel-is-unbalanced","title":"Warning: \"Panel is unbalanced\"","text":"<p>Info only: PanelBox handles unbalanced panels automatically</p> <p>If you want balanced: Follow balancing steps above</p>"},{"location":"how-to/load_data/#error-not-enough-observations","title":"Error: \"Not enough observations\"","text":"<p>Cause: Too many missing values after cleaning</p> <p>Solution: - Relax missing value handling - Use different time period - Check data quality</p>"},{"location":"how-to/load_data/#best-practices","title":"Best Practices","text":"<p>\u2705 Do: - Always sort by entity and time before creating lags - Check for duplicates (entity-time pairs should be unique) - Inspect missing value patterns - Save intermediate cleaned datasets - Document all transformations</p> <p>\u274c Don't: - Assume data is already sorted - Ignore missing values without investigating - Create lags without grouping by entity - Delete outliers without justification - Mix wide and long formats</p>"},{"location":"how-to/load_data/#next-steps","title":"Next Steps","text":"<p>After loading data:</p> <ol> <li> <p>Tutorial 1: Getting Started: Estimate your first model</p> </li> <li> <p>How-To: Choose Model: Decide which estimator to use</p> </li> <li> <p>Tutorial 2: Static Models: Learn Fixed Effects, Random Effects</p> </li> </ol> <p>Advanced data preparation: - Merging multiple datasets - Panel-specific transformations - Handling highly unbalanced panels - Time-varying treatment indicators</p> <p>Need help? Open an issue on GitHub with a sample of your data structure.</p>"},{"location":"tutorials/01_getting_started/","title":"Getting Started with PanelBox","text":"<p>Learn the basics of panel data analysis with PanelBox in 15 minutes.</p>"},{"location":"tutorials/01_getting_started/#what-youll-learn","title":"What You'll Learn","text":"<p>In this tutorial, you will:</p> <ul> <li>Install PanelBox</li> <li>Load and explore panel data</li> <li>Estimate your first panel model (Pooled OLS)</li> <li>Interpret the results</li> <li>Understand the output</li> </ul>"},{"location":"tutorials/01_getting_started/#prerequisites","title":"Prerequisites","text":"<p>This tutorial assumes you have:</p> <ul> <li>Basic Python knowledge: Variables, functions, imports</li> <li>Familiarity with pandas: DataFrames and basic operations</li> <li>Understanding of linear regression: OLS, coefficients, p-values</li> </ul> <p>No prior panel data experience required!</p>"},{"location":"tutorials/01_getting_started/#installation","title":"Installation","text":"<p>Install PanelBox using pip:</p> <pre><code>pip install panelbox\n</code></pre> <p>Requirements: - Python \u2265 3.9 - NumPy \u2265 1.24.0 - Pandas \u2265 2.0.0</p> <p>Verify installation:</p> <pre><code>import panelbox as pb\nprint(f\"PanelBox version: {pb.__version__}\")\n</code></pre>"},{"location":"tutorials/01_getting_started/#what-is-panel-data","title":"What is Panel Data?","text":"<p>Panel data combines cross-sectional and time-series dimensions:</p> <ul> <li>Cross-sectional: Multiple entities (firms, countries, individuals)</li> <li>Time-series: Observed over multiple time periods</li> </ul> <p>Example: 10 firms observed over 20 years = 200 observations</p> <p>Panel data allows us to: - Control for unobserved heterogeneity - Study dynamics over time - Increase statistical power</p>"},{"location":"tutorials/01_getting_started/#your-first-panel-model","title":"Your First Panel Model","text":""},{"location":"tutorials/01_getting_started/#step-1-load-data","title":"Step 1: Load Data","text":"<p>PanelBox includes the classic Grunfeld dataset:</p> <pre><code>import panelbox as pb\n\n# Load example data\ndata = pb.load_grunfeld()\n\n# Display first rows\nprint(data.head())\n</code></pre> <p>Output: <pre><code>   firm  year   invest     value   capital\n0     1  1935   317.60   3078.50    2.80\n1     1  1936   391.80   4661.70   52.60\n2     1  1937   410.60   5387.10  156.90\n3     1  1938   257.70   2792.20  209.20\n4     1  1939   330.80   4313.20  203.40\n</code></pre></p> <p>Variables: - <code>firm</code>: Firm identifier (1-10) - <code>year</code>: Year (1935-1954) - <code>invest</code>: Gross investment (millions of dollars) - <code>value</code>: Market value of the firm - <code>capital</code>: Stock of plant and equipment</p>"},{"location":"tutorials/01_getting_started/#step-2-explore-the-data","title":"Step 2: Explore the Data","text":"<p>Understanding your panel structure is crucial:</p> <pre><code># Panel dimensions\nn_firms = data['firm'].nunique()\nn_years = data['year'].nunique()\nn_obs = len(data)\n\nprint(f\"Entities (N): {n_firms}\")  # 10 firms\nprint(f\"Time periods (T): {n_years}\")  # 20 years\nprint(f\"Total observations: {n_obs}\")  # 200\n\n# Check if balanced\nobs_per_firm = data.groupby('firm').size()\nis_balanced = (obs_per_firm == n_years).all()\nprint(f\"Balanced panel: {is_balanced}\")  # True\n</code></pre> <p>Output: <pre><code>Entities (N): 10\nTime periods (T): 20\nTotal observations: 200\nBalanced panel: True\n</code></pre></p> <p>Visualize relationships:</p> <pre><code>import matplotlib.pyplot as plt\n\n# Investment over time for each firm\nfor firm_id in data['firm'].unique()[:3]:  # First 3 firms\n    firm_data = data[data['firm'] == firm_id]\n    plt.plot(firm_data['year'], firm_data['invest'],\n             label=f'Firm {firm_id}', marker='o')\n\nplt.xlabel('Year')\nplt.ylabel('Investment')\nplt.title('Investment Over Time')\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"tutorials/01_getting_started/#step-3-estimate-pooled-ols","title":"Step 3: Estimate Pooled OLS","text":"<p>Let's estimate a simple investment model:</p> <pre><code># Estimate Pooled OLS\nmodel = pb.PooledOLS(\n    formula=\"invest ~ value + capital\",\n    data=data,\n    entity_col=\"firm\",\n    time_col=\"year\"\n)\n\n# Fit the model\nresults = model.fit(cov_type='robust')\n\n# Display results\nprint(results.summary())\n</code></pre> <p>Output: <pre><code>================================================================================\n                        Pooled OLS Estimation Results\n================================================================================\nDependent Variable:              invest        No. Observations:             200\nModel:                       Pooled OLS        Df Residuals:                 197\nMethod:                    Least Squares        Df Model:                       2\nDate:                     2026-02-05            R-squared:                  0.812\nTime:                     14:30:25              Adj. R-squared:             0.810\nCov. Type:                    robust\n================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept       -42.714     14.532     -2.939      0.004     -71.365     -14.063\nvalue             0.116      0.006     19.721      0.000       0.104       0.127\ncapital           0.231      0.028      8.251      0.000       0.176       0.286\n================================================================================\n</code></pre></p>"},{"location":"tutorials/01_getting_started/#step-4-understand-the-results","title":"Step 4: Understand the Results","text":"<p>Let's interpret each part of the output:</p> <p>Model Information: - 200 observations: All firm-year combinations - R-squared: 0.812: Model explains 81.2% of investment variation - Cov. Type: robust: Heteroskedasticity-robust standard errors</p> <p>Coefficient Interpretation:</p> <ol> <li>value = 0.116 (p &lt; 0.001)</li> <li>A $1 million increase in firm value \u2192 $0.116 million more investment</li> <li> <p>Highly significant (p &lt; 0.001)</p> </li> <li> <p>capital = 0.231 (p &lt; 0.001)</p> </li> <li>A $1 million increase in capital stock \u2192 $0.231 million more investment</li> <li> <p>Also highly significant</p> </li> <li> <p>Intercept = -42.714</p> </li> <li>Baseline investment when value and capital are zero</li> <li>Less meaningful interpretation</li> </ol> <p>Statistical Significance:</p> <ul> <li>t-statistic: Tests if coefficient \u2260 0</li> <li>|t| &gt; 2 typically indicates significance</li> <li>p-value: Probability of observing this coefficient by chance</li> <li>p &lt; 0.05: Significant at 5% level</li> <li>p &lt; 0.01: Significant at 1% level</li> </ul> <p>All our coefficients have p &lt; 0.001, showing strong evidence of effects.</p> <p>Confidence Intervals:</p> <p>The 95% confidence interval for <code>value</code> is [0.104, 0.127]: - We're 95% confident the true effect lies in this range - Since it doesn't include 0, confirms significance</p>"},{"location":"tutorials/01_getting_started/#step-5-access-results-programmatically","title":"Step 5: Access Results Programmatically","text":"<p>Extract specific results for further analysis:</p> <pre><code># Coefficients\nprint(\"Coefficients:\")\nprint(results.params)\n\n# Standard errors\nprint(\"\\nStandard Errors:\")\nprint(results.std_errors)\n\n# R-squared\nprint(f\"\\nR-squared: {results.rsquared:.4f}\")\n\n# Specific coefficient\nvalue_coef = results.params['value']\nvalue_se = results.std_errors['value']\nprint(f\"\\nValue coefficient: {value_coef:.4f} (SE: {value_se:.4f})\")\n</code></pre> <p>Output: <pre><code>Coefficients:\nIntercept   -42.713967\nvalue         0.115562\ncapital       0.230789\ndtype: float64\n\nStandard Errors:\nIntercept    14.532461\nvalue         0.005860\ncapital       0.027971\ndtype: float64\n\nR-squared: 0.8119\n\nValue coefficient: 0.1156 (SE: 0.0059)\n</code></pre></p>"},{"location":"tutorials/01_getting_started/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 You've learned to: - Load panel data with <code>pb.load_grunfeld()</code> - Explore panel structure (N, T, balanced/unbalanced) - Estimate a Pooled OLS model - Interpret regression output - Access results programmatically</p> <p>\u26a0\ufe0f Important caveat: Pooled OLS ignores the panel structure! It treats all observations as independent, which may not be realistic. In most applications, you'll want to use: - Fixed Effects: Control for time-invariant firm characteristics - Random Effects: Model entity-specific effects - GMM: Handle dynamics and endogeneity</p>"},{"location":"tutorials/01_getting_started/#next-steps","title":"Next Steps","text":"<p>Continue learning:</p> <ol> <li> <p>Static Panel Models Tutorial: Learn Fixed Effects, Random Effects, and when to use each</p> </li> <li> <p>How-To: Choose a Model: Decision guide for selecting the right estimator</p> </li> <li> <p>API Reference: Complete documentation of all models</p> </li> </ol> <p>Try it yourself:</p> <pre><code># Load your own data\nimport pandas as pd\ndata = pd.read_csv('your_panel_data.csv')\n\n# Estimate a model\nmodel = pb.PooledOLS(\n    formula=\"dependent ~ var1 + var2\",\n    data=data,\n    entity_col=\"entity_id\",  # Your entity column\n    time_col=\"time\"          # Your time column\n)\nresults = model.fit(cov_type='robust')\nprint(results.summary())\n</code></pre>"},{"location":"tutorials/01_getting_started/#common-issues","title":"Common Issues","text":"<p>Problem: <code>KeyError: 'firm'</code> - Solution: Check that <code>entity_col</code> and <code>time_col</code> match your column names</p> <p>Problem: <code>ValueError: Formula parse error</code> - Solution: Use R-style formulas: <code>\"y ~ x1 + x2\"</code>, not Python-style</p> <p>Problem: Import error - Solution: Reinstall: <code>pip install --upgrade panelbox</code></p>"},{"location":"tutorials/01_getting_started/#further-reading","title":"Further Reading","text":"<ul> <li>Textbooks:</li> <li>Wooldridge (2010): Econometric Analysis of Cross Section and Panel Data</li> <li> <p>Baltagi (2021): Econometric Analysis of Panel Data</p> </li> <li> <p>Papers:</p> </li> <li>Grunfeld (1958): Original dataset paper</li> </ul> <p>Congratulations! You've completed your first panel data analysis with PanelBox. \ud83c\udf89</p> <p>Ready to learn more advanced models? Continue to Tutorial 2: Static Panel Models.</p>"},{"location":"tutorials/02_static_models/","title":"Tutorial 2: Static Panel Models","text":"<p>Master the core panel data models: Pooled OLS, Fixed Effects, and Random Effects.</p>"},{"location":"tutorials/02_static_models/#what-youll-learn","title":"What You'll Learn","text":"<p>In this tutorial, you will:</p> <ul> <li>Understand when Pooled OLS is insufficient</li> <li>Estimate Fixed Effects (FE) models</li> <li>Estimate Random Effects (RE) models</li> <li>Run and interpret the Hausman test</li> <li>Compare models systematically</li> <li>Choose the right model for your data</li> </ul>"},{"location":"tutorials/02_static_models/#prerequisites","title":"Prerequisites","text":"<p>This tutorial assumes you've completed: - Tutorial 1: Getting Started</p> <p>You should be familiar with: - Loading panel data - Basic PanelBox syntax - Interpreting regression output</p>"},{"location":"tutorials/02_static_models/#the-problem-with-pooled-ols","title":"The Problem with Pooled OLS","text":"<p>In Tutorial 1, we estimated a Pooled OLS model:</p> <pre><code>import panelbox as pb\n\n# Load data\ndata = pb.load_grunfeld()\n\n# Pooled OLS\npooled = pb.PooledOLS(\"invest ~ value + capital\", data, \"firm\", \"year\")\npooled_results = pooled.fit(cov_type='robust')\nprint(pooled_results.summary())\n</code></pre> <p>Problem: Pooled OLS assumes all firms are identical except for their observed characteristics (value, capital). But in reality:</p> <ul> <li>Firm 1 might be well-managed (higher investment for same fundamentals)</li> <li>Firm 2 might have conservative culture (lower investment)</li> <li>Firm 3 might face different regulations</li> </ul> <p>These unobserved firm-specific factors (\u03b1\u2081, \u03b1\u2082, \u03b1\u2083, ...) cause:</p> <ol> <li>Omitted variable bias if they're correlated with X</li> <li>Inefficient estimates even if uncorrelated</li> </ol> <p>Solution: Use panel models that account for this heterogeneity!</p>"},{"location":"tutorials/02_static_models/#fixed-effects-controlling-for-unobservables","title":"Fixed Effects: Controlling for Unobservables","text":""},{"location":"tutorials/02_static_models/#the-model","title":"The Model","text":"<p>Fixed Effects (FE) adds firm-specific constants (\u03b1_i):</p> <pre><code>invest_it = \u03b1_i + \u03b2\u2081\u00b7value_it + \u03b2\u2082\u00b7capital_it + \u03b5_it\n</code></pre> <p>where: - <code>\u03b1_i</code> = firm-specific effect (captures management, culture, etc.) - <code>\u03b2\u2081, \u03b2\u2082</code> = coefficients we want to estimate - <code>\u03b5_it</code> = idiosyncratic error</p> <p>Key idea: Within transformation removes \u03b1_i by demeaning within each firm.</p>"},{"location":"tutorials/02_static_models/#estimation","title":"Estimation","text":"<pre><code># Fixed Effects\nfe = pb.FixedEffects(\n    formula=\"invest ~ value + capital\",\n    data=data,\n    entity_col=\"firm\",\n    time_col=\"year\",\n    entity_effects=True,   # Include firm fixed effects (default)\n    time_effects=False     # Exclude time fixed effects (can add if needed)\n)\n\nfe_results = fe.fit(cov_type='clustered')  # Cluster by firm\nprint(fe_results.summary())\n</code></pre> <p>Output (typical): <pre><code>================================================================================\n                       Fixed Effects Estimation Results\n================================================================================\nDependent Variable:              invest        No. Observations:             200\nModel:                     Fixed Effects        Df Residuals:                 188\nMethod:                           Within        Df Model:                       2\nDate:                       2026-02-05          R-squared (within):         0.766\nTime:                         15:30:00          R-squared (between):        0.892\nCov. Type:                   clustered          R-squared (overall):        0.812\n================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nvalue             0.110      0.012      9.180      0.000       0.086       0.134\ncapital           0.310      0.052      5.962      0.000       0.208       0.412\n================================================================================\nF-statistic:                     120.5\nProb (F-statistic):           1.23e-31\nEntity fixed effects:              Yes\nTime fixed effects:                 No\nNumber of entities:                 10\nAvg obs per entity:                 20\n================================================================================\n</code></pre></p>"},{"location":"tutorials/02_static_models/#understanding-the-output","title":"Understanding the Output","text":"<p>R-squared values: - Within R\u00b2 = 0.766: Variation explained within firms over time - Between R\u00b2 = 0.892: Variation explained between firms - Overall R\u00b2 = 0.812: Total variation explained</p> <p>Coefficients: - <code>value = 0.110</code>: Within a firm, $1M increase in value \u2192 $0.11M more investment - <code>capital = 0.310</code>: Within a firm, $1M increase in capital \u2192 $0.31M more investment</p> <p>Note: Coefficients slightly different from Pooled OLS (0.116, 0.231) because we've removed bias from unobserved firm effects.</p> <p>Standard errors: - Clustered by firm to account for within-firm correlation over time - More conservative than non-clustered SEs</p>"},{"location":"tutorials/02_static_models/#when-to-use-fixed-effects","title":"When to Use Fixed Effects","text":"<p>\u2705 Use FE when: - Unobserved heterogeneity exists - It's likely correlated with regressors - You don't need to estimate time-invariant effects (gender, country, etc.) - You have multiple observations per entity (T \u2265 2)</p> <p>\u274c Don't use FE when: - You need to estimate time-invariant variables (they get dropped!) - You have very few time periods (T = 2 is borderline) - No unobserved heterogeneity exists</p>"},{"location":"tutorials/02_static_models/#random-effects-efficiency-gains","title":"Random Effects: Efficiency Gains","text":""},{"location":"tutorials/02_static_models/#the-model_1","title":"The Model","text":"<p>Random Effects (RE) also includes entity-specific effects, but treats them as random draws:</p> <pre><code>invest_it = \u03b2\u2080 + \u03b2\u2081\u00b7value_it + \u03b2\u2082\u00b7capital_it + u_i + \u03b5_it\n</code></pre> <p>where: - <code>u_i ~ N(0, \u03c3\u00b2_u)</code> = random firm effect - <code>\u03b5_it ~ N(0, \u03c3\u00b2_\u03b5)</code> = idiosyncratic error</p> <p>Key assumption: <code>u_i</code> is uncorrelated with regressors (value, capital)</p> <p>Key advantage: Can estimate time-invariant variables and has smaller standard errors than FE (if assumption holds).</p>"},{"location":"tutorials/02_static_models/#estimation_1","title":"Estimation","text":"<pre><code># Random Effects\nre = pb.RandomEffects(\n    formula=\"invest ~ value + capital\",\n    data=data,\n    entity_col=\"firm\",\n    time_col=\"year\"\n)\n\nre_results = re.fit()\nprint(re_results.summary())\n</code></pre> <p>Output (typical): <pre><code>================================================================================\n                      Random Effects Estimation Results\n================================================================================\nDependent Variable:              invest        No. Observations:             200\nModel:                    Random Effects        Df Residuals:                 197\nMethod:                  GLS (Swamy-Arora)      Df Model:                       2\nDate:                       2026-02-05          R-squared:                  0.812\nTime:                         15:32:00\n================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept       -57.834     28.899     -2.001      0.047    -114.566      -1.102\nvalue             0.110      0.011     10.000      0.000       0.088       0.132\ncapital           0.308      0.049      6.286      0.000       0.212       0.404\n================================================================================\nVariance Components:\n    Var(u_i):                    2341.62\n    Var(\u03b5_it):                    457.82\n    Theta:                        0.862\n================================================================================\n</code></pre></p>"},{"location":"tutorials/02_static_models/#understanding-random-effects-output","title":"Understanding Random Effects Output","text":"<p>Coefficients: - Very similar to FE (0.110 vs 0.110 for value) - But we can estimate the intercept (unlike FE)</p> <p>Variance components: - <code>Var(u_i) = 2341.62</code>: Variance between firms - <code>Var(\u03b5_it) = 457.82</code>: Variance within firms over time - <code>Theta = 0.862</code>: Quasi-demeaning parameter (\u03b8 \u2248 1 means close to FE)</p> <p>Standard errors: - Slightly smaller than FE (0.011 vs 0.012 for value) - But only valid if E[u_i | X_it] = 0 holds!</p>"},{"location":"tutorials/02_static_models/#when-to-use-random-effects","title":"When to Use Random Effects","text":"<p>\u2705 Use RE when: - Effects are uncorrelated with X (e.g., random sample from population) - You need to estimate time-invariant variables - You want more efficient estimates than FE - Hausman test doesn't reject RE</p> <p>\u274c Don't use RE when: - Effects are correlated with X (biased and inconsistent!) - Hausman test rejects RE</p>"},{"location":"tutorials/02_static_models/#the-hausman-test-fe-vs-re","title":"The Hausman Test: FE vs RE","text":""},{"location":"tutorials/02_static_models/#the-question","title":"The Question","text":"<p>Should I use Fixed Effects or Random Effects?</p> <p>The Hausman test answers this by testing:</p> <ul> <li>H\u2080: Random effects are consistent (E[u_i | X_it] = 0 holds)</li> <li>H\u2081: Random effects are inconsistent (use fixed effects)</li> </ul> <p>Decision rule: - p &lt; 0.05: Reject H\u2080 \u2192 Use Fixed Effects - p \u2265 0.05: Fail to reject \u2192 Use Random Effects</p>"},{"location":"tutorials/02_static_models/#running-the-test","title":"Running the Test","text":"<pre><code># Estimate both models\nfe_results = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\").fit()\nre_results = pb.RandomEffects(\"invest ~ value + capital\", data, \"firm\", \"year\").fit()\n\n# Hausman test\nfrom panelbox.validation import HausmanTest\n\nhausman = HausmanTest(fe_results, re_results)\nprint(hausman)\n</code></pre> <p>Output: <pre><code>================================================================================\n                            Hausman Test Results\n================================================================================\nTest statistic:                  2.3356\nDegrees of freedom:                   2\nP-value:                         0.3113\n================================================================================\nH0: Random Effects model is consistent\nH1: Fixed Effects model is preferred\n\nDecision: Fail to reject H0 (p = 0.3113)\nRecommendation: Use Random Effects (more efficient)\n================================================================================\n</code></pre></p>"},{"location":"tutorials/02_static_models/#interpreting-the-result","title":"Interpreting the Result","text":"<p>p = 0.3113 &gt; 0.05 \u2192 Fail to reject H\u2080</p> <p>Interpretation: - No evidence that RE is inconsistent - The difference between FE and RE coefficients is small (not statistically significant) - RE assumption E[u_i | X_it] = 0 appears to hold</p> <p>Conclusion: Use Random Effects (more efficient, smaller standard errors)</p>"},{"location":"tutorials/02_static_models/#what-if-hausman-rejects","title":"What if Hausman Rejects?","text":"<p>If p &lt; 0.05, you'd see:</p> <pre><code>P-value:                         0.0089\nDecision: Reject H0 (p = 0.0089)\nRecommendation: Use Fixed Effects (Random Effects is inconsistent)\n</code></pre> <p>Interpretation: - RE coefficients significantly differ from FE - RE assumption E[u_i | X_it] = 0 is violated - Firm effects are correlated with regressors</p> <p>Conclusion: Use Fixed Effects (consistent even if effects correlated with X)</p>"},{"location":"tutorials/02_static_models/#comparing-all-three-models","title":"Comparing All Three Models","text":""},{"location":"tutorials/02_static_models/#side-by-side-comparison","title":"Side-by-Side Comparison","text":"<pre><code>import pandas as pd\n\n# Estimate all three\npooled_results = pb.PooledOLS(\"invest ~ value + capital\", data, \"firm\", \"year\").fit()\nfe_results = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\").fit()\nre_results = pb.RandomEffects(\"invest ~ value + capital\", data, \"firm\", \"year\").fit()\n\n# Extract coefficients\ncomparison = pd.DataFrame({\n    'Pooled OLS': pooled_results.params,\n    'Fixed Effects': fe_results.params,\n    'Random Effects': re_results.params\n})\n\nprint(comparison)\n</code></pre> <p>Output: <pre><code>           Pooled OLS  Fixed Effects  Random Effects\nIntercept   -42.71400            NaN       -57.83400\nvalue         0.11556        0.11006         0.11009\ncapital       0.23079        0.31002         0.30815\n</code></pre></p> <p>Key observations: 1. Intercept: Pooled and RE have intercepts; FE does not (absorbed by firm effects) 2. value coefficient: Similar across all three (0.116, 0.110, 0.110) 3. capital coefficient: Pooled OLS lower (0.231 vs 0.310) \u2192 omitted variable bias!</p>"},{"location":"tutorials/02_static_models/#standard-error-comparison","title":"Standard Error Comparison","text":"<pre><code>se_comparison = pd.DataFrame({\n    'Pooled OLS': pooled_results.std_errors,\n    'Fixed Effects': fe_results.std_errors,\n    'Random Effects': re_results.std_errors\n})\n\nprint(se_comparison)\n</code></pre> <p>Output: <pre><code>           Pooled OLS  Fixed Effects  Random Effects\nIntercept    14.53246            NaN        28.89900\nvalue         0.00586        0.01199         0.01100\ncapital       0.02797        0.05200         0.04900\n</code></pre></p> <p>Observation: RE has smaller SEs than FE (more efficient), but larger than Pooled (which ignores heterogeneity).</p>"},{"location":"tutorials/02_static_models/#complete-workflow-model-selection","title":"Complete Workflow: Model Selection","text":""},{"location":"tutorials/02_static_models/#step-1-estimate-pooled-ols-baseline","title":"Step 1: Estimate Pooled OLS (Baseline)","text":"<pre><code>pooled = pb.PooledOLS(\"invest ~ value + capital\", data, \"firm\", \"year\")\npooled_results = pooled.fit()\n\nprint(f\"Pooled R\u00b2: {pooled_results.rsquared:.4f}\")\n</code></pre>"},{"location":"tutorials/02_static_models/#step-2-test-for-unobserved-heterogeneity","title":"Step 2: Test for Unobserved Heterogeneity","text":"<pre><code>fe = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\nfe_results = fe.fit()\n\nprint(f\"FE within R\u00b2: {fe_results.rsquared_within:.4f}\")\nprint(f\"FE overall R\u00b2: {fe_results.rsquared_overall:.4f}\")\n\n# If FE R\u00b2 much higher \u2192 heterogeneity exists\n</code></pre> <p>If FE R\u00b2 \u2248 Pooled R\u00b2: No heterogeneity \u2192 Use Pooled OLS</p> <p>If FE R\u00b2 &gt;&gt; Pooled R\u00b2: Heterogeneity exists \u2192 Continue to Step 3</p>"},{"location":"tutorials/02_static_models/#step-3-hausman-test-fe-vs-re","title":"Step 3: Hausman Test (FE vs RE)","text":"<pre><code>re = pb.RandomEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\nre_results = re.fit()\n\nfrom panelbox.validation import HausmanTest\nhausman = HausmanTest(fe_results, re_results)\nprint(hausman)\n</code></pre> <p>If p \u2265 0.05: Use Random Effects (efficient and consistent)</p> <p>If p &lt; 0.05: Use Fixed Effects (consistent, RE is biased)</p>"},{"location":"tutorials/02_static_models/#step-4-report-final-model","title":"Step 4: Report Final Model","text":"<pre><code># Assume Hausman favored RE\nfinal_results = re_results\n\nprint(\"=\"*80)\nprint(\"FINAL MODEL: Random Effects\")\nprint(\"=\"*80)\nprint(final_results.summary())\n\n# Export to LaTeX\nfinal_results.to_latex(\"investment_model.tex\")\n</code></pre>"},{"location":"tutorials/02_static_models/#adding-time-fixed-effects","title":"Adding Time Fixed Effects","text":"<p>Sometimes you want to control for time-varying shocks affecting all firms (e.g., recession, policy changes):</p> <pre><code># Two-way fixed effects (entity + time)\nfe_twoway = pb.FixedEffects(\n    formula=\"invest ~ value + capital\",\n    data=data,\n    entity_col=\"firm\",\n    time_col=\"year\",\n    entity_effects=True,   # Firm fixed effects\n    time_effects=True      # Year fixed effects\n)\n\nfe_twoway_results = fe_twoway.fit(cov_type='twoway')  # Two-way clustering\nprint(fe_twoway_results.summary())\n</code></pre> <p>When to use: - Time-varying aggregate shocks exist (business cycles, policy changes) - You want to control for common trends - Difference-in-differences designs</p>"},{"location":"tutorials/02_static_models/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"tutorials/02_static_models/#mistake-1-using-pooled-ols-when-fere-is-needed","title":"\u274c Mistake 1: Using Pooled OLS when FE/RE is needed","text":"<p>Problem: Omitted variable bias</p> <p>Solution: Always test for heterogeneity by comparing Pooled vs FE R\u00b2</p>"},{"location":"tutorials/02_static_models/#mistake-2-using-re-when-hausman-rejects","title":"\u274c Mistake 2: Using RE when Hausman rejects","text":"<p>Problem: Biased and inconsistent estimates</p> <p>Solution: Trust the Hausman test! If it rejects, use FE</p>"},{"location":"tutorials/02_static_models/#mistake-3-forgetting-to-cluster-standard-errors","title":"\u274c Mistake 3: Forgetting to cluster standard errors","text":"<p>Problem: Standard errors too small (over-rejection of H\u2080)</p> <p>Solution: Always use <code>cov_type='clustered'</code> for FE</p> <pre><code># GOOD\nfe_results = fe.fit(cov_type='clustered')\n\n# BAD (SEs likely too small)\nfe_results = fe.fit()\n</code></pre>"},{"location":"tutorials/02_static_models/#mistake-4-expecting-time-invariant-variables-in-fe","title":"\u274c Mistake 4: Expecting time-invariant variables in FE","text":"<p>Problem: Variables like firm size, country, gender get dropped</p> <p>Solution: Use RE if you need time-invariant variables, or use Between estimator</p>"},{"location":"tutorials/02_static_models/#mistake-5-using-fe-with-t-2","title":"\u274c Mistake 5: Using FE with T = 2","text":"<p>Problem: No degrees of freedom for identifying dynamics</p> <p>Solution: Need T \u2265 3 for meaningful FE; consider first-differences if T = 2</p>"},{"location":"tutorials/02_static_models/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 You've learned to: - Identify when Pooled OLS is insufficient - Estimate Fixed Effects and Random Effects models - Run and interpret the Hausman test - Follow a systematic model selection workflow - Avoid common pitfalls</p> <p>\ud83d\udcca Model Selection Summary: 1. Pooled OLS: No heterogeneity 2. Fixed Effects: Heterogeneity correlated with X 3. Random Effects: Heterogeneity uncorrelated with X</p> <p>\ud83e\uddea Decision Tools: - Compare R\u00b2: Pooled vs FE - Hausman test: FE vs RE</p>"},{"location":"tutorials/02_static_models/#next-steps","title":"Next Steps","text":"<p>Continue learning:</p> <ol> <li> <p>Tutorial 3: GMM Introduction: Learn when and how to use dynamic panel models</p> </li> <li> <p>How-To: Interpret Tests: Deep dive into diagnostic tests</p> </li> <li> <p>Guide: Fixed vs Random Effects: Detailed explanation of the differences</p> </li> </ol> <p>Practice yourself:</p> <pre><code># Try with your own data\nimport pandas as pd\n\ndata = pd.read_csv('my_panel_data.csv')\n\n# Model selection workflow\npooled = pb.PooledOLS(\"y ~ x1 + x2\", data, \"entity_id\", \"time\")\npooled_results = pooled.fit()\n\nfe = pb.FixedEffects(\"y ~ x1 + x2\", data, \"entity_id\", \"time\")\nfe_results = fe.fit(cov_type='clustered')\n\nre = pb.RandomEffects(\"y ~ x1 + x2\", data, \"entity_id\", \"time\")\nre_results = re.fit()\n\n# Hausman test\nfrom panelbox.validation import HausmanTest\nhausman = HausmanTest(fe_results, re_results)\nprint(hausman)\n</code></pre>"},{"location":"tutorials/02_static_models/#further-reading","title":"Further Reading","text":"<p>Textbooks: - Wooldridge (2010): Econometric Analysis of Cross Section and Panel Data, Chapter 10 - Baltagi (2021): Econometric Analysis of Panel Data, Chapters 2-3 - Cameron &amp; Trivedi (2005): Microeconometrics, Chapter 21</p> <p>Papers: - Hausman (1978): \"Specification Tests in Econometrics\", Econometrica, 46(6), 1251-1271 - Mundlak (1978): \"On the Pooling of Time Series and Cross Section Data\", Econometrica, 46(1), 69-85</p> <p>Congratulations! You now understand the core static panel models and how to choose between them. \ud83c\udf89</p> <p>Ready for dynamics and endogeneity? Continue to Tutorial 3: GMM Introduction.</p>"},{"location":"tutorials/03_gmm_intro/","title":"Tutorial 3: Introduction to GMM for Panel Data","text":"<p>Learn when and how to use Generalized Method of Moments (GMM) for dynamic panel models.</p>"},{"location":"tutorials/03_gmm_intro/#what-youll-learn","title":"What You'll Learn","text":"<p>In this tutorial, you will:</p> <ul> <li>Understand why standard panel models fail with dynamics</li> <li>Learn the difference between Difference GMM and System GMM</li> <li>Estimate your first GMM model</li> <li>Interpret diagnostic tests (Hansen J, AR tests)</li> <li>Understand instrument selection and collapse</li> <li>Avoid common pitfalls</li> </ul>"},{"location":"tutorials/03_gmm_intro/#prerequisites","title":"Prerequisites","text":"<p>This tutorial assumes you've completed: - Tutorial 1: Getting Started - Tutorial 2: Static Panel Models</p> <p>You should understand: - Fixed Effects estimation - Panel data structure - Basic econometric concepts (endogeneity, instruments)</p>"},{"location":"tutorials/03_gmm_intro/#the-dynamic-panel-problem","title":"The Dynamic Panel Problem","text":""},{"location":"tutorials/03_gmm_intro/#why-fixed-effects-fails","title":"Why Fixed Effects Fails","text":"<p>Consider a dynamic panel model where current investment depends on past investment:</p> <pre><code>invest_it = \u03b3\u00b7invest_{i,t-1} + \u03b2\u2081\u00b7value_it + \u03b2\u2082\u00b7capital_it + \u03b1_i + \u03b5_it\n</code></pre> <p>Problem: Using Fixed Effects on this model produces biased estimates (Nickell bias).</p> <p>Why? The within transformation creates correlation:</p> <pre><code>(invest_it - invest\u0304_i) = \u03b3\u00b7(invest_{i,t-1} - invest\u0304_i) + ... + (\u03b5_it - \u03b5\u0304_i)\n</code></pre> <p>Even if <code>\u03b5_it</code> is uncorrelated with <code>invest_{i,t-1}</code>, the demeaned error <code>(\u03b5_it - \u03b5\u0304_i)</code> is correlated with the demeaned lag <code>(invest_{i,t-1} - invest\u0304_i)</code> because <code>invest\u0304_i</code> includes all periods including period t.</p> <p>Magnitude: Bias is O(1/T), so severe for short panels (T &lt; 10).</p>"},{"location":"tutorials/03_gmm_intro/#when-do-you-need-gmm","title":"When Do You Need GMM?","text":"<p>\u2705 Use GMM when: - Your model includes lagged dependent variable (y_{t-1}) - You have short panels (small T, large N) - Strict exogeneity fails (E[\u03b5_it | X_i] \u2260 0) - You suspect endogenous regressors</p> <p>\u274c Don't use GMM when: - No dynamics (use FE or RE instead) - Long panels (T &gt; 20) where FE bias is negligible - You have weak instruments (persistent series with small T)</p>"},{"location":"tutorials/03_gmm_intro/#difference-gmm-arellano-bond-1991","title":"Difference GMM (Arellano-Bond 1991)","text":""},{"location":"tutorials/03_gmm_intro/#the-idea","title":"The Idea","text":"<p>Step 1: First-difference to eliminate fixed effects \u03b1_i:</p> <pre><code>\u0394invest_it = \u03b3\u00b7\u0394invest_{i,t-1} + \u03b2\u2081\u00b7\u0394value_it + \u03b2\u2082\u00b7\u0394capital_it + \u0394\u03b5_it\n</code></pre> <p>Problem: \u0394invest_{i,t-1} is still correlated with \u0394\u03b5_it</p> <p>Step 2: Use lagged levels as instruments:</p> <p>Valid instruments: <code>invest_{i,t-2}, invest_{i,t-3}, ...</code> (if E[invest_{i,t-s}\u00b7\u0394\u03b5_it] = 0)</p>"},{"location":"tutorials/03_gmm_intro/#your-first-gmm-model","title":"Your First GMM Model","text":"<p>Let's estimate a dynamic investment model:</p> <pre><code>import panelbox as pb\n\n# Load data\ndata = pb.load_grunfeld()\n\n# Create lagged investment (GMM does this automatically, but let's see it)\ndata = data.sort_values(['firm', 'year'])\ndata['invest_lag'] = data.groupby('firm')['invest'].shift(1)\n\n# Difference GMM\ngmm_diff = pb.DifferenceGMM(\n    data=data,\n    dep_var='invest',           # Dependent variable\n    lags=1,                     # Include invest_{t-1}\n    exog_vars=['value', 'capital'],  # Exogenous regressors\n    id_var='firm',              # Entity identifier\n    time_var='year',            # Time identifier\n    collapse=True,              # CRITICAL: avoid instrument proliferation\n    robust=True                 # Windmeijer-corrected SEs\n)\n\n# Fit the model\ngmm_results = gmm_diff.fit()\nprint(gmm_results.summary())\n</code></pre> <p>Output (typical): <pre><code>================================================================================\n                     Difference GMM Estimation Results\n================================================================================\nDependent Variable:              invest        No. Observations:             170\nModel:                    Difference GMM        No. Entities:                  10\nMethod:                Two-step efficient        No. Instruments:               18\nDate:                       2026-02-05          Hansen J statistic:         14.23\nTime:                         16:00:00          Hansen J p-value:           0.290\n                                                AR(1) p-value:              0.012\n                                                AR(2) p-value:              0.356\n================================================================================\n                    coef    std err          z      P&gt;|z|      [0.025      0.975]\n--------------------------------------------------------------------------------\ninvest_L1         0.485      0.145      3.345      0.001       0.201       0.769\nvalue             0.092      0.038      2.421      0.015       0.017       0.167\ncapital           0.198      0.091      2.176      0.030       0.020       0.376\n================================================================================\nInstruments for level equation: None (differenced model only)\nInstruments for diff equation: L2.invest, L3.invest, ..., L2.value, L2.capital\nNumber of instruments: 18\nInstrument ratio (instruments/entities): 1.8\n================================================================================\nDiagnostic Tests:\n  Hansen J test (p=0.290): Overidentifying restrictions valid\n  AR(1) test (p=0.012): Expected first-order autocorrelation\n  AR(2) test (p=0.356): No second-order autocorrelation \u2713\n================================================================================\n</code></pre></p>"},{"location":"tutorials/03_gmm_intro/#understanding-gmm-output","title":"Understanding GMM Output","text":"<p>Coefficients: - <code>invest_L1 = 0.485</code>: Strong persistence (past investment predicts current) - <code>value = 0.092</code>: Smaller than FE (0.110) after controlling for dynamics - <code>capital = 0.198</code>: Also smaller than FE (0.310)</p> <p>Why coefficients differ from FE: - FE was biased upward on the lag coefficient - GMM properly accounts for endogeneity</p> <p>Diagnostic Tests (CRITICAL!):</p> <ol> <li>Hansen J-test (p=0.290)</li> <li>Tests if instruments are valid (overidentification test)</li> <li>p &gt; 0.10: Good (instruments appear valid)</li> <li>p &lt; 0.10: Bad (instruments may be invalid)</li> <li> <p>Interpretation: p=0.290 \u2192 instruments pass validity test \u2713</p> </li> <li> <p>AR(1) test (p=0.012)</p> </li> <li>Tests for first-order autocorrelation in differenced errors</li> <li>p &lt; 0.05: Expected and OK (mechanical due to differencing)</li> <li> <p>Interpretation: p=0.012 is fine \u2713</p> </li> <li> <p>AR(2) test (p=0.356)</p> </li> <li>Tests for second-order autocorrelation in differenced errors</li> <li>p &gt; 0.10: Good (moment conditions are valid)</li> <li>p &lt; 0.10: Bad (model is misspecified)</li> <li>Interpretation: p=0.356 \u2192 no problematic autocorrelation \u2713</li> </ol> <p>Instrument count: - 18 instruments for 10 entities - Instrument ratio = 1.8 (&lt; 1.0 is ideal, &lt; 2.0 is acceptable) - Always use <code>collapse=True</code> to keep this low!</p>"},{"location":"tutorials/03_gmm_intro/#interpreting-results","title":"Interpreting Results","text":"<p>Model validity: \u2705 - Hansen J p-value &gt; 0.10 \u2713 - AR(2) p-value &gt; 0.10 \u2713 - Instrument ratio reasonable (1.8)</p> <p>Economic interpretation: - Strong persistence: 48.5% of last year's investment carries over - Value matters: $1M increase in firm value \u2192 $0.092M more investment - Capital stock matters: $1M increase in capital \u2192 $0.198M more investment - Dynamics are important: Static FE would have overestimated these effects</p>"},{"location":"tutorials/03_gmm_intro/#system-gmm-blundell-bond-1998","title":"System GMM (Blundell-Bond 1998)","text":""},{"location":"tutorials/03_gmm_intro/#why-system-gmm","title":"Why System GMM?","text":"<p>Problem with Difference GMM: When series are persistent (invest_it highly correlated with invest_{i,t-1}), lagged levels are weak instruments for first-differences.</p> <p>Solution: Add level equations with lagged differences as instruments.</p>"},{"location":"tutorials/03_gmm_intro/#the-system","title":"The System","text":"<p>System GMM combines:</p> <ol> <li>Difference equations (like Difference GMM):</li> <li>\u0394invest_it = \u03b3\u00b7\u0394invest_{i,t-1} + ...</li> <li> <p>Instruments: Lagged levels</p> </li> <li> <p>Level equations (additional):</p> </li> <li>invest_it = \u03b3\u00b7invest_{i,t-1} + ...</li> <li>Instruments: Lagged differences</li> </ol> <p>Extra assumption: E[\u0394invest_{i,1}\u00b7\u03b7_i] = 0 (stationarity of initial conditions)</p> <p>Benefit: More efficient (smaller standard errors), especially for persistent series.</p>"},{"location":"tutorials/03_gmm_intro/#estimation","title":"Estimation","text":"<pre><code># System GMM\ngmm_sys = pb.SystemGMM(\n    data=data,\n    dep_var='invest',\n    lags=1,\n    exog_vars=['value', 'capital'],\n    id_var='firm',\n    time_var='year',\n    collapse=True,\n    robust=True\n)\n\ngmm_sys_results = gmm_sys.fit()\nprint(gmm_sys_results.summary())\n</code></pre> <p>Output (typical): <pre><code>================================================================================\n                       System GMM Estimation Results\n================================================================================\nDependent Variable:              invest        No. Observations:             180\nModel:                       System GMM        No. Entities:                  10\nMethod:                Two-step efficient        No. Instruments:               25\nDate:                       2026-02-05          Hansen J statistic:         18.45\nTime:                         16:05:00          Hansen J p-value:           0.185\n                                                AR(1) p-value:              0.009\n                                                AR(2) p-value:              0.412\n                                                Difference-in-Hansen p:     0.523\n================================================================================\n                    coef    std err          z      P&gt;|z|      [0.025      0.975]\n--------------------------------------------------------------------------------\ninvest_L1         0.512      0.098      5.224      0.000       0.320       0.704\nvalue             0.088      0.029      3.034      0.002       0.031       0.145\ncapital           0.185      0.067      2.761      0.006       0.054       0.316\n================================================================================\nInstruments for level equation: L1.\u0394invest, L1.\u0394value, L1.\u0394capital\nInstruments for diff equation: L2.invest, L3.invest, ..., L2.value, L2.capital\nNumber of instruments: 25\nInstrument ratio (instruments/entities): 2.5\n================================================================================\nDiagnostic Tests:\n  Hansen J test (p=0.185): Overidentifying restrictions valid\n  Difference-in-Hansen (p=0.523): Level instruments valid\n  AR(1) test (p=0.009): Expected first-order autocorrelation\n  AR(2) test (p=0.412): No second-order autocorrelation \u2713\n================================================================================\n</code></pre></p>"},{"location":"tutorials/03_gmm_intro/#system-vs-difference-gmm","title":"System vs Difference GMM","text":"<p>Comparison:</p> Aspect Difference GMM System GMM invest_L1 0.485 (SE=0.145) 0.512 (SE=0.098) Standard errors Larger Smaller (32% reduction!) Instruments 18 25 Observations 170 (loses first period) 180 (keeps more data) Hansen J p-value 0.290 0.185 AR(2) p-value 0.356 0.412 <p>Key insight: System GMM is more efficient (smaller SEs) because it uses more moment conditions.</p> <p>When to use System GMM: - Series are persistent (\u03c1 &gt; 0.8) - You want more efficient estimates - Panel doesn't start at \"event time\" (e.g., firm entry) - Stationarity assumption is plausible</p> <p>When to use Difference GMM: - Series not highly persistent - Panel starts at event time (initial conditions assumption fails) - More conservative (fewer assumptions)</p>"},{"location":"tutorials/03_gmm_intro/#the-critical-importance-of-collapse","title":"The Critical Importance of Collapse","text":""},{"location":"tutorials/03_gmm_intro/#the-instrument-proliferation-problem","title":"The Instrument Proliferation Problem","text":"<p>Without collapse:</p> <pre><code># BAD: Don't do this!\ngmm_bad = pb.DifferenceGMM(\n    data=data,\n    dep_var='invest',\n    lags=1,\n    exog_vars=['value', 'capital'],\n    id_var='firm',\n    time_var='year',\n    collapse=False,  # \u274c Danger!\n    robust=True\n)\n\nbad_results = gmm_bad.fit()\nprint(f\"Number of instruments: {bad_results.n_instruments}\")  # 87!\nprint(f\"Instrument ratio: {bad_results.instrument_ratio:.1f}\")  # 8.7!\n</code></pre> <p>Problems with 87 instruments: - Overfitting: Model fits sample perfectly but doesn't generalize - Hansen J test loses power: Always p \u2248 1.0 (can't detect invalid instruments) - Downward bias in SEs: Confidence intervals too narrow - Computational issues: Matrix inversion unstable</p>"},{"location":"tutorials/03_gmm_intro/#always-use-collapse","title":"Always Use Collapse","text":"<p>Rule of thumb (Roodman 2009): - Instrument count should be &lt; number of entities - Instrument ratio &lt; 1.0 is ideal - Always set collapse=True unless you have a specific reason</p> <pre><code># GOOD: Always do this\ngmm_good = pb.DifferenceGMM(\n    data=data,\n    dep_var='invest',\n    lags=1,\n    exog_vars=['value', 'capital'],\n    id_var='firm',\n    time_var='year',\n    collapse=True,  # \u2705 Essential\n    robust=True\n)\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#complete-gmm-workflow","title":"Complete GMM Workflow","text":""},{"location":"tutorials/03_gmm_intro/#step-1-verify-dynamics-are-needed","title":"Step 1: Verify dynamics are needed","text":"<pre><code># Compare static FE with GMM\nfe = pb.FixedEffects(\"invest ~ value + capital\", data, \"firm\", \"year\")\nfe_results = fe.fit()\n\n# If value/capital coefficients differ much between FE and GMM \u2192 dynamics matter\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#step-2-start-with-difference-gmm","title":"Step 2: Start with Difference GMM","text":"<pre><code>gmm_diff = pb.DifferenceGMM(\n    data=data,\n    dep_var='invest',\n    lags=1,\n    exog_vars=['value', 'capital'],\n    id_var='firm',\n    time_var='year',\n    collapse=True,\n    robust=True\n)\n\ngmm_diff_results = gmm_diff.fit()\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#step-3-check-diagnostics","title":"Step 3: Check diagnostics","text":"<pre><code># Print results\nprint(gmm_diff_results.summary())\n\n# Check critical tests\nprint(f\"\\nHansen J p-value: {gmm_diff_results.hansen_j.pvalue:.3f}\")\nprint(f\"AR(2) p-value: {gmm_diff_results.ar2_test.pvalue:.3f}\")\nprint(f\"Instrument ratio: {gmm_diff_results.instrument_ratio:.2f}\")\n\n# Decision criteria\nhansen_ok = gmm_diff_results.hansen_j.pvalue &gt; 0.10\nar2_ok = gmm_diff_results.ar2_test.pvalue &gt; 0.10\ninstruments_ok = gmm_diff_results.instrument_ratio &lt; 2.0\n\nif hansen_ok and ar2_ok and instruments_ok:\n    print(\"\u2713 Model passes all diagnostic tests\")\nelse:\n    print(\"\u2717 Model fails diagnostics - reconsider specification\")\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#step-4-try-system-gmm-if-appropriate","title":"Step 4: Try System GMM (if appropriate)","text":"<pre><code># Estimate System GMM\ngmm_sys = pb.SystemGMM(\n    data=data,\n    dep_var='invest',\n    lags=1,\n    exog_vars=['value', 'capital'],\n    id_var='firm',\n    time_var='year',\n    collapse=True,\n    robust=True\n)\n\ngmm_sys_results = gmm_sys.fit()\n\n# Compare standard errors\nprint(\"\\nStandard Error Comparison:\")\nprint(f\"Difference GMM - invest_L1 SE: {gmm_diff_results.std_errors['invest_L1']:.3f}\")\nprint(f\"System GMM - invest_L1 SE: {gmm_sys_results.std_errors['invest_L1']:.3f}\")\nprint(f\"Efficiency gain: {(1 - gmm_sys_results.std_errors['invest_L1']/gmm_diff_results.std_errors['invest_L1'])*100:.1f}%\")\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#step-5-report-final-model","title":"Step 5: Report final model","text":"<pre><code># Choose model (System GMM if diagnostics pass and more efficient)\nfinal_results = gmm_sys_results\n\n# Export to LaTeX\nfinal_results.to_latex(\"investment_gmm.tex\")\n\n# Create summary table\nsummary = {\n    'Coefficient': final_results.params,\n    'Std Error': final_results.std_errors,\n    'z-stat': final_results.tstats,\n    'p-value': final_results.pvalues\n}\n\nimport pandas as pd\nsummary_df = pd.DataFrame(summary)\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL GMM RESULTS\")\nprint(\"=\"*60)\nprint(summary_df)\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#common-pitfalls-and-solutions","title":"Common Pitfalls and Solutions","text":""},{"location":"tutorials/03_gmm_intro/#pitfall-1-forgetting-collapsetrue","title":"\u274c Pitfall 1: Forgetting collapse=True","text":"<p>Problem: 87 instruments, Hansen J always passes (p \u2248 1.0)</p> <p>Solution: Always use collapse=True</p> <pre><code># GOOD\ngmm = pb.DifferenceGMM(..., collapse=True)\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#pitfall-2-ignoring-diagnostic-tests","title":"\u274c Pitfall 2: Ignoring diagnostic tests","text":"<p>Problem: Reporting results even when Hansen J or AR(2) fail</p> <p>Solution: Check tests BEFORE interpreting coefficients</p> <pre><code># Check tests first\nif results.hansen_j.pvalue &lt; 0.10:\n    print(\"\u26a0 Warning: Instruments may be invalid\")\nif results.ar2_test.pvalue &lt; 0.10:\n    print(\"\u26a0 Warning: Moment conditions violated\")\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#pitfall-3-using-system-gmm-inappropriately","title":"\u274c Pitfall 3: Using System GMM inappropriately","text":"<p>Problem: Using System GMM when panel starts at \"event time\" (e.g., firm entry)</p> <p>Solution: Use Difference GMM if initial conditions assumption fails</p>"},{"location":"tutorials/03_gmm_intro/#pitfall-4-too-few-time-periods","title":"\u274c Pitfall 4: Too few time periods","text":"<p>Problem: T &lt; 5 gives very weak instruments</p> <p>Solution: - Need at least T \u2265 5 for Difference GMM - Consider static FE if T &lt; 5</p>"},{"location":"tutorials/03_gmm_intro/#pitfall-5-highly-persistent-series-with-small-t","title":"\u274c Pitfall 5: Highly persistent series with small T","text":"<p>Problem: When \u03c1 &gt; 0.9 and T &lt; 8, lagged levels are weak instruments</p> <p>Solution: - Use System GMM (more efficient with weak instruments) - Or consider long-difference IV (not in PanelBox yet)</p>"},{"location":"tutorials/03_gmm_intro/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 You've learned to: - Recognize when GMM is needed (dynamics, endogeneity) - Estimate Difference GMM and System GMM - Interpret Hansen J and AR(2) diagnostic tests - Understand the critical importance of collapse=True - Follow a complete GMM workflow - Avoid common pitfalls</p> <p>\ud83d\udd11 Critical concepts: - Dynamics cause bias in FE (Nickell bias) - Difference GMM: First-difference + lagged levels as instruments - System GMM: Add level equations for efficiency - Always collapse: Avoid instrument proliferation - Diagnostic tests: Hansen J &gt; 0.10, AR(2) &gt; 0.10</p> <p>\u26a0\ufe0f Remember: - GMM is powerful but requires careful diagnostic checking - Don't report results if tests fail - Instrument count should be &lt; number of entities</p>"},{"location":"tutorials/03_gmm_intro/#next-steps","title":"Next Steps","text":"<p>Deepen your understanding:</p> <ol> <li> <p>How-To: Interpret Tests: Deep dive into Hansen J, AR tests, Sargan</p> </li> <li> <p>Guide: GMM Explained: Mathematical details of GMM estimation</p> </li> <li> <p>API Reference: GMM: Complete documentation of DifferenceGMM and SystemGMM</p> </li> </ol> <p>Advanced topics: - Including predetermined variables (not strictly exogenous) - Testing for weak instruments - Difference-in-Hansen test for subset validity - Bootstrap standard errors</p> <p>Practice yourself:</p> <pre><code># Try GMM with your data\ndata = pd.read_csv('my_dynamic_panel.csv')\n\n# Difference GMM\ngmm = pb.DifferenceGMM(\n    data=data,\n    dep_var='y',\n    lags=1,  # or 2 for y_{t-2}\n    exog_vars=['x1', 'x2'],\n    id_var='entity_id',\n    time_var='time',\n    collapse=True,  # Always!\n    robust=True\n)\n\nresults = gmm.fit()\n\n# Check diagnostics FIRST\nprint(f\"Hansen J p-value: {results.hansen_j.pvalue:.3f}\")\nprint(f\"AR(2) p-value: {results.ar2_test.pvalue:.3f}\")\n\n# Then interpret if tests pass\nif results.hansen_j.pvalue &gt; 0.10 and results.ar2_test.pvalue &gt; 0.10:\n    print(results.summary())\n</code></pre>"},{"location":"tutorials/03_gmm_intro/#further-reading","title":"Further Reading","text":"<p>Seminal Papers: - Arellano &amp; Bond (1991): \"Some Tests of Specification for Panel Data\", Review of Economic Studies, 58(2), 277-297   - Original Difference GMM paper - Blundell &amp; Bond (1998): \"Initial Conditions and Moment Restrictions\", Journal of Econometrics, 87(1), 115-143   - Introduces System GMM - Windmeijer (2005): \"A Finite Sample Correction for GMM\", Journal of Econometrics, 126(1), 25-51   - Two-step standard error correction</p> <p>Practical Guides: - Roodman (2009): \"How to do xtabond2\", The Stata Journal, 9(1), 86-136   - Best practical guide to GMM (Stata, but concepts apply) - Bond (2002): \"Dynamic Panel Data Models: A Guide to Micro Data Methods\", Portuguese Economic Journal, 1(2), 141-162   - Accessible introduction</p> <p>Textbooks: - Baltagi (2021): Econometric Analysis of Panel Data, Chapter 8 - Wooldridge (2010): Econometric Analysis of Cross Section and Panel Data, Chapter 11</p> <p>Congratulations! You can now estimate and validate dynamic panel models using GMM. \ud83c\udf89</p> <p>You've completed all three core PanelBox tutorials! Explore the how-to guides and API reference for more advanced features.</p>"},{"location":"tutorials/04_html_reports/","title":"HTML Report System Tutorial","text":"<p>Learn how to generate professional HTML reports for your panel data analysis.</p> <p>NEW in v0.8.0</p>"},{"location":"tutorials/04_html_reports/#what-youll-learn","title":"What You'll Learn","text":"<p>In this tutorial, you will:</p> <ul> <li>Create a PanelExperiment for analysis</li> <li>Generate validation reports with diagnostic tests</li> <li>Compare multiple models side-by-side</li> <li>Analyze residuals with interactive plots</li> <li>Generate a master report with navigation</li> <li>Customize reports with different themes</li> </ul>"},{"location":"tutorials/04_html_reports/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Getting Started</li> <li>Completed Static Panel Models</li> <li>PanelBox \u2265 0.8.0</li> </ul>"},{"location":"tutorials/04_html_reports/#what-is-the-report-system","title":"What is the Report System?","text":"<p>PanelBox v0.8.0 introduces a comprehensive HTML report system that generates:</p> <ul> <li>Validation Reports: Diagnostic tests with pass/fail indicators</li> <li>Comparison Reports: Side-by-side model comparison</li> <li>Residual Reports: Interactive diagnostic plots</li> <li>Master Reports: Overview dashboard with navigation</li> </ul> <p>All reports are: - Self-contained (work offline) - Interactive (Plotly charts, sortable tables) - Professional (three themes available) - Exportable (JSON format for programmatic analysis)</p>"},{"location":"tutorials/04_html_reports/#step-1-create-panelexperiment","title":"Step 1: Create PanelExperiment","text":"<p>The <code>PanelExperiment</code> class is the high-level interface for analysis:</p> <pre><code>import panelbox as pb\n\n# Load data\ndata = pb.load_grunfeld()\n\n# Create experiment\nexperiment = pb.PanelExperiment(\n    data=data,\n    formula=\"invest ~ value + capital\",\n    entity_col=\"firm\",\n    time_col=\"year\"\n)\n\nprint(experiment)\n</code></pre> <p>Output: <pre><code>PanelExperiment(\n  formula='invest ~ value + capital',\n  n_obs=200,\n  n_models=0,\n  models=[none]\n)\n</code></pre></p>"},{"location":"tutorials/04_html_reports/#step-2-fit-multiple-models","title":"Step 2: Fit Multiple Models","text":"<p>Fit different panel models to compare:</p> <pre><code># Fit three models\nexperiment.fit_model('pooled_ols', name='ols')\nexperiment.fit_model('fixed_effects', name='fe')\nexperiment.fit_model('random_effects', name='re')\n\n# List fitted models\nprint(f\"Fitted models: {experiment.list_models()}\")\n</code></pre> <p>Output: <pre><code>Fitting pooled_ols model 'ols'...\n\u2705 Model 'ols' fitted successfully\n\nFitting fixed_effects model 'fe'...\n\u2705 Model 'fe' fitted successfully\n\nFitting random_effects model 're'...\n\u2705 Model 're' fitted successfully\n\nFitted models: ['ols', 'fe', 're']\n</code></pre></p>"},{"location":"tutorials/04_html_reports/#step-3-generate-validation-report","title":"Step 3: Generate Validation Report","text":"<p>Run diagnostic tests and generate an interactive HTML report:</p> <pre><code># Validate Fixed Effects model\nvalidation = experiment.validate_model('fe', config='full')\n\n# Generate HTML report\nvalidation.save_html(\n    'validation_report.html',\n    test_type='validation',\n    theme='professional'\n)\n\nprint(validation.summary())\n</code></pre> <p>What's in the validation report: - Heteroskedasticity test (Breusch-Pagan) - Autocorrelation test (Wooldridge) - Normality test (Jarque-Bera) - Hausman test (FE vs RE) - Pass/fail indicators with color coding - Test statistics and p-values - Recommendations</p>"},{"location":"tutorials/04_html_reports/#validation-configs","title":"Validation Configs","text":"<p>Three preset configurations are available:</p> <pre><code># Quick: 2 tests (heteroskedasticity, autocorrelation)\nval_quick = experiment.validate_model('fe', config='quick')\n\n# Basic: 3 tests (adds normality)\nval_basic = experiment.validate_model('fe', config='basic')\n\n# Full: 4+ tests (adds Hausman)\nval_full = experiment.validate_model('fe', config='full')\n</code></pre>"},{"location":"tutorials/04_html_reports/#step-4-generate-comparison-report","title":"Step 4: Generate Comparison Report","text":"<p>Compare multiple models side-by-side:</p> <pre><code># Compare all three models\ncomparison = experiment.compare_models(['ols', 'fe', 're'])\n\n# Generate HTML report\ncomparison.save_html(\n    'comparison_report.html',\n    test_type='comparison',\n    theme='professional'\n)\n\n# Identify best model\nbest_aic = comparison.best_model('aic', prefer_lower=True)\nbest_r2 = comparison.best_model('rsquared_adj', prefer_lower=False)\n\nprint(f\"Best by AIC: {best_aic}\")\nprint(f\"Best by R\u00b2: {best_r2}\")\n\nprint(comparison.summary())\n</code></pre> <p>What's in the comparison report: - Side-by-side coefficient comparison - Standard errors and significance stars - Fit statistics (R\u00b2, AIC, BIC, F-statistic) - Interactive table (sortable, searchable) - Best model highlighted</p>"},{"location":"tutorials/04_html_reports/#step-5-generate-residual-diagnostics","title":"Step 5: Generate Residual Diagnostics","text":"<p>Analyze residuals with interactive plots:</p> <pre><code># Analyze residuals from Fixed Effects model\nresiduals = experiment.analyze_residuals('fe')\n\n# Generate HTML report\nresiduals.save_html(\n    'residuals_report.html',\n    test_type='residuals',\n    theme='professional'\n)\n\nprint(residuals.summary())\n</code></pre> <p>What's in the residuals report: - Residuals vs Fitted plot - QQ plot (normality check) - Scale-Location plot (homoskedasticity) - Residuals vs Leverage - ACF/PACF plots (autocorrelation) - Diagnostic test statistics:   - Shapiro-Wilk test (normality)   - Durbin-Watson test (autocorrelation)   - Jarque-Bera test (normality)   - Ljung-Box test (serial correlation)</p>"},{"location":"tutorials/04_html_reports/#step-6-generate-master-report","title":"Step 6: Generate Master Report","text":"<p>Create a master report with navigation to all sub-reports:</p> <pre><code># Generate master report\nexperiment.save_master_report(\n    'master_report.html',\n    theme='professional',\n    title='Panel Data Analysis - Complete Report',\n    reports=[\n        {\n            'type': 'validation',\n            'title': 'Model Validation',\n            'description': 'Specification tests for Fixed Effects model',\n            'file_path': 'validation_report.html'\n        },\n        {\n            'type': 'comparison',\n            'title': 'Model Comparison',\n            'description': 'Compare Pooled OLS, FE, and RE models',\n            'file_path': 'comparison_report.html'\n        },\n        {\n            'type': 'residuals',\n            'title': 'Residual Diagnostics',\n            'description': 'Diagnostic plots and tests',\n            'file_path': 'residuals_report.html'\n        }\n    ]\n)\n\nprint(\"\u2705 Master report generated: master_report.html\")\n</code></pre> <p>What's in the master report: - Experiment overview (formula, observations, entities) - Summary of all fitted models - Quick start guide - Navigation cards to all sub-reports - Responsive design (works on mobile)</p> <p>Open <code>master_report.html</code> in your browser to explore!</p>"},{"location":"tutorials/04_html_reports/#step-7-try-different-themes","title":"Step 7: Try Different Themes","text":"<p>PanelBox provides three professional themes:</p>"},{"location":"tutorials/04_html_reports/#professional-theme-default","title":"Professional Theme (Default)","text":"<p><pre><code>validation.save_html('val_professional.html', theme='professional')\n</code></pre> - Color: Blue (#2563eb) - Use Case: Corporate reports, general analysis - Style: Clean, modern, professional</p>"},{"location":"tutorials/04_html_reports/#academic-theme","title":"Academic Theme","text":"<p><pre><code>validation.save_html('val_academic.html', theme='academic')\n</code></pre> - Color: Gray (#4b5563) - Use Case: Research papers, publications - Style: Conservative, publication-ready</p>"},{"location":"tutorials/04_html_reports/#presentation-theme","title":"Presentation Theme","text":"<p><pre><code>validation.save_html('val_presentation.html', theme='presentation')\n</code></pre> - Color: Purple (#7c3aed) - Use Case: Presentations, slides, demos - Style: Bold, eye-catching</p>"},{"location":"tutorials/04_html_reports/#step-8-export-to-json","title":"Step 8: Export to JSON","text":"<p>All results can be exported to JSON for programmatic analysis:</p> <pre><code># Export to JSON\nvalidation.save_json('validation_results.json')\ncomparison.save_json('comparison_results.json')\nresiduals.save_json('residuals_results.json')\n\nprint(\"\u2705 All results exported to JSON\")\n</code></pre> <p>JSON files contain: - All test results and statistics - Model metadata - Timestamps - Configuration settings</p> <p>Use JSON export for: - Custom analysis pipelines - Integration with other tools - Archiving results - Reproducibility</p>"},{"location":"tutorials/04_html_reports/#complete-workflow","title":"Complete Workflow","text":"<p>Here's the complete workflow in one script:</p> <pre><code>import panelbox as pb\n\n# 1. Load data and create experiment\ndata = pb.load_grunfeld()\nexperiment = pb.PanelExperiment(\n    data=data,\n    formula=\"invest ~ value + capital\",\n    entity_col=\"firm\",\n    time_col=\"year\"\n)\n\n# 2. Fit multiple models\nexperiment.fit_model('pooled_ols', name='ols')\nexperiment.fit_model('fixed_effects', name='fe')\nexperiment.fit_model('random_effects', name='re')\n\n# 3. Generate all reports\nvalidation = experiment.validate_model('fe', config='full')\nvalidation.save_html('validation.html', test_type='validation')\n\ncomparison = experiment.compare_models(['ols', 'fe', 're'])\ncomparison.save_html('comparison.html', test_type='comparison')\n\nresiduals = experiment.analyze_residuals('fe')\nresiduals.save_html('residuals.html', test_type='residuals')\n\n# 4. Generate master report\nexperiment.save_master_report('master.html', reports=[\n    {'type': 'validation', 'title': 'Validation',\n     'description': 'Specification tests', 'file_path': 'validation.html'},\n    {'type': 'comparison', 'title': 'Comparison',\n     'description': 'Model comparison', 'file_path': 'comparison.html'},\n    {'type': 'residuals', 'title': 'Residuals',\n     'description': 'Diagnostic plots', 'file_path': 'residuals.html'}\n])\n\nprint(\"\u2705 Complete analysis finished! Open master.html\")\n</code></pre>"},{"location":"tutorials/04_html_reports/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/04_html_reports/#1-always-validate-models","title":"1. Always Validate Models","text":"<p>Before interpreting results, run validation tests:</p> <pre><code>validation = experiment.validate_model('fe', config='full')\nif validation.all_passed:\n    print(\"\u2705 Model passes all tests\")\nelse:\n    print(\"\u26a0\ufe0f Some tests failed - review validation report\")\n</code></pre>"},{"location":"tutorials/04_html_reports/#2-compare-multiple-models","title":"2. Compare Multiple Models","text":"<p>Never rely on a single model:</p> <pre><code># Fit multiple specifications\nexperiment.fit_model('pooled_ols', name='ols')\nexperiment.fit_model('fixed_effects', name='fe')\nexperiment.fit_model('random_effects', name='re')\n\n# Compare and choose best\ncomparison = experiment.compare_models(['ols', 'fe', 're'])\nbest = comparison.best_model('rsquared_adj', prefer_lower=False)\n</code></pre>"},{"location":"tutorials/04_html_reports/#3-check-residuals","title":"3. Check Residuals","text":"<p>Always inspect residuals for violations:</p> <pre><code>residuals = experiment.analyze_residuals('fe')\n\n# Check diagnostic tests\nif residuals.shapiro_test[1] &lt; 0.05:\n    print(\"\u26a0\ufe0f Residuals not normal\")\n\nif residuals.durbin_watson &lt; 1.5 or residuals.durbin_watson &gt; 2.5:\n    print(\"\u26a0\ufe0f Autocorrelation detected\")\n</code></pre>"},{"location":"tutorials/04_html_reports/#4-use-master-reports","title":"4. Use Master Reports","text":"<p>Generate master reports for comprehensive documentation:</p> <pre><code>experiment.save_master_report(\n    'analysis_complete.html',\n    title=f'{data_name} Panel Analysis',\n    reports=[...]  # Include all sub-reports\n)\n</code></pre>"},{"location":"tutorials/04_html_reports/#5-archive-results","title":"5. Archive Results","text":"<p>Export to JSON for reproducibility:</p> <pre><code>validation.save_json(f'validation_{timestamp}.json')\ncomparison.save_json(f'comparison_{timestamp}.json')\n</code></pre>"},{"location":"tutorials/04_html_reports/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"tutorials/04_html_reports/#custom-test-selection","title":"Custom Test Selection","text":"<p>Run specific tests only:</p> <pre><code>validation = experiment.validate_model('fe', tests=[\n    'heteroskedasticity',\n    'autocorrelation'\n])\n</code></pre>"},{"location":"tutorials/04_html_reports/#theme-customization","title":"Theme Customization","text":"<p>Try all themes and choose the best for your use case:</p> <pre><code>themes = ['professional', 'academic', 'presentation']\nfor theme in themes:\n    validation.save_html(f'report_{theme}.html', theme=theme)\n</code></pre>"},{"location":"tutorials/04_html_reports/#batch-processing","title":"Batch Processing","text":"<p>Analyze multiple datasets:</p> <pre><code>datasets = ['data1.csv', 'data2.csv', 'data3.csv']\n\nfor data_file in datasets:\n    data = pd.read_csv(data_file)\n    experiment = pb.PanelExperiment(data, formula, entity_col, time_col)\n    experiment.fit_model('fixed_effects', name='fe')\n    validation = experiment.validate_model('fe')\n    validation.save_html(f'validation_{data_file}.html')\n</code></pre>"},{"location":"tutorials/04_html_reports/#next-steps","title":"Next Steps","text":"<p>Now that you've mastered the HTML report system:</p> <ul> <li>Explore GMM models for dynamic panels</li> <li>Check API Reference for detailed documentation</li> <li>Review the examples directory for complete workflow examples</li> </ul>"},{"location":"tutorials/04_html_reports/#summary","title":"Summary","text":"<p>You learned how to:</p> <ul> <li>\u2705 Create PanelExperiment for analysis</li> <li>\u2705 Generate validation reports with diagnostic tests</li> <li>\u2705 Compare multiple models side-by-side</li> <li>\u2705 Analyze residuals with interactive plots</li> <li>\u2705 Generate master reports with navigation</li> <li>\u2705 Customize reports with themes</li> <li>\u2705 Export results to JSON</li> </ul> <p>The HTML report system makes panel data analysis professional, reproducible, and easy to share!</p> <p>Tutorial complete! \ud83c\udf89</p> <p>For more information: - API Reference - Check the <code>examples/</code> directory for complete workflow examples - View the project CHANGELOG for latest updates</p>"}]}